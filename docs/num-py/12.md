# 12.数据处理和分析

在前几章中，我们已经讨论了传统科学计算的主要课题。这些主题为大多数计算工作提供了基础。从这一章开始，我们继续探索数据处理和分析、统计学和统计建模。作为这个方向的第一步，我们看一下数据分析库`pandas`。这个库提供了方便的数据结构来表示数据的系列和表格，并使转换、拆分、合并和转换数据变得容易。这些是将原始数据整理成适合分析的整洁形式的过程中的重要步骤。Pandas 库建立在 NumPy 的基础上，并补充了一些在处理数据时特别有用的特性，例如标记索引、层次索引、用于比较和合并数据集的数据对齐、缺失数据的处理等等。因此，`pandas`库已经成为 Python 中高级数据处理的事实上的标准库，尤其是统计应用程序。`pandas`库本身只包含对统计建模(即线性回归)的有限支持。对于更复杂的统计分析和建模，还有其他可用的软件包，比如`statsmodels`、`patsy`和`scikit-learn`，我们将在后面的章节中介绍。然而，对于使用这些包的统计建模，`pandas`仍然可以用于数据表示和准备。因此,`pandas`库是使用 Python 进行数据分析的软件栈中的一个关键组件。

### 熊猫

`pandas`库是 Python 中数据处理和分析的框架。在撰写本文时，Pandas 的最新版本是 0.23.4。有关`pandas`库及其官方文档的更多信息，请访问该项目的网站 [`http://pandas.pydata.org`](http://pandas.pydata.org) 。

本章的重点是介绍`pandas`库的基本特性和用法。在本章的最后，我们还简要地探讨了统计可视化库 Seaborn，它是建立在 Matplotlib 之上的。这个库提供了表示为`pandas`数据结构(或 NumPy 数组)的数据的快速方便的图形化。可视化是探索性数据分析的一个非常重要的部分，Pandas 库本身也提供了基本数据可视化的功能(它也构建在 Matplotlib 之上)。Seaborn 库更进一步，提供了额外的统计图形功能和改进的样式:Seaborn 库以使用默认设置生成好看的图形而闻名。

### 希伯恩

**Seaborn 库* *是统计图形的可视化库。它建立在 Matplotlib 的基础上，为常见的统计图提供了易于使用的函数。在撰写本文时，Seaborn 的最新版本是 0.8.1。有关 Seaborn 及其官方文档的更多信息，请访问该项目的网站:* [`http://stanford.edu/~mwaskom/software/seaborn`](http://stanford.edu/%257Emwaskom/software/seaborn) 。*

 *## 导入模块

在本章中，我们主要使用的是`pandas`库，我们假设它是以名称`pd`导入的:

```
In [1]: import pandas as pd

```

我们还需要 NumPy 和 Matplotlib，我们通常以下列方式导入它们:

```
In [2]: import numpy as np
In [3]: import matplotlib.pyplot as plt

```

为了使由`pandas`库生成的 Matplotlib 图形外观更加美观，我们使用函数`mpl.style.use`选择了一种适合统计图形的样式:

```
In [4]: import matplotlib as mpl
   ...: mpl.style.use('ggplot')

```

在本章的后面，我们还需要导入`seaborn`模块，我们将以`sns`的名称导入它:

```
In [5]: import seaborn as sns

```

## 熊猫简介

本章的主要焦点是用于数据分析的`pandas`库，我们从这个库的介绍开始。`pandas`库主要提供用于表示和操作数据的数据结构和方法。Pandas 中的两个主要数据结构是`Series`和`DataFrame`对象，它们分别用于表示数据序列和表格数据。这两个对象都有一个索引，用于访问由对象表示的数据中的元素或行。默认情况下，索引是从零开始的整数，就像 NumPy 数组一样，但是也可以使用任何标识符序列作为索引。

### 系列

即使在最简单的例子中，能够用标签而不是整数来索引数据序列的优点也是显而易见的:考虑下面一个`Series`对象的构造。我们给构造函数一个整数列表，创建一个代表给定数据的`Series`对象。在 IPython 中显示对象会显示`Series`对象的数据以及相应的索引:

```
In [6]: s = pd.Series([909976, 8615246, 2872086, 2273305])
In [7]: s
Out[7]: 0     909976
        1     8615246
        2     2872086
        3     2273305
        dtype: int64

```

得到的对象是一个数据类型为(`dtype` ) `int64`的`Series`实例，元素由整数 0、1、2 和 3 索引。使用`index`和`values`属性，我们可以提取索引的底层数据和存储在序列中的值:

```
In [8]: list(s.index)
Out[8]: RangeIndex(start=0, stop=4, step=1)
In [9]: s.values
Out[9]: array([ 909976, 8615246, 2872086, 2273305], dtype=int64)

```

虽然使用整数索引数组或数据序列是数据的完整功能表示，但它不是描述性的。例如，如果数据代表四个欧洲国家首都的人口，那么使用城市名称作为索引而不是整数会更方便，也更具描述性。对于一个`Series`对象，这是可能的，我们可以将一个`Series`对象的`index`属性分配给一个带有新索引的列表来完成这个任务。我们还可以设置`Series`对象的`name`属性，给它一个描述性的名称:

```
In [10]: s.index = ["Stockholm", "London", "Rome", "Paris"]
In [11]: s.name = "Population"
In [12]: s
Out[12]: Stockholm     909976
         London       8615246
         Rome         2872086
         Paris        2273305
         Name: Population, dtype: int64

```

这些数据代表了什么，现在一目了然。或者，我们也可以在创建`Series`对象时通过关键字参数来设置`index`和`name`属性:

```
In [13]: s = pd.Series([909976, 8615246, 2872086, 2273305], name="Population",
    ...:               index=["Stockholm", "London", "Rome", "Paris"])

```

虽然完全可以将这些城市的人口数据直接存储在一个 NumPy 数组中，但即使在这个简单的示例中，当数据点用有意义的标签进行索引时，数据所代表的内容也更加清晰。当数据集的复杂性增加时，使数据描述更接近数据的好处甚至更大。

我们可以通过相应的索引(标签)或直接通过与索引同名的属性(如果索引标签是有效的 Python 符号名)来访问`Series`中的元素:

```
In [14]: s["London"]
Out[14]: 8615246
In [15]: s.Stockholm
Out[15]: 909976

```

用一个索引列表索引一个`Series`对象会产生一个新的`Series`对象，它带有原始数据的一个子集(对应于所提供的索引列表):

```
In [16]: s[["Paris", "Rome"]]
Out[16]: Paris    2273305
         Rome     2872086
         Name: Population, dtype: int64

```

将一个数据序列表示为一个`Series`对象，我们可以使用`Series`方法`count`(数据点数)、`median`(计算中值)、`mean`(计算平均值)、`std`(计算标准差)、`min`、`max`(最小和最大值)以及`quantile`(计算分位数)，轻松计算其描述性统计数据:

```
In [17]: s.median(), s.mean(), s.std()
Out[17]: (2572695.5, 3667653.25, 3399048.5005155364)
In [18]: s.min(), s.max()
Out[18]: (909976, 8615246)
In [19]: s.quantile(q=0.25), s.quantile(q=0.5), s.quantile(q=0.75)
Out[19]: (1932472.75, 2572695.5, 4307876.0)

```

所有前面的数据都组合在`describe`方法的输出中，它提供了一个由`Series`对象表示的数据的摘要:

```
In [20]: s.describe()
Out[20]: count          4.000000
         mean     3667653.250000
         std      3399048.500516
         min       909976.000000
         25%      1932472.750000
         50%      2572695.500000
         75%      4307876.000000
         max      8615246.000000
         Name: Population, dtype: float64

```

使用`plot`方法，我们可以快速、轻松地生成图形，将`Series`对象中的数据可视化。`pandas`库使用 Matplotlib 进行绘图，我们可以通过`ax`参数将 Matplotlib `Axes`实例传递给`plot`方法。使用`kind`参数指定图形的类型(有效选项为`line`、`hist`、`bar`、`barh`、`box`、`kde`、`density`、`area`和`pie`)。

![../images/332789_2_En_12_Chapter/332789_2_En_12_Fig1_HTML.png](../images/332789_2_En_12_Chapter/332789_2_En_12_Fig1_HTML.png)

图 12-1

使用`Series.plot`方法可以生成熊猫的绘图样式示例

```
In [21]: fig, axes = plt.subplots(1, 4, figsize=(12, 3))
    ...: s.plot(ax=axes[0], kind="line", title="line")
    ...: s.plot(ax=axes[1], kind="bar", title="bar")
    ...: s.plot(ax=axes[2], kind="box", title="box")
    ...: s.plot(ax=axes[3], kind="pie", title="pie")

```

### 数据帧

正如我们在前面的例子中看到的，`pandas Series`对象为一维数组提供了一个方便的容器，它可以为元素使用描述性标签，并提供对描述性统计和可视化的快速访问。对于更高维的数组(主要是二维数组，或者表格)，对应的数据结构是 Pandas `DataFrame`对象。它可以被看作是具有公共索引的`Series`对象的集合。

有许多方法可以初始化一个`DataFrame`。对于简单的例子，最简单的方法是将嵌套的 Python 列表或字典传递给`DataFrame`对象的构造函数。例如，考虑我们在上一节中使用的数据集的扩展，其中，除了每个城市的人口，我们还包括指定每个城市属于哪个州的列。我们可以用下面的方法创建相应的`DataFrame`对象:

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"></colgroup> 
|   | `0` | `1` |
| `0` | `909976` | `Sweden` |
| `1` | `8615246` | `United Kingdom` |
| `2` | `2872086` | `Italy` |
| `3` | `2273305` | `France` |

```
In [22]: df = pd.DataFrame([[909976, "Sweden"],
    ...:                    [8615246, "United Kingdom"],
    ...:                    [2872086, "Italy"],
    ...:                    [2273305, "France"]])
In [23]: df
Out[23]:

```

结果是具有行和列的表格数据结构。像使用`Series`对象一样，我们可以通过将一系列标签分配给`index`属性来对行使用标签索引，此外，我们可以将`columns`属性设置为一系列列标签:

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"></colgroup> 
|   | `Population` | `State` |
| `Stockholm` | `909976` | `Sweden` |
| `London` | `8615246` | `United Kingdom` |
| `Rome` | `2872086` | `Italy` |
| `Paris` | `2273305` | `France` |

```
In [24]: df.index = ["Stockholm", "London", "Rome", "Paris"]
In [25]: df.columns = ["Population", "State"]
In [26]: df
Out[26]:

```

在创建`DataFrame`对象时，也可以使用相应的关键字参数来设置`index`和`columns`属性:

```
In [27]: df = pd.DataFrame([[909976, "Sweden"],
    ...:                    [8615246, "United Kingdom"],
    ...:                    [2872086, "Italy"],
    ...:                    [2273305, "France"]],
    ...:                   index=["Stockholm", "London", "Rome", "Paris"],
    ...:                   columns=["Population", "State"])

```

创建相同数据框的另一种方法(有时可能更方便)是传递一个字典，其中列标题作为键，列数据作为值:

```
In [28]: df = pd.DataFrame({"Population": [909976, 8615246, 2872086, 2273305],
    ...:                    "State": ["Sweden", "United Kingdom", "Italy", "France"]},
    ...:                   index=["Stockholm", "London", "Rome", "Paris"])

```

和以前一样，`DataFrame`中的底层数据可以作为 NumPy 数组获得，分别使用`values`属性以及通过`index`和`columns`属性的索引和列数组。数据框中的每一列都可以使用列名作为属性进行访问(或者，通过使用列标签进行索引，例如`df["Population"]`):

```
In [29]: df.Population
Out[29]: Stockholm     909976
         London       8615246
         Rome         2872086
         Paris        2273305
         Name: Population, dtype: int64

```

从一个`DataFrame`中提取一列的结果是一个新的`Series`对象，我们可以用上一节讨论的方法处理和操作它。使用`loc`索引器属性可以访问`DataFrame`实例的行。索引该属性还会产生一个`Series`对象，它对应于原始数据框中的一行:

```
In [30]: df.loc["Stockholm"]
Out[30]: Population    909976
         State         Sweden
         Name: Stockholm, dtype: object

```

将一列行标签传递给`loc`索引器会产生一个新的`DataFrame`，它是原始`DataFrame`的子集，只包含选中的行:

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"></colgroup> 
|   | `Population` | `State` |
| `Paris` | `2273305` | `France` |
| `Rome` | `2872086` | `Italy` |

```
In [31]: df.loc[["Paris", "Rome"]]
Out[31]:

```

`loc`索引器也可用于同时选择行和列，首先传递一个行标签(或其列表)，然后传递一个列标签(或其列表)。结果是一个`DataFrame`、`Series`或一个元素值，这取决于所选的列和行的数量:

```
In [32]: df.loc[["Paris", "Rome"], "Population"]
Out[32]: Paris    2273305
         Rome     2872086
         Name: Population, dtype: int64

```

我们可以使用已经用于`Series`对象的相同方法来计算描述性统计。当调用这些方法时(`mean`、`std`、`median`、`min`、`max`等)。)对于`DataFrame`，计算是针对每一列的数字数据类型进行的:

```
In [33]: df.mean()
Out[33]: Population    3667653.25
         dtype: float64

```

在这种情况下，两列中只有一列具有数字数据类型(名为`Population`的那一列)。使用`DataFrame`方法`info`和属性`dtypes`，我们可以获得一个`DataFrame`中内容的汇总和每一列的数据类型:

```
In [34]: df.info()
<class 'pandas.core.frame.DataFrame'>
Index: 4 entries, Stockholm to Paris
Data columns (total 2 columns):
Population    4 non-null int64
State         4 non-null object
dtypes: int64(1), object(1)
memory usage: 96.0+ bytes
In [35]: df.dtypes
Out[35]: Population     int64
         State         object
         dtype: object

```

使用`pandas`的真正优势出现在处理比我们目前使用的例子更大更复杂的数据集时。这样的数据很少能被定义为显式列表或字典，它们可以被传递给`DataFrame`初始化器。更常见的情况是必须从文件或其他外部来源读取数据。`pandas`库支持从不同格式的文件中读取数据的多种方法。这里我们使用`read_csv`函数读入数据，并从 CSV 文件创建一个`DataFrame`对象。 <sup>[2](#Fn2)</sup> 该函数接受大量可选参数来调整其行为。详见文档字符串`help(pd.read_csv)`。一些最有用的参数是`header`(指定哪一行，如果有的话，包含带有列名的标题)；`skiprows`(在开始读取数据之前要跳过的行数，或者要跳过的行数的列表)；`delimiter`(用作列值之间的分隔符的字符)；`encoding`(文件中使用的编码的名称，例如`utf-8`；以及`nrows`(要读取的行数)。`pd.read_csv`函数的第一个也是唯一一个强制参数是文件名或数据源的 URL。例如，要读入存储在名为`european_cities.csv`、<sup>、 [3](#Fn3) 、</sup>的文件中的数据集，其中的前五行显示在下面的代码中，我们可以简单地调用`pd.read_csv("european_cities.csv")`，因为默认分隔符是`","`，并且默认情况下标题取自第一行。但是，我们也可以明确写出所有这些选项:

```
In [36]: !head –n 5 european_cities.csv
Rank,City,State,Population,Date of census
1,London, United Kingdom,"8,615,246",1 June 2014
2,Berlin, Germany,"3,437,916",31 May 2014
3,Madrid, Spain,"3,165,235",1 January 2014
4,Rome, Italy,"2,872,086",30 September 2014
In [37]: df_pop = pd.read_csv("european_cities.csv",
    ...:                      delimiter=",", encoding="utf-8", header=0)

```

该数据集类似于我们在本章前面使用的示例数据，但是这里有其他城市的附加列和更多行。一旦一个数据集被读入到一个`DataFrame`对象中，从检查由`info`方法给出的摘要开始，对数据集的属性形成一个概念是很有用的。

```
In [38]: df_pop.info()
<class 'pandas.core.frame.DataFrame'>
Int64Index: 105 entries, 0 to 104
Data columns (total 5 columns):
Rank              105 non-null int64
City              105 non-null object
State             105 non-null object
Population        105 non-null object
Date of census    105 non-null object
dtypes: int64(1), object(4) memory usage: 4.9+ KB

```

这里我们看到这个数据集中有 105 行，有 5 列。只有`Rank`列是数字数据类型。特别是，`Population`列还不是数字数据类型，因为它的值是`"8,615,246"`的格式，因此被`read_csv`函数解释为字符串值。显示数据的表格视图也很有用。然而，这个数据集太大，无法完整显示，在这种情况下，`head`和`tail`方法可以方便地创建一个截断的数据集，分别包含前几行和后几行。这两个函数都有一个可选参数，指定在截断的`DataFrame`中包含多少行。还要注意的是`df.head(n)`等同于`df[:n]`，其中`n`是一个整数。

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"> <col class="tcol4 align-left"> <col class="tcol5 align-left"> <col class="tcol6 align-left"></colgroup> 
|   | `Rank` | `City` | `State` | `Population` | `Date of census` |
| `0` | `1` | `London` | `United Kingdom` | `8,615,246` | `1 June 2014` |
| `1` | `2` | `Berlin` | `Germany` | `3,437,916` | `31 May 2014` |
| `2` | `3` | `Madrid` | `Spain` | `3,165,235` | `1 January 2014` |
| `3` | `4` | `Rome` | `Italy` | `2,872,086` | `30 September 2014` |
| `4` | `5` | `Paris` | `France` | `2,273,305` | `1 January 2013` |

```
In [39]: df_pop.head()
Out[39]:

```

显示截断的数据帧可以很好地了解数据的样子，以及在数据准备好进行分析之前还需要做些什么。通常必须以某种方式转换列，并通过按特定列排序或按索引排序来对表进行重新排序。下面我们探索一些修改`DataFrame`对象的方法。首先，我们可以简单地通过将一个`Series`对象分配给由列名索引的数据帧来创建新列和更新`DataFrame`中的列，并且我们可以使用 Python `del`关键字删除列。

`apply`方法是转换列中内容的强大工具。它创建并返回一个新的`Series`对象，传递给`apply`的函数已经应用于原始列中的每个元素。例如，我们可以使用`apply`方法将`Population`列中的元素从字符串转换为整数，方法是传递一个 lambda 函数，从字符串中删除`","`字符并将结果转换为整数。这里我们将转换后的列分配给一个名为`NumericPopulation`的新列。使用相同的方法，我们还通过使用 string 方法`strip`移除元素中多余的空格来整理`State`值。

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"> <col class="tcol4 align-left"> <col class="tcol5 align-left"> <col class="tcol6 align-left"> <col class="tcol7 align-left"></colgroup> 
|   | `Rank` | `City` | `State` | `Population` | `Date of census` | `NumericPopulation` |
| `0` | `1` | `London` | `United Kingdom` | `8,615,246` | `1 June 2014` | `8615246` |
| `1` | `2` | `Berlin` | `Germany` | `3,437,916` | `31 May 2014` | `3437916` |
| `2` | `3` | `Madrid` | `Spain` | `3,165,235` | `1 January 2014` | `3165235` |
| `3` | `4` | `Rome` | `Italy` | `2,872,086` | `30 September 2014` | `2872086` |
| `4` | `5` | `Paris` | `France` | `2,273,305` | `1 January 2013` | `2273305` |

```
In [40]: df_pop["NumericPopulation"] = df_pop.Population.apply(
    ...:     lambda x: int(x.replace(",", "")))
In [41]: df_pop["State"].values[:3]  # contains extra white spaces
Out[41]: array([' United Kingdom', ' Germany', ' Spain'], dtype=object)
In [42]: df_pop["State"] = df_pop["State"].apply(lambda x: x.strip())
In [43]: df_pop.head()
Out[43]:

```

检查更新后的`DataFrame`中列的数据类型，确认新列`NumericPopulation`确实是整数类型(而`Population`列没有变化):

```
In [44]: df_pop.dtypes
Out[44]: Rank                int64
         City               object
         State              object
         Population         object
         Date of census     object
         NumericPopulation   int64
         dtype: object

```

我们可能还需要将索引更改为`DataFrame`的一列。在当前示例中，我们可能希望使用`City`列作为索引。我们可以使用`set_index`方法来实现这一点，该方法将用作索引的列的名称作为参数。结果是一个新的`DataFrame`对象，而原来的`DataFrame`没有改变。此外，使用`sort_index`方法，我们可以根据索引对数据帧进行排序:

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"> <col class="tcol4 align-left"> <col class="tcol5 align-left"> <col class="tcol6 align-left"></colgroup> 
| `City` | `Rank` | `State` | `Population` | `Date of census` | `NumericPopulation` |
| `Aarhus` | `92` | `Denmark` | `326,676` | `1 October 2014` | `326676` |
| `Alicante` | `86` | `Spain` | `334,678` | `1 January 2012` | `334678` |
| `Amsterdam` | `23` | `Netherlands` | `813,562` | `31 May 2014` | `813562` |
| `Antwerp` | `59` | `Belgium` | `510,610` | `1 January 2014` | `510610` |
| `Athens` | `34` | `Greece` | `664,046` | `24 May 2011` | `664046` |

```
In [45]: df_pop2 = df_pop.set_index("City")
In [46]: df_pop2 = df_pop2.sort_index()
In [47]: df_pop2.head()
Out[47]:

```

`sort_index`方法也接受列名列表，在这种情况下，创建一个层次索引。分级索引使用索引标签元组来寻址数据框中的行。我们可以使用带有整数值参数`level`的`sort_index`方法，根据层次索引的第`n`级对`DataFrame`中的行进行排序，其中`level=n`。在下面的例子中，我们创建了一个层次索引，将`State`和`City`作为索引，并使用`sort_index`方法按照第一个索引(`State`)进行排序:

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"> <col class="tcol4 align-left"> <col class="tcol5 align-left"></colgroup> 
| `State` | `City` | `Rank` | `Population` | `Date of census` |
| `Austria` | `Vienna` | `7` | `1794770` | `1 January 2015` |
| `Belgium` | `Antwerp` | `59` | `510610` | `1 January 2014` |
| `Brussels` | `16` | `1175831` | `1 January 2014` |
| `Bulgaria` | `Plovdiv` | `84` | `341041` | `31 December 2013` |
| `Sofia` | `14` | `1291895` | `14 December 2014` |
| `Varna` | `85` | `335819` | `31 December 2013` |
| `Croatia` | `Zagreb` | `24` | `790017` | `31 March 2011` |

```
In [48]: df_pop3 = df_pop.set_index(["State", "City"]).sort_index(level=0)
In [49]: df_pop3.head(7)
Out[49]:

```

具有分层索引的数据帧可以仅使用其零级索引(`df3.loc["Sweden"]`)进行部分索引，或者使用所有分层索引的元组(`df3.loc[("Sweden", "Gothenburg")]`)进行完全索引:

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"> <col class="tcol4 align-left"> <col class="tcol5 align-left"></colgroup> 
| `City` | `Rank` | `Population` | `Date of census` | `NumericPopulation` |
| `Gothenburg` | `53` | `528,014` | `31 March 2013` | `528014` |
| `Malmö` | `102` | `309,105` | `31 March 2013` | `309105` |
| `Stockholm` | `20` | `909,976` | `31 January 2014` | `909976` |

```
In [50]: df_pop3.loc["Sweden"]
Out[50]:

```

```
In [51]: df_pop3.loc[("Sweden", "Gothenburg")]
Out[51]: Rank                            53
         Population                 528,014
         Date of census       31 March 2013
         NumericPopulation           528014
         Name: (Sweden, Gothenburg), dtype: object

```

如果我们想按列而不是索引排序，我们可以使用`sort_values`方法。它接受一个列名，或者一个列名列表，根据这个列表对`DataFrame`进行排序。它还接受关键字参数`ascending`，这是一个布尔值或布尔值列表，指定对应的列是按升序还是降序排序:

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"> <col class="tcol4 align-left"> <col class="tcol5 align-left"> <col class="tcol6 align-left"></colgroup> 
| `City` | `Rank` | `State` | `Population` | `Date of census` | `NumericPopulation` |
| `Nottingham` | `103` | `United Kingdom` | `308,735` | `30 June 2012` | `308735` |
| `Wirral` | `97` | `United Kingdom` | `320,229` | `30 June 2012` | `320229` |
| `Coventry` | `94` | `United Kingdom` | `323,132` | `30 June 2012` | `323132` |
| `Wakefield` | `91` | `United Kingdom` | `327,627` | `30 June 2012` | `327627` |
| `Leicester` | `87` | `United Kingdom` | `331,606` | `30 June 2012` | `331606` |

```
In [52]: df_pop.set_index("City").sort_values(["State", "NumericPopulation"],
    ...:                                      ascending=[False, True]).head()
Out[52]:

```

对于像`State`列这样的分类数据，总结一个列包含多少个分类值通常是有意义的。这种计数可以使用`Series`对象的`value_counts`方法来计算。例如，要计算每个国家在欧洲 105 个最大城市列表中的城市数量，我们可以使用:

```
In [53]: city_counts = df_pop.State.value_counts()
In [54]: city_counts.head()
Out[54]: Germany           19
         United Kingdom    16
         Spain             13
         Poland            10
         Italy             10
         dtype: int64

```

在本例中，我们从结果中看到，列表中城市数量最多的州是德国，有 19 个城市，其次是英国，有 16 个城市，依此类推。一个相关的问题是一个州内所有城市的总人口是多少。要回答这类问题，我们可以从两个方面着手:首先，我们可以使用`State`和`City`创建一个分层索引，并使用`sum`方法沿着其中一个索引减少`DataFrame`。在这种情况下，我们希望对索引级别`State`内的所有条目求和，因此我们可以使用`sum(level="State")`，它消除了`City`索引。为了演示，我们还按照列`NumericPopulation`的降序对结果`DataFrame`进行排序:

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"></colgroup> 
| `State` | `NumericPopulation` |
| `United Kingdom` | `16011877` |
| `Germany` | `15119548` |
| `Spain` | `10041639` |
| `Italy` | `8764067` |
| `Poland` | `6267409` |

```
In [55]: df_pop3 = df_pop[["State", "City", "NumericPopulation"]].set_index(["State", "City"])
In [56]: df_pop4 = df_pop3.sum(level="State").sort_values("NumericPopulation", ascending=False)
In [57]: df_pop4.head()
Out[57]:

```

其次，我们可以使用`groupby`方法获得相同的结果，该方法允许我们根据给定列的值对`DataFrame`的行进行分组，并对结果对象应用归约函数(例如，`sum`、`mean`、`min`、`max`等)。).结果是一个新的`DataFrame`，其分组依据列作为索引。使用这种方法，我们可以通过以下方式计算按州分组的 105 个城市的总人口:

```
In [58]: df_pop5 = (df_pop.drop("Rank", axis=1)
    ...:                  .groupby("State").sum()
    ...:                  .sort_values("NumericPopulation", ascending=False))

```

注意，这里我们还使用了`drop`方法从`DataFrame (since it is not meaningful to aggregate the rank by summation).`中删除了`Rank`列(因此使用了`axis=1`，使用`axis=0`删除了行)。最后，我们使用了`Series`对象的`plot`方法来绘制城市计数和总人口的条形图。结果如图 [12-2](#Fig2) 所示。

![../images/332789_2_En_12_Chapter/332789_2_En_12_Fig2_HTML.png](../images/332789_2_En_12_Chapter/332789_2_En_12_Fig2_HTML.png)

图 12-2

欧洲人口最多的 105 个城市列表中的城市数量(左)和这些城市的总人口(右)，按州分组

```
In [59]: fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
​    ...: city_counts.plot(kind='barh', ax=ax1)
    ...: ax1.set_xlabel("# cities in top 105")
    ...: df_pop5.NumericPopulation.plot(kind='barh', ax=ax2)
    ...: ax2.set_xlabel("Total pop. in top 105 cities")

```

### 时间序列

时间序列是一种常见的数据形式，其中给出了一个数量，例如，在规则或不规则间隔的时间戳或固定或可变的时间跨度(周期)。在`pandas`中，有专门的数据结构来表示这些类型的数据。`Series`和`DataFrame`可以有列和索引，数据类型描述时间戳和时间跨度。在处理时态数据时，能够用时间数据类型对数据进行索引特别有用。使用`pandas`、`DatetimeIndex`和`PeriodIndex`时间序列索引器，我们可以执行许多常见的日期、时间、周期和日历操作，例如选择时间范围以及对时间序列中的数据点进行移位和重采样。

例如，为了生成一个可以在`pandas Series`或`DataFrame`对象中用作索引的日期序列，我们可以使用`date_range`函数。它将起点作为日期和时间字符串(或者，Python 标准库中的`datetime`对象)作为第一个参数，并且可以使用`periods`关键字参数设置范围内的元素数量:

```
In [60]: pd.date_range("2015-1-1", periods=31)
Out[60]: <class 'pandas.tseries.index.DatetimeIndex'>
         [2015-01-01, ..., 2015-01-31]
         Length: 31, Freq: D, Timezone: None

```

为了指定时间戳的频率(默认为一天)，我们可以使用`freq`关键字参数，而不是使用`periods`来指定点数，我们可以将起点和终点作为日期和时间字符串(或`datetime`对象)作为第一个和第二个参数。例如，要生成 2015 年 1 月 1 日 00:00 到 12:00 之间的每小时时间戳，我们可以使用:

```
In [61]: pd.date_range("2015-1-1 00:00", "2015-1-1 12:00", freq="H")
Out[61]: <class 'pandas.tseries.index.DatetimeIndex'>
         [2015-01-01 00:00:00, ..., 2015-01-01 12:00:00]
         Length: 13, Freq: H, Timezone: None

```

`date_range`函数返回`DatetimeIndex`的一个实例，例如，它可以用作`Series`或`DataFrame`对象的索引:

```
In [62]: ts1 = pd.Series(np.arange(31), index=pd.date_range("2015-1-1", periods=31))
In [63]: ts1.head()
Out[63]: 2015-01-01    0
         2015-01-02    1
         2015-01-03    2
         2015-01-04    3
         2015-01-05    4
         Freq: D, dtype: int64

```

例如，可以使用带有日期和时间字符串的索引来访问`DatetimeIndex`对象的元素。`DatetimeIndex`中的元素属于`Timestamp`类型，这是一个扩展标准 Python `datetime`对象的`pandas`对象(参见 Python 标准库中的`datetime`模块)。

```
In [64]: ts1["2015-1-3"]
Out[64]: 2
In [65]: ts1.index[2]
Out[65]: Timestamp('2015-01-03 00:00:00', offset="D")

```

在许多方面，`Timestamp`和`datetime`对象是可以互换的，`Timestamp`类和`datetime`类一样，具有访问时间字段的属性，比如`year`、`month`、`day`、`hour`、`minute`等等。然而，`Timestamp`和`datetime`的一个显著区别是，`Timestamp`以纳秒的分辨率存储时间戳，而`datetime`对象只用微秒的分辨率。

```
In [66]: ts1.index[2].year, ts1.index[2].month, ts1.index[2].day
Out[66]: (2015, 1, 3)
In [67]: ts1.index[2].nanosecond
Out[67]: 0

```

我们可以使用`to_pydatetime`方法将`Timestamp`对象转换成标准的 Python `datetime`对象:

```
In [68]: ts1.index[2].to_pydatetime()
Out[68]: datetime.datetime(2015, 1, 3, 0, 0)

```

我们可以使用一系列的`datetime`对象来创建`pandas`时间序列:

```
In [69]: import datetime
In [70]: ts2 = pd.Series(np.random.rand(2),
    ...:                 index=[datetime.datetime(2015, 1, 1), datetime.datetime(2015, 2, 1)])
In [71]: ts2
Out[71]: 2015-01-01    0.683801
         2015-02-01    0.916209
         dtype: float64

```

为时间跨度序列定义的数据可以用使用`PeriodIndex`类索引的`Series`和`DataFrame`对象来表示。我们可以通过传递一列`Period`对象显式地构造一个`PeriodIndex`类的实例，然后在创建一个`Series`或`DataFrame`对象时将其指定为 index:

```
In [72]: periods = pd.PeriodIndex([pd.Period('2015-01'),
    ...:                           pd.Period('2015-02'),
    ...:                           pd.Period('2015-03')])
In [73]: ts3 = pd.Series(np.random.rand(3), index=periods)
In [74]: ts3
Out[74]: 2015-01    0.969817
         2015-02    0.086097
         2015-03    0.016567
         Freq: M, dtype: float64
In [75]: ts3.index
Out[75]: <class 'pandas.tseries.period.PeriodIndex'>
         [2015-01, ..., 2015-03]
         Length: 3, Freq: M

```

我们还可以使用`to_period`方法将由`DatetimeIndex`对象索引的`Series`或`DataFrame`对象转换为`PeriodIndex`(该方法使用一个指定周期频率的参数，这里`'M'`表示月份):

```
In [76]: ts2.to_period('M')
Out[76]: 2015-01    0.683801
         2015-02    0.916209
         Freq: M, dtype: float64

```

在本节的剩余部分，我们将通过示例探索`pandas`时间序列的特定特征。我们着眼于操纵两个时间序列，其中包含在给定的时间戳温度测量序列。我们有一个室内温度传感器数据集和一个室外温度传感器数据集，这两个数据集在 2014 年的大部分时间里大约每 10 分钟观测一次。`temperature_indoor_2014.tsv`和`temperature_outdoor_2014.tsv`这两个数据文件是 TSV(制表符分隔值，CSV 格式的一种变体)文件，有两列:第一列包含 UNIX 时间戳(自 1970 年 1 月 1 日以来的秒数)，第二列是以摄氏度为单位的测量温度。例如，室外数据集中的前五行是

```
In [77]: !head -n 5 temperature_outdoor_2014.tsv
1388530986    4.380000
1388531586    4.250000
1388532187    4.190000
1388532787    4.060000
1388533388    4.060000

```

我们可以通过指定列之间的分隔符是制表符:`delimiter="\t"`来使用`read_csv`读取数据文件。在读取这两个文件时，我们还使用`names`关键字参数显式地指定了列名，因为本例中的文件没有包含列名的标题行。

```
In [78]: df1 = pd.read_csv('temperature_outdoor_2014.tsv', delimiter="\t",
    ...:                   names=["time", "outdoor"])
In [79]: df2 = pd.read_csv('temperature_indoor_2014.tsv', delimiter="\t",
    ...:                   names=["time", "indoor"])

```

一旦我们为时序数据创建了`DataFrame`对象，就可以通过显示前几行来检查数据:

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"></colgroup> 
|   | `time` | `outdoor` |
| `0` | `1388530986` | `4.38` |
| `1` | `1388531586` | `4.25` |
| `2` | `1388532187` | `4.19` |
| `3` | `1388532787` | `4.06` |
| `4` | `1388533388` | `4.06` |

```
In [80]: df1.head()
Out[80]:

```

时序数据有意义表示的下一步是使用带有`unit="s"`参数的`to_datetime`将 UNIX 时间戳转换为日期和时间对象。此外，我们使用`tz_localize`本地化时间戳(分配一个时区)，并使用`tz_convert`将时区属性转换为`Europe/Stockholm`时区。我们还使用`set_index`将`time`列设置为索引:

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"></colgroup> 
| `time` | `outdoor` |
| `2014-01-01 00:03:06+01:00` | `4.38` |
| `2014-01-01 00:13:06+01:00` | `4.25` |
| `2014-01-01 00:23:07+01:00` | `4.19` |
| `2014-01-01 00:33:07+01:00` | `4.06` |
| `2014-01-01 00:43:08+01:00` | `4.06` |

```
In [81]: df1.time = (pd.to_datetime(df1.time.values, unit="s")
    ...:               .tz_localize('UTC').tz_convert('Europe/Stockholm'))
In [82]: df1 = df1.set_index("time")
In [83]: df2.time = (pd.to_datetime(df2.time.values, unit="s")
    ...:               .tz_localize('UTC').tz_convert('Europe/Stockholm'))
In [84]: df2 = df2.set_index("time")
In [85]: df1.head()
Out[85]:

```

显示室外温度数据集的数据框的前几行显示索引现在确实是一个日期和时间对象。正如我们将在下面看到的例子，将时间序列的索引表示为适当的日期和时间对象(与使用例如表示 UNIX 时间戳的整数相比)允许我们容易地执行许多面向时间的操作。在我们更详细地研究数据之前，我们首先绘制两个时间序列，以了解数据的样子。为此我们可以使用`DataFrame.plot`方法，结果如图 [12-3](#Fig3) 所示。请注意，八月份的部分数据缺失。数据不完整是一个常见的问题，以合适的方式处理缺失的数据是`pandas`库的使命陈述的重要部分。

![../images/332789_2_En_12_Chapter/332789_2_En_12_Fig3_HTML.png](../images/332789_2_En_12_Chapter/332789_2_En_12_Fig3_HTML.png)

图 12-3

室内和室外温度时间序列图

```
In [86]: fig, ax = plt.subplots(1, 1, figsize=(12, 4))
    ...: df1.plot(ax=ax)
    ...: df2.plot(ax=ax)

```

显示`DataFrame`对象的`info`方法的结果也很有启发性。这样做告诉我们在这个数据集中有将近 50000 个数据点，并且它包含从 2014-01-01 00:03:06 开始到 2014-12-30 23:56:35:

```
In [87]: df1.info()
<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 49548 entries, 2014-01-01 00:03:06+01:00 to 2014-12-30 23:56:35+01:00
Data columns (total 1 columns):
outdoor    49548 non-null float64
dtypes: float64(1) memory usage: 774.2 KB

```

对时间序列的一个常见操作是选择和提取部分数据。例如，从包含 2014 年全年数据的完整数据集中，我们可能只对选择和分析一月份的数据感兴趣。在`pandas`中，我们可以通过多种方式来实现这一点。例如，我们可以使用一个`DataFrame`的布尔索引来为数据子集创建一个`DataFrame`。为了创建选择一月份数据的布尔索引掩码，我们可以利用`pandas`时间序列特性，该特性允许我们将时间序列索引与日期和时间的字符串表示进行比较。在下面的代码中，类似于`df1.index >= "2014-1-1"`的表达式，其中`df1.index`是一个时间`DateTimeIndex`实例，产生一个布尔 NumPy 数组，该数组可用作选择所需元素的掩码。

```
In [88]: mask_jan = (df1.index >= "2014-1-1") & (df1.index < "2014-2-1")
In [89]: df1_jan = df1[mask_jan]
In [90]: df1_jan.info()
<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4452 entries, 2014-01-01 00:03:06+01:00 to 2014-01-31 23:56:58+01:00
Data columns (total 1 columns):
outdoor    4452 non-null float64
dtypes: float64(1) memory usage: 69.6 KB

```

或者，我们可以对日期和时间字符串直接使用切片语法:

```
In [91]: df2_jan = df2["2014-1-1":"2014-1-31"]

```

结果是两个`DataFrame`对象，`df1_jan`和`df2_jan`，它们只包含一月份的数据。使用`plot`方法绘制原始数据的这个子集产生了如图 [12-4](#Fig4) 所示的图表。

![../images/332789_2_En_12_Chapter/332789_2_En_12_Fig4_HTML.png](../images/332789_2_En_12_Chapter/332789_2_En_12_Fig4_HTML.png)

图 12-4

选定月份(一月)的室内和室外温度时间序列图

```
In [92]: fig, ax = plt.subplots(1, 1, figsize=(12, 4))
    ...: df1_jan.plot(ax=ax)
    ...: df2_jan.plot(ax=ax)

```

与 Python 标准库中的`datetime`类一样，`pandas`中用于表示时间值的`Timestamp`类也具有用于访问年、月、日、小时、分钟等字段的属性。这些字段在处理时间序列时特别有用。例如，如果我们希望计算一年中每个月的平均温度，我们可以通过创建一个新列`month`开始，我们将它分配给`DatetimeIndex`索引器的`Timestamp`值的`month`字段。为了从每个`Timestamp`值中提取月份字段，我们首先调用`reset_index`将索引转换为数据框中的一列(在这种情况下，新的`DataFrame`对象退回到使用整数索引)，之后我们可以对新创建的`time`列使用`apply`函数。 <sup>[4](#Fn4)</sup>

```
In [93]: df1_month = df1.reset_index()
In [94]: df1_month["month"] = df1_month.time.apply(lambda x: x.month)
In [95]: df1_month.head()
Out[95]:

```

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"> <col class="tcol4 align-left"></colgroup> 
|   | `time` | `outdoor` | `month` |
| `0` | `2014-01-01 00:03:06+01:00` | `4.38` | `1` |
| `1` | `2014-01-01 00:13:06+01:00` | `4.25` | `1` |
| `2` | `2014-01-01 00:23:07+01:00` | `4.19` | `1` |
| `3` | `2014-01-01 00:33:07+01:00` | `4.06` | `1` |
| `4` | `2014-01-01 00:43:08+01:00` | `4.06` | `1` |

接下来，我们可以通过新的`month`字段对`DataFrame`进行分组，并使用`mean`函数对分组后的值进行聚合，以计算每个组内的平均值。

```
In [96]: df1_month = df1_month.groupby("month").aggregate(np.mean)
In [97]: df2_month = df2.reset_index()
In [98]: df2_month["month"] = df2_month.time.apply(lambda x: x.month)
In [99]: df2_month = df2_month.groupby("month").aggregate(np.mean)

```

在对第二个`DataFrame`(室内温度)重复相同的过程后，我们可以使用`join`方法将`df1_month`和`df2_month`合并成一个`DataFrame`:

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"></colgroup> 
| `time` | `outdoor` | `indoor` |
| `1` | `-1.776646` | `19.862590` |
| `2` | `2.231613` | `20.231507` |
| `3` | `4.615437` | `19.597748` |

```
In [100]: df_month = df1_month.join(df2_month)
In [101]: df_month.head(3)
Out[101]:

```

在短短几行代码中，我们利用了`pandas`的许多数据处理功能来转换和计算数据。通常情况下，有许多不同的方法来组合由`pandas`提供的工具来完成相同或相似的分析。对于当前的例子，我们可以在一行代码中完成整个过程，使用`to_period`和`groupby`方法以及`concat`函数(类似于`join`将`DataFrame`合并成一个`DataFrame`):

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"></colgroup> 
| `time` | `outdoor` | `indoor` |
| `2014-01` | `-1.776646` | `19.862590` |
| `2014-02` | `2.231613` | `20.231507` |
| `2014-03` | `4.615437` | `19.597748` |

```
In [102]: df_month = pd.concat([df.to_period("M").groupby(level=0).mean() for df in [df1, df2]],
     ...:                      axis=1)
In [103]: df_month.head(3)
Out[103]:

```

为了直观显示结果，我们使用`DataFrame`方法`plot`将月平均温度绘制成柱状图和箱线图。结果如图 [12-5](#Fig5) 所示。

![../images/332789_2_En_12_Chapter/332789_2_En_12_Fig5_HTML.png](../images/332789_2_En_12_Chapter/332789_2_En_12_Fig5_HTML.png)

图 12-5

每月平均室内和室外温度(左)和每月室内和室外温度箱线图(右)

```
In [104]: fig, axes = plt.subplots(1, 2, figsize=(12, 4))
     ...: df_month.plot(kind='bar', ax=axes[0])
     ...: df_month.plot(kind='box', ax=axes[1])

```

最后，`pandas`时序对象的一个非常有用的特性是能够使用`resample`方法对时序进行上下采样。重采样意味着时间序列中数据点的数量发生变化。它可以增加(上采样)或减少(下采样)。对于上采样，我们需要选择一种方法来填充缺失值，对于下采样，我们需要选择一种方法来聚合每个新采样点之间的多个采样点。`resample`方法需要一个字符串作为第一个参数，该字符串指定重新采样的时间序列中数据点的新周期。例如，字符串`H`代表一个小时，字符串`D`代表一天，字符串`M`代表一个月，以此类推。 <sup>[5](#Fn5)</sup> 我们也可以把这些用简单的表达式组合起来，比如`7D`，表示七天的时间段。`resample`方法返回一个重采样器对象，我们可以为其调用聚合方法，如`mean`和`sum`，以获得重采样的数据。

为了说明`resample`方法的使用，考虑带有温度数据的前两个时间序列。最初的采样频率大约是 10 分钟，这相当于一年多的大量数据点。为了绘图的目的，或者如果我们想要比较两个时间序列，这两个时间序列是在稍微不同的时间戳采样的，通常需要对原始数据进行下采样。这可以给出不太繁忙的图表和规则间隔的时间序列，可以很容易地相互比较。在下面的代码中，我们以四种不同的采样频率对室外温度时间序列进行重新采样，并绘制出结果时间序列。我们还将室外和室内的时间序列重采样为日平均值，减去日平均值，得到全年室内和室外的日平均温差。这些类型的操作在处理时间序列时非常方便，这也是`pandas`库真正大放异彩的众多领域之一。

![../images/332789_2_En_12_Chapter/332789_2_En_12_Fig6_HTML.png](../images/332789_2_En_12_Chapter/332789_2_En_12_Fig6_HTML.png)

图 12-6

室外温度，重新采样为每小时、每天、每周和每月的平均值(顶部)。室外和室内的日温差(下图)

```
In [105]: df1_hour = df1.resample("H").mean()
In [106]: df1_hour.columns = ["outdoor (hourly avg.)"]
In [107]: df1_day = df1.resample("D").mean()
In [108]: df1_day.columns = ["outdoor (daily avg.)"]
In [109]: df1_week = df1.resample("7D").mean()
In [110]: df1_week.columns = ["outdoor (weekly avg.)"]
In [111]: df1_month = df1.resample("M").mean()
In [112]: df1_month.columns = ["outdoor (monthly avg.)"]
In [113]: df_diff = (df1.resample("D").mean().outdoor - df2.resample("D").mean().indoor)
In [114]: fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 6))
     ...: df1_hour.plot(ax=ax1, alpha=0.25)
     ...: df1_day.plot(ax=ax1)
     ...: df1_week.plot(ax=ax1)
     ...: df1_month.plot(ax=ax1)
     ...: df_diff.plot(ax=ax2)
     ...: ax2.set_title("temperature difference between outdoor and indoor")
     ...: fig.tight_layout()

```

作为上采样的说明，考虑下面的例子，其中我们使用三种不同的聚合方法(`mean`、`ffill`用于前向填充，以及`bfill`用于后向填充)，将数据帧`df1`重新采样到 5 分钟的采样频率。原始采样频率大约为 10 分钟，因此该重采样实际上是上采样。结果是三个新的数据帧，我们使用`concat`函数将它们组合成一个`DataFrame`对象。下例中还显示了数据框中的前五行。请注意，每隔一个数据点就是一个新的样本点，根据聚合方法的值，这些值会根据指定的策略进行填充(或不填充)。当未选择填充策略时，使用`NaN`值将相应的值标记为缺失。

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"> <col class="tcol4 align-left"></colgroup> 
| `time` | `None` | `ffill` | `bfill` |
| `2014-01-01 00:00:00+01:00` | `4.38` | `4.38` | `4.38` |
| `2014-01-01 00:05:00+01:00` | `NaN` | `4.38` | `4.25` |
| `2014-01-01 00:10:00+01:00` | `4.25` | `4.25` | `4.25` |
| `2014-01-01 00:15:00+01:00` | `NaN` | `4.25` | `4.19` |
| `2014-01-01 00:20:00+01:00` | `4.19` | `4.19` | `4.19` |

```
In [115]: pd.concat(
     ...:     [df1.resample("5min").mean().rename(columns={"outdoor": 'None'}),
     ...:      df1.resample("5min").ffill().rename(columns={"outdoor": 'ffill'}),
     ...:      df1.resample("5min").bfill().rename(columns={"outdoor": 'bfill'})],
     ...:     axis=1).head()
Out[115]:

```

## Seaborn 图形库

Seaborn 图形库建立在 Matplotlib 之上，它提供了用于生成图形的函数，这些图形在处理统计数据和数据分析时非常有用，包括分布图、核密度图、联合分布图、因子图、热图、分面图以及几种可视化回归的方法。它还提供了为图表中的数据着色的方法和许多精心制作的调色板。Seaborn 库的创建密切关注它所生成的图形的美感，用该库生成的图形往往既好看又有信息。Seaborn 库与底层 Matplotlib 库的区别在于，它为特定的应用领域(即统计分析和数据可视化)提供了完善的高级图形函数。使用该库可以轻松地生成标准统计图，这使得它成为探索性数据分析中的一个有价值的工具。

为了开始使用 Seaborn 库，我们首先使用`sns.set`函数为它生成的图形设置一个样式。这里我们选择使用名为`darkgrid`的样式，它生成带有灰色背景的图形(也可以尝试一下`whitegrid`样式)。

```
In [116]: sns.set(style="darkgrid")

```

导入`seaborn`并为库设置样式会改变 Matplotlib 图形显示的默认设置，包括由`pandas`库生成的图形。例如，考虑以下先前使用的室内和室外温度时间序列的图。生成的图形如图 [12-7](#Fig7) 所示，虽然图形是使用`pandas DataFrame`方法`plot`生成的，但使用`sns.set`功能改变了图形的外观(与图 [12-3](#Fig3) 比较)。

![../images/332789_2_En_12_Chapter/332789_2_En_12_Fig7_HTML.png](../images/332789_2_En_12_Chapter/332789_2_En_12_Fig7_HTML.png)

图 12-7

Matplotlib 使用 Pandas 库生成的时间序列绘图，其绘图样式由 Seaborn 库设置

```
In [117]: df1 = pd.read_csv('temperature_outdoor_2014.tsv', delimiter="\t",
     ...:                   names=["time", "outdoor"])
     ...: df1.time = (pd.to_datetime(df1.time.values, unit="s")
     ...:               .tz_localize('UTC').tz_convert('Europe/Stockholm'))
     ...: df1 = df1.set_index("time").resample("10min").mean()
In [118]: df2 = pd.read_csv('temperature_indoor_2014.tsv', delimiter="\t",
     ...:                   names=["time", "indoor"])
     ...: df2.time = (pd.to_datetime(df2.time.values, unit="s")
     ...:               .tz_localize('UTC').tz_convert('Europe/Stockholm'))
     ...: df2 = df2.set_index("time").resample("10min").mean()
In [119]: df_temp = pd.concat([df1, df2], axis=1)
In [120]: fig, ax = plt.subplots(1, 1, figsize=(8, 4))
     ...: df_temp.resample("D").mean().plot(y=["outdoor", "indoor"], ax=ax)

```

除了生成好看的图形之外，Seaborn 库的主要优势在于它收集了易于使用的统计图。例如`kdeplot`和`distplot`，它们分别绘制了核密度估计图和直方图，其中核密度估计覆盖在直方图的顶部。例如，下面两行代码产生了如图 [12-8](#Fig8) 所示的图形。图中蓝色和绿色的实线是内核密度估计值，也可以使用函数`kdeplot`(此处未显示)单独绘制。

![../images/332789_2_En_12_Chapter/332789_2_En_12_Fig8_HTML.png](../images/332789_2_En_12_Chapter/332789_2_En_12_Fig8_HTML.png)

图 12-8

对应于四月份的室内和室外数据集子集的直方图(条)和核密度图(实线)

```
In [121]: sns.distplot(df_temp.to_period("M")["outdoor"]["2014-04"].dropna().values, bins=50);
     ...: sns.distplot(df_temp.to_period("M")["indoor"]["2014-04"].dropna().values, bins=50);

```

`kdeplot`函数也可以对二维数据进行操作，显示联合核密度估计的等高线图。与此相关，我们可以使用`jointplot`函数来绘制两个独立数据集的联合分布。在下面的例子中，我们使用`kdeplot`和`jointplot`来显示室内和室外数据序列之间的相关性，这些数据序列在可视化之前被重新采样为每小时的平均值(我们还使用`dropna`方法删除缺失值，因为来自`seaborn`模块的函数不接受含有缺失数据的数组)。结果如图 [12-9](#Fig9) 所示。

![../images/332789_2_En_12_Chapter/332789_2_En_12_Fig9_HTML.png](../images/332789_2_En_12_Chapter/332789_2_En_12_Fig9_HTML.png)

图 12-9

二维核密度估计等值线(左)以及室内和室外温度数据集的联合分布(右)。x 轴表示室外温度，y 轴表示室内温度。

```
In [122]: sns.kdeplot(df_temp.resample("H").mean()["outdoor"].dropna().values,
     ...:             df_temp.resample("H").mean()["indoor"].dropna().values, shade=False)
In [123]: with sns.axes_style("white"):
     ...:     sns.jointplot(df_temp.resample("H").mean()["outdoor"].values,
     ...:                   df_temp.resample("H").mean()["indoor"].values, kind="hex")

```

`seaborn`库还提供了处理分类数据的函数。图表类型的一个简单示例是用于可视化数据集的描述性统计数据(最小值、最大值、中值和四分位数)的标准箱线图，这种图表类型通常适用于包含分类变量的数据集。标准箱线图的一个有趣变化是 violin 图，其中内核密度估计值显示在箱线图的宽度中。`boxplot`和`violinplot`函数可以用来生成这样的图形，如下例所示，生成的图形如图 [12-10](#Fig10) 所示。

![../images/332789_2_En_12_Chapter/332789_2_En_12_Fig10_HTML.png](../images/332789_2_En_12_Chapter/332789_2_En_12_Fig10_HTML.png)

图 12-10

室内和室外温度数据集的箱线图(左)和小提琴图(右)

```
In [124]: fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))
     ...: sns.boxplot(df_temp.dropna(), ax=ax1, palette="pastel")
     ...: sns.violinplot(df_temp.dropna(), ax=ax2, palette="pastel")

```

作为 violin 图的另一个示例，考虑按月份划分的室外温度数据集，这可以通过将数据框索引的 month 字段作为第二个参数(用于将数据分组到类别中)来生成。结果图如图 [12-11](#Fig11) 所示，提供了一年中每个月的温度分布的紧凑和信息可视化。

![../images/332789_2_En_12_Chapter/332789_2_En_12_Fig11_HTML.png](../images/332789_2_En_12_Chapter/332789_2_En_12_Fig11_HTML.png)

图 12-11

按月分组的室外温度的小提琴图

```
In [125]: sns.violinplot(x=df_temp.dropna().index.month,
     ...:                y=df_temp.dropna().outdoor, color="skyblue");

```

热图是另一种类型的图表，在处理分类变量时很方便，特别是对于有大量类别的变量。Seaborn 库提供了函数`heatmap`来生成这种类型的图形。例如，使用室外温度数据集，我们可以创建两个分类列`month`和`hour`，方法是从索引中提取这些字段，并将它们分配给数据字段中的新列。接下来，我们可以使用`pandas`中的`pivot_table`函数将列旋转到一个表(矩阵)中，其中两个选定的分类变量构成了新的索引和列。这里我们旋转温度数据集，使一天中的小时是列，一年中的月份是行(`index`)。为了聚合属于每个小时-月类别的多个数据点，我们使用`aggfunc=np.mean`参数来计算所有值的平均值:

```
In [126]: df_temp["month"] = df_temp.index.month
     ...: df_temp["hour"] = df_temp.index.hour
In [127]: table = pd.pivot_table(df_temp, values="outdoor", index=['month'], columns=['hour'],
     ...:                        aggfunc=np.mean)

```

一旦我们创建了一个数据透视表，我们可以使用 Seaborn 中的热图功能将其可视化为热图。结果如图 [12-12](#Fig12) 所示。

![../images/332789_2_En_12_Chapter/332789_2_En_12_Fig12_HTML.png](../images/332789_2_En_12_Chapter/332789_2_En_12_Fig12_HTML.png)

图 12-12

室外温度数据的热图，按一天中的小时和一年中的月份分组

```
In [128]: fig, ax = plt.subplots(1, 1, figsize=(8, 4))
     ...: sns.heatmap(table, ax=ax)

```

Seaborn 库包含的统计可视化工具比我们在这里所能看到的要多得多。但是，我希望通过几个例子来说明 Seaborn 库的本质——它是一个用于统计分析和数据探索的方便工具，能够以最小的工作量生成许多标准的统计图表。在接下来的章节中，我们将会看到更多关于 Seaborn 库应用的例子。

## 摘要

在这一章中，我们已经探索了使用 Pandas 库的数据表示和数据处理，并且我们简要地调查了 Seaborn 可视化库提供的统计图形工具。Pandas 库提供了用 Python 完成的许多数据争论的后端。它通过在 NumPy 数组之上的数据表示中添加一个更高级别的抽象层来实现这一点，并添加了对底层数据进行操作的其他方法。数据易于加载、转换和操作，这使得它成为 Python 中数据处理工作流的重要组成部分。`pandas`库还包含可视化数据的基本功能，这些数据由它的数据结构表示。能够快速可视化表示为 Pandas 系列和数据框的数据是探索性数据分析和演示的重要工具。Seaborn 库更进了一步，提供了丰富的统计图集合，通常只需一行代码就可以生成。Seaborn 库中的许多函数可以直接在 Pandas 数据结构上操作。

## 进一步阅读

McKinney (2013)中的库的原始创建者给出了关于熊猫库的很好的介绍，这也是对 NumPy 的相当详细的介绍。熊猫官方文档，可在 [`http://pandas.pydata.org/pandas-docs/stable`](http://pandas.pydata.org/pandas-docs/stable) 获得，也提供了一个可访问的和非常详细的图书馆特征的描述。另外一个很好的学习熊猫的网上资源是 [`http://github.com/jvns/pandas-cookbook`](http://github.com/jvns/pandas-cookbook) 。对于数据可视化，我们在本章中看到了 Seaborn 库，在其网站上的文档中有很好的描述。关于更高级的可视化工具，同样值得探索的是 Python 的`ggplot`库、 [`http://ggplot.yhathq.com`](http://ggplot.yhathq.com) ，它是基于著名的*图形的语法* (L. Wilkinson，2005)的一个实现。这个库还与 Pandas 库紧密集成，它提供了统计可视化工具，在分析数据时非常方便。有关 Python 可视化的更多信息，请参见 Vaingast (2014)。

## 参考

长度威尔金森博士(2005 年)。*图形的语法。*芝加哥:施普林格。

McKinney，W. (2013 年)。 *Python 进行数据分析。*塞瓦斯托波尔:奥莱利。

Vaingast，S. (2014 年)。开始 Python 可视化。纽约:一家出版社。

<aside class="FootnoteSection" epub:type="footnotes">Footnotes [1](#Fn1_source)

也称为数据管理或数据争论

  [2](#Fn2_source)

CSV 或逗号分隔值是一种常见的文本格式，其中行存储在行中，列由逗号(或其他文本分隔符)分隔。参见第 [18](18.html) 章了解更多关于这种和其他文件格式的细节。

  [3](#Fn3_source)

这个数据集是从维基页面获得的: [`http://en.wikipedia.org/wiki/Largest_cities_of_the_European_Union_by_population_within_city_limits`](http://en.wikipedia.org/wiki/Largest_cities_of_the_European_Union_by_population_within_city_limits)

  [4](#Fn4_source)

我们也可以直接使用`DatetimeIndex` index 对象的`month`方法，但是为了便于演示，我们在这里使用了一种更显式的方法。

  [5](#Fn5_source)

`There are a large number of available time-unit codes. See the sections on “Offset aliases” and “Anchored offsets” in the Pandas reference manual for details.`

 </aside>*