# 十五、机器学习

本章我们探索机器学习。这个主题与统计建模密切相关，我们在第 [14 章](14.html)中考虑过，从这个意义上说，两者都处理使用数据来描述和预测不确定或未知过程的结果。然而，尽管统计建模强调分析中使用的模型，但机器学习回避了模型部分，而是专注于可以训练来预测新观察结果的算法。换句话说，统计建模中采用的方法强调理解数据是如何产生的，即设计模型并通过拟合数据来调整其参数。如果发现模型很好地拟合了数据，并且满足了相关的模型假设，那么模型给出了过程的总体描述，并且它可以用于计算具有已知分布的统计数据，以及用于评估统计测试。然而，如果实际数据过于复杂，无法用现有的统计模型来解释，这种方法就达到了极限。另一方面，在机器学习中，生成数据及其潜在模型的实际过程并不重要。相反，观察到的数据和解释变量是机器学习应用程序的基本出发点。给定数据，机器学习方法可用于发现数据中的模式和结构，这可用于预测新观察的结果。因此，机器学习无法理解数据是如何生成的，并且因为对数据的分布和统计属性做出的假设较少，所以我们通常无法计算统计数据并对某些观察结果的显著性进行统计测试。相反，机器学习非常强调预测新观察结果的准确性。

虽然在统计建模和机器学习中采用的基本方法存在显著差异，但使用的许多数学方法密切相关，有时甚至相同。在本章的过程中，我们将认识到我们在第 [14](14.html) 章中使用的关于统计建模的几种方法，但是它们将会以不同的心态和略微不同的目标被使用。

在这一章中，我们简要介绍了基本的机器学习方法，并概述了如何在 Python 中使用这些方法。重点是在科学和技术计算的许多领域有广泛应用的机器学习方法。最突出和最全面的 Python 机器学习库是 scikit-learn，尽管还有几个替代和补充库:例如 TensorFlow、Keras、PyTorch 等等。在本章中，我们专门使用 scikit-learn 库，它提供了最常见的机器学习算法的实现。然而，鼓励对机器学习特别感兴趣的读者也去探索前面提到的其他库。

### Scikit-learn

scikit-learn 库包含一个全面的机器学习相关算法的集合，包括回归、分类、维度减少和聚类。有关项目及其文档的更多信息，请参见项目网页 [`http://scikit-learn.org`](http://scikit-learn.org) 。在撰写本文时，scikit-learn 的最新版本是 0.19.2。

## 导入模块

在本章中，我们将使用 scikit-learn 库，它提供了`sklearn` Python 模块。对于`sklearn`模块，我们使用与 SciPy 库相同的导入策略:也就是说，我们从库中显式导入我们工作所需的模块。在本章中，我们使用了来自`sklearn`库的以下模块:

```py
In [1]: from sklearn import datasets
In [2]: from sklearn import model_selection
In [3]: from sklearn import linear_model
In [4]: from sklearn import metrics
In [5]: from sklearn import tree
In [6]: from sklearn import neighbors
In [7]: from sklearn import svm
In [8]: from sklearn import ensemble
In [9]: from sklearn import cluster

```

对于绘图和基本数字，我们还需要 Matplotlib 和 NumPy 库，它们是以通常的方式导入的:

```py
In [10]: import matplotlib.pyplot as plt
In [11]: import numpy as np

```

我们还使用 Seaborn 库进行图形和数字样式设计:

```py
In [12]: import seaborn as sns

```

## 机器学习概述

机器学习是计算机科学人工智能领域的一个课题。机器学习可以被视为包括将训练数据输入计算机程序使其能够执行给定任务的所有应用。这是一个非常宽泛的定义，但在实践中，机器学习通常与一组更加具体的技术和方法相关联。在这里，我们采用一种实用的方法，并通过实例探索机器学习中的几种基本方法和关键概念。在开始具体示例之前，我们先简要介绍一下术语和核心概念。

在机器学习中，将模型或算法拟合到观察数据的过程被称为*训练*。机器学习应用程序通常可以分为两种类型:*监督的*和*非监督的*学习，它们在应用程序训练的数据类型上有所不同。在*监督学习*中，数据包括特征变量和已知响应变量。特征变量和响应变量可以是连续的，也可以是离散的。准备这样的数据通常需要手工操作，有时甚至需要专业领域的知识。因此，用手工制作的数据来训练该应用，并且该训练因此可以被视为受监督的机器学习。应用示例包括回归(连续响应变量的预测)和分类(离散响应变量的预测)，其中响应变量的值对于训练数据集是已知的，但对于新样本是未知的。

相比之下，*无监督学习*对应于用未被标记或以其他方式手动准备的原始数据来训练机器学习应用的情况。无监督学习的一个例子是将数据聚类成组，或者换句话说，将数据分组到合适的类别中。与监督分类相反，对于非监督学习来说，通常最终类别是事先不知道的，因此训练数据不能被相应地标记。也可能是这样的情况，例如，因为样本的数量太大，数据的人工标记很困难或者成本很高。不言而喻，无监督的机器学习比有监督的机器学习更困难，并且在可用于什么方面受到限制，因此只要有可能，就应该首选有监督的机器学习。然而，当不可能创建标记的训练数据集时，无监督的机器学习可以是一个强大的工具。

自然，机器学习比前面文本中概述的基本问题类型要复杂得多，但这些概念在许多机器学习应用程序中是反复出现的主题。在这一章中，我们看一些基本机器学习技术的例子，这些例子展示了机器学习的几个核心概念。在此之前，我们先简要介绍一下常见的机器学习术语，我们将在以下几节中提到这些术语:

*   *交叉验证*是将可用数据分为*训练数据*和*测试数据*(也称为*验证数据*)的实践，其中只有训练数据用于训练机器学习模型，并且测试数据允许在之前未见过的数据上测试训练的应用。这样做的目的是衡量模型预测新观察值的能力，并限制过度拟合的问题。有几种方法可以将数据划分为训练数据集和测试数据集。例如，一种极端的方法是测试划分数据的所有可能方式(*穷举交叉验证*)并使用结果的集合(例如，平均值或最小值，取决于具体情况)。然而，对于大型数据集，训练和测试数据的可能组合的数量变得非常大，使得穷举交叉验证不切实际。另一个极端是使用训练集中除了一个样本之外的所有样本，以及训练集中的剩余样本(*留一交叉验证*)，并对所有组合重复训练-测试循环，其中从可用数据中选择一个样本。这种方法的一个变体是将可用数据分成 *k* 组，并使用数据集的 *k* 组执行留一交叉验证。这种方法被称为 *k* 折叠交叉验证，是实践中经常使用的一种流行技术。在 scikit-learn 库中，模块`sklearn.model_selection`包含用于交叉验证的函数。

*   *特征提取*是机器学习问题预处理阶段的重要步骤。它包括创建合适的特征变量和相应的特征矩阵，这些变量和矩阵可以传递给 scikit-learn 库中实现的许多机器学习算法之一。scikit-learn 模块`sklearn.feature_extraction`在许多机器学习应用程序中扮演的角色与 Patsy 公式库在统计建模中扮演的角色类似，特别是对于基于文本和图像的机器学习问题。使用来自`sklearn.feature_extraction`模块的方法，我们可以从各种数据源自动组装特征矩阵(设计矩阵)。

*   *降维*和*特征选择*是机器学习应用中经常使用的技术，在这些应用中，通常有大量的解释变量(特征)，其中许多可能不会显著提高应用的预测能力。为了降低模型的复杂性，通常需要消除不太有用的特征，从而降低问题的维度。当特征的数量相当于或大于观察的数量时，这一点尤其重要。scikit-learn 模块`sklearn.decomposition`和`sklearn.feature_selection`包含用于降低机器学习问题维度的函数:例如，主成分分析(PCA)是一种流行的降维技术，它通过对特征矩阵进行奇异值分解并仅保留与最重要的奇异向量相对应的维度来工作。

在接下来的几节中，我们将看看如何使用 scikit-learn 来解决机器学习问题的示例，这些示例使用了前面文本中讨论的技术。在这里，我们使用生成的数据和内置的数据集。与 statsmodels 库一样，scikit-learn 附带了许多内置数据集，可用于探索机器学习方法。`sklearn`中的`datasets`模块提供了三组函数，分别用于加载内置数据集(前缀为`load_`，如`load_boston`)、获取外部数据集(前缀为`fetch_`，如`fetch_californa_housing`)以及最终从随机数生成数据集(前缀为`make_`，如`make_regression`)。

## 回归

正如我们在第 [14](14.html) 章已经看到的，回归是机器学习和统计建模的核心部分。在机器学习中，我们不太关心回归模型与数据的拟合程度，而是关心它对新观察结果的预测程度。例如，如果我们有大量的要素和少量的观察值，我们通常可以将回归完美地拟合到数据，而不会对预测新值非常有用。这是一个过度拟合的例子:数据和回归模型之间的少量残差并不能保证模型能够准确预测未来的观测值。在机器学习中，处理这一问题的一种常见方法是将可用数据划分为训练数据集和测试数据集，测试数据集用于根据以前未见过的数据验证回归结果。

为了了解如何拟合训练数据集并根据测试数据集验证结果，让我们考虑一个有 50 个样本和 50 个特征的回归问题，其中只有 10 个特征是有信息的(与响应变量线性相关)。这模拟了一个我们有 50 个已知特征的场景，但结果表明只有 10 个特征对回归模型的预测能力有贡献。`sklearn.datasets`模块中的`make_regression`函数生成以下类型的数据:

```py
In [13]: X_all, y_all = datasets.make_regression(n_samples=50, n_features=50, n_informative=10)

```

结果是形状`(50, 50)`和`(50,)`的两个阵列`X_all`和`y_all`，对应于具有 50 个样本和 50 个特征的回归问题的设计矩阵。我们没有对整个数据集进行回归(并因为少量的观察而获得完美的拟合)，而是使用`sklearn.model_selection`模块中的`train_test_split`函数将数据集分成两个大小相等的数据集。结果是训练数据集`X_train`、`y_train`和测试数据集`X_test`、`y_test`:

```py
In [14]: X_train, X_test, y_train, y_test = \
    ...:     model_selection.train_test_split(X_all, y_all, train_size=0.5)

```

在 scikit-learn 中，可以使用来自`sklearn.linear_model`模块的`LinearRegression`类来执行普通的线性回归，这与来自 statsmodels 库的`statsmodels.api.OLS`具有可比性。为了执行回归，我们首先创建一个`LinearRegression`实例:

```py
In [15]: model = linear_model.LinearRegression()

```

为了使模型符合数据，我们需要调用`fit`方法，该方法将特征矩阵和响应变量向量作为第一个和第二个参数:

```py
In [16]: model.fit(X_train, y_train)
Out[16]: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)

```

注意，与 statsmodels 中的`OLS`类相比，特征矩阵和响应变量向量的顺序是相反的，在 statsmodels 中，数据是在创建类实例时指定的，而不是在调用`fit`方法时指定的。此外，在 scikit-learn 中，调用`fit`方法不会返回新的结果对象，而是将结果直接存储在模型实例中。当与 statsmodels 和 scikit-learn 模块互换使用时，这些细微的差异是很小的不便，值得注意。 <sup>[1](#Fn1)</sup>

由于回归问题有 50 个特征，而我们只训练了 25 个样本的模型，我们可以期待完全的过度拟合，完美地拟合数据。这可以通过计算模型和数据之间的误差平方和(SSEs)来量化。为了评估一组给定特征的模型，我们可以使用`predict`方法，由此我们可以计算残差和 SSE:

```py
In [17]: def sse(resid):
    ...:     return np.sum(resid**2)
In [18]: resid_train = y_train - model.predict(X_train)
    ...: sse_train = sse(resid_train)
    ...: sse_train
Out[18]: 8.1172209425431673e-25

```

正如预期的那样，对于训练数据集，残差基本上都为零，这是由于拥有两倍于数据点的要素所允许的过度拟合。然而，这种过度拟合的模型根本不适合预测看不见的数据。这可以通过计算我们的测试数据集的 SSE 来验证:

```py
In [19]: resid_test = y_test - model.predict(X_test)
    ...: sse_test = sse(resid_test)
    ...: sse_test
Out[19]: 213555.61203039082

```

结果是一个非常大的 SSE 值，这表明该模型在预测新的观察值方面做得不好。衡量模型与数据集拟合程度的另一种方法是 R 平方得分(见第 [14 章](14.html))，我们可以使用`score`方法计算。它采用特征矩阵和响应变量向量作为自变量，并计算得分。对于训练数据集，我们如预期的那样获得了 1.0 的 *r* 平方分数，但是对于测试数据集，我们获得了较低的分数:

```py
In [20]: model.score(X_train, y_train)
Out[20]: 1.0
In [21]: model.score(X_test, y_test)
Out[21]: 0.31407400675201746

```

训练和测试数据集得分之间的巨大差异再次表明模型过度拟合。

最后，我们还可以采用图形方法，绘制训练和测试数据集的残差，并直观地检查系数和残差的值。从一个`LinearRegression`对象中，我们可以使用`coef_`属性提取合适的参数。为了简化训练和测试残差以及模型参数的重复绘制，这里我们首先创建一个函数`plot_residuals_and_coeff`来绘制这些量。然后，我们使用普通线性回归模型的结果调用该函数，该模型分别在训练和测试数据集上进行训练和测试。结果如图 [15-1](#Fig1) 所示，很明显，对于每个样本，测试数据集和训练数据集的残差幅度存在很大差异。

![img/332789_2_En_15_Chapter/332789_2_En_15_Fig1_HTML.png](img/332789_2_En_15_Chapter/332789_2_En_15_Fig1_HTML.png)

图 15-1

普通线性回归模型和训练数据之间的残差(左)，模型和测试数据之间的残差(中)，以及 50 个特征的系数值(右)

```py
In [22]: def plot_residuals_and_coeff(resid_train, resid_test, coeff):
    ...:    fig, axes = plt.subplots(1, 3, figsize=(12, 3))
    ...:    axes[0].bar(np.arange(len(resid_train)), resid_train)
    ...:    axes[0].set_xlabel("sample number")
    ...:    axes[0].set_ylabel("residual")
    ...:    axes[0].set_title("training data")
    ...:    axes[1].bar(np.arange(len(resid_test)), resid_test)
    ...:    axes[1].set_xlabel("sample number")
    ...:    axes[1].set_ylabel("residual")
    ...:    axes[1].set_title("testing data")
    ...:    axes[2].bar(np.arange(len(coeff)), coeff)
    ...:    axes[2].set_xlabel("coefficient number")
    ...:    axes[2].set_ylabel("coefficient")
    ...:    fig.tight_layout()
    ...:    return fig, axes
In [23]: fig, ax = plot_residuals_and_coeff(resid_train, resid_test, model.coef_)

```

这个例子中的过度拟合是因为我们的样本太少，一个解决方案是收集更多的样本，直到过度拟合不再是一个问题。然而，这并不总是可行的，因为收集观察值可能是昂贵的，并且因为在一些应用中，我们可能有非常大量的特征。对于这种情况，希望能够以尽可能避免过度拟合的方式来拟合回归问题(以不能完美拟合训练数据为代价)，以便模型可以对新的观察结果给出有意义的预测。

正则化回归是这个问题的一个可能的解决方案。下面我们来看看正则化回归的几种不同的变化。在普通的线性回归中，选择模型参数使得残差平方和最小。因此，作为优化问题，目标函数是![$$ {\min}_{\beta }{\left\Vert X\beta -y\right\Vert}_2^2, $$](img/332789_2_En_15_Chapter/332789_2_En_15_Chapter_TeX_IEq1.png)，其中 *X* 是特征矩阵， *y* 是响应变量， *β* 是模型参数的向量，其中‖T9】2 表示 L2 范数。在*正则化*回归中，我们在最小化问题的目标函数中增加了一个*惩罚项*。不同类型的罚项对原始回归问题施加不同类型的正则化。通过将参数向量的 L1 或 L2 范数添加到最小化目标函数![$$ {\min}_{\beta}\left\{{\left\Vert X\beta -y\right\Vert}_2^2+\alpha {\left\Vert \beta \right\Vert}_1\right\} $$](img/332789_2_En_15_Chapter/332789_2_En_15_Chapter_TeX_IEq2.png)和![$$ {\min}_{\beta}\left\{{\left\Vert X\beta -y\right\Vert}_2^2+\alpha {\left\Vert \beta \right\Vert}_2^2\right\}. $$](img/332789_2_En_15_Chapter/332789_2_En_15_Chapter_TeX_IEq3.png)中，可以获得两种流行的正则化，这两种正则化分别被称为套索和岭回归。这里 *α* 是确定正则化强度的自由参数。添加 L2 范数![$$ {\left\Vert \beta \right\Vert}_2^2 $$](img/332789_2_En_15_Chapter/332789_2_En_15_Chapter_TeX_IEq4.png)有利于系数较小的模型参数向量，添加 L1 范数‖ * β * ‖ <sub>1</sub> 有利于非零元素尽可能少的模型参数向量。哪种类型的正则化更适合取决于手头的问题:当我们希望消除尽可能多的特征时，我们可以使用 L1 正则化和套索回归，当我们希望限制模型系数的大小时，我们可以使用 L2 正则化和岭回归。

通过 scikit-learn，我们可以使用 sklearn.linear_model 模块中的 Ridge 类来执行岭回归。该类的用法与我们在前面的文本中使用的 LinearRegression 类几乎相同，但是我们也可以在初始化该类时将确定正则化强度的参数 *α* 的值作为参数给出。这里我们选择了值 *α* = 2.5。本章稍后将介绍选择 *α* 的更系统的方法。

```py
In [24]: model = linear_model.Ridge(alpha=2.5)

```

为了使回归模型符合数据，我们再次使用 fit 方法，将训练特征矩阵和响应变量作为参数传递:

```py
In [25]: model.fit(X_train, y_train)
Out[25]: Ridge(alpha=2.5, copy_X=True, fit_intercept=True, max_iter=None,
               normalize=False, solver="auto", tol=0.001)

```

一旦模型适合训练数据，我们就可以计算训练和测试数据集的模型预测，并计算相应的 SSE 值:

```py
In [26]: resid_train = y_train - model.predict(X_train)
    ...: sse_train = sse(resid_train)
    ...: sse_train
Out[26]: 178.50695164950841
In [27]: resid_test = y_test - model.predict(X_test)
    ...: sse_test = sse(resid_test)
    ...: sse_test
Out[27]: 212737.00160105844

```

我们注意到，训练数据的 SSE 不再接近于零，但是测试数据的 SSE 略有下降。为了与普通回归进行比较，我们还使用前面定义的函数 plot_residuals_and_coeff 绘制了训练和测试残差以及模型参数。结果如图 [15-2](#Fig2) 所示。

![img/332789_2_En_15_Chapter/332789_2_En_15_Fig2_HTML.png](img/332789_2_En_15_Chapter/332789_2_En_15_Fig2_HTML.png)

图 15-2

岭正则化回归模型和训练数据(左)、模型和测试数据(中)以及 50 个特征的系数值(右)之间的残差

```py
In [28]: fig, ax = plot_residuals_and_coeff(resid_train, resid_test, model.coef_)

```

同样，我们可以使用 sklearn.linear_model 模块中的 Lasso 类执行 L1 正则化 LASSO 回归。当初始化类实例时，它还接受参数 *α* 的值作为参数。这里，我们选择 *α* = 1.0，并以与前述相同的方式执行模型对训练数据的拟合以及对训练和测试数据的 SSE 的计算:

```py
In [29]: model = linear_model.Lasso(alpha=1.0)
In [30]: model.fit(X_train, y_train)
Out[30]: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,
               normalize=False, positive=False, precompute=False, random_state=None,
               selection='cyclic', tol=0.0001, warm_start=False)
In [31]: resid_train = y_train - model.predict(X_train)
    ...: sse_train = sse(resid_train)
    ...: sse_train
Out[31]: 309.74971389531891
In [32]: resid_test = y_test - model.predict(X_test)
    ...: sse_test = sse(resid_test)
    ...: sse_test
Out[32]: 1489.1176065002333

```

这里我们注意到，虽然与普通回归相比，训练数据的 SSE 增加了，但是测试数据的 SSE 却显著降低了。因此，通过在回归模型拟合训练数据的程度方面付出代价，我们获得了预测测试数据集的能力显著提高的模型。为了与之前的方法进行比较，我们再次使用 plot_residuals_and_coeff 函数绘制残差和模型参数的图形。结果如图 [15-3](#Fig3) 所示。在该图最右边的面板中，我们看到系数分布图与图 [15-1](#Fig1) 和图 [15-2](#Fig2) 中所示的系数分布图明显不同，并且使用套索回归生成的系数向量包含大部分零。这是一种适合当前数据的方法，因为在开始时，当我们生成数据集时，我们选择了 50 个要素，其中只有 10 个是信息性的。如果我们怀疑可能有大量在回归模型中贡献不大的要素，那么使用套索回归的 L1 正则化是一种很好的尝试方法。

![img/332789_2_En_15_Chapter/332789_2_En_15_Fig3_HTML.png](img/332789_2_En_15_Chapter/332789_2_En_15_Fig3_HTML.png)

图 15-3

套索正则化回归模型和训练数据(左)、模型和测试数据(中)以及 50 个要素的系数值(右)之间的残差

```py
In [33]: fig, ax = plot_residuals_and_coeff(resid_train, resid_test, model.coef_)

```

我们在前面两个使用岭和套索回归的例子中使用的`The values of` *α* 是任意选择的。最合适的值 *α* 取决于问题，对于每一个新问题，我们需要使用试错法找到一个合适的值。scikit-learn 库提供了帮助这一过程的方法，正如我们将在下文中看到的那样，但在我们探索这些方法之前，看看训练和测试数据集的回归模型参数和 SSE 如何依赖于特定问题的 *α* 的值是有益的。这里我们关注 LASSO 回归，因为它被认为对当前问题很有效，并且我们使用正则化强度参数 *α* 的不同值重复解决相同的问题，同时将系数的值和 SSE 值存储在 NumPy 数组中。

我们首先创建所需的 NumPy 数组。我们使用`np.logspace`来创建一系列跨越几个数量级的 *α* 值:

```py
In [34]: alphas = np.logspace(-4, 2, 100)
In [35]: coeffs = np.zeros((len(alphas), X_train.shape[1]))
In [36]: sse_train = np.zeros_like(alphas)
In [37]: sse_test = np.zeros_like(alphas)

```

接下来，我们循环遍历 *α* 值，并对每个值执行套索回归:

```py
In [38]: for n, alpha in enumerate(alphas):
    ...:     model = linear_model.Lasso(alpha=alpha)
    ...:     model.fit(X_train, y_train)
    ...:     coeffs[n, :] = model.coef_
    ...:     sse_train[n] = sse(y_train - model.predict(X_train))
    ...:     sse_test[n] = sse(y_test - model.predict(X_test))

```

最后，我们使用 Matplotlib 绘制了训练和测试数据集的系数和 SSE。结果如图 [15-4](#Fig4) 所示。我们可以在左图中看到，对于非常小的α值，大量系数是非零的。这对应于过度拟合状态。我们还可以看到，当α增加到某个阈值以上时，许多系数会坍缩为零，只有少数系数保持非零。在图的右侧面板中，我们看到，虽然训练集的 SSE 随着 *α* 的增加而稳步增加，但测试数据集的 SSE 也急剧下降。这就是《套索回归》中抢手的效果。然而，对于过大的α值，所有系数都收敛到零，并且训练和测试数据集的 SSEs 都变大。因此，α存在一个最佳区域，可防止过度拟合并提高模型预测未知数据的能力。虽然这些观察并不普遍正确，但在许多问题上可以看到类似的模式。

![img/332789_2_En_15_Chapter/332789_2_En_15_Fig4_HTML.png](img/332789_2_En_15_Chapter/332789_2_En_15_Fig4_HTML.png)

图 15-4

训练和测试数据集(右)的系数(左)和误差平方和(SSEs)，用于作为正则化强度参数 *α* 的对数函数的 LASSO 回归

```py
In [39]: fig, axes = plt.subplots(1, 2, figsize=(12, 4), sharex=True)
    ...: for n in range(coeffs.shape[1]):
    ...:     axes[0].plot(np.log10(alphas), coeffs[:, n], color="k", lw=0.5)
    ...:
    ...: axes[1].semilogy(np.log10(alphas), sse_train, label="train")
    ...: axes[1].semilogy(np.log10(alphas), sse_test, label="test")
    ...: axes[1].legend(loc=0)
​    ...:
    ...: axes[0].set_xlabel(r"${\log_{10}}\alpha$", fontsize=18)
    ...: axes[0].set_ylabel(r"coefficients", fontsize=18)
    ...: axes[1].set_xlabel(r"${\log_{10}}\alpha$", fontsize=18)
    ...: axes[1].set_ylabel(r"sse", fontsize=18)

```

使用几个值 *α* 测试正则化回归的过程可以使用例如`RidgeCV`和`LassoCV`类自动执行。岭和套索回归的这些变体使用交叉验证方法在内部执行对最优 *α* 的搜索。默认情况下，使用一个 *k* -fold 交叉验证，其中 *k* = 3，尽管这可以使用这些类的`cv`参数进行更改。由于内置的交叉验证，我们不需要像以前那样将数据集明确划分为训练数据集和测试数据集。

要对自动选择的 *α* 使用套索方法，我们只需创建一个`LassoCV`实例并调用它的`fit`方法:

```py
In [40]: model = linear_model.LassoCV()
In [41]: model.fit(X_all, y_all)
Out[41]: LassoCV(alphas=None, copy_X=True, cv=None, eps=0.001, fit_intercept=True, max_iter=1000, n_alphas=100, n_jobs=1, normalize=False, positive=False, precompute="auto", random_state=None, selection="cyclic", tol=0.0001, verbose=False)

```

通过交叉验证搜索选择的正则化强度参数 *α* 的值可通过`alpha_`属性访问:

```py
In [42]: model.alpha_
Out[42]: 0.13118477495069433

```

我们注意到, *α* 的建议值与我们从图 [15-4](#Fig4) 中推测的值相当一致。为了与前面的方法进行比较，我们还计算了训练和测试数据集的 SSE(尽管两者都用于 LassoCV.fit 调用中的训练),并将 SSE 值与模型参数一起绘制成图，如图 [15-5](#Fig5) 所示。通过使用交叉验证的 LASSO 方法，我们获得了一个模型，该模型以相对较高的精度预测训练和测试数据集，并且我们不再可能遭受过度拟合的问题，尽管与特征的数量 <sup>[2](#Fn2)</sup> 相比样本很少。

```py
In [43]: resid_train = y_train - model.predict(X_train)
    ...: sse_train = sse(resid_train)
    ...: sse_train
Out[43]: 66.900068715063625
In [44]: resid_test = y_test - model.predict(X_test)
    ...: sse_test = sse(resid_test)
    ...: sse_test
Out[44]: 966.39293785448456
In [45]: fig, ax = plot_residuals_and_coeff(resid_train, resid_test, model.coef_)

```

![img/332789_2_En_15_Chapter/332789_2_En_15_Fig5_HTML.png](img/332789_2_En_15_Chapter/332789_2_En_15_Fig5_HTML.png)

图 15-5

对训练数据(左)和测试数据(中)进行交叉验证的 LASSO 正则化回归模型的残差。还显示了 50 个特征的系数值(右图)。

最后，还有另一种流行的正则化回归，它结合了套索和岭方法的 L1 和 L2 正则化，被称为弹性网正则化。该方法的最小化目标函数是![$$ {\min}_{\beta}\left\{{\left\Vert X\beta -y\right\Vert}_2^2+\alpha \rho {\left\Vert \beta \right\Vert}_1+\alpha \left(1-\rho \right){\left\Vert \beta \right\Vert}_2^2\right\} $$](img/332789_2_En_15_Chapter/332789_2_En_15_Chapter_TeX_IEq5.png)，其中参数 *ρ* (在 scikit-learn 中为`l1_ratio`)决定了 L1 和 L2 惩罚的相对权重，从而决定了该方法在多大程度上类似于套索和脊方法。在 scikit-learn 中，我们可以使用`ElasticNet`类执行弹性网回归，我们可以向该类给出 *α* ( `alpha`)和 *ρ* ( `l1_ratio`)参数的显式值，或者交叉验证版本`ElasticNetCV`，它会自动找到 *α* 和 *ρ* 参数的合适值:

```py
In [46]: model = linear_model.ElasticNetCV()
In [47]: model.fit(X_train, y_train)
Out[47]: ElasticNetCV(alphas=None, copy_X=True, cv=None, eps=0.001, fit_intercept=True, l1_ratio=0.5, max_iter=1000, n_alphas=100, n_jobs=1, normalize=False, positive=False, precompute="auto", random_state=None, selection="cyclic", tol=0.0001, verbose=0)

```

交叉验证搜索建议的正则化参数 *α* 和 *ρ* 的值可通过`alpha_`和`l1_ratio`属性获得；

```py
In [48]: model.alpha_
Out[48]: 0.13118477495069433
In [49]: model.l1_ratio
Out[49]: 0.5

```

为了与前面的方法进行比较，我们再次计算 SSE 并绘制模型系数，如图 [15-6](#Fig6) 所示。正如对 *ρ* = 0.5 的预期，结果同时具有套索回归(倾向于只有几个主要元素的稀疏解向量)和岭回归(抑制系数的幅度)的特征。

![img/332789_2_En_15_Chapter/332789_2_En_15_Fig6_HTML.png](img/332789_2_En_15_Chapter/332789_2_En_15_Fig6_HTML.png)

图 15-6

对训练数据(左)和测试数据(中)进行交叉验证的弹性网正则化回归模型的残差。还显示了 50 个特征的系数值(右图)。

```py
In [50]: resid_train = y_train - model.predict(X_train)
    ...: sse_train = sse(resid_train)
    ...: sse_train
Out[50]: 2183.8391729391255
In [51]: resid_test = y_test - model.predict(X_test)
    ...: sse_test = sse(resid_test)
    ...: sse_test
Out[51]: 2650.0504463382508
In [52]: fig, ax = plot_residuals_and_coeff(resid_train, resid_test, model.coef_)

```

## 分类

像回归一样，分类是机器学习中的一个中心话题。在第 [14](14.html) 章中，关于统计建模，我们已经看到了分类的例子，其中我们使用了逻辑回归模型将观察结果分类为离散的类别。逻辑回归也用于相同任务的机器学习，但也有各种各样的分类替代算法，如最近邻方法、支持向量机(SVM)、决策树和随机森林方法。scikit-learn 库提供了一个方便的统一 API，允许所有这些不同的方法在任何给定的分类问题上互换使用。

为了了解我们如何使用训练数据集训练分类模型，并在测试数据集上测试其性能，让我们再次看看 Iris 数据集，它提供了 Iris 花朵样本的特征(萼片和花瓣的宽度和高度)，以及每个样本的物种( *setosa* 、 *versicolor* 和 *virginica* )。scikit-learn 库中(以及 statsmodels 库中)包含的 Iris 数据集是一个经典数据集，通常用于测试和演示机器学习算法和统计模型。在这里，我们重新讨论根据萼片和花瓣的宽度和高度对花朵样本的种类进行分类的问题(参见第 [14 章](14.html))。首先，为了加载数据集，我们调用了`datasets`模块中的`load_iris`函数。结果是一个包含数据和元数据的容器对象(在 scikit-learn 行话中称为`Bunch`对象)。

```py
In [53]: iris = datasets.load_iris()
In [54]: type(iris)
Out[54]: sklearn.datasets.base.Bunch

```

例如，通过`feature_names`和`target_names`属性可以获得特征和目标类的描述性名称:

```py
In [55]: iris.target_names
Out[55]: array(['setosa', 'versicolor', 'virginica'], dtype='|S10')
In [56]: iris.feature_names
Out[56]: ['sepal length (cm)',  'sepal width (cm)',  'petal length (cm)',  'petal width (cm)']

```

实际的数据集可通过`data`和`target`属性获得:

```py
In [57]: iris.data.shape
Out[57]: (150, 4)
In [58]: iris.target.shape
Out[58]: (150,)

```

我们首先使用`train_test_split`函数将数据集分成训练和测试部分。我们选择将 70%的样本包含在训练集中，剩下的 30%用于测试和验证:

```py
In [59]: X_train, X_test, y_train, y_test = \
    ...:      model_selection.train_test_split(iris.data, iris.target, train_size=0.7)

```

使用 scikit-learn 训练分类器和执行分类任务的第一步是创建一个分类器实例。如前文所述以及下文所述，有许多可用的分类器。我们从一个逻辑回归分类器开始，它是由`linear_model`模块中的`LogisticRegression`类提供的:

```py
In [60]: classifier = linear_model.LogisticRegression()

```

分类器的训练是通过调用分类器实例的`fit`方法进行的。参数是特征和目标变量的设计矩阵。这里我们使用 Iris 数据集数组的训练部分，它是在使用`load_iris`函数加载数据集时为我们创建的。如果设计矩阵还不可用，我们可以使用我们在第 [14 章](14.html)中使用的相同技术:也就是说，使用 NumPy 函数手工构建矩阵，或者使用 Patsy 库自动构建适当的阵列。我们也可以使用 scikit-learn 库中的`feature_extraction`模块中的特征提取实用程序。

```py
In [61]: classifier.fit(X_train, y_train)
Out[61]: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, max_iter=100, multi_class="ovr", penalty="l2", random_state=None, solver="liblinear", tol=0.0001, verbose=0)

```

一旦训练了分类器，我们可以立即开始使用它来使用`predict`方法预测新观察的类别。在这里，我们应用这个方法来预测分配给测试数据集的样本的类别，以便我们可以将预测值与实际值进行比较。

```py
In [62]: y_test_pred = classifier.predict(X_test)

```

`sklearn.metrics`模块包含辅助函数，用于帮助分析分类器的性能和准确性。例如，`classification_report`函数采用实际值和预测值的数组，返回与假阴性和假阳性率相关的信息分类指标的表格摘要:

```py
In [63]: print(metrics.classification_report(y_test, y_test_pred))
             precision    recall  f1-score   support
          0       1.00      1.00      1.00        13
          1       1.00      0.92      0.96        13
          2       0.95      1.00      0.97        19
avg / total       0.98      0.98      0.98        45

```

所谓的混淆矩阵可以使用`confusion_matrix`函数来计算，它也以紧凑的形式提供了有用的分类度量:对角线对应于对类别变量的每个级别正确分类的样本数量，非对角线元素是错误分类的样本数量。更具体地，混淆矩阵 *C* 的元素 *C* <sub>*ij*</sub> 是被归类为 *j* 的类别 *i* 的样本的数量。对于当前数据，我们获得混淆矩阵:

```py
In [64]: metrics.confusion_matrix(y_test, y_test_pred)
Out[64]: array([[13  0  0]
                [ 0 12  1]
                [ 0  0 19]])

```

这个混淆矩阵表明，第一类和第三类中的所有元素都被正确分类，但第二类中的一个元素被错误地分类为第三类。请注意，混淆矩阵的每一行中的元素加起来就是相应类别的样本总数。在这个测试样本中，第一类和第二类各有 13 个元素，第三类有 19 个元素，通过计算`y_test`数组中的唯一值也可以看出:

```py
In [65]: np.bincount(y_test)
Out[65]: array([13, 13, 19])

```

要使用不同的分类器算法执行分类，我们需要做的就是创建相应分类器类的实例。例如，要使用决策树而不是逻辑回归，我们可以使用来自`sklearn.tree`模块的`DesicisionTreeClassifier`类。对所有分类器来说，训练分类器和预测新观察值的方式完全相同:

```py
In [66]: classifier = tree.DecisionTreeClassifier()
    ...: classifier.fit(X_train, y_train)
    ...: y_test_pred = classifier.predict(X_test)
    ...: metrics.confusion_matrix(y_test, y_test_pred)
Out[66]: array([[13,  0,  0],
                [ 0, 12,  1],
                [ 0,  1, 18]])

```

使用决策树分类器，得到的混淆矩阵有些不同，对应于测试数据集中的一个额外的错误分类。

scikit-learn 中可用的其他流行分类器包括来自`sklearn.neighbors`模块的最近邻分类器`KNeighborsClassifier`，来自`sklearn.svm`模块的支持向量分类器`VC)`，以及来自`sklearn.ensemble`模块的随机森林分类器`RandomForestClassifier`。因为它们都具有相同的使用模式，所以我们可以在同一问题上有计划地应用一系列分类器，并比较它们的性能(在这个特定问题上)，例如，作为训练和测试样本大小的函数。为此，我们创建了一个 NumPy 数组，其训练大小比率从 10%到 90%不等:

```py
In [67]: train_size_vec = np.linspace(0.1, 0.9, 30)

```

接下来，我们创建一个我们希望应用的分类器类列表:

```py
In [68]: classifiers = [tree.DecisionTreeClassifier,
    ...:                neighbors.KNeighborsClassifier,
    ...:                svm.SVC,
    ...:                ensemble.RandomForestClassifier]

```

以及一个数组，在该数组中，我们可以将混淆矩阵的对角线存储为训练大小比率和分类器的函数:

```py
In [69]: cm_diags = np.zeros((3, len(train_size_vec), len(classifiers)), dtype=float)

```

最后，我们循环每个训练大小比率和分类器，对于每个组合，我们训练分类器，预测测试数据的值，计算混淆矩阵，并将其对角线除以理想值存储在`cm_diags`数组中:

```py
In [70]: for n, train_size in enumerate(train_size_vec):
    ...:     X_train, X_test, y_train, y_test = \
    ...:         model_selection.train_test_split(iris.data, iris.target,
    ...:                                           train_size=train_size)
    ...:     for m, Classifier in enumerate(classifiers):
    ...:         classifier = Classifier()
    ...:         classifier.fit(X_train, y_train)
    ...:         y_test_p = classifier.predict(X_test)
    ...:         cm_diags[:, n, m] = metrics.confusion_matrix(y_test, y_test_p).diagonal()
    ...:         cm_diags[:, n, m] /= np.bincount(y_test)

```

图 [15-7](#Fig7) 绘制并显示了每个分类器的最终分类精度，作为训练大小比率的函数。

![img/332789_2_En_15_Chapter/332789_2_En_15_Fig7_HTML.png](img/332789_2_En_15_Chapter/332789_2_En_15_Fig7_HTML.png)

图 15-7

四种不同分类器的分类精度比较

```py
In [71]: fig, axes = plt.subplots(1, len(classifiers), figsize=(12, 3))
​    ...: for m, Classifier in enumerate(classifiers):
    ...:     axes[m].plot(train_size_vec, cm_diags[2, :, m], label=iris.target_names[2])
    ...:     axes[m].plot(train_size_vec, cm_diags[1, :, m], label=iris.target_names[1])
    ...:     axes[m].plot(train_size_vec, cm_diags[0, :, m], label=iris.target_names[0])
    ...:     axes[m].set_title(type(Classifier()).__name__)
    ...:     axes[m].set_ylim(0, 1.1)
    ...:     axes[m].set_ylabel("classification accuracy")
    ...:     axes[m].set_xlabel("training size ratio")
    ...:     axes[m].legend(loc=4)

```

在图 [15-7](#Fig7) 中，我们看到每个模型的分类误差都不同，但是对于这个特殊的例子，它们的性能相当。哪种分类器最好取决于手头的问题，一般情况下很难给出哪种分类器更适合的明确答案。幸运的是，在 scikit-learn 中很容易在不同的分类器之间切换，因此可以毫不费力地针对给定的分类问题尝试几种不同的分类器。除了分类精度之外，另一个重要的方面是计算性能和对更大问题的缩放。对于具有许多特征的大型分类问题，决策树方法(如随机森林)通常是一个很好的起点。

## 使聚集

在前两节中，我们探讨了回归和分类，这两者都是监督学习的例子，因为响应变量在数据集中给出。聚类是一种不同类型的问题，也是机器学习中的一个重要课题。它可以被认为是一个类别未知的分类问题，这使得聚类成为无监督学习的一个例子。聚类分析算法的训练数据集只包含特征变量，该算法的输出是一个整数数组，该数组将每个样本分配给一个分类(或类)。该输出数组对应于监督分类问题中的响应变量。

scikit-learn 库实现了大量的聚类算法，适用于不同类型的聚类问题和不同类型的数据集。流行的通用聚类方法包括 *K-means 算法*，其将样本分组为聚类，使得组内偏离组中心的平方和最小化，以及*均值漂移算法*，其通过将数据拟合到密度函数(例如，高斯函数)来对样本进行聚类。

在 scikit-learn 中，`sklearn.cluster`模块包含几种聚类算法，包括 K-means 算法`KMeans`和 mean-shift 算法`MeanShift`，仅举几例。为了使用这些方法中的一种来执行聚类任务，我们首先初始化相应类的一个实例，并使用`fit`方法用一个只包含特征的数据集来训练它，最后通过调用`predict`方法来获得聚类的结果。许多聚类算法需要将聚类数作为输入参数，我们可以在创建类实例时使用`n_clusters`参数来指定。

作为聚类的一个例子，再次考虑我们在上一节中使用的 Iris 数据集，但现在我们将不使用监督分类中使用的响应变量，而是尝试使用 *K* -means 方法自动发现样本的合适聚类。像以前一样，我们首先加载虹膜数据，并将特征和目标数据分别存储在变量`X`和`y`中:

```py
In [72]: X, y = iris.data, iris.target

```

使用 K-means 聚类方法，我们需要指定在输出中需要多少个聚类。最合适的聚类数并不总是事先就很明显，通常有必要尝试用几个不同的聚类数进行聚类。然而，这里我们知道数据对应于三种不同种类的鸢尾花，所以我们使用三个聚类。为了执行集群，我们创建了一个`Kmeans`类的实例，使用`n_clusters`参数来设置集群的数量。

```py
In [73]: n_clusters = 3
In [74]: clustering = cluster.KMeans(n_clusters=n_clusters)

```

为了实际执行计算，我们使用虹膜特征矩阵作为参数来调用`fit`方法:

```py
In [75]: clustering.fit(X)
Out[75]: KMeans(copy_x=True, init='k-means++', max_iter=300, n_clusters=3, n_init=10, n_jobs=1, precompute_distances="auto", random_state=None, tol=0.0001, verbose=0) 

```

通过`predict`方法可以获得聚类结果，我们还向该方法传递一个特征数据集，该数据集可以选择性地包含新样本的特征。然而，并非 scikit-learn 中实现的所有聚类方法都支持预测新样本的聚类。在这种情况下，`predict`方法不可用，我们需要使用`fit_predict`方法来代替。这里，我们对训练特征数据集使用`predict`方法来获得聚类结果:

```py
In [76]: y_pred = clustering.predict(X)

```

结果是一个长度和训练数据集中的样本数相同的整数数组。数组中的元素表示每个样本被分配到哪个组(从`0`到`n_samples-1`)。由于生成的数组`y_pred`很长，我们使用 NumPy stride 索引`::8`只显示数组中的第八个元素。

```py
In [77]: y_pred[::8]
Out[77]: array([1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0], dtype=int32)

```

我们可以将获得的聚类与虹膜样本的监督分类进行比较:

```py
In [78]: y[::8]
Out[78]: array([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2])

```

这两者之间似乎有很好的相关性，但是聚类的输出为组分配了与监督分类中的目标向量中所使用的不同的整数值。为了能够用诸如`confusion_matrix`函数这样的度量来比较这两个数组，我们首先需要重命名元素，以便相同的整数值用于同一个组。我们可以通过 NumPy 数组操作来完成此操作:

```py
In [79]: idx_0, idx_1, idx_2 = (np.where(y_pred == n) for n in range(3))
In [80]: y_pred[idx_0], y_pred[idx_1], y_pred[idx_2] = 2, 0, 1
In [81]: y_pred[::8]
Out[81]: array([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2], dtype=int32)

```

现在我们用相同的整数表示相应的组，我们可以使用`confusion_matrix`函数总结虹膜样本的监督和非监督分类之间的重叠:

```py
In [82]: metrics.confusion_matrix(y, y_pred)
Out[82]: array([[50,  0,  0],
                [ 0, 48,  2],
                [ 0, 14, 36]])

```

该混淆矩阵表明聚类算法能够正确地将对应于第一物种的所有样本识别为其自己的一组，但是由于第二和第三组中的重叠样本，这些样本不能被完全分辨为不同的聚类。例如，第一组中的 2 个元素被分配给第二组，第二组中的 14 个元素被分配给第一组。

聚类的结果也可以可视化，例如，通过绘制每对特征的散点图，如下所述。我们循环每对特征和每个聚类，并使用不同的颜色(橙色、蓝色和绿色，在图 [15-8](#Fig8) 中显示为不同的灰色阴影)为每个聚类绘制散点图，我们还在聚类与监督分类不一致的每个样本周围画一个红色方块。结果如图 [15-8](#Fig8) 所示。

![img/332789_2_En_15_Chapter/332789_2_En_15_Fig8_HTML.png](img/332789_2_En_15_Chapter/332789_2_En_15_Fig8_HTML.png)

图 15-8

使用 K-means 算法对 Iris 数据集特征进行聚类的结果

```py
In [83]: N = X.shape[1]
​    ...: fig, axes = plt.subplots(N, N, figsize=(12, 12), sharex=True, sharey=True)
    ...: colors = ["coral", "blue", "green"]
    ...: markers = ["^", "v", "o"]
    ...: for m in range(N):
    ...:     for n in range(N):
    ...:         for p in range(n_clusters):
    ...:             mask = y_pred == p
    ...:             axes[m, n].scatter(X[:, m][mask], X[:, n][mask], s=30,
    ...:                                marker=markers[p], color=colors[p], alpha=0.25)
    ...:         for idx in np.where(y != y_pred):
    ...:             axes[m, n].scatter(X[idx, m], X[idx, n], s=30,
    ...:                                marker="s", edgecolor="red", facecolor=(1,1,1,0))
    ...:     axes[N-1, m].set_xlabel(iris.feature_names[m], fontsize=16)
    ...:     axes[m, 0].set_ylabel(iris.feature_names[m], fontsize=16)

```

图 [15-8](#Fig8) 中虹膜样本的聚类结果表明，聚类在识别哪些样本属于不同的组方面做得非常好。当然，由于图中以蓝色(深灰)和绿色(中灰)显示的类的特征重叠，我们不能期望任何非监督聚类算法都可以完全解析数据集中的各种组，因此与监督响应变量存在一些偏差是可以预期的。

## 摘要

在这一章中，我们已经介绍了使用 Python 进行机器学习。我们首先简要回顾和总结了该主题及其术语，然后介绍了 Python 库 scikit-learn，我们将它应用于三种不同类型的问题，这些问题是机器学习中的基本主题:首先，我们从机器学习的角度重新回顾了回归，然后是分类，最后我们考虑了一个聚类示例。其中前两个主题是有监督机器学习的示例，而聚类方法是无监督机器学习的示例。除了我们已经能够在这里涵盖的，还有更多的方法和问题领域涵盖了广泛的机器学习主题。例如，机器学习的一个重要部分是基于文本的问题，我们在这个简短的介绍中没有涉及到。scikit-learn 包含一个扩展模块(`sklearn.text`)，其中包含用于处理基于文本的问题的工具和方法，而自然语言工具包( [`www.nltk.org`](http://www.nltk.org) )是一个功能强大的平台，用于处理人类语言文本形式的数据。图像处理和计算机视觉是机器学习中另一个突出的问题领域，例如，可以用 OpenCV ( [`http://opencv.org`](http://opencv.org) )及其 Python 绑定来处理。机器学习中的其他大主题的例子是神经网络和深度学习，近年来备受关注。对这类方法感兴趣的读者，推荐去探索 TensorFlow ( [`www.tensorflow.org`](http://www.tensorflow.org) )和 Keras 库( [`http://keras.io`](http://keras.io) )。

## 进一步阅读

机器学习是人工智能的计算机科学领域的一部分，这是一个具有众多技术、方法和应用的广阔领域。在这一章中，我们只能展示一些基本的机器学习方法的例子，尽管如此，这些方法在许多实际应用中还是很有用的。有关机器学习的更全面介绍，请参见 T. Hastie (2013)，有关特定于 Python 环境的机器学习的介绍，请参见例如 R. Garreta (2013)、Hackeling (2014)和 L. Pedro Coelho (2015)。

## 参考

哈克林，G. (2014)。使用 scikit-learn 掌握机器学习。孟买:Packt。

长度佩德罗·科埃略(2015 年)。用 Python 构建机器学习系统。孟买:Packt。

R.通用汽车公司加雷塔(2013 年)。学习 scikit-learn:Python 中的机器学习。孟买:Packt。

T.r . t . hastie(2013 年)。统计学习的要素:数据挖掘、推理和预测。纽约:斯普林格。

<aside class="FootnoteSection" epub:type="footnotes">Footnotes [1](#Fn1_source)

在实践中，同时使用 statsmodels 和 scikit-learn 是很常见的，因为它们在许多方面相互补充。然而，在本章中，我们只关注 scikit-learn。

  [2](#Fn2_source)

然而，请注意，在我们看到应用程序如何根据新的观察结果执行之前，我们永远无法确定机器学习应用程序不会遭受过度拟合，定期对应用程序进行重复的重新评估是一种良好的做法。

 </aside>