# 13.统计数字

统计学长期以来一直是一个数学领域，几乎与科学和工程的所有应用学科以及商业、医学和其他使用数据获取知识和做出决策的领域相关。随着最近数据分析的激增，人们对统计方法重新产生了兴趣。尽管如此，计算机辅助统计已经有很长的历史了，而且这个领域传统上一直由特定领域的软件包和编程环境所主导，例如 S 语言，以及最近它的开源对应物:R 语言。在过去的几年中，Python 在统计分析中的应用发展迅速，现在已经有了一个成熟的 Python 统计库集合。有了这些库，Python 可以在统计的许多领域(尽管不是所有领域)匹配特定于领域的语言的性能和功能，同时还提供了 Python 编程语言及其环境的独特优势。我们在第 [12](12.html) 章中讨论的 Pandas 库是 Python 社区内的一个发展实例，它受到统计软件的强烈影响，将数据框数据结构引入到 Python 环境中。NumPy 和 SciPy 库为许多基本的统计概念提供了计算工具，而更高级别的统计建模和机器学习则包含在`statsmodels`和`scikit-learn`库中，我们将在接下来的章节中看到更多。

在本章中，我们将重点介绍使用 Python 的基本统计应用，尤其是 SciPy 中的`stats`模块。在这里，我们讨论计算描述性统计，随机数，随机变量，分布和假设检验。我们将更复杂的统计建模和机器学习应用推迟到后面的章节。一些基本的统计函数也可以通过 NumPy 库获得，比如计算描述性统计的函数和方法以及生成随机数的模块。SciPy `stats`模块构建在 NumPy 之上，例如，它提供了具有更专业分布的随机数生成器。

## 导入模块

在本章中，我们主要使用 SciPy 中的`stats`模块，按照从 SciPy 中有选择地导入模块的惯例，我们在这里假设这个模块以及`optimize`模块是以如下方式导入的:

```py
In [1]: from scipy import stats
   ...: from scipy import optimize

```

此外，像往常一样，我们还需要 NumPy 和 Matplotlib 库:

```py
In [2]: import numpy as np
In [3]: import matplotlib.pyplot as plt

```

对于统计图和样式，我们使用 Seaborn 库:

```py
In [4]: import seaborn as sns
In [5]: sns.set(style="whitegrid")

```

## 统计与概率复习

我们首先简要回顾一下统计学，以便介绍我们在本章和后面几章中使用的一些关键概念和符号。统计学处理数据的收集和分析，目的是获得洞察力，得出结论，并支持决策。当我们对某一现象的信息不完全时，统计方法是必要的。通常情况下，我们的信息是不完整的，因为我们无法从*群体*的所有成员中收集数据，或者如果在我们进行的观察中存在*不确定性*(例如，由于测量噪声)。当我们无法调查整个人口时，可以研究随机选择的*样本*，我们可以使用统计方法和计算描述性统计数据(参数，如平均值和方差)来系统地推断整个人口(也称为*样本空间*)的特性，并控制误差风险。

统计方法建立在概率论提供的基础上，通过概率论，我们可以使用概率随机变量对不确定性和不完全信息进行建模。例如，使用*随机选择的*总体样本，我们可以希望获得代表性样本，其属性可用于推断整个总体的属性。在概率论中，观察的每个可能结果都有一个概率，所有可能结果的概率构成了概率分布。给定概率分布，我们可以计算总体的属性，如均值和方差，但对于随机选择的样本，我们只知道*预期*或平均结果。

在统计分析中，区分总体统计和样本统计是很重要的。这里，我们用希腊符号表示总体参数，用相应的总体符号加上下标 *x* (或用于表示样本的符号)表示样本参数。例如，一个总体的均值和方差用 *μ* 和*σ*T6】2 表示，一个样本的均值和方差 *x* 用*μ*T12】T13】xT15】和![$$ {\sigma}_x^2 $$](../images/332789_2_En_13_Chapter/332789_2_En_13_Chapter_TeX_IEq1.png)表示。此外，我们用大写字母表示代表总体(随机变量)的变量，例如， *X* ，用小写字母表示一组样本元素，例如， *x* 。符号上的横条表示平均值或均值，![$$ \mu =\overline{X}=\frac{1}{N}\sum \limits_{i=1}^N\ {x}_i $$](../images/332789_2_En_13_Chapter/332789_2_En_13_Chapter_TeX_IEq2.png)和![$$ {\mu}_x=\overline{x}=\frac{1}{n}\sum \limits_{i=1}^n\ {x}_i, $$](../images/332789_2_En_13_Chapter/332789_2_En_13_Chapter_TeX_IEq3.png)，其中 *N* 是总体中元素的数量 *X* ，而 *n* 是样本中元素的数量 *x* 。这两个表达式的唯一区别是 sum 中元素的个数( *N* ≥ *n* )。对于方差来说，情况稍微复杂一些:总体方差是距均值的平方距离的均值![$$ {\sigma}^2=\frac{1}{N}\sum \limits_{i=1}^N{\left({x}_i-\mu \right)}^2 $$](../images/332789_2_En_13_Chapter/332789_2_En_13_Chapter_TeX_IEq4.png)，对应的样本方差是![$$ {\sigma}_x^2=\frac{1}{n-1}\sum \limits_{i=1}^n{\left({x}_i-{\mu}_x\right)}^2\. $$](../images/332789_2_En_13_Chapter/332789_2_En_13_Chapter_TeX_IEq5.png)在后一个表达式中，我们用样本均值 *μ* <sub>* x *</sub> 替换了总体均值 *μ* ，并用*n*1 而不是 *n* 来除和。其原因是，在计算样本均值 *μ* <sub>* x *</sub> 时，样本集中已经消除了一个自由度，因此在计算样本方差时，只剩下*n*1 个自由度。因此，计算总体和样本方差的方法略有不同。这反映在 Python 中我们可以用来计算这些统计数据的函数中。

在第 [2](02.html) 章中，我们已经看到，我们可以使用 NumPy 函数或相应的`ndarray`方法来计算数据的描述性统计。例如，为了计算数据集的平均值和中值，我们可以使用 NumPy 函数`mean`和`median`:

```py
In [6]: x = np.array([3.5, 1.1, 3.2, 2.8, 6.7, 4.4, 0.9, 2.2])
In [7]: np.mean(x)
Out[7]: 3.1
In [8]: np.median(x)
Out[8]: 3.0

```

类似地，我们可以使用`min`和`max`函数或`ndarray`方法来计算数组中的最小值和最大值:

```py
In [9]: x.min(), x.max()
Out[9]: (0.90, 6.70)

```

为了计算数据集的方差和标准差，我们使用了`var`和`std`方法。默认情况下，使用总体方差和标准差的公式(即假设数据集是整个总体)。

```py
In [10]: x.var()
Out[10]: 3.07
In [11]: x.std()
Out[11]: 1.7521415467935233

```

但是，要改变这种行为，我们可以使用参数`ddof` (delta 自由度)。方差表达式中的分母是数组中的元素数减去`ddof`，因此要计算方差的无偏估计和样本的标准偏差，我们需要设置`ddof=1`:

```py
In [12]: x.var(ddof=1)
Out[12]: 3.5085714285714293
In [13]: x.std(ddof=1)
Out[13]: 1.8731181032095732

```

在接下来的小节中，我们将更详细地介绍如何使用 NumPy 和 SciPy 的`stats`模块来生成随机数、表示随机变量和分布，以及测试假设。

## 随机数

Python 标准库包含模块`random`，该模块提供了用一些基本分布生成单个随机数的函数。NumPy 模块中的`random`模块提供了类似的功能，但是提供了用随机数生成 NumPy 数组的函数，并且它支持更广泛的概率分布选择。具有随机数的数组对于计算来说通常是实用的，所以这里我们关注 NumPy 中的`random`模块，稍后还有`scipy.stats`中的高级函数和类，它们构建在 NumPy 之上并扩展了 NumPy。

在本书前面，我们已经使用过`np.random.rand`，它在半开区间[0，1]内生成均匀分布的浮点数(即 0.0 是可能的结果，1.0 不是)。除了这个函数之外，`np.random`模块还包含一个用于生成随机数的其他函数的大集合，这些随机数覆盖不同的间隔，具有不同的分布，并且取不同类型的值(例如，浮点数和整数)。例如，`randn`函数产生按照*标准正态分布*(均值为 0，标准差为 1 的正态分布)分布的随机数，而`randint`函数产生给定低值(含)和高值(不含)之间均匀分布的整数。当不带任何参数调用`rand`和`randn`函数时，它们会产生一个随机数:

```py
In [14]: np.random.rand()
Out[14]: 0.532833024789759
In [15]: np.random.randn()
Out[15]: 0.8768342101492541

```

但是，将数组的形状作为参数传递给这些函数会产生随机数数组。例如，这里我们使用`rand`通过传递一个参数 5 来生成一个长度为 5 的向量，使用`randn`通过传递 2 和 4 作为参数来生成一个 2 × 4 的数组(更高维的数组是通过传递每个维度的长度作为参数来生成的):

```py
In [16]: np.random.rand(5)
Out[16]: array([ 0.71356403,  0.25699895,  0.75269361,  0.88387918,  0.15489908])
In [17]: np.random.randn(2, 4)
Out[17]: array([[ 3.13325952,  1.15727052,  1.37591514,  0.94302846],
                [ 0.8478706 ,  0.52969142, -0.56940469,  0.83180456]])

```

为了使用`randint`(参见`random_integers`)生成随机整数，我们需要要么提供随机数的上限(在这种情况下，下限隐含为零)，要么提供下限和上限。使用`size`关键字参数指定生成的数组的大小，它可以是整数或指定多维数组形状的元组:

```py
In [18]: np.random.randint(10, size=10)
Out[18]: array([0, 3, 8, 3, 9, 0, 6, 9, 2, 7])
In [19]: np.random.randint(low=10, high=20, size=(2, 10))
Out[19]: array([[12, 18, 18, 17, 14, 12, 14, 10, 16, 19],
                [15, 13, 15, 18, 11, 17, 17, 10, 13, 17]])

```

注意`randint`函数在半开区间【低，高】生成随机整数。为了证明由`rand`、`randn,`和`randint`产生的随机数确实是不同分布的，我们可以画出由每个函数产生的 10000 个随机数的直方图。结果如图 [13-1](#Fig1) 所示。我们注意到`rand`和`randint`的分布看起来是均匀的，但是具有不同的范围和类型，而`randn`产生的数字的分布就像预期的那样，类似于以零为中心的高斯曲线。

![../images/332789_2_En_13_Chapter/332789_2_En_13_Fig1_HTML.png](../images/332789_2_En_13_Chapter/332789_2_En_13_Fig1_HTML.png)

图 13-1

NumPy 的`random`模块中的`rand`、`randn`和`randint`函数生成的 10000 个随机数的分布

```py
In [20]: fig, axes = plt.subplots(1, 3, figsize=(12, 3))
    ...: axes[0].hist(np.random.rand(10000))
    ...: axes[0].set_title("rand")
    ...: axes[1].hist(np.random.randn(10000))
    ...: axes[1].set_title("randn")
    ...: axes[2].hist(np.random.randint(low=1, high=10, size=10000), bins=9, align="left")
    ...: axes[2].set_title("randint(low=1, high=10)")

```

在统计分析中，经常需要生成一个唯一的整数列表。这相当于从一个集合(总体)中抽样(随机选择)项目而不替换(这样我们就不会两次得到相同的项目)。从 NumPy `random`模块中，我们可以使用`choice`函数来生成这种类型的随机数。作为第一个参数，我们可以提供一个包含人口中的值的列表(或数组),也可以提供一个与人口中的元素数量相对应的整数。作为第二个参数，我们给出了要采样的值的数量。可以使用`replace`关键字参数指定采样值是否替换，该参数采用布尔值`True`或`False`。例如，要从 0(含)和 10(不含)之间的整数集中抽取五个唯一的(无替换)项，我们可以使用

```py
In [21]: np.random.choice(10, 5, replace=False)
Out[21]: array([9, 0, 5, 8, 1])

```

当处理随机数生成时，*播种*随机数生成器会很有用。种子是一个将随机数生成器初始化为特定状态的数字，因此一旦它被植入了特定的数字，它总是生成相同的随机数序列。这在测试和重现以前的结果时非常有用，有时在需要为随机数生成器重新设定种子的应用程序中也很有用(例如，在分叉一个进程后)。要在 NumPy 中播种随机数生成器，我们可以使用`seed`函数，它接受一个整数作为参数:

```py
In [22]: np.random.seed(123456789)
In [23]: np.random.rand()
Out[23]: 0.532833024789759

```

请注意，在为随机数生成器植入特定的数字(此处为 123456789)后，对随机数生成器的以下调用总是会产生相同的结果:

```py
In [24]: np.random.seed(123456789); np.random.rand()
Out[24]: 0.532833024789759

```

随机数发生器的种子是`np.random`模块的全局状态。通过使用`RandomState`类可以更好地控制随机数生成器的状态，该类可以选择将一个种子整数作为其初始化器的参数。`RandomState`对象跟踪随机数发生器的状态，并允许在同一个程序中维护几个独立的随机数发生器(这很有用，例如，当使用线程应用程序时)。一旦创建了一个`RandomState`对象，我们就可以使用这个对象的方法来生成随机数。`RandomState`类有对应于`np.random`模块中可用函数的方法。例如，我们可以使用`RandomState`类的方法`randn`来生成标准的正态分布随机数:

```py
In [25]: prng = np.random.RandomState(123456789)
In [26]: prng.randn(2, 4)
Out[26]: array([[ 2.212902,    2.1283978,   1.8417114,   0.08238248],
                [ 0.85896368, -0.82601643,  1.15727052,  1.37591514]])

```

同样还有方法，`rand`，`randint`，`rand_integers`，`choice`，也对应着`np.random`模块中同名的函数。使用`RandomState`实例而不是直接使用`np.random`模块中的函数被认为是良好的编程实践，因为它避免了依赖全局状态变量并提高了代码的隔离性。在开发使用随机数的库函数时，这是一个重要的考虑因素，但在较小的应用程序和计算中，这可能不太重要。

除了我们到目前为止看到的基本随机数分布(离散和连续均匀分布，`randint`和`rand`，以及标准正态分布，`randn`)，还有函数和`RandomState`方法，用于统计中出现的大量概率分布。仅举几个，就有连续的*χ*T9】2 分布(`chisquare`)，学生的 *t* 分布(`standard_t`)，以及 *F* 分布(`f`):

```py
In [27]: prng.chisquare(1, size=(2, 2))
Out[27]: array([[ 0.78631596,  0.19891367],
                [ 0.11741336,  2.8713997 ]])
In [28]: prng.standard_t(1, size=(2, 3))
Out[28]: array([[ 0.39697518, -0.19469463,  1.15544019],
                [-0.65730814, -0.55125015,  0.13578694]])
In [29]: prng.f(5, 2, size=(2, 4))
Out[29]: array([[  0.45471421,  17.64891848,   1.48620557,   2.55433261],
                [  1.21823269,   3.47619315,   0.50835525,   0.70599655]])

```

以及离散二项式分布(`binomial`)和泊松分布(`poisson`):

```py
In [30]: prng.binomial(10, 0.5, size=10)
Out[30]: array([4, 5, 6, 7, 3, 5, 7, 5, 4, 5])
In [31]: prng.poisson(5, size=10)
Out[31]: array([3, 5, 5, 5, 0, 6, 5, 4, 6, 3])

```

有关可用分布函数的完整列表，请参见`np.random`模块、`help(np.random)`和`RandomState`类的文档字符串。虽然可以使用`np.random`中的函数和`RandomState`中的方法从许多不同的统计分布函数中提取随机数，但在处理分布时，`scipy.stats`模块中有一个高级接口，它将随机数采样与许多其他方便的概率分布函数结合起来。在下一节中，我们将对此进行更详细的探讨。

## 随机变量和分布

在概率论中，随机过程的可能结果的集合被称为*样本空间*。样本空间中的每个元素(即，实验或观察的结果)可以被分配一个概率，并且所有可能结果的概率定义了概率分布。*随机变量*是从样本空间到实数或整数的映射。例如，掷硬币的可能结果是正面和反面，所以样本空间是{正面，反面}，一个可能的随机变量取值 0 表示正面，1 表示反面。总的来说，有许多方法来定义给定随机过程的可能结果的随机变量。随机变量是随机过程中与问题无关的表示。处理随机变量更容易，因为它们是由数字描述的，而不是来自特定问题样本空间的结果。因此，解决统计问题的一个常见步骤是将结果映射为数值，并计算出这些值的概率分布。

因此，随机变量的特征在于它的可能值及其概率分布，概率分布为每个可能值分配一个概率。随机变量的每次观察都会产生一个随机数，观察值的分布由概率分布来描述。有两种主要类型的分布，离散和连续分布，它们分别是整数值和实数值。在处理统计数据时，处理随机变量至关重要，在实践中这通常意味着处理概率分布。SciPy `stats`模块提供了表示具有大量概率分布的随机变量的类。离散和连续随机变量有两个基类:`rv_discrete`和`rv_continuous`。这些类不是直接使用的，而是作为特定分布的随机变量的基类，在 SciPy `stats`中为所有随机变量类定义了一个公共接口。表 [13-1](#Tab1) 总结了离散和连续随机变量的选择方法。

表 13-1

SciPy `stats`模块中离散和连续随机变量的选择方法

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"></colgroup> 
| 

方法

 | 

描述

 |
| --- | --- |
| `pdf/pmf` | 概率分布函数(连续)或概率质量函数(离散)。 |
| `cdf` | 累积分布函数。 |
| `sf` | 生存函数(1–CDF)。 |
| `ppf` | 百分点函数(cdf 的倒数)。 |
| `moment` | n 阶非中心矩。 |
| `stats` | 分布的统计数据(通常是平均值和方差，有时是附加统计数据)。 |
| `fit` | 使用数值最大似然优化使分布符合数据(对于连续分布)。 |
| `expect` | 函数关于分布的期望值。 |
| `interval` | 包含给定分布百分比的区间的端点(置信区间)。 |
| `rvs` | 随机变量样本。将结果样本数组的大小作为参数。 |
| `mean`、`median`、`std`、`var` | 描述性统计:平均值、中位数、标准差和分布的方差。 |

SciPy `stats`模块中有大量离散和连续随机变量的类。在撰写本文时，有 13 个离散分布和 98 个连续分布的类，其中包括最常见的分布(和许多不太常见的)。要获得完整的参考，请参见`stats`模块的 docstring:`help(stats)`。在下文中，我们将探讨一些更常见的发行版，但是所有其他发行版的使用都遵循相同的模式。

SciPy `stats`模块中的随机变量类有几个用例。它们都是分布的表示，可用于计算描述性统计数据和绘制图表，也可用于使用`rvs`(随机变量样本)方法生成遵循给定分布的随机数。后一种用例类似于我们在本章前面使用的`np.random`模块。

为了演示如何使用 SciPy `stats`中的随机变量类，考虑下面的例子，我们创建了一个均值为 1.0、标准差为 0.5 的正态分布随机变量:

```py
In [32]: X = stats.norm(1, 0.5)

```

现在`X`是一个表示随机变量的对象，我们可以使用例如`mean`、`median`、`std`和`var`方法来计算这个随机变量的描述性统计数据:

```py
In [33]: X.mean()
Out[33]: 1.0
In [34]: X.median()
Out[34]: 1.0
In [35]: X.std()
Out[35]: 0.5
In [36]: X.var()
Out[36]: 0.25

```

任意阶的非中心矩可以用`moment`方法计算:

```py
In [37]: [X.moment(n) for n in range(5)]
Out[37]: [1.0, 1.0, 1.25, 1.75, 2.6875]

```

我们可以使用`stats`方法获得一个依赖于分布的统计列表(这里，对于一个正态分布的随机变量，我们得到平均值和方差):

```py
In [38]: X.stats()
Out[38]: (array(1.0), array(0.25))

```

我们可以评估概率分布函数、累积分布函数、生存函数等。，使用`pdf`、cdf、`sf`等方法。这些函数都采用一个值或一组值来计算函数:

```py
In [39]: X.pdf([0, 1, 2])
Out[39]: array([ 0.10798193,  0.79788456,  0.10798193])
In [40]: X.cdf([0, 1, 2])
Out[40]: array([ 0.02275013,  0.5,         0.97724987])

```

`interval`方法可用于计算 *x* 的下限值和上限值，使得概率分布的给定百分比落在区间(下限值、上限值)内。该方法有助于计算置信区间和选择一系列的 *x* 值进行绘图:

```py
In [41]: X.interval(0.95)
Out[41]: (0.020018007729972975, 1.979981992270027)
In [42]: X.interval(0.99)
Out[42]: (-0.28791465177445019, 2.2879146517744502)

```

为了直观地了解概率分布的特性，将它与相应的累积概率函数和百分点函数一起用图表表示是很有用的。为了更容易地对几个分布重复这个过程，我们首先创建一个函数`plot_rv_distribution`，它在包含概率分布函数的 99.9%的区间内绘制 SciPy `stats`随机变量对象的`pdf`或`pmf`、`cdf`和`sf`以及`ppf`方法的结果。我们还使用`fill_between`绘图方法突出显示了包含 95%概率分布的区域:

```py
In [43]: def plot_rv_distribution(X, axes=None):
    ...:     """Plot the PDF or PMF, CDF, SF and PPF of a given random variable"""
    ...:     if axes is None:
    ...:         fig, axes = plt.subplots(1, 3, figsize=(12, 3))
    ...:
    ...:     x_min_999, x_max_999 = X.interval(0.999)
    ...:     x999 = np.linspace(x_min_999, x_max_999, 1000)
    ...:     x_min_95, x_max_95 = X.interval(0.95)
    ...:     x95 = np.linspace(x_min_95, x_max_95, 1000)
    ...:
    ...:     if hasattr(X.dist, "pdf"):
    ...:         axes[0].plot(x999, X.pdf(x999), label="PDF")
    ...:         axes[0].fill_between(x95, X.pdf(x95), alpha=0.25)
    ...:     else:
    ...:         # discrete random variables do not have a pdf method, instead we use pmf:
    ...:         x999_int = np.unique(x999.astype(int))
    ...:         axes[0].bar(x999_int, X.pmf(x999_int), label="PMF")
    ...:     axes[1].plot(x999, X.cdf(x999), label="CDF")
    ...:     axes[1].plot(x999, X.sf(x999), label="SF")
    ...:     axes[2].plot(x999, X.ppf(x999), label="PPF")
    ...:
    ...:     for ax in axes:
    ...:         ax.legend()

```

接下来我们用这个函数来绘制一些分布的例子:正态分布、 *F* 分布和离散泊松分布。结果如图 [13-2](#Fig2) 所示。

![../images/332789_2_En_13_Chapter/332789_2_En_13_Fig2_HTML.png](../images/332789_2_En_13_Chapter/332789_2_En_13_Fig2_HTML.png)

图 13-2

正态分布(上图)、f 分布(中图)和泊松分布(下图)的概率分布函数(PDF)或概率质量函数(PMF)、累积分布函数(CDF)、生存函数(SF)和百分点函数(PPF)的示例

```py
In [44]: fig, axes = plt.subplots(3, 3, figsize=(12, 9))
​    ...: X = stats.norm()
    ...: plot_rv_distribution(X, axes=axes[0, :])
    ...: axes[0, 0].set_ylabel("Normal dist.")
    ...: X = stats.f(2, 50)
    ...: plot_rv_distribution(X, axes=axes[1, :])
    ...: axes[1, 0].set_ylabel("F dist.")
    ...: X = stats.poisson(5)
    ...: plot_rv_distribution(X, axes=axes[2, :])
    ...: axes[2, 0].set_ylabel("Poisson dist.") 

```

在到目前为止的示例中，我们已经初始化了一个随机变量类的实例，并使用方法调用计算统计数据和其他属性。在 SciPy 的`stats`模块中使用随机变量类的另一种方法是使用类方法，例如`stats.norm.mean`，并将分布参数作为参数传递(通常是`loc`和`scale`，如本例中的正态分布值):

```py
In [45]: stats.norm.stats(loc=2, scale=0.5)
Out[45]: (array(2.0), array(0.25))

```

这与首先创建一个实例，然后调用相应的方法产生相同的结果:

```py
In [46]: stats.norm(loc=1, scale=0.5).stats()
Out[46]: (array(1.0), array(0.25))

```

以这种方式，`rv_discrete`和`rv_continuous`类中的大多数方法都可以用作类方法。

到目前为止，我们只研究了随机变量的分布函数的性质。请注意，虽然分布函数描述的是随机变量，但分布本身是完全确定的。要画出按照给定的概率分布分布的随机数，我们可以用`rvs`(随机变量样本)的方法。它将所需数组的形状作为参数(对于向量可以是整数，对于更高维的数组可以是一组维度长度)。这里我们使用`rvs(10)`来生成一个有十个值的一维数组:

```py
In [47]: X = stats.norm(1, 0.5)
In [48]: X.rvs(10)
Out[48]: array([2.106451,    2.0641989,   1.9208557,  1.04119124,  1.42948184,
                0.58699179,  1.57863526,  1.68795757, 1.47151423,  1.4239353 ])

```

为了看到产生的随机数确实是根据相应的概率分布函数分布的，我们可以绘制一个随机变量的大量样本的直方图，并将其与概率分布函数进行比较。同样，为了能够对几个随机变量的样本容易地做到这一点，我们为此创建了一个函数`plot_dist_samples`。该函数使用`interval`方法为给定的随机变量对象获取合适的绘图范围。

```py
In [49]: def plot_dist_samples(X, X_samples, title=None, ax=None):
    ...:     """ Plot the PDF and histogram of samples of a continuous random variable"""
    ...:     if ax is None:
    ...:          fig, ax = plt.subplots(1, 1, figsize=(8, 4))
​    ...:
    ...:     x_lim = X.interval(.99)
    ...:     x = np.linspace(*x_lim, num=100)
​    ...:
    ...:     ax.plot(x, X.pdf(x), label="PDF", lw=3)
    ...:     ax.hist(X_samples, label="samples", normed=1, bins=75)
    ...:     ax.set_xlim(*x_lim)
    ...:     ax.legend()
    ...:
    ...:     if title:
    ...:         ax.set_title(title)
    ...:     return ax

```

注意，在这个函数中，我们使用了元组解包语法`*x_lim`，它将元组`x_lim`中的元素分配给函数的不同参数。在这种情况下，它相当于`np.linspace(x_lim[0], x_lim[1], num=100)`。

接下来我们用这个函数来可视化三个不同分布的随机变量的 2000 个样本:这里我们用学生的 *t* 分布、 *χ* <sup>2</sup> 分布、指数分布，结果如图 [13-3](#Fig3) 所示。由于 2000 年是一个相当大的样本，样本的直方图与概率分布函数非常吻合。随着样本数量的增加，可以预期一致性会更好。

![../images/332789_2_En_13_Chapter/332789_2_En_13_Fig3_HTML.png](../images/332789_2_En_13_Chapter/332789_2_En_13_Fig3_HTML.png)

图 13-3

概率分布函数(PDF)以及来自学生的 *t* 分布(左)、 *χ* <sup>2</sup> 分布(中)和指数分布(右)的 2000 个随机样本的直方图

```py
In [50]: fig, axes = plt.subplots(1, 3, figsize=(12, 3))
    ...: N = 2000
    ...: # Student's t distribution
    ...: X = stats.t(7.0)
    ...: plot_dist_samples(X, X.rvs(N), "Student's t dist.", ax=axes[0])
    ...: # The chisquared distribution
    ...: X = stats.chi2(5.0)
    ...: plot_dist_samples(X, X.rvs(N), r"$\chi^2$ dist.", ax=axes[1])
    ...: # The exponential distribution
    ...: X = stats.expon(0.5)
    ...: plot_dist_samples(X, X.rvs(N), "exponential dist.", ax=axes[2]) 

```

与从已知分布函数中抽取随机样本相反的是，将带有未知参数的给定概率分布拟合到一组数据点。在这样的拟合中，我们通常希望优化未知参数，使得观察到给定数据的可能性最大化。这被称为最大似然拟合。SciPy `stats`模块中的许多随机变量类实现了对给定数据进行拟合的方法`fit`。作为第一个例子，考虑从具有五个自由度(`df=5`)的χ <sup>2</sup> 分布中抽取 500 个随机样本，然后使用`fit`方法将随机变量重新调整为χ <sup>2</sup> 分布。

```py
In [51]: X = stats.chi2(df=5)
In [52]: X_samples = X.rvs(500)
In [53]: df, loc, scale = stats.chi2.fit(X_samples)
In [54]: df, loc, scale
Out[54]: (5.2886783664198465, 0.0077028130326141243, 0.93310362175739658)
In [55]: Y = stats.chi2(df=df, loc=loc, scale=scale)

```

对于给定的数据，`fit`方法返回分布的最大似然参数。我们可以将这些参数传递给`stats.chi2`的初始化器来创建一个新的随机变量实例`Y`。`Y`的概率分布应该类似于原始随机变量`X`的概率分布。为了验证这一点，我们可以画出两个随机变量的概率分布函数。结果图如图 [13-4](#Fig4) 所示。

![../images/332789_2_En_13_Chapter/332789_2_En_13_Fig4_HTML.png](../images/332789_2_En_13_Chapter/332789_2_En_13_Fig4_HTML.png)

图 13-4

原始和重建的概率分布函数(左)和误差(右)，来自原始分布的 500 个随机样本的最大似然拟合

```py
In [56]:  fig, axes = plt.subplots(1, 2, figsize=(12, 4))
    ...: x_lim = X.interval(.99)
    ...: x = np.linspace(*x_lim, num=100)
    ...:
    ...: axes[0].plot(x, X.pdf(x), label="original")
    ...: axes[0].plot(x, Y.pdf(x), label="recreated")
    ...: axes[0].legend()
    ...:
    ...: axes[1].plot(x, X.pdf(x) - Y.pdf(x), label="error")
    ...: axes[1].legend()

```

在本节中，我们探讨了如何使用 SciPy stats 模型中的随机变量对象来描述具有各种分布的随机变量，以及如何使用它们来计算给定分布的属性，并生成随机变量样本和执行最大似然拟合。在下一节中，我们将看到如何进一步使用这些随机变量对象进行假设检验。

## 假设检验

假设检验是科学方法的基石，它要求对主张进行客观调查，并在事实观察的基础上拒绝或接受主张。统计假设检验有更具体的含义。它是一种系统的方法，以数据为基础，评估一个主张或假设是否合理。因此，它是统计学的一个重要应用。在这种方法中，我们用一个零假设和一个替代假设来表述假设，零假设代表当前被接受的知识状态，替代假设代表挑战当前知识状态的新主张。零假设和备择假设必须是互斥的和互补的，因此有且只有一个假设是正确的。

一旦 *H* <sub>0</sub> 和 *H* <sub>*A*</sub> 被定义，支持测试的数据必须被收集，例如，通过测量、观察或调查。下一步是找到一个可以从数据中计算出来的检验统计量，其概率分布函数可以在零假设下找到。接下来，我们可以使用零假设所暗示的分布函数，通过计算获得测试统计的观察值(或更极端的值)的概率(p 值*T11)来评估数据。如果*p*-值小于预定的阈值，称为显著性水平，用 *α* (通常为 5%或 1%)表示，我们可以得出结论，观察到的数据不太可能用对应于零假设的分布来描述。在这种情况下，我们可以因此拒绝零假设，支持替代假设。下表总结了执行假设检验的步骤:*

1.  阐明零假设和替代假设。

2.  选择一个检验统计量，使其在零假设下的抽样分布是已知的(精确或近似)。

3.  收集数据。

4.  根据数据计算测试统计量，并计算其在零假设下的 *p* 值。

5.  如果 *p* 值小于预定的显著性水平 *α* ，我们拒绝零假设。如果*p*-值较大，我们无法拒绝零假设。

统计假设检验是一种概率方法，这意味着我们不能确定是否拒绝零假设。可能有两种错误:我们可能错误地拒绝零假设，而实际上它不应该被拒绝；我们可能在应该拒绝零假设时没有拒绝零假设。这些分别被称为第一类和第二类错误。通过选择所需的显著性水平，我们可以平衡这两种类型的误差。

一般来说，上一节概述的方法中最具挑战性的步骤是知道测试统计的抽样分布。幸运的是，许多假设检验属于概率分布已知的几个标准类别。表 [13-2](#Tab2) 给出了常见假设检验案例及其检验统计量相应分布的简要总结和概述。关于为什么这些测试中的每一个都适合所述情况的动机，以及测试有效性的全套条件，参见统计学教科书，如乏色曼(2004)或赖斯(1995)。SciPy `stats`模块中列出的每个函数的 docstring 还包含关于每个测试的更多信息。

表 13-2

具有相应分布和 SciPy 函数的常见假设检验案例摘要

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"></colgroup> 
| 

虚假设

 | 

分布

 | 

测试的 SciPy 函数

 |
| --- | --- | --- |
| 测试总体的平均值是否为给定值。 | 正态分布(`stats.norm`)，或者学生的 *t* 分布(`stats.t`) | `stats.ttest_1samp` |
| 测试两个随机变量的均值是否相等(独立样本或成对样本)。 | 学生的分布(`stats.t`) | `stats.ttest_ind`，`stats.ttest_rel` |
| 测试连续分布对数据的拟合优度。 | 科尔莫戈罗夫-斯米尔诺夫分布 | `stats.kstest` |
| 测试分类数据是否以给定的频率出现(正态分布变量的平方和)。 | χ <sup>2</sup> 分布(`stats.chi2`) | `stats.chisquare` |
| 列联表中分类变量独立性的检验。 | χ <sup>2</sup> 分布(`stats.chi2`) | `stats.chi2_contingency` |
| 检验两个或多个变量样本的方差是否相等。 | *F* 分布(`stats.f`) | `stats.barlett`，`stats.levene` |
| 两个变量之间不相关的检验。 | 贝塔分布(`stats.beta, stasts.mstats.betai`) | `stats.pearsonr`，`stats.spearmanr` |
| 测试两个或多个变量是否具有相同的总体均值(ANOVA–方差分析)。 | *F* 分布 | `stats.f_oneway, stats.kruskal` |

在下文中，我们还将查看如何使用 SciPy `stats`模块中的相应函数来执行前面给出的过程中的步骤 4 和 5 的示例:计算测试统计和相应的 *p* 值。

例如，一个常见的无效假设是声称总体的均值 *μ* 是某个值*μ*T4】0。然后，我们可以对总体进行抽样，并使用样本均值![$$ \overline{x} $$](../images/332789_2_En_13_Chapter/332789_2_En_13_Chapter_TeX_IEq6.png)来形成检验统计量![$$ z=\frac{\overline{x}-{\mu}_0}{\sigma /\sqrt{n}} $$](../images/332789_2_En_13_Chapter/332789_2_En_13_Chapter_TeX_IEq7.png)，其中 *n* 是样本大小。如果总体很大，并且方差 *σ* 已知，那么使用假设检验统计量正态分布是合理的。如果方差未知，我们可以用样本方差![$$ {\sigma}_x^2 $$](../images/332789_2_En_13_Chapter/332789_2_En_13_Chapter_TeX_IEq8.png)代替*σ*T14】2。然后，检验统计遵循学生的 *t* 分布，在大量样本的限制下，该分布接近正态分布。不管我们最终使用哪种分布，我们都可以使用给定的分布为测试统计计算一个 *p* 值。

作为如何使用 SciPy `stats`模块提供的函数进行这种假设检验的示例，考虑一个声称随机变量 *X* 的均值*μ*T5】0= 1 的零假设。给定样本 *X* ，然后我们希望测试采样数据是否符合零假设。这里，我们通过从与零假设(使用 *μ* = 0.8)声称的分布略有不同的分布中抽取 100 个随机样本来模拟样本:

```py
In [57]: mu0, mu, sigma = 1.0, 0.8, 0.5
In [58]: X = stats.norm(mu, sigma)
In [59]: n = 100
In [60]: X_samples = X.rvs(n)

```

给定样本数据`X_samples`，接下来我们需要计算一个检验统计量。如果已知总体标准差 *σ* ，如本例所示，我们可以使用正态分布的![$$ z=\frac{\overline{x}-{\mu}_0}{\sigma /\sqrt{n}} $$](../images/332789_2_En_13_Chapter/332789_2_En_13_Chapter_TeX_IEq9.png)。

```py
In [61]: z = (X_samples.mean() - mu0)/(sigma/np.sqrt(n))
In [62]: z
Out[62]: -2.8338979550098298

```

如果总体方差未知，我们可以用样本标准差来代替:![$$ t=\frac{\overline{x}-\mu }{\sigma_x/\sqrt{n}} $$](../images/332789_2_En_13_Chapter/332789_2_En_13_Chapter_TeX_IEq10.png)。然而，在这种情况下，测试统计数据 *t* 遵循学生的 *t* 分布，而不是正态分布。为了在这种情况下计算 *t* ，我们可以使用带有`ddof=1`参数的 NumPy 方法`std`来计算样本标准偏差:

```py
In [63]: t = (X_samples.mean() - mu0)/(X_samples.std(ddof=1)/np.sqrt(n))
In [64]: t
Out[64]: -2.9680338545657845

```

在这两种情况下，我们都会得到一个检验统计量，可以与相应的分布进行比较，以获得一个 *p* 值。例如，对于正态分布，我们可以使用一个`stats.norm`实例来表示一个正态分布的随机变量，通过它的`ppf`方法，我们可以查找对应于某个显著性水平的统计值。对于显著性水平为 5%(每侧 2.5%)的双侧假设检验，统计阈值为

```py
In [65]: stats.norm().ppf(0.025)
Out[65]: -1.9599639845400545

```

由于观察到的统计值约为-2.83，小于显著性水平为 5%的双边检验的阈值-1.96，我们有足够的理由拒绝这种情况下的零假设。我们可以使用`cdf`方法显式计算观察到的测试统计的 *p* 值(对于双边测试，乘以 2)。得到的 *p* 值确实相当小，这支持了对零假设的拒绝:

```py
In [66]: 2 * stats.norm().cdf(-abs(z))
Out[66]: 0.0045984013290753566

```

如果我们想使用 *t* 分布，我们可以使用`stats.t`类代替`stats.norm`。计算样本平均值![$$ \overline{x} $$](../images/332789_2_En_13_Chapter/332789_2_En_13_Chapter_TeX_IEq11.png)后，样本数据中只剩下*n*—1 个自由度(`df`)。自由度的数量是 *t* 分布的一个重要参数，我们需要在创建随机变量实例时指定:

```py
In [67]: 2 * stats.t(df=(n-1)).cdf(-abs(t))
Out[67]: 0.0037586479674227209

```

p 的*值再次非常小，这表明我们应该拒绝零假设。不是显式地执行这些步骤(计算测试统计，然后计算*p*-值)，而是在 SciPy 的`stats`模块中有内置函数来执行许多常见的测试，如表 [13-2](#Tab2) 中所总结的。对于我们在这里使用的测试，我们可以使用`stats.ttest_1samp`函数直接计算测试统计数据和*p*-值:*

```py
In [68]: t, p = stats.ttest_1samp(X_samples, mu)
In [69]: t
Out[69]: -2.9680338545657841
In [70]: p
Out[70]: 0.0037586479674227209

```

我们再次看到*p*-值非常小(与前面文本中的值相同)，我们应该拒绝零假设。绘制与零假设相对应的分布以及采样数据也很有说明性(见图 [13-5](#Fig5) ):

![../images/332789_2_En_13_Chapter/332789_2_En_13_Fig5_HTML.png](../images/332789_2_En_13_Chapter/332789_2_En_13_Fig5_HTML.png)

图 13-5

根据零假设的分布函数(浅绿色)和样本估计分布函数(深蓝色)

```py
In [71]: fig, ax = plt.subplots(figsize=(8, 3))
    ...: sns.distplot(X_samples, ax=ax)
    ...: x = np.linspace(*X.interval(0.999), num=100)
    ...: ax.plot(x, stats.norm(loc=mu, scale=sigma).pdf(x))

```

作为另一个例子，考虑两个变量的问题，其中零假设表明两个随机变量的总体均值相等(例如，对应于接受和未接受治疗的独立受试者)。我们可以通过创建两个正态分布的随机变量来模拟这种类型的测试，并随机选择总体均值。这里我们为每个随机变量选择 50 个样本。

```py
In [72]: n, sigma = 50, 1.0
In [73]: mu1, mu2 = np.random.rand(2)
In [74]: X1 = stats.norm(mu1, sigma)
In [75]: X1_sample = X1.rvs(n)
In [76]: X2 = stats.norm(mu2, sigma)
In [77]: X2_sample = X2.rvs(n)

```

我们感兴趣的是评估观察样本是否提供了两个总体均值不相等的充分证据(拒绝零假设)。对于这种情况，我们可以对两个独立的样本使用 *t* 测试，这在 SciPy `stats.ttext_ind`中可用，它返回测试统计和相应的*p*-值:

```py
In [78]: t, p = stats.ttest_ind(X1_sample, X2_sample)
In [79]: t
Out[79]: -1.4283175246005888
In [80]: p
Out[80]: 0.15637981059673237

```

这里的*p*-值约为 0.156，这个值不足以支持拒绝两个均值不同的零假设。在本例中，两个总体均值确实不同:

```py
In [81]: mu1, mu2
Out[81]: (0.24764580637159606, 0.42145435527527897)

```

然而，从这些分布中抽取的特定样本并没有从统计上证明这些平均值是不同的(第二类误差)。为了提高统计检验的功效，我们需要增加每个随机变量的样本数。

SciPy `stats`模块包含常见假设检验类型的函数(参见表 [13-2](#Tab2) 中的总结)，它们的使用与我们在本节示例中看到的非常相似。但是，有些测试需要分布参数的附加参数。有关详细信息，请参见每个单独测试函数的文档字符串。

## 非参数方法

到目前为止，我们已经描述了分布完全由几个参数决定的随机变量，例如正态分布的均值和方差。给定采样数据，我们可以使用关于分布参数的最大似然优化来拟合分布函数。这种分布函数称为*参数*，基于这种分布函数的统计方法(如假设检验)称为*参数方法*。当使用这些方法时，我们强烈假设采样数据确实由给定的分布描述。构建未知分布函数表示的另一种方法是*核密度估计* (KDE)，它可以被视为采样数据直方图的平滑版本(参见图 [13-6](#Fig6) )。在这种方法中，概率分布是通过以每个数据点![$$ \widehat{f}(x)=\frac{1}{n\cdotp \mathrm{bw}}\sum \limits_{i=0}^nK\left(\frac{x-{x}_i}{\mathrm{bw}}\right) $$](../images/332789_2_En_13_Chapter/332789_2_En_13_Chapter_TeX_IEq12.png)为中心的核函数的总和来估计的，其中 bw 是一个称为带宽的自由参数，而 *K* 是核函数(归一化，以便积分为 1)。带宽是一个重要参数，它定义了总和中每一项的影响范围。太宽的带宽给出了一个无特征的概率分布估计，而太小的带宽给出了一个有噪声的过度结构化的估计(见图 [13-6](#Fig6) 中的中间面板)。核函数的不同选择也是可能的。高斯核是一种流行的选择，因为它具有平滑的形状和局部支持，并且相对容易执行计算。

![../images/332789_2_En_13_Chapter/332789_2_En_13_Fig6_HTML.png](../images/332789_2_En_13_Chapter/332789_2_En_13_Fig6_HTML.png)

图 13-6

直方图(左)，分布函数的核密度估计(中)，以及同一图形中的直方图和核密度估计(右)

在 SciPy 的中，使用高斯核的 KDE 方法在函数`stats.kde.gaussian_kde`中实现。该函数返回一个可调用的对象，该对象的行为类似于概率分布函数，并且可以用作概率分布函数。例如，考虑从具有未知分布的随机变量 *X* 中抽取的一组样本`X_samples`(这里使用具有五个自由度的*χ*T6】2 分布进行模拟):

```py
In [82]: X = stats.chi2(df=5)
In [83]: X_samples = X.rvs(100)

```

为了计算给定数据的核密度估计，我们调用函数`stats.kde.guassian_kde`,将样本点数组作为参数:

```py
In [84]: kde = stats.kde.gaussian_kde(X_samples)

```

默认情况下，使用计算合适带宽的标准方法，这通常会给出可接受的结果。然而，如果我们愿意，我们也可以指定一个函数来计算带宽，或者使用`bw_method`参数直接设置带宽。例如，要设置较小的带宽，我们可以使用

```py
In [85]: kde_low_bw = stats.kde.gaussian_kde(X_samples, bw_method=0.25)

```

`gaussian_kde`函数返回分布函数的估计值，例如，我们可以用它来绘图或用于其他应用。这里我们绘制了数据和两个内核密度估计值的直方图(使用默认和显式设置的带宽)。作为参考，我们还绘制了样本的真实概率分布函数。结果如图 [13-6](#Fig6) 所示。

```py
In [86]: x = np.linspace(0, 20, 100)
In [87]: fig, axes = plt.subplots(1, 3, figsize=(12, 3))
    ...: axes[0].hist(X_samples, normed=True, alpha=0.5, bins=25)
    ...: axes[1].plot(x, kde(x), label="KDE")
    ...: axes[1].plot(x, kde_low_bw(x), label="KDE (low bw)")
    ...: axes[1].plot(x, X.pdf(x), label="True PDF")
    ...: axes[1].legend()
    ...: sns.distplot(X_samples, bins=25, ax=axes[2])

```

`seaborn`统计图形库为绘制一组数据的直方图和核密度估计提供了一个方便的函数:`distplot`。该功能产生的图形如图 [13-6](#Fig6) 的右面板所示。

给定内核密度估计值，我们还可以使用它来生成新的随机数，使用`resample`方法，该方法将数据点的数量作为参数:

```py
In [88]: kde.resample(10)
Out[88]: array([[1.75376869,  0.5812183,  8.19080268,  1.38539326,  7.56980335,
                1.16144715,  3.07747215,  5.69498716,  1.25685068,  9.55169736]])

```

内核密度估计对象不直接包含计算累积分布函数(CDF)及其逆函数，即百分点函数(PPF)的方法。但是有几种方法可以对概率分布函数的核密度估计进行积分。例如，对于一维 KDE，我们可以使用`integrate_box_1d`来获得相应的 CDF:

```py
In [89]: def _kde_cdf(x):
    ...:     return kde.integrate_box_1d(-np.inf, x)
In [90]: kde_cdf = np.vectorize(_kde_cdf)

```

并且可以使用 SciPy `optimize.fsolve`函数来求逆(PPF):

```py
In [91]: def _kde_ppf(q):
    ...:     return optimize.fsolve(lambda x, q: kde_cdf(x) - q, kde.dataset.mean(), args=(q,))[0]
    ...:                            
In [92]: kde_ppf = np.vectorize(_kde_ppf)

```

例如，有了核密度估计的 CDF 和 PPF，我们可以进行统计假设检验和计算置信区间。例如，使用上一节中定义的`kde_ppf`函数，我们可以计算样本总体平均值的大约 90%置信区间:

```py
In [93]: kde_ppf([0.05, 0.95])
Out[93]: array([  0.39074674,  11.94993578])

```

如本例所示，一旦我们有了代表统计问题概率分布的 KDE，我们就可以继续使用参数统计中使用的许多相同方法。非参数方法的优点是我们不一定需要对分布函数的形状做出假设。然而，因为非参数方法比参数方法使用更少的信息(更弱的假设)，所以它们的统计功效更低。因此，如果我们可以证明使用参数方法的合理性，那么这通常是最好的方法。非参数方法提供了一个通用的方法，当参数方法不可行时，我们可以依靠它。

## 摘要

在本章中，我们探讨了如何在基本统计应用中使用 NumPy 和 SciPy `stats`模块，包括随机数生成、表示随机变量和概率分布函数、数据分布的最大似然拟合，以及使用概率分布和测试统计进行假设检验。作为非参数方法的一个例子，我们也简要地看了未知概率分布的核密度估计。本章讨论的概念和方法是处理统计数据的基础，这里介绍的计算工具也为许多统计应用提供了基础。在接下来的章节中，我们将在这里讨论的基础上，更深入地探讨统计建模和机器学习。

## 进一步阅读

赖斯(1995)和乏色曼(2004)对统计学和数据分析的基础做了很好的介绍。Dalgaard (2008)给出了面向计算的统计学介绍，尽管它使用 R 语言，但也与 Python 中的统计学相关。也有免费的关于统计学的在线资源，例如，OpenIntro Statistics，可以从 [`www.openintro.org/stat/textbook.php`](http://www.openintro.org/stat/textbook.php) 获得。

## 参考

达尔加德教授(2008 年)。纽约:施普林格出版社。

赖斯，J. A. (1995 年)。*数理统计与数据分析。贝尔蒙特:杜克斯伯里出版社。*

乏色曼大学(2004 年)。*所有的统计数据。*纽约:施普林格。