# 8.使用决策树的分类

这一章介绍了最普遍的集成方法，决策树。决策树分类器估计分类因变量或连续因变量。它解决了二进制和多类分类问题。我们将模型建立在树状结构的基础上。它将数据分解成小的、可管理的块，同时增量地开发决策树。结果是一个具有决策节点和叶节点的树状结构。我们认为它是一个贪婪的模型，因为它主要关心的是减少训练时间，同时最大化信息增益。

为了充分利用决策树，需要预先了解数据和分区。我们通过将训练数据递归分割成决策节点来构建决策树。此后，我们检查变量和基于检查结果的分支情况。

它选择预测能力强、杂质少、熵低的变量。它还探讨了减少杂质的最重要的变量。最重要的是分区后叶片的纯度；它在节点上发现具有最低熵的树。总之，决策树分类器有两个用途:将数据分成不同的子集和缩短决策树的分支。它限制了树的深度。

## 熵

熵表示对随机性或不确定性的估计。熵越低，分布越不均匀，节点越多。它显示了数据的无序程度。它估计节点中样本的同质性。如果变量是齐次的，那么熵为零。如果我们平分样本，那么熵就是 1。我们用等式 8-1 来估计熵。

![$$ Entropy=p(A)\kern0.5em \mathit{\log}\left(p(A)\right)-p(B)\mathit{\log}\left(p(B)\right) $$](../images/506148_1_En_8_Chapter/506148_1_En_8_Chapter_TeX_Equ1.png)

(方程式 8-1)

这里， *p* 是一个范畴的 prop 或 ratio。我们使用熵将可比较的数据分组为可比较的类别。高熵表明我们有高度无序的数据。低熵值表明数据组织良好。该模型假设较不纯的节点需要较少的信息来描述它，而较不纯的节点需要更多的信息。

决策树估计节点的熵，然后估计分区的每个节点的熵。然后，加权子节点的平均值和估计信息增益，并选择具有最高信息增益的节点进行划分。为决策树分类组织数据包括将数据分区，并将样本按它们所属的类分组，并在每次发展一个节点时最大化组的纯度。

## 信息增益

信息增益是指在划分之后增加确定性水平的信息。它是熵的反义词。如果加权熵减少，那么信息增益增加，反之亦然。总之，决策树分类器找到返回最值得注意的信息增益的变量。为了计算信息增益，我们使用等式 8-2。

![$$ Information\ gain=\left( Entropy\ before\ the\ split\right)-\Big( Weighted\ entropy\ after\ the\ split $$](../images/506148_1_En_8_Chapter/506148_1_En_8_Chapter_TeX_Equ2.png)

(方程式 8-2)

## 决策树的结构

如上所述，决策树是基于流程图的树状结构。决策树使用一组`if` - `then` - `else`决策规则来估计正弦曲线。决策规则的复杂性取决于树的深度。决策树包含决策节点和叶节点。最上面的决策节点对应于根节点(值得注意的自变量)。叶节点是一个分类或决策。图 [8-1](#Fig1) 显示了决策树的结构。

![../images/506148_1_En_8_Chapter/506148_1_En_8_Fig1_HTML.png](../images/506148_1_En_8_Chapter/506148_1_En_8_Fig1_HTML.png)

图 8-1

决策树结构

## 开发决策树分类器

清单 [8-1](#PC1) 开发了一个带有默认超参数的决策树分类器。

```
from sklearn.tree import plot_tree
from sklearn.tree import DecisionTreeClassifier
dt = DecisionTreeClassifier()
dt.fit(x_train,y_train)

Listing 8-1Develop the Decision Tree Classifier with Default Hyperparameters

```

### 决策树超参数优化

有许多可调的决策树超参数。我们只涉及两个关键的超参数:`criterion`和`max_depth.`标准包括`gini`杂质和`entropy`。默认情况下，标准是`gini`，它给出了每个标签或类的概率。较高的值表示高均匀性。清单 [8-2](#PC2) 找到最佳超参数。

```
param_griddt = {"criterion":("gini","entropy"),
                "max_depth":[1,3,5,7,9,12]}
grid_modeldt = GridSearchCV(estimator=dt, param_grid=param_griddt)
grid_modeldt.fit(x_train,y_train)
print("Best score: ", grid_modeldt.best_score_, "Best parameters:", grid_modeldt.best_params_)

Listing 8-2Hyperparameter Optimization

```

最佳得分:0.7182993469278954 最佳参数:{'criterion': 'entropy '，' max_depth': 3}

前面的结果表明，我们应该使用`entropy`作为标准，并将 3 设置为树的最大深度。参见清单 [8-3](#PC3) 。

```
dt = DecisionTreeClassifier(criterion= 'entropy', max_depth= 3)
dt.fit(x_train,y_train)

Listing 8-3Finalize the Decision Tree Classifier

```

### 可视化决策树

清单 [8-4](#PC4) 可视化了决策树(见图 [8-2](#Fig2) )。

![../images/506148_1_En_8_Chapter/506148_1_En_8_Fig2_HTML.jpg](../images/506148_1_En_8_Chapter/506148_1_En_8_Fig2_HTML.jpg)

图 8-2

决策图表

```
plt.figure(figsize=(24,14))
tree.plot_tree(dt, filled=True)
plt.show()

Listing 8-4Visualize the Decision Tree

```

### 特征重要性

特征重要性决定了自变量对因变量的相对重要性。它给每个自变量分配一个从 0 到 1 的分数。得分最高的自变量是最重要的变量，得分第二高的自变量是第二重要的变量，依此类推。列表 [8-5](#PC5) 绘制特征重要性(见图 [8-3](#Fig3) )。

![../images/506148_1_En_8_Chapter/506148_1_En_8_Fig3_HTML.jpg](../images/506148_1_En_8_Chapter/506148_1_En_8_Fig3_HTML.jpg)

图 8-3

特征重要性

```
diabetes_features = [x for i,x in enumerate(df.columns) if i!=8]
def plot_feature_importances_diabetes(model):
    plt.figure(figsize=(8,6))
    n_features = 8
    plt.barh(range(n_features), model.feature_importances_, align="center")
    plt.yticks(np.arange(n_features), diabetes_features)
    plt.xlabel("Feature Importance")
    plt.ylabel("Feature")
    plt.ylim(-1, n_features)
plot_feature_importances_diabetes(dt)
plt.savefig('feature_importance')

Listing 8-5Feature Importance

```

图 [8-3](#Fig3) 显示了因变量有几个重要变量。葡萄糖得分最高，这意味着它比因变量(糖尿病结果)的其他变量更重要。其后分别是`bmi`和`age,`。

我们使用以前的发现来减少数据中的变量数量。清单 [8-6](#PC6) 减少了数据。

```
x = df[["Glucose","DiabetesPedigreeFunction","Age"]]
x = df.iloc[::,0:8]
y = df.iloc[::,-1]
x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=0)
scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test)
dt = DecisionTreeClassifier(criterion= 'entropy', max_depth= 3)
dt.fit(x_train,y_train)

Listing 8-6Re-processing

```

### 评估决策树分类器

清单 [8-7](#PC7) 返回一个比较实际值和预测值的表格(见表格 [8-1](#Tab1) )。

表 8-1

实际值和预测值

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"></colgroup> 
|   | 

实际的

 | 

预测

 |
| --- | --- | --- |
| **661** | one | one |
| **122** | Zero | Zero |
| **113** | Zero | Zero |
| **14** | one | Zero |
| **529** | Zero | Zero |
| **...** | ... | ... |
| **第 476 章** | one | Zero |
| **第 482 章** | Zero | Zero |
| **230** | one | one |
| **527** | Zero | Zero |
| **380** | Zero | Zero |

```
y_preddt = dt.predict(x_test)
pd.DataFrame({"Actual":y_test, "Predicted": y_preddt})

Listing 8-7Actual Values and Predicted Values

```

#### 混淆矩阵

清单 [8-8](#PC8) 和表格 [8-2](#Tab2) 展示了决策树分类器的性能。它有四种实际值和预测值的组合。

表 8-2

混淆矩阵

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"></colgroup> 
|   | 

预测:否

 | 

预测:是

 |
| --- | --- | --- |
| **实际:否** | Ninety-three | Fourteen |
| **实际:是** | Twenty-three | Twenty-four |

```
cmatdt = pd.DataFrame(metrics.confusion_matrix(y_test,y_preddt), index=["Actual: No","Actual: Yes"],
columns=("Predicted: No","Predicted: Yes"))
cmatdt

Listing 8-8Confusion Matrix

```

#### 分类报告

为了深入了解决策树分类器的性能，我们使用分类报告。清单 [8-9](#PC9) 列出了一份分类报告(见表 [8-3](#Tab3) )。

表 8-3

分类报告

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"> <col class="tcol4 align-left"> <col class="tcol5 align-left"></colgroup> 
|   | 

精确

 | 

召回

 | 

f1-分数

 | 

支持

 |
| --- | --- | --- | --- | --- |
| **0** | 0.801724 | 0.869159 | 0.834081 | 107.00000 |
| **1** | 0.631579 | 0.510638 | 0.564706 | 47.00000 |
| **精度** | 0.759740 | 0.759740 | 0.759740 | 0.75974 |
| **宏平均值** | 0.716652 | 0.689899 | 0.699393 | 154.00000 |
| **加权平均值** | 0.749797 | 0.759740 | 0.751869 | 154.00000 |

```
creportdt = pd.DataFrame(metrics.classification_report(y_test,y_preddt, output_dict=True)).transpose()
creportdt

Listing 8-9Classification Report

```

表 [8-3](#Tab3) 表明决策树分类器表现不佳。准确度分数为 74%，比逻辑回归分类器、线性支持向量分类器和线性判别分析分类器的准确度分数低大约 8%。该分类器还具有比两个分类器更低的精度分数。

#### 受试者工作特征曲线

最可靠的方法是预测每一类的概率。首先，我们预测每一类的概率。此后，我们构建 ROC 并找到 AUC。列表 [8-10](#PC10) 产生一条 ROC 曲线(见图 [8-4](#Fig4) )。

![../images/506148_1_En_8_Chapter/506148_1_En_8_Fig4_HTML.jpg](../images/506148_1_En_8_Chapter/506148_1_En_8_Fig4_HTML.jpg)

图 8-4

受试者工作特征曲线

```
y_preddt_proba = dt.predict_proba(x_test)[::,1]
fprdt, tprdt, _ = metrics.roc_curve(y_test,y_preddt_proba)
aucdt = metrics.roc_auc_score(y_test, y_preddt_proba)
plt.plot(fprdt, tprdt, label="AUC: "+str(aucdt), color="navy")
plt.plot([0,1],[0,1],color="red")
plt.xlim([0.00,1.01])
plt.ylim([0.00,1.01])
plt.xlabel("Specificity")
plt.ylabel("Sensitivity")
plt.legend(loc=4)
plt.show()

Listing 8-10ROC Curve

```

图 [8-4](#Fig4) 显示 AUC 评分接近 80%。理想情况下，我们希望 AUC 得分大于 80%。先前的 AUC 分数显示分类器不善于区分类别。

#### 精确回忆曲线

列表 [8-11](#PC11) 产生了一条曲线，给出了关于假阳性和假阴性的有意义的洞察(见图 [8-5](#Fig5) )。

![../images/506148_1_En_8_Chapter/506148_1_En_8_Fig5_HTML.jpg](../images/506148_1_En_8_Chapter/506148_1_En_8_Fig5_HTML.jpg)

图 8-5

精确回忆曲线

```
precisiondt, recalldt, thresholddt = metrics.precision_recall_curve(y_test,y_preddt)
apsdt = metrics.roc_auc_score(y_test,y_preddt)
plt.plot(precisiondt, recalldt, label="APS: "+str(apsdt),color="navy")
plt.axhline(y=0.5,color="red")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.legend(loc=4)
plt.show()

Listing 8-11Precision-Recall Curve

```

不考虑决策阈值，APS 为 69%。

#### 学习曲线

清单 [8-12](#PC12) 生成一条曲线，描绘了 LinearSVC 分类器在学习训练数据时的精度变化(见图 [8-6](#Fig6) )。

![../images/506148_1_En_8_Chapter/506148_1_En_8_Fig6_HTML.jpg](../images/506148_1_En_8_Chapter/506148_1_En_8_Fig6_HTML.jpg)

图 8-6

学习曲线

```
trainsizedt, trainscoredt, testscoredt = learning_curve(dt, x, y, cv=5, n_jobs=5, train_sizes=np.linspace(0.1,1.0,50))
trainscoredt_mean = np.mean(trainscoredt,axis=1)
testscoredt_mean = np.mean(testscoredt,axis=1)
plt.plot(trainsizedt,trainscoredt_mean,color="red", label="Training Score")
plt.plot(trainsizedt,testscoredt_mean,color="navy", label="Cross Validation Score")
plt.xlabel("Training Set Size")
plt.ylabel("Accuracy")
plt.legend(loc=4)
plt.show()

Listing 8-12Learning Curve

```

图 [8-6](#Fig6) 显示从决策树分类器学习数据开始，训练准确率得分就高于交叉验证。分类器开始时非常乐观，但随着我们增加训练集，大小会下降，并在 0.75 到 0.80 的范围内变得舒适。

## 结论

本章展示了树分类建模技术，包括发现最佳超参数、发现对因变量最重要的变量，以及仅使用导入变量和最佳超参数来可视化决策树和分类器。有替代的分类器可以唯一地扩展决策树分类器，比如额外树和随机森林树。额外的树随机分割决策树的一个点。随机森林树迭代地并行构建多个决策树。