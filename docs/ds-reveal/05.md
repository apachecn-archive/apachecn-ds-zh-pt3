# 5.逻辑回归分析

本章以结构化的方式介绍了逻辑回归的概念和实现。前面的章节介绍了监督学习，并集中在参数方法。在监督学习中，我们提供一个具有一组正确答案的模型，然后我们允许一个模型预测看不见的数据。我们使用参数方法来解决回归问题(当因变量是连续变量时)。

本章介绍一种被认为是非参数方法(或分类方法)的监督学习方法。与线性回归方法不同，它对数据结构有灵活的假设。它没有线性和正态假设。分类方法有两个完整的系列。它们是二元分类，在因变量有两种结果(即是/否、通过/失败)时使用，以及多类分类，在因变量有两种以上结果(负/中性/正)时使用。

## 什么是逻辑回归？

逻辑回归是一种估计自变量影响因变量程度的模型。自变量是连续变量或分类变量，因变量总是只有两个结果的分类变量。logistic 回归虽然叫*回归*，但它不是回归模型，而是分类模型。像线性回归一样，我们使用模型来寻找截距和斜率。

## 逻辑回归假设

分类方法不包含关于数据结构的严格假设。它假设因变量是分类变量，并且数据中有超过 50 个数据点。理想情况下，我们需要一个大样本。

## 实践中的逻辑回归

我们从 Kaggle 获得了示例数据。 <sup>[1](#Fn1)</sup> 表 [5-1](#Tab1) 显示第一行数据。

表 5-1

资料组

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"> <col class="tcol4 align-left"> <col class="tcol5 align-left"> <col class="tcol6 align-left"> <col class="tcol7 align-left"> <col class="tcol8 align-left"> <col class="tcol9 align-left"> <col class="tcol10 align-left"></colgroup> 
|   | 

怀孕

 | 

葡萄糖

 | 

血压

 | 

表皮厚度

 | 

胰岛素

 | 

身体质量指数

 | 

糖尿病患者

 | 

年龄

 | 

结果

 |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| **0** | six | One hundred and forty-eight | seventy-two | Thirty-five | Zero | Thirty-three point six | Zero point six two seven | Fifty | one |
| **1** | one | eighty-five | Sixty-six | Twenty-nine | Zero | Twenty-six point six | Zero point three five one | Thirty-one | Zero |
| **2** | eight | One hundred and eighty-three | Sixty-four | Zero | Zero | Twenty-three point three | Zero point six seven two | Thirty-two | one |
| **3** | one | eighty-nine | Sixty-six | Twenty-three | Ninety-four | Twenty-eight point one | Zero point one six seven | Twenty-one | Zero |
| **4** | Zero | One hundred and thirty-seven | Forty | Thirty-five | One hundred and sixty-eight | Forty-three point one | Two point two eight eight | Thirty-three | one |

## Sigmoid 函数

逻辑回归使用 sigmoid 函数对输出进行转换，以便快速返回分配给两个类别的概率值。的标准公式是 S 形或 S 形。图 [5-1](#Fig1) 显示了一个标准的逻辑功能。

![../images/506148_1_En_5_Chapter/506148_1_En_5_Fig1_HTML.jpg](../images/506148_1_En_5_Chapter/506148_1_En_5_Fig1_HTML.jpg)

图 5-1

Sigmoid 函数

等式 5-1 表达了 sigmoid 函数。

![$$ S(x)=\frac{L}{1-{e}^{-x}}=\frac{e^x}{e^x+1} $$](../images/506148_1_En_5_Chapter/506148_1_En_5_Chapter_TeX_Equ1.png)

(Equation 5-1)

标准 sigmoid 函数接受任何输入，并输出一个介于 0 和 1 之间的值。

## 描述性分析

列表 [5-1](#PC1) 产生描述性统计数据(见表 [5-2](#Tab2) )。

表 5-2

描述统计学

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"> <col class="tcol4 align-left"> <col class="tcol5 align-left"> <col class="tcol6 align-left"> <col class="tcol7 align-left"> <col class="tcol8 align-left"> <col class="tcol9 align-left"></colgroup> 
|   | 

数数

 | 

意思是

 | 

标准

 | 

部

 | 

25%

 | 

50%

 | 

75%

 | 

最大

 |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| **怀孕** | Seven hundred and sixty-eight | 3.845052 | 3.369578 | Zero | 1.00000 | 3.0000 | 6.00000 | Seventeen |
| **葡萄糖** | Seven hundred and sixty-eight | 120.894531 | 31.972618 | Zero | 99.00000 | 117.0000 | 140.25000 | One hundred and ninety-nine |
| **血压** | Seven hundred and sixty-eight | 69.105469 | 19.355807 | Zero | 62.00000 | 72.0000 | 80.00000 | One hundred and twenty-two |
| **皮肤厚度** | Seven hundred and sixty-eight | 20.536458 | 15.952218 | Zero | 0.00000 | 23.0000 | 32.00000 | Ninety-nine |
| **胰岛素** | Seven hundred and sixty-eight | 79.799479 | 115.244002 | Zero | 0.00000 | 30.5000 | 127.25000 | Eight hundred and forty-six |
| **身体质量指数** | Seven hundred and sixty-eight | 31.992578 | 7.884160 | Zero | 27.30000 | 32.0000 | 36.60000 | Sixty-seven point one |
| **糖尿病糖尿病功能** | Seven hundred and sixty-eight | 0.471876 | 0.331329 | Zero point zero seven eight | 0.24375 | 0.3725 | 0.62625 | Two point four two |
| **年龄** | Seven hundred and sixty-eight | 33.240885 | 11.760232 | Twenty-one | 24.00000 | 29.0000 | 41.00000 | Eighty-one |
| **结果** | Seven hundred and sixty-eight | 0.348958 | 0.476951 | Zero | 0.00000 | 0.0000 | 1.00000 | One |

```py
df.describe().transpose()

Listing 5-1Descriptive Statistics

```

## 皮尔逊相关法

清单 [5-2](#PC2) 展示了线性关系的强度(见图 [5-2](#Fig2) )。

![../images/506148_1_En_5_Chapter/506148_1_En_5_Fig2_HTML.jpg](../images/506148_1_En_5_Chapter/506148_1_En_5_Fig2_HTML.jpg)

图 5-2

皮尔逊相关矩阵

```py
dfcorr = df.corr(method="pearson")
sns.heatmap(dfcorr, annot=True,annot_kws={"size":12}, cmap="Blues")
plt.show()

Listing 5-2Pearson Correlation Matrix

```

图 [5-2](#Fig2) 显示了数据中大多数变量之间的弱正关联。

## 其他相关方法

还有其他方法用于测量变量之间的相关性，如肯德尔方法和斯皮尔曼方法。它们的使用取决于用例。

### 肯德尔相关法

肯德尔相关法估计顺序变量中排名之间的关联。序数变量包括具有未知距离的分类变量。有序数据的一个例子是李克特量表。肯德尔相关法的值范围为-1 到 1，其中-1 表示排名不相同，0 表示排名独立，1 表示两个排名相同。列表 [5-3](#PC3) 产生肯德尔相关矩阵(见图 [5-3](#Fig3) )。

![../images/506148_1_En_5_Chapter/506148_1_En_5_Fig3_HTML.jpg](../images/506148_1_En_5_Chapter/506148_1_En_5_Fig3_HTML.jpg)

图 5-3

肯德尔相关矩阵

```py
dfcorr_kendall = df.corr(method="kendall")
sns.heatmap(dfcorr_kendall, annot=True,annot_kws={"size":12}, cmap="Oranges")
plt.show()

Listing 5-3Kendall Correlation Matrix

```

图 [5-3](#Fig3) 显示大多数排名接近相同。肯德尔相关法和皮尔逊相关法产生的值略有不同。

### 斯皮尔曼相关法

斯皮尔曼相关法是一种替代等级相关法。它衡量两个变量的排名之间的统计相关性。该方法有助于识别变量是否是线性的。它还具有范围从-1 到 1 的值，其中-1 表示弱关联，0 表示没有关联，1 表示强关联。清单 [5-4](#PC4) 返回一个斯皮尔曼相关矩阵(见图 [5-4](#Fig4) )。

![../images/506148_1_En_5_Chapter/506148_1_En_5_Fig4_HTML.jpg](../images/506148_1_En_5_Chapter/506148_1_En_5_Fig4_HTML.jpg)

图 5-4

斯皮尔曼相关矩阵

```py
-

Listing 5-4Spearman Correlation Matrix

```

图 [5-4](#Fig4) 也证实了数据的底层结构是线性的。

## 协方差矩阵

协方差给出了自变量和因变量之间联合可变性的细节。至多，我们对协方差不感兴趣；相反，我们感兴趣的是变量之间的相关性。列表 [5-5](#PC5) 产生协方差矩阵(见图 [5-5](#Fig5) )。

![../images/506148_1_En_5_Chapter/506148_1_En_5_Fig5_HTML.jpg](../images/506148_1_En_5_Chapter/506148_1_En_5_Fig5_HTML.jpg)

图 5-5

协方差矩阵

```py
dfcov = df.cov() sns.heatmap(dfcov, annot=True,annot_kws={"size":12}, cmap="Blues")
plt.show

Listing 5-5Covariance Matrix

```

图 [5-5](#Fig5) 描述了变量之间的可变性。

## 创建 X 和 Y 数组

在进行描述性分析和降维后，后续的步骤是将数据分解成两组一维数组(x，y)，其中 x 代表自变量，y 代表因变量。清单 [5-6](#PC6) 以这样一种方式分割数据，即数据的前八列属于 x 数组，最后一列属于 y 数组。

```py
x = df.iloc[::,0:8]
y = df.iloc[::,-1]

Listing 5-6Create X and Y arrays

```

## 将数据分为训练数据和测试数据

在监督学习模型中，我们将数据分为训练数据和测试数据。清单 [5-7](#PC7) 将数据分为训练数据和测试数据。

```py
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=0)

Listing 5-7Split Data

```

## 特征矩阵

最常见的多重共线性检测方法是容差和方差膨胀因子(VIF)。容差测量唯一的总标准方差，VIF 是模型的总方差，包括单个自变量。一个更可信的方法是使用特征值来确定严重程度。小于 0 的特征值表示多重共线性。介于 10 和 100 之间的特征值表示存在轻微的多重共线性。最后，大于 100 的特征值显示严重的多重共线性。清单 [5-8](#PC8) 使用 NumPy 包生成特征向量和值，并使用 Pandas 将它们作为数据帧传递，这样您就可以对矩阵有一个清晰的了解(参见表 [5-3](#Tab3) )。

表 5-3

自定义矩阵

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"> <col class="tcol4 align-left"> <col class="tcol5 align-left"> <col class="tcol6 align-left"> <col class="tcol7 align-left"> <col class="tcol8 align-left"> <col class="tcol9 align-left"> <col class="tcol10 align-left"> <col class="tcol11 align-left"></colgroup> 
|   | 

特征值

 | 

怀孕

 | 

葡萄糖

 | 

血压

 | 

表皮厚度

 | 

胰岛素

 | 

身体质量指数

 | 

糖尿病患者

 | 

年龄

 | 

结果

 |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| **怀孕** | 13456.577591 | -0.002022 | 0.022650 | -0.022465 | -0.049041 | -0.151620 | -0.005077 | -0.986468 | 0.018049 | 0.010692 |
| **葡萄糖** | 932.805966 | 0.097812 | 0.972186 | 0.143425 | 0.119804 | 0.087995 | 0.050824 | -0.000769 | 0.006061 | 0.000643 |
| **血压** | 390.577869 | 0.016093 | 0.141901 | -0.922468 | -0.262749 | 0.232160 | 0.075596 | 0.001177 | -0.002469 | -0.000071 |
| **皮肤厚度** | 198.184055 | 0.060757 | -0.057856 | -0.307012 | 0.884371 | -0.259927 | 0.221412 | 0.000379 | 0.001118 | -0.002349 |
| **胰岛素** | 112.693345 | 0.993111 | -0.094629 | 0.020977 | -0.065549 | 0.000169 | -0.006137 | -0.001426 | -0.000072 | -0.000295 |
| **身体质量指数** | 45.837383 | 0.014011 | 0.046977 | -0.132444 | 0.192811 | -0.021518 | -0.970677 | 0.003045 | 0.013921 | 0.000672 |
| **糖尿病糖尿病功能** | 7.763548 | 0.000537 | 0.000817 | -0.000640 | 0.002699 | -0.001642 | -0.002032 | 0.006306 | -0.239281 | 0.970922 |
| **年龄** | 0.164361 | -0.003565 | 0.140168 | -0.125454 | -0.301007 | -0.920492 | -0.014979 | 0.162649 | 0.003234 | -0.001209 |
| **结果** | 0.099139 | 0.000585 | 0.007010 | 0.000309 | 0.002625 | -0.006131 | -0.013184 | -0.019319 | -0.970655 | -0.239141 |

```py
eigenvalues, eigenvectors = np.linalg.eig(dfcov)
eigenvalues = pd.DataFrame(eigenvalues)
eigenvectors = pd.DataFrame(eigenvectors)
eigens = pd.concat([eigenvalues,eigenvectors],axis=1)
eigens.index = df.columns
eigens.columns = ("Eigen values","Pregnancies","Glucose","BloodPressure","SkinThickness","Insulin","BMI","DiabetesPedigreeFunction","Age","Outcome")
eigens

Listing 5-8Create the Eigen Matrix

```

## 标准化数据

清单 [5-9](#PC9) 以平均值为 0，标准偏差为 1 的方式转换数据。

```py
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test)

Listing 5-9Normalize Data

```

## 建模数据

我们开发了两个模型来解决手头的分类问题；第一个模型使用 Statsmodels，第二个模型使用 SciKit-Learn。

## 使用 Statsmodels 开发逻辑分类器

在过去的两章(涵盖时间序列分析)中，我们批评了使用 Statsmodels 开发可靠的时间序列模型是多么困难。这并不意味着整个包装是坏的。它仍然是相关的；实际上，很少有像 Statsmodels 这样提供深入分析的包。

### 添加常数

默认情况下，Statsmodels 不包含常量。清单 [5-10](#PC10) 手动添加一个常数。

```py
from statsmodels.api import sm
x_constant = sm.add_constant(x_train)
x_test = sm.add_constant(x_test)

Listing 5-10Add the Constant

```

### 开发逻辑分类器

默认分类器 Statsmodels 使用 logit 模型和最大似然法(MLE)。我们用等式 5-2 表示这个公式。

![$$ {F}_{ML}=\mathit{\log}\left|\sum \left(\varTheta \right)\right|-\mathit{\log}\left|S\right|+ tr\left[S\sum {\left(\varTheta \right)}^{-1}\right]-p $$](../images/506148_1_En_5_Chapter/506148_1_En_5_Chapter_TeX_Equ2.png)

(Equation 5-2)

这里， *log* 表示自然对数， *S* 表示经验协方差矩阵，`ϴ`表示参数向量，∑( `ϴ`)和|∑( `ϴ` ) |表示协方差。参见清单 [5-11](#PC11) 。

```py
model = sm.Logit(y_train,x_constant).fit()

Listing 5-11Develop the Logistic Classifier

```

#### 偏回归

描述变量之间关系的轻松方式是使用部分回归图。列表 [5-12](#PC12) 描绘了被调查变量之间的关联(见图 [5-6](#Fig6) )。

![../images/506148_1_En_5_Chapter/506148_1_En_5_Fig6_HTML.jpg](../images/506148_1_En_5_Chapter/506148_1_En_5_Fig6_HTML.jpg)

图 5-6

部分回归网格

```py
fig = sm.graphics.plot_partregress_grid(model)
plt.show()

Listing 5-12Partial Regression

```

### 模型摘要

清单 [5-13](#PC13) 和表格 [5-4](#Tab4) 总结了该型号。

表 5-4

轮廓

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"> <col class="tcol4 align-left"></colgroup> 
| 部门。变量: | 结果 | **观察次数:** | Six hundred and fourteen |
| **型号:** | 分对数 | **测向残差:** | Six hundred and five |
| **方法:** | 极大似然估计 | **测向模型:** | eight |
| **日期:** | 2020 年 10 月 15 日星期四 | **伪 R-squ。::t1]** | 0.2607 |
| **时间:** | 19:15:31 | **对数似然:** | -296.59 |
| **收敛:** | 真实的 | ll-null: | -401.18 |
| **协方差类型:** | 不稳健 | **LLR p-value:** | 7.418e-41 |

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"> <col class="tcol4 align-left"> <col class="tcol5 align-left"> <col class="tcol6 align-left"> <col class="tcol7 align-left"></colgroup> 
|   | 

**coef**

 | 

**标准误差**

 | 

**z**

 | 

**P > &#124;z&#124;**

 | 

**【0.025**

 | 

**0.975】**

 |
| --- | --- | --- | --- | --- | --- | --- |
| **常数** | -0.7920 | Zero point one zero six | -7.484 | Zero | -0.999 | -0.585 |
| **x1** | 0.3147 | Zero point one one eight | Two point six six four | Zero point zero zero eight | Zero point zero eight three | Zero point five four six |
| **x2** | 1.0788 | Zero point one three one | Eight point two two four | Zero | Zero point eight two two | One point three three six |
| **x3** | -0.2685 | Zero point one one three | -2.369 | Zero point zero one eight | -0.491 | -0.046 |
| **x4** | 0.0710 | Zero point one two five | Zero point five six nine | Zero point five six nine | -0.174 | Zero point three one six |
| **x5** | -0.1664 | Zero point one one five | -1.443 | Zero point one four nine | -0.393 | Zero point zero six |
| **x6** | 0.6955 | Zero point one three one | Five point three one three | Zero | Zero point four three nine | Zero point nine five two |
| **x7** | 0.2983 | Zero point one one | Two point seven | Zero point zero zero seven | Zero point zero eight two | Zero point five one five |
| **x8** | 0.2394 | Zero point one two four | One point nine three one | Zero point zero five four | -0.004 | Zero point four eight three |

```py
summary = model.summary()
summary

Listing 5-13Profile

```

表 [5-4](#Tab4) 显示了关于逻辑回归模型的信息。它概述了估计的截距和斜率。此外，它还具有测试统计结果，这些结果对于测试假设和有关模型性能的信息非常有用。在分类分析中，我们不使用 R <sup>2</sup> 来度量可变性。相反，我们使用伪 R <sup>2</sup> 。表 [5-4](#Tab4) 表明我们有统计上显著的关系。很少有确定的关系在统计上是不重要的。

## 使用 SciKit-Learn 开发逻辑分类器

在下一节中，我们将使用 Scikit-Learn 包。我们遵循与其他章节相同的程序。清单 [5-14](#PC14) 用默认超参数训练模型。

```py
from sklearn.linear_model import LogisticRegression
logreg = LogisticRegression()
logreg.fit(x_train,y_train)

Listing 5-14Develop the Logistic Classifier with Default Hyperparameters

```

### 逻辑超参数优化

在回顾了前面几章的内容后，您可能已经注意到超参数在模型性能中起着重要的作用。在最终确定机器学习模型之前，请确保模型具有最佳超参数。清单 [5-15](#PC15) 返回最佳超参数。

```py
from sklearn.model_selection import GridSearchCV
param_grid = {"dual":[False,True],
              "fit_intercept":[False,True],
              "max_iter":[1,10,100,1000],
              "penalty":("l1","l2"),
              "tol":[0.0001,0.001,0.01,1.0],
              "warm_start":[False,True]}
grid_model = GridSearchCV(estimator=logreg, param_grid=param_grid)
grid_model.fit(x_train,y_train)
print("Best score: ", grid_model.best_score_, "Best parameters: ", grid_model.best_params_)

Listing 5-15Hyperparameter Optimization

```

最佳得分:0.7960609991158407 最佳参数:{'dual': False，' fit_intercept': True，' max_iter': 100，' penalty': 'l2 '，' tol': 0.0001，' warm_start': False}

清单 [5-16](#PC16) 完成了模型。

```py
logreg = LogisticRegression(dual= False,
                            fit_intercept= True,
                            max_iter= 10,
                            n_jobs= -5,
                            penalty= 'l2',
                            tol=0.0001,
                            warm_start= False)
logreg.fit(x_train,y_train)

Listing 5-16Finalize the Logistic Classifier

```

### 预言

列表 [5-17](#PC17) 获得预测值，然后创建一个显示实际值和预测值的数据框(见表 [5-5](#Tab5) )。

表 5-5

实际值和预测值

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"></colgroup> 
|   | 

实际的

 | 

预测

 |
| --- | --- | --- |
| **661** | one | one |
| **122** | Zero | Zero |
| **113** | Zero | Zero |
| **14** | one | one |
| **529** | Zero | Zero |
| **...** | ... | ... |
| **第 476 章** | one | Zero |
| **第 482 章** | Zero | Zero |
| **230** | one | one |
| **527** | Zero | Zero |
| **380** | Zero | Zero |

```py
y_pred = logreg.predict(x_test)
y_pred  = pd.DataFrame({"Actual":y_test, "Predicted": y_predlogreg})
y_pred

Listing 5-17Actual Values and Predicted Values

```

### 找到截击点

清单 [5-18](#PC18) 找到截距。

```py
logreg.intercept_
array([-0.78763914])

Listing 5-18Intercept

```

### 找出估计的系数

清单 [5-19](#PC19) 显示了我们模型的参数。

```py
logreg.coef_
array([[ 0.3097449 ,  1.06006236, -0.26057825,  0.06865213, -0.15816976,
         0.68419394,  0.29353764,  0.2396453 ]])

Listing 5-19Coefficients

```

### 评估逻辑分类器

在确定了二元分类器之后，我们必须看看二元分类器对类的分类有多好。这包括比较实际标签和预测标签之间的差异。我们从开发一个混淆矩阵开始。

#### 混淆矩阵

当分类器进行预测时，很容易出错。当处理二元分类问题时，有两种类型的错误，即类型 I 错误(假阳性)和类型 II 错误(假阴性)。

*   *假阳性(FP)* :错误地预测事件发生。一个例子是当患者不是糖尿病患者时，预测患者是糖尿病患者。

*   *假阴性(FN)* :错误地预测一个从未发生的事件。一个例子是当患者是糖尿病患者时，预测患者不是糖尿病患者。

尽管分类器容易出错，但它确实能做出一些正确的预测。

*   *真阳性(TP)* :正确预测事件发生。一个例子是正确地预测病人是糖尿病患者。

*   *真阴性(TN)* :正确预测某事件从未发生。一个例子是正确预测患者不是糖尿病患者。

混淆矩阵采用实际类别和预测的四种组合。一个混淆矩阵看起来像表 [5-6](#Tab6) ，列表 [5-20](#PC20) ，表 [5-7](#Tab7) 。

表 5-7

混淆矩阵

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"></colgroup> 
|   | 

预测:否

 | 

预测:是

 |
| --- | --- | --- |
| **实际:否** | Ninety-eight | nine |
| **实际:是** | Eighteen | Twenty-nine |

表 5-6

混淆矩阵

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"></colgroup> 
|   | 

预测:否

 | 

预测:是

 |
| --- | --- | --- |
| **实际:否** | TN = 98 | FP = 9 |
| **实际:是** | FN = 18 | TP = 29 |

```py
cmatlogreg = pd.DataFrame(metrics.confusion_matrix(y_test,y_predlogreg), index=["Actual: No","Actual: Yes"],
                         columns=("Predicted: No","Predicted: Yes"))
cmatlogreg

Listing 5-20Confusion Matrix

```

#### 分类报告

分类报告是一份详细的报告，强调分类器的性能。它包括准确性、精确度、F-1 支持、召回率和流行率等关键指标。这些指标的计算来自混淆矩阵。表 [5-8](#Tab8) 概述了分类报告中的关键指标，清单 [5-21](#PC21) 返回分类报告。

表 5-8

分类报告

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"></colgroup> 
| 

公制的

 | 

描述

 |
| --- | --- |
| 精确 | 已确定分类器正确的频率 |
| 准确 | 确定分类器获得正确预测的频率 |
| f1-支持 | 确定了精确度和召回率的平均值 |
| 支持 | 确定该类别中真实响应的样本数 |

```py
creportlogreg = pd.DataFrame(metrics.classification_report(y_test,y_predlogreg, output_dict=True)).transpose()
creportlogreg

Listing 5-21Classification Report

```

表 [5-9](#Tab9) 强调了逻辑分类器在 82%的时候是准确的。这也告诉我们，数据中存在不平衡。分类器在预测类 0 时比预测类 1 时更精确。

表 5-9

分类报告

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"> <col class="tcol4 align-left"> <col class="tcol5 align-left"></colgroup> 
|   | 

精确

 | 

召回

 | 

f1-分数

 | 

支持

 |
| --- | --- | --- | --- | --- |
| **0** | 0.844828 | 0.915888 | 0.878924 | 107.000000 |
| **1** | 0.763158 | 0.617021 | 0.682353 | 47.000000 |
| **精度** | 0.824675 | 0.824675 | 0.824675 | 0.824675 |
| **宏平均值** | 0.803993 | 0.766455 | 0.780638 | 154.000000 |
| **加权平均值** | 0.819902 | 0.824675 | 0.818931 | 154.000000 |

#### 受试者工作特征曲线

受试者工作特性(ROC)曲线是一种用于寻找合适的超参数设置的工具。它有助于总结使用不同概率阈值的真阳性率和假阳性率之间的权衡。x 轴表示假阳性率，y 轴表示真阳性率。曲线越靠近 ROC 空间的左侧边界，就越准确。参见清单 [5-22](#PC22) 。

```py
y_predlogreg_proba = logreg.predict_proba(x_test)[::,1]
fprlogreg, tprlogreg, _ = metrics.roc_curve(y_test,y_predlogreg_proba)
auclogreg = metrics.roc_auc_score(y_test, y_predlogreg_proba)
plt.plot(fprlogreg, tprlogreg, label="AUC: "+str(auclogreg), color="navy")
plt.plot([0,1],[0,1],color="red")
plt.xlim([0.00,1.01])
plt.ylim([0.00,1.01])
plt.xlabel("Specificity")
plt.ylabel("Sensitivity")
plt.legend(loc=4)
plt.show()

Listing 5-22ROC Curve

```

图 [5-7](#Fig7) 中的曲线跟随左侧边界一段时间；然后它平滑地弯曲到 ROC 空间的顶部边界。曲线慢慢接近 45 度线。这意味着逻辑分类器不像我们希望的那样准确。

![../images/506148_1_En_5_Chapter/506148_1_En_5_Fig7_HTML.jpg](../images/506148_1_En_5_Chapter/506148_1_En_5_Fig7_HTML.jpg)

图 5-7

受试者工作特征曲线

##### 曲线下面积

曲线下面积(AUC)也被认为是准确性的指标。它由 ROC 曲线的性能指标组成。它指示分类器如何区分类。曲线下面积分数越接近 1，模型的预测能力越强。AUC 分数为 0.87。使用 80/20 规则，分类器能够熟练地区分实际类别和预测类别。

#### 精确召回曲线

我们使用精确-召回曲线来显示不同阈值的精确和召回之间的权衡。理想情况下，我们希望一条曲线直接移动到右上角，然后水平急剧弯曲。这样的曲线精度高，召回率高。这意味着二元分类器得到所有正确的预测。参见清单 [5-23](#PC23) 。

```py
precisionlogreg, recalllogreg, thresholdlogreg = metrics.precision_recall_curve(y_test,y_predlogreg)
apslogreg = metrics.roc_auc_score(y_test,y_predlogreg)
plt.plot(precisionlogreg, recalllogreg, label="aps: "+str(apslogreg),color="navy",alpha=0.8)
plt.axhline(y=0.5,color="red",alpha=0.8)
plt.xlabel("Precision")
plt.ylabel("Recall")
plt.legend(loc=4)
plt.show()

Listing 5-23Precision-Recall Curve

```

图 [5-8](#Fig8) 中的曲线没有接近右上边框；相反，它慢慢下降到右下角。这表明糖尿病患者和非糖尿病患者之间存在重叠。准确率和召回率都不够高。

![../images/506148_1_En_5_Chapter/506148_1_En_5_Fig8_HTML.jpg](../images/506148_1_En_5_Chapter/506148_1_En_5_Fig8_HTML.jpg)

图 5-8

精确回忆曲线

##### 找到平均精度分数

为了理解精确回忆曲线，我们分解了中心趋势。平均精度分数(APS)是精度-召回曲线内精度分数的算术平均值。分类器在 76%的时候是精确的。

#### 学习曲线

学习曲线发现模型是否具有低偏差误差项(欠拟合)和高方差(过拟合)。它描述了一个模型随时间的学习过程。该曲线使我们能够确定从训练数据中增加的数据点中获益的程度，并找出估计量是否存在方差误差或偏差。有两种类型的学习曲线，即训练学习曲线(根据训练数据计算)和验证学习曲线(使用验证数据计算)。学习曲线有两个轴:x 轴上的训练集大小和 y 轴上的准确度分数。图 [5-9](#Fig9) 显示了分类器的学习过程。另请参见清单 [5-24](#PC24) 。

![../images/506148_1_En_5_Chapter/506148_1_En_5_Fig9_HTML.jpg](../images/506148_1_En_5_Chapter/506148_1_En_5_Fig9_HTML.jpg)

图 5-9

学习曲线

```py
trainsizelogreg, trainscorelogreg, testscorelogreg = learning_curve(logreg, x, y, cv=5, n_jobs=5, train_sizes=np.linspace(0.1,1.0,50))
trainscorelogreg_mean = np.mean(trainscorelogreg,axis=1)
testscorelogreg_mean = np.mean(testscorelogreg,axis=1)
plt.plot(trainsizelogreg,trainscorelogreg_mean,color="red", label="Training score", alpha=0.8)
plt.plot(trainsizelogreg,testscorelogreg_mean,color="navy", label="Cross validation score", alpha=0.8)
plt.xlabel("Training set size")
plt.ylabel("Accuracy")
plt.legend(loc=4)
plt.show()

Listing 5-24Learning Curve

```

在学习过程的开始阶段，逻辑分类器过拟合。但是，随着训练集大小的增加，分类器的过度拟合会减少。随着分类器接近第 400 个<sup>个</sup>数据点，交叉验证准确度分数开始降低。增加更多的数据点不会增加泛化能力。在接下来的章节中，你会学到更多关于如何解释学习曲线的知识。

## 结论

本章介绍了非参数方法。它评估了使用 Statsmodels 和 SciKit-Learn 开发的两个逻辑分类器。第二种模式显示了行为良好的模型的特征。这个模型 85%的时候都是正确的。理想情况下，我们想要一个 100%正确的模型。有几种方法可以提高逻辑分类器的性能，例如降维和正则化。在 SciKit-Learn 包中，有一个内置交叉验证的逻辑分类器和一个脊分类器。这些模型有助于提高分类器的性能。

<aside aria-label="Footnotes" class="FootnoteSection" epub:type="footnotes">Footnotes [1](#Fn1_source)

[T2`https://www.kaggle.com/uciml/pima-indians-diabetes-database`](https://www.kaggle.com/uciml/pima-indians-diabetes-database)

 </aside>