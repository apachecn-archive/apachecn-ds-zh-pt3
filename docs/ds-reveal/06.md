# 6.利用线性判别分析进行降维和多元分析

前一章介绍了一种称为逻辑回归的分类方法。它解决了二元分类问题。多项式逻辑回归(MLR)是使用 Softmax 函数的逻辑回归的扩展；它应用交叉熵损失函数，而不是 Sigmoid 函数。它是逻辑回归的一种形式，用于预测具有两个以上类别的目标变量。它不同于线性判别分析(LDA ),因为 MLR 不假设数据来自正态分布。LDA 来自一个线性家庭；它假设正态性和线性。

我们使用 LDA 来解决二元类问题和多类分类问题。本章介绍线性分类和判别分析。它揭示了一种使用 LDA 将数据压缩到更少维度并使用连续变量估计分类变量的方法。

该模型的工作原理类似于前面章节中隐藏的模型，如线性回归和逻辑回归。它也类似于协方差分析(ANOVA)。方差分析使用分类变量估计连续变量。LDA 合理地假设各组的协方差结构是相似的。如果协方差结构组不相等，则使用二次判别分析。LDA 模型的扩展被称为 Fisher 判别分析(FDA)。FDA 不执行分类，但是变换后获得的特征可以用于分类。

逻辑回归和 LDA 都估计分类因变量。区别 LDA 和逻辑回归的是有更多的假设。它也像主成分分析和因子分析一样，寻找能最好地解释数据的线性组合。LDA 在大样本时效果最好。

它应用判别函数，通过寻找变量的线性组合并最大化它们之间的差异，将一组连续变量分类。同样，它应用 Fisher 线性判别规则来最大化类内散布矩阵和类间散布矩阵之间的比率，并发现组中的线性组合。

最后，它估计分类变量只使用连续变量。如果自变量是分类的，因变量是分类的，使用被认为是判别对应分析的替代模型。鉴于其继承自线性家族，根据线性和正态性假设测试模型。LDA 有两个目的:降维和分类。

## 降维

我们使用 LDA 进行降维，它类似于 PCA。它发现数据中解释的差异，并将数据减少到更少的维度。记住使用特征值来寻找数据中相当大的变化的来源。负载最高的特征值是第一个函数，负载第二高的特征值是第二个函数，依此类推。我们根据一些标准排除具有过多特征值(极端可变性)的因素。

## 分类

LDA 解决了二元和多类分类问题。它应用线性分类器将变量分配给一个类。假设模型应用线性分类器，它继承了严格的线性和正态假设。

## 假设

LDA 对数据的结构做出了强有力的假设。如果 LDA 分类器满足表 [6-1](#Tab1) 中强调的假设，我们认为它是可靠的。

表 6-1

LDA 假设

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"></colgroup> 
| 

**假设**

 | 

**描述**

 |
| --- | --- |
| **多元常态** | 每组变量中必须有多元正态性；独立变量必须服从正态分布。 |
| **协方差** | 组变量之间的方差在不同预测因子水平上是相同的。当协方差相等时，可以利用线性判别分析。否则，使用二次判别分析。 |
| **相关性** | 变量不能高度相关。 |
| **随机抽样** | 必须采用随机抽样的方式选择参与者。参与者的分数必须独立于变量。 |

假设有 C 个类，设类的均值向量为类内样本数。

等式 6-1 用于类内散布矩阵。

![$$ {S}_w={\sum}_{i=1}^C{\sum}_{j=1}^{M_i}\left({y}_j-{\mu}_i\right){\left({y}_j-{\mu}_i\right)}^T $$](img/506148_1_En_6_Chapter/506148_1_En_6_Chapter_TeX_Equ1.png)

(Equation 6-1)

等式 6-2 用于类间散布矩阵。等式 6-3 在散布矩阵内。

![$$ {S}_b={\sum}_{i=1}^C\left({y}_j-{\mu}_i\right){\left({y}_j-{\mu}_i\right)}^T $$](img/506148_1_En_6_Chapter/506148_1_En_6_Chapter_TeX_Equ2.png)

(Equation 6-2)

![$$ \mu =\frac{1}{C}{\sum}_{i=1}^C{\mu}_i\left( mean\ of\ the\ entire\ dataset\right) $$](img/506148_1_En_6_Chapter/506148_1_En_6_Chapter_TeX_Equ3.png)

(Equation 6-3)

它执行一种变换，最大化类间散布矩阵，同时最小化类内散布。参见等式 6-4。

![$$ \mathit{\operatorname{maximize}}=\frac{\mathit{\det}\left({S}_w\right)}{\mathit{\det}\left({S}_b\right)} $$](img/506148_1_En_6_Chapter/506148_1_En_6_Chapter_TeX_Equ4.png)

(Equation 6-4)

这种转换保持了类的可分离性，同时减少了由于除身份之外的来源而引起的变化。线性变换由一个矩阵 *U* 给出，其列是*S*<sub>T5】w</sub><sup>-1</sup>*S*<sub>*b*</sub>的特征向量。

基本上，它计算 d 维平均向量，随后是散布矩阵和特征向量以及散布矩阵的等价特征值。此后，模型对特征值进行分类，并选择较大的特征值以形成 *d×k* 维矩阵，并将样本转换到新的子空间上。最终结果是阶级分离。

## 开发 LDA 分类器

示例数据是从 ML 数据中检索的。 <sup>[1](#Fn1)</sup> 我们要根据一组自变量来预测汽车的质量。见清单 [6-1](#PC1) 。

```py
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
LDA = LinearDiscriminantAnalysis()
LDA.fit(x_train,y_train)

Listing 6-1Develop the Model with Default Hyperparameters

```

### LDA 超参数优化

调整 LDA 超参数不像调整其他分类模型的超参数那样繁琐。表 [6-2](#Tab2) 突出了重要的超参数。

表 6-2

可调超参数

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"></colgroup> 
| 

因素

 | 

描述

 |
| --- | --- |
| `n_component` | 确定组件的数量。 |
| `shrinkage` | 使用 Ledoit-Wolf 引理确定自动收缩或指定值。 |
| `solver` | 确定要使用的规划求解；默认情况下，使用`svd`进行单值分解，使用`lsqr`进行最小二乘解，使用`eigen`进行特征值分解 |
| `store_covariance` | 确定是否存储协方差 |
| `tol` | 确定优化的公差 |

清单 [6-2](#PC2) 找到产生最佳模型性能的超参数。

```py
param_gridLDA = {"n_components":[1,2,3,4,5,6,7,8,9],
                 "solver":("svd", "lsqr", "eigen"),
                 "store_covariance":[False,True],
                 "tol":[0.0001,0.001,0.01,1.0]}
grid_modelLDA = GridSearchCV(estimator=LDA, param_grid= param_gridLDA)
grid_modelLDA.fit(x_train,y_train)
print("Best score: ", grid_modelLDA.best_score_, "Best parameters: ", grid_modelLDA.best_params_)
Best score: 0.7622550979608157 Best parameters: {‘n_components’: 1, ‘solver’: ‘svd’, ‘store_covariance’: False, ‘tol’: 0.0001}

Listing 6-2Hyperparameter Optimizations

```

清单 [6-3](#PC3) 使用默认的超参数完成了模型。

```py
LDA = LinearDiscriminantAnalysis(n_components= 1,
                                 solver= 'svd',
                                 store_covariance= False,
                                 tol= 0.0001)
LDA.fit(x_train,y_train)

Listing 6-3Finalize the LDA Classifier

```

清单 [6-4](#PC4) 转换变量。

```py
features_new = LDA.transform(x_train)

Listing 6-4Create New Features

```

清单 [6-5](#PC5) 估计了由每个所选组件解释的方差百分比。

```py
print(LDA.explained_variance_ratio_)
[1.]

Listing 6-5Explained Variance Ratio

```

每一个选定的组成部分解释了 100%的差异。清单 [6-6](#PC6) 打印原始特征数和减少的特征数。

```py
print('Original feature #:', x_train.shape[1])
print('Reduced feature #:', features_new.shape[1])
Original feature #: 7
Reduced feature #: 1

Listing 6-6The Number of Original and Reduced Features

```

最初，我们有八个特征；现在有七个特征。

### 预言

最终确定分类器后，后续步骤包括比较因变量的实际值和变量的预测值。清单 [6-7](#PC7) 列出了实际值和预测值(见表 [6-3](#Tab3) )。

表 6-3

实际值和预测值

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"></colgroup> 
|   | 

实际的

 | 

预测

 |
| --- | --- | --- |
| **661** | one | one |
| **122** | Zero | Zero |
| **113** | Zero | Zero |
| **14** | one | one |
| **529** | Zero | Zero |
| **...** | ... | ... |
| **第 476 章** | one | Zero |
| **第 482 章** | Zero | Zero |
| **230** | one | one |
| **527** | Zero | Zero |
| **380** | Zero | Zero |

```py
y_predLDA = LDA.predict(x_test)
pd.DataFrame({"Actual": y_test,"Predicted": y_predLDA})

Listing 6-7Actual Values and Predicted Values

```

表 [6-3](#Tab3) 没有告诉我们太多关于分类器如何执行的信息。

### 评估 LDA 分类器

为了理解 LDA 分类器的性能，我们必须并排比较实际的类和预测的类。

### 混淆矩阵

我们通常将混淆矩阵称为误差矩阵。它是一个 2×2 矩阵，对实际标签和预测标签进行计数。清单 [6-8](#PC8) 列出了混淆矩阵(见表 [6-4](#Tab4) )。

表 6-4

混淆矩阵

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"></colgroup> 
|   | 

预测:否

 | 

预测:是

 |
| --- | --- | --- |
| **实际:否** | Two hundred and sixty-three | Zero |
| **实际:是** | Zero | Two hundred and sixty-three |

```py
cmatLDA = pd.DataFrame(metrics.confusion_matrix(y_test,y_predLDA), index=["Actual: No","Actual: Yes"],
                         columns=("Predicted: No","Predicted: Yes"))
cmatLDA

Listing 6-8Confusion Matrix

```

表 [6-4](#Tab4) 突出显示了与逻辑分类器相似的值。我们期望找到类似的性能结果。

### 分类报告

表 [6-5](#Tab5) 强调了重要的分类评估指标。它让我们对分类器的性能有一个大致的了解。参见清单 [6-9](#PC9) 。

表 6-5

分类报告

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"> <col class="tcol4 align-left"> <col class="tcol5 align-left"></colgroup> 
|   | 

精确

 | 

召回

 | 

f1-分数

 | 

支持

 |
| --- | --- | --- | --- | --- |
| **0** | One | One | One | Two hundred and sixty-three |
| **1** | One | One | One | Eighty-three |
| **精度** | One | One | One | One |
| **宏平均值** | One | One | One | Three hundred and forty-six |
| **加权平均值** | One | One | One | Three hundred and forty-six |

```py
creportLDA = pd.DataFrame(metrics.classification_report(y_test,y_predLDA, output_dict=True)).transpose()
creportLDA

Listing 6-9Classification Report

```

LDA 分类器显示了最佳的模型性能。它 100%的时间都是准确的。

### 受试者工作特征曲线

清单 [6-10](#PC10) 应用`roc_curve()`和`roc_auc_score()`方法描绘实际类别和每个类别的概率，以绘制曲线(见图 [6-1](#Fig1) )。

![img/506148_1_En_6_Chapter/506148_1_En_6_Fig1_HTML.jpg](img/506148_1_En_6_Chapter/506148_1_En_6_Fig1_HTML.jpg)

图 6-1

受试者工作特征曲线

```py
y_predLDA_probaLDA = LDA.predict_proba(x_test)[::,1]
fprLDA, tprLDA, _ = metrics.roc_curve(y_test,y_predLDA_probaLDA)
aucLDA = metrics.roc_auc_score(y_test,y_predLDA_probaLDA)
plt.plot(fprLDA, tprLDA,label="AUC: " + str(aucLDA),color="navy")
plt.plot([0,1], [0,1],color="red")
plt.xlim([0.00,1.01])
plt.ylim([0.00,1.01])
plt.xlabel("Sensitivity")
plt.ylabel("Specificity")
plt.legend(loc=4)
plt.show()

Listing 6-10ROC Curve

```

图 [6-1](#Fig1) 显示 AUC 得分为 1.0。LDA 分类器显示了最佳模型的表现。

### 精确回忆曲线

清单 [6-11](#PC11) 生成一条曲线，告诉我们 LDA 分类器在预测类别时的相关性和精度。我们使用精确回忆曲线。

```py
precisionLDA, recallLDA, thresholdLDA = metrics.precision_recall_curve(y_test,y_predLDA)
apsLDA = metrics.roc_auc_score(y_test,y_predLDA)
plt.plot(precisionLDA, recallLDA, label="APS: "+str(apsLDA),color="navy")
plt.axhline(y=0.5,color="red",alpha=0.8)
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.legend(loc=4)
plt.show()

Listing 6-11Precision-Recall Curve

```

图 [6-2](#Fig2) 显示了性能良好的精确召回曲线的特征。

![img/506148_1_En_6_Chapter/506148_1_En_6_Fig2_HTML.jpg](img/506148_1_En_6_Chapter/506148_1_En_6_Fig2_HTML.jpg)

图 6-2

精确回忆曲线

## 学习曲线

清单 [6-12](#PC12) 和图 [6-3](#Fig3) 描述了 LDA 分类器的学习过程。

![img/506148_1_En_6_Chapter/506148_1_En_6_Fig3_HTML.jpg](img/506148_1_En_6_Chapter/506148_1_En_6_Fig3_HTML.jpg)

图 6-3

学习曲线

```py
trainsizeLDA, trainscoreLDA, testscoreLDA = learning_curve(LDA, x, y, cv=5, n_jobs=5, train_sizes=np.linspace(0.1,1.0,50))
trainscoreLDA_mean = np.mean(trainscoreLDA,axis=1)
testscoreLDA_mean = np.mean(testscoreLDA,axis=1)
plt.plot(trainsizeLDA,trainscoreLDA_mean,color="red", label="Training Score")
plt.plot(trainsizeLDA,testscoreLDA_mean,color="navy", label="Cross Validation Score")
plt.xlabel("Training Set Size")
plt.ylabel("Accuracy")
plt.legend(loc=4)
plt.show()

Listing 6-12Learning Curve

```

图 [6-3](#Fig3) 表明分类器的训练和交叉验证精度在前 550 个数据点是稳定的，但是随着训练集的增加，精度会下降。

## 结论

本章探讨了判别分析。它主要侧重于线性判别分析，并说明了使用它进行降维线性分类的方法。该模型使用单个分解求解器，该求解器被限制为将优化集的协方差和容差存储为 0.0001。它显示了最佳的模型性能。

<aside aria-label="Footnotes" class="FootnoteSection" epub:type="footnotes">Footnotes [1](#Fn1_source)

[T2`https://www.mldata.io/dataset-details/cars/`](https://www.mldata.io/dataset-details/cars/)

 </aside>