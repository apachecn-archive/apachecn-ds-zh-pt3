# 2.基本数据访问和合并

有许多方法可以访问和合并 pandas 的数据帧。本章将介绍从数据帧中获取数据、创建子数据帧以及合并数据帧的基本方法。

## 数据帧创建和访问

pandas 有一个类似字典的语法，对于熟悉 Python 但不熟悉 pandas 的人来说非常直观。每个列名被视为一个键，行值作为值返回。DataFrame 对象构造函数也接受字典作为创建 DataFrame 的方法。注意，当你从一个数据帧中获取列时，它指回原始数据帧，这就是我们可以对原始数据帧进行修改的地方。尽管语法暗示我们将它存储到原始文件的一个子集，但还是会发生这种情况，如清单 [2-1](#PC1) 底部所示。这对基于内存的性能非常有利，因为我们不会不断地创建数据的副本。

```
>> import pandas as pd
>> account_info = pd.DataFrame({
     "name": ["Bob", "Mary", "Mita"],
     "account": [123846, 123972, 347209],
     "balance": [123, 3972, 7209],
})
>> account_info["name"]
     0    Bob
     1    Mary
     2    Mita
Name: name, dtype: object
>> account_info["name"] = ["Smith", "Jane", "Patel"]
>> account_info
          name  account      balance
     0    Smith 123846       123
     1    Jane  123972       3972
     2    Patel 347209       7209

Listing 2-1Example of dictionary syntax

```

类似地，可以通过传入一个列列表来创建子数据框架，如清单 [2-2](#PC2) 所示。

```
>> import pandas as pd
>> account_info = pd.DataFrame({
     "name": ["Bob", "Mary", "Mita"],
     "account": [123846, 123972, 347209],
     "balance": [123, 3972, 7209],
})
>> account_info[["name", "balance"]]
           name  balance
     0     Bob   123
     1     Mary  3972
     2     Mita  7209

Listing 2-2Example of creating a sub-DataFrame

```

如果从原始数据帧创建子数据帧，并修改子数据帧，希望原始数据帧保持不变，那么字典语法会导致混乱。除了清单 [2-1](#PC1) 和 [2-2](#PC2) 中给出的简单情况之外，熊猫不保证字典语法返回的结果对象是视图还是副本。这就是为什么对于具有多索引或多级列的数据帧，loc 方法优于 dictionary 语法的原因。我们将在下一节讨论的 loc 方法保证了您是在原始数据帧而不是副本上操作。类似地，如果您真的想要数据帧的副本，您应该显式地创建一个。

## iloc 方法

数据帧的行可以通过 iloc 方法访问，该方法使用类似列表的语法。清单 [2-3](#PC3) 演示了这一点。

```
>> import pandas as pd
>> account_info = pd.DataFrame({
     "name": ["Bob", "Mary", "Mita"],
     "account": [123846, 123972, 347209],
     "balance": [123, 3972, 7209],
})
>> account_info.iloc[1]
     name        Mary
     account     123972
     balance     3972
>> account_info.iloc[0:2]
          name  account  balance
     0    Bob   123846   123
     1    Mary  123972   3972
>> account_info.iloc[:]
          name  account  balance
     0    Bob   123846   123
     1    Mary  123972   3972
     2    Mita  347209   7209

Listing 2-3Example of accessing rows in a DataFrame using iloc

```

iloc 用于通过基于整数位置的索引来索引数据帧。iloc 函数中的第一个位置指定行索引，而第二个位置指定列索引。这意味着我们可以选择行和列，如清单 [2-4](#PC4) 所示。

```
>> import pandas as pd
>> account_info = pd.DataFrame({
     "name": ["Bob", "Mary", "Mita"],
     "account": [123846, 123972, 347209],
     "balance": [123, 3972, 7209],
})
>> account_info.iloc[1, 2]
     3972
>> account_info.iloc[1, 2] = 3975
>> account_info.iloc[1, 2]
     3975
>> account_info.iloc[:, [0, 2]]
          name  balance
     0    Bob   123
     1    Mary  3975
     2    Mita  7209

Listing 2-4Example of accessing rows and columns in a DataFrame using iloc

```

iloc 也接受布尔数组。在清单 [2-5](#PC5) 中，我们通过获取每个行索引的模数并将其转换为布尔值来获取所有奇数行。

```
>> import pandas as pd
>> account_info = pd.DataFrame({
     "name": ["Bob", "Mary", "Mita"],
     "account": [123846, 123972, 347209],
     "balance": [123, 3972, 7209],
})
>> account_info.iloc[account_info.index % 2 == 1]
          name  account    balance
     1    Mary  123972     3972

Listing 2-5Example of accessing rows and columns in a DataFrame using iloc

```

iloc 也接受一个函数；然而，这个函数在整个数据帧中被调用一次，传递它和简单地预先调用这个函数没有什么区别，所以我们在这里不再赘述。

iloc 在处理多索引和多级别列数据帧时非常方便，因为级别是整数值。我们来回顾一个例子，并进行分解。在这里，我们将想要获取的行指定为“:”，这意味着我们想要所有的行，并且我们使用一个布尔数组来指定列。我们获取多级列“数据”的值[“分数”、“日期”、“分数”、“日期”]，然后通过指定该值必须等于“分数”来创建一个布尔数组。这在清单 [2-6](#PC6) 中被分成几个阶段，这样更容易理解。

```
>> restaurant_inspections
     inspection             0                1
     data                 score date       score date
     restaurant location
     Diner      (4, 2)    90    02/18      100   05/18
     Pandas     (5, 4)    55    04/18      76    01/18

>> score_columns = (
     restaurant_inspections.columns.get_level_values("data")
     == "score")
>> score_columns

     [True, False, True, False]
>> restaurant_inspections.iloc[:, score_columns]
     inspection                0          1
     data                      score      score
     restaurant location
     Diner      (4, 2)         90         100
     Pandas     (5, 4)         55         76

Listing 2-6Extracting a sub-DataFrame from a multi-indexed multi-level column DataFrame using iloc

```

## 该锁定方法

loc 类似于 iloc，但是它允许您通过列名或标签对数据帧进行索引。清单 [2-7](#PC7) 显示了清单 [2-4](#PC4) 的 loc 等价物。

```
>> import pandas as pd
>> account_info = pd.DataFrame({
     "name": ["Bob", "Mary", "Mita"],
     "account": [123846, 123972, 347209],
     "balance": [123, 3972, 7209],
})
>> account_info.loc[1, "balance"]
     3972
>> account_info.loc[:, ["name", "balance"]]
          name  balance
     0    Bob   123
     1    Mary  3972
     2    Mita  7209

Listing 2-7Example of accessing rows and columns in a DataFrame using loc

```

loc 也可以用在多索引多级列数据帧上，就像 iloc 支持布尔数组一样。清单 [2-8](#PC8) 演示了这一点。

```
>> import pandas as pd
>> account_info
     account         0                    1
     account_info    number   balance     number   balance
     name  username
     Bob   smithb    123846   123         123847   450
     Mary  mj100     123972   3972        123973   222
     Mita  patelm    347209   7209

>> account_info.loc[
     ("Mary", "mj100"), pd.IndexSlice[:, "balance"]
]
     0    balance    3972
     1    balance    222

Listing 2-8Example of extracting a sub-DataFrame from a multi-indexed multi-level column DataFrame using loc

```

在字典语法一节的末尾，提到了对于复杂的数据帧，loc 方法优于字典语法。让我们看看当我们使用每种语法来解释为什么会这样时，下面发生了什么。清单 [2-9](#PC9) 展示了在更复杂的数据帧上操作时，每种访问方法转化成的内容。注意，在清单 [2-9](#PC9) 的后半部分，使用了字典语法，下面的代码使用 __getitem__ 方法，然后对它调用 __setitem__。这与直接调用 __setitem__ 的 loc 方法相反。这里不能信任的是 __getitem__ 并且不能保证它是返回一个副本，还是返回一个指向原始数据帧的视图。在没有多级列的简单情况下，这两种情况下的代码看起来是一样的，但是在这里看到的更复杂的情况下，字典语法导致链式索引并调用不可预测的 __getitem__。

```
"""
The code below is equivalent to:
account_info.__setitem__(
      (slice(None), (0, 'balance')),
      NEW_BALANCE,
)
"""
account_info.loc[:, (0, "balance")] = NEW_BALANCE
"""

The code below is equivalent to:
account_info.__getitem__(0).__setitem__('balance', NEW_BALANCE )
"""
account_info[0]["balance"] = NEW_BALANCE

Listing 2-9A comparison of using loc vs. dictionary syntax to extract a sub-DataFrame

```

通常情况下，您可能需要将来自多个来源的数据合并到一个数据框架中。现在您已经知道了如何进行一些基本的数据访问，我们将看看将来自不同数据框架的数据组合在一起的不同方法。

## 使用合并方法组合数据帧

Merge 的工作方式与关系数据库连接相同，甚至还有我们熟悉的选项:外部、内部、左侧和右侧。右合并基本上与左合并相同，但是数据帧只是以相反的顺序传入，所以本章不提供右合并的明确示例。

当你想找到两个熊猫数据帧之间的交集时，使用内部合并(图 [2-1](#Fig1) )。例如，在清单 [2-10](#PC10) 中，我们试图找到同时存在于两个数据集中的数据，或者在本例中，找到那些在 1844 年矗立至今的建筑。

![../images/487367_1_En_2_Chapter/487367_1_En_2_Fig1_HTML.png](../images/487367_1_En_2_Chapter/487367_1_En_2_Fig1_HTML.png)

图 2-1

内部合并的文氏图

```
>> import pandas as pd
>> building_records_1844
                       established
     building
     Grande Hotel      1830
     Jone's Farm       1842
     Public Library    1836
     Marietta House    1823
>> building_records_2020
                          established
     building
     Sam's Bakery         1962
     Grande Hotel         1830
     Public Library       1836
     Mayberry's Factory   1924
>> cols = building_records_2020.columns.difference(
               building_records_1844.columns
)
>> pd.merge(
     building_records_1844,
     building_records_2020[cols],
     how='inner',
     on=["building"],
)
                          established
     building
     Grande Hotel         1830
     Public Library       1836

Listing 2-10Finding 1844 buildings that are still standing in 2020 using an inner merge

```

在清单 [2-11](#PC11) 中，我们将两个基因样本数据集合并在一起，这意味着我们希望来自两个数据集的所有数据都在同一个数据集中，没有重复。我们可以通过外部合并来实现这一点(图 [2-2](#Fig2) )。

![../images/487367_1_En_2_Chapter/487367_1_En_2_Fig2_HTML.png](../images/487367_1_En_2_Chapter/487367_1_En_2_Fig2_HTML.png)

图 2-2

外部合并的文氏图

```
>> import pandas as pd
>> gene_group1
                  FC1           P1
     id
     Myc          2             0.05
     BRCA1        3             0.01
     BRCA2        8             0.02
>> gene_group2
                  FC2           P2
     id
     Myc          2             0.05
     BRCA1        3             0.01
     Notch1       2             0.03
     BRCA2        8             0.02

>> pd.merge(
     gene_group1,
     gene_group2,
     how='outer',
     on=["id"],
)
                  FC1          P2            FC2           P2
     id
     Myc          2            0.05          2             0.05
     BRCA1        3            0.01          3             0.01
     BRCA2        8            0.02          8             0.02
     Notch1       NaN          NaN           2             0.03

Listing 2-11Merging two gene samplings together without duplicating the data in common using outer merge

```

在清单 [2-12](#PC12) 中，我们用更精确的历史数据更新了现代建筑记录。历史记录包含确切的建立日期，我们希望用它来更新只包含估计值的现代记录。首先，我们使用 merge left 添加新的更准确的建立日期作为数据集中的新列(图 [2-3](#Fig3) )。左侧合并在这种情况下很有用，因为我们只关心更新现代记录中仍然存在的建筑的建立日期。注意，我们还利用 suffixes 参数为列名提供名称。这是有利的，这样我们就不必在完成操作后将列重命名为与原始列相同。合并完成后，我们需要将两个已建立的列中的数据合并在一起。这是通过用现代记录中的值替换旧的已建立列中所有缺失的值(即 nan)来完成的。所以，如果历史记录有一个确定的日期，那么我们就用它；否则，我们就回到现代记录的建立日期。最后，删除现代记录的原始已建立列，以支持包含来自现代记录和历史记录的合并值的新列。

![../images/487367_1_En_2_Chapter/487367_1_En_2_Fig3_HTML.png](../images/487367_1_En_2_Chapter/487367_1_En_2_Fig3_HTML.png)

图 2-3

左侧合并的文氏图

```
>> import pandas as pd
>> building_records_1844
     building          established
     Grande Hotel      1832
     Jone's Farm       1842
     Public Library    1836
     Marietta House    1823
>> building_records_2020

     building             established
     Sam's Bakery         1962
     Grande Hotel         1830
     Public Library       1836
     Mayberry's Factory   1924
>> merged_records = pd.merge(
     building_records_2020,
     building_records_1844,
     how='left',
     right_on="building",
     left_on="building",
     suffixes=("_2000", ""),
)
>> merged_records
     building             established_2000     established
     Sam’s Bakery         1962                 NaN
     Grande Hotel         1830                 1832
     Public Library       1835                 1836
     Mayberry’s Factory   1924                 NaN
>> merged_records["established"].fillna(
     merged_records["established_2000"],
     inplace=True,
)
>> del merged_records["established_2000"]
>> merged_records
     building             established
     Sam's Bakery         1962
     Grande Hotel         1832
     Public Library       1836
     Mayberry's Factory   1924

Listing 2-12Updating modern records with more accurate historical data using a merge left

```

在清单 [2-13](#PC13) 中，我们计划进行第三次医学试验，我们希望生成一个合格的参与者列表。只有参加过前一次试验 a 或 b 的参与者，而不是两者都参加，才有资格参加第三次试验。为了生成符合条件的患者列表，我们需要在合并试验 a 和试验 b 患者时使用反加入方法(图 [2-4](#Fig4) )。pandas merge 方法提供了一个名为 indicator 的参数，该参数将一个名为 _merge 的附加列添加到生成的数据帧中，该列报告该键是只出现在 left_only 中、只出现在 right_only 中，还是同时出现在两个数据帧中。在这种特殊的情况下，这很方便，因为我们希望做一些非常规的合并。使用查询方法，我们能够选择 _merge 值不是 both 的行，然后删除 _merge 列。这可以在一行中完成，如清单 [2-13](#PC13) 的末尾所示，但是事先分成两步，这样你就可以看到它是如何工作的。

![../images/487367_1_En_2_Chapter/487367_1_En_2_Fig4_HTML.png](../images/487367_1_En_2_Chapter/487367_1_En_2_Fig4_HTML.png)

图 2-4

反连接的文氏图

```
>> import pandas as pd
>> trial_a_records
                 name
     patient
     230858       John
     237340       May
     240932       Catherine
     124093       Ahmed
>> trial_b_records
                  name
     patient
     210858       Abi
     237340       May
     240932       Catherine
     154093       Julia

>> both_trials = pd.merge(
     trial_a_records,
     trial_b_records,
     how='outer',
     indicator=True,
     right_index=True,
     left_index=True,
     on="name",
)
                  name            _merge

     patient
     230858       John            left_only
     237340       May             both
     240932       Catherine       both
     124093       Ahmed           left_only
     210858       Abi             right_only
     154093       Julia           right_only
>> both_trials.query('_merge != "both"').drop('_merge', 1)
                  name
     patient
     230858       John
     124093       Ahmed
     210858       Abi
     154093       Julia
>> both_trials = pd.merge(
     trial_a_records,
     trial_b_records,
     how='outer',
     indicator=True,
     right_index=True,
     left_index=True,
     on="name",
).query('_merge != "both"').drop('_merge', 1)

Listing 2-13Eliminating patients who participated in both trials using anti-join merge method

```

## 使用 join 方法组合数据帧

pandas join 方法只是 merge 的一个包装器，它提供了相同的基本合并方法:左、右、外和内。它允许您自动对多索引数据帧执行合并操作，而无需指定要合并的索引。当进行左连接时，它自动使用左数据帧的索引进行连接，右数据帧也是如此。由于 join 是在一个数据帧上执行的，而 merge 是显式传入两个数据帧，因此 join 的默认设置是在“右边”数据帧的索引上进行合并。在这种情况下，“右”是传入的数据帧。这与 merge 默认的内部连接相反。

使用 merge，可以不指定要合并的显式键。如果要合并两个具有相同数据的数据帧，并且不希望左右数据帧具有重复的列，而只是将两个数据集合并在一起，则 merge 比 join 更可取。因为 join 调用在下面合并，所以它显式地指定了要合并的键，从而消除了不输出共享公共列名的数据帧的重复列的可能性。这里要遵循的一个基本规则是，如果不在索引上联接，就使用 merge。

清单 [2-14](#PC14) 延续了清单 [2-10](#PC10) 中先前的内部合并示例，但与先前的示例不同，在先前的示例中，建筑物的记录是一致的，这一次有差异。在这种情况下，出于几个原因，联接是可取的。首先，数据已经根据唯一的建筑物进行了索引，join 将自动选取索引并使用这些索引来连接两组数据。其次，数据中存在差异，因此我们希望在输出数据帧中并排看到两个数据帧中的列，以便我们可以比较它们。

```
>> import pandas as pd
>> building_records_1844
                                   established
     building         location
     Grande Hotel     (4,5)        1831
     Jone's Farm      (1,2)        1842
     Public Library   (6,4)        1836
     Marietta House   (1,7)        1823
>> building_records_2020
                                      established
     building           location
     Sam's Bakery        (5,1)        1962
     Grande Hotel        (4,5)        1830
     Public Library      (6,4)        1835
     Mayberry's Factory  (3,2)        1924
>> building_records_1844.join(
     building_records_2020,
     how='inner',
     rsuffix="_2000",
)
                                 established   established_2000
     building          location
     Grande Hotel      (4,5)     1831          1830
     Public Library    (6,4)     1836          1835

Listing 2-14Highlighting discrepancies in established date of 1844 buildings that are still standing in 2020 using an inner join

```

## 使用 concat 方法组合数据帧

Concatenate 是将两个数据帧组合在一起的简单方法。清单 [2-15](#PC15) 展示了来自多个数据源的相同数据的简单连接。Concatenate 有许多选项，包括指定是使用外部合并还是内部合并的选项 join，以及指定是跨 axis=1 的列合并还是跨 axis=0 的行合并的 axis。默认情况下，concatenate 跨行执行外部合并。注意在清单 [2-15](#PC15) 中，位置(6，4)同时出现在 county_a 和 county_b 数据中，并且在连接的结果中，它在索引中重复出现。

```
>> import pandas as pd
>> temp_county_a
                   temp
     location
     (4,5)          35.6
     (1,2)          37.4
     (6,4)          36.3
     (1,7)          40.2
>> temp_county_b
                    temp
     location
     (6,4)          34.2
     (0,4)          33.7
     (3,8)          38.1
     (1,5)          37.0

>> pd.concat([temp_county_a, temp_county_b])
                    temp
     location
     (4,5)          35.6
     (1,2)          37.4
     (6,4)          36.3

     (1,7)          40.2
     (6,4)          34.2
     (0,4)          33.7
     (3,8)          38.1
     (1,5)          37.0

Listing 2-15Joining two DataFrames together using concat

```

Concatenate 还可以以更复杂的方式用于创建多级列或索引。清单 [2-16](#PC16) 展示了一个连接，其中每个被连接的数据帧是一个多级列中的一个值。注:在清单 [2-16](#PC16) 中，设备 a 和设备 b 数据是相同位置的温度测量值。在这里，我们指定 axis=1，以便两个数据帧跨列进行外部合并。清单 [2-16](#PC16) 中的关键参数告诉 concatenate 将两个温度列视为不同的列，即使它们被命名为相同的列，因为双产品创建了一个多级列。跨列执行外部合并，并将每个设备的温度放入单独的列中，这意味着连接的结果没有重复的位置索引值。这与清单 [2-15](#PC15) 相反，在清单 2-15 中，结果索引值是重复的，两个数据帧简单地堆叠在一起。

```
>> import pandas as pd
>> temp_device_a
                   temp
     location
     (4,5)          35.6
     (1,2)          37.4
     (6,4)          36.3
     (1,7)          40.2
>> temp_device_b
                    temp
     location
     (4,5)          34.2
     (1,2)          36.7
     (6,4)          37.1
     (1,7)          39.0

>> pd.concat(
     [temp_device_a, temp_device_b],
     keys=["device_a", "device_b"],
     axis=1,
)
                   device_a       device_b
                   temp           temp
     location
     (4,5)         35.6           34.2
     (1,2)         37.4           36.7
     (6,4)         36.3           37.1
     (1,7)         40.2           39.0

Listing 2-16Joining two DataFrames together using a multi-level column concat

```

在 pandas 中，有许多不同的方法将数据帧组合在一起并提取子数据帧。您使用哪种方法实际上取决于您的特定用例。这里给出的例子是一个代表性的例子，但是你应该查阅每种方法的文档，因为有一些参数在本章中没有明确地涉及，比如排序。 <sup>[1](#Fn1)</sup>

<aside aria-label="Footnotes" class="FootnoteSection" epub:type="footnotes">Footnotes [1](#Fn1_source)

[T2`https://pandas.pydata.org/pandas-docs/version/0.25/user_guide/merging.html`](https://pandas.pydata.org/pandas-docs/version/0.25/user_guide/merging.html)

 </aside>