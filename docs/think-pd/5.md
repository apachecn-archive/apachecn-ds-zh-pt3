# 5.Pandas中的基础数据转换

Pandas库有一个巨大的 API，它提供了许多转换数据的方法。在这一章中，我们将介绍一些在 pandas 中转换数据的最强大和最流行的方法。

## 枢纽和枢纽表

Pivot 和 pivot table 非常受欢迎，对初学者特别有吸引力，因为它们非常强大。然而，它们的强大是以性能为代价的。虽然 pivot 是一个很好的工具，可以作为数据规范化步骤的一部分对数据帧进行初始转换，但是在整个数据分析阶段不应该频繁使用它。清单 [5-1](#PC1) 展示了一个使用数据透视表将原始检查数据转换成餐馆及其平均检查分数的汇总格式的例子。注意在清单 [5-1](#PC1) 中，聚集函数被明确指定为 np.mean，尽管这是不必要的，因为 np.mean 是默认值。Pivot 本质上是执行 groupby，根据需要应用聚合函数，并将结果重新组织成新的表格格式。

```py
>> df
     restaurant  location    date       score
     Diner       (4, 2)      02/18      90
     Pandas      (5, 4)      04/18      55
     Diner       (4, 2)      05/18      100
     Pandas      (5, 4)      01/18      76
>> df = df.pivot_table(
     values=['score'],
     index=["restaurant","location"],
     aggfunc=np.mean
)
>> df
                                score
     restaurant  location       
     Diner       (4, 2)         95
     Pandas      (5, 4)         66

Listing 5-1Calculating the average inspection score per restaurant with pivot_table

```

清单 [5-1](#PC1) 中有几个性能问题。数据透视表没有限制内存复制的选项，因此每次使用时都会创建一个全新的数据帧。如果您的数据帧非常大，这可能会严重影响您的程序的性能。在内部，数据透视表是按唯一的餐馆和位置组合对数据进行分组，这需要时间，尤其是有大量组合时。如果这被用作数据标准化步骤的一部分，它将比在整个程序中多次被用作数据分析的一部分要好得多。这是因为对所有内存进行唯一分组和复制的性能影响只会发生一次，而在整个程序中会发生多次。对数据帧进行一次规范化和定向，使其能够优化您计划对其执行的所有分析，这要比将其留在某种程度上未优化的原始形式中，并且在每个分析步骤中都必须对其进行重新定向好得多。注意，如果数据帧已经被唯一分组，我们可以运行 groupby 来计算平均分数，如清单 [5-2](#PC2) 所示，这样会快一倍。我们将在第 7 章[中深入讨论 groupby 的性能。其他分析很可能需要按唯一的餐馆分组的数据，因此本例中的分组至少应该是规范化步骤的一部分，在这种情况下，根本没有必要使用数据透视表。](7.html)

```py
>> df
                            date        score
     restaurant  location
     Diner       (4, 2)     02/18       90
                            04/18       55
     Diner       (4, 2)     05/18       100
                            01/18       76
>> df = df[["score"]].groupby(["restaurant","location"]).mean()
>> df
     restaurant  location     score
     Diner       (4, 2)       95
     Pandas      (5, 4)       66

Listing 5-2Calculating the average inspection score per restaurant with groupby

```

Pivot 的功能与 pivot table 相同，但它不允许您聚合数据。使用数据透视表时，任何导致多个值的列和索引值组合都必须聚合在一起。另一方面，Pivot 如果遇到这种情况，就会抛出 ValueError。注意在清单 [5-3](#PC3) 中，药物和日期的组合不会产生多个值；然而，在清单 [5-4](#PC4) 中，相同的药品和日期有或将会有多行；因此，清单 [5-4](#PC4) 抛出了一个 ValueError。因此，pivot 和 pivot table 的一个令人遗憾的限制是，它们不输出索引和列组合有多个值的数据。Pivot table 强制您将多个值聚合在一起，或者选择一个值，Pivot 只是抛出一个 ValueError。

```py
>> df
     date          tumor_size    drug      dose
     02/18         90            01384     10
     02/25         80            01384     10
     03/07         65            01384     10
     03/21         60            01384     10
     02/18         30            01389     7
     02/25         20            01389     7
     03/07         25            01389     7
     03/21         25            01389     7
>> df.pivot(
     index="drug",
     columns="date",
     values="tumor_size",
)
ValueError: Index contains duplicate entries, cannot reshape

Listing 5-4Pivot throws a ValueError when there are multiple values for the same column-index combination

```

```py
>> df
     date           tumor_size      drug         dose
     02/18          90              01384        10
     02/25          80              01384        10
     03/07          65              01384        10
     03/21          60              01384        10
     02/18          30              01389        7
     02/25          20              01389        7
     03/07          25              01384        10
     03/21          25              01389        7
>> df.pivot(
     index="drug",
     columns="date",
     values="tumor_size"
)
     date    02/18    02/25    03/07     03/21
     drug
     01384   90        80       65         60
     01389   30        20       25         25

Listing 5-3Re-orienting a DataFrame using pivot

```

Pivot 比 pivot table 更具性能，因为它不允许指定和生成多级列和多索引。因此，它没有生成和处理这种更复杂的数据帧格式的开销。无论生成的数据帧是多索引还是多级别列数据帧，pivot table 仍然会运行各种计算，就像它是多级别的一样，这增加了相当多的开销，在某些情况下比 pivot 多六倍。虽然 pivot 允许您指定多个值并为它们创建一个多级列，但它不允许您提供一个显式的列列表来生成多级列，也不允许您提供一个索引列表来生成多级索引。另一方面，数据透视表支持这种类型的多级数据框架。它还有其他一些很好的选项，比如添加所有行和列的小计，以及删除包含 nan 的列。总之，如果您可以不使用 pivot，那么您应该这样做，因为它比使用 pivot table 更高效。

## 堆叠和取消堆叠

Stack 和 unstack 将数据帧的列级重新整形为最内部的索引，反之亦然。清单 [5-5](#PC5) 中显示了一个这样的例子，其中每一列都是一个餐馆卫生检查，值是卫生检查分数，指数代表被检查的餐馆。Stack 用于改变数据的形状，以便每个餐馆的健康检查分数出现在每行而不是每列。Note stack 将顶部的列名转换成列值，然后最终从数据帧中删除。

```py
>> df
                                      score
     inspection                       0    1
     restaurant  location
     Diner       (4, 2)               90   100
     Pandas      (5, 4)               55   76
>> df = df.stack().reset_index()
>> df
     restaurant  location   inspection  score
     Diner       (4, 2)      0          90
                             1          100
     Pandas      (5, 4)      0          55
                             1          76
>> df.drop(column=["inspection"], inplace=True)
>> df.set_index(["restaurant", "location"], inplace=True)
>> df
                           score
     restaurant  location
     Diner       (4, 2)     90
                            100
     Pandas      (5, 4)     55
                            76

Listing 5-5Reshaping a DataFrame so that each row represents an inspection using stack

```

您可能会从清单 [3-22](3.html#PC22) 中认出清单 [5-5](#PC5) 中原始数据帧的形状。清单 [5-5](#PC5) 中数据帧整形前的形状是在第 [3](3.html) 章末尾的“选择正确的数据帧”一节中被认为是最佳的方向。清单 [5-5](#PC5) 显示了如何从最佳形状转换为原始的非最佳形状。现在让我们来看看如何把原来的非最优形状变成最优形状。清单 [5-6](#PC6) 向数据帧添加一个名为 inspection 的新列，其值成为新数据帧的列名。我们还使用了一个方便的 groupby 聚合函数 cumcount，它为每个组中的每一行创建一个行号。

```py
>> df
                             score
     restaurant  location
     Diner       (4, 2)      90
                             100
     Pandas      (5, 4)      55
                             76
>> df["inspection"] = df.groupby(
     ["restaurant", "location"]).cumcount()
>> df
                          inspection  score
     restaurant  location
     Diner       (4, 2)    0          90
                           1          100
     Pandas      (5, 4)    0          55
                           1          76
>> df.set_index("inspection", append=True, inplace=True)
>> df
                                        score
     restaurant  location   inspection
     Diner        (4, 2)    0           90
                            1           100
     Pandas        (5, 4)   0           55
                            1           76
>> df = df.unstack()
>> df
                                        score
     inspection                         0    1
     restaurant  location
     Diner       (4, 2)                 90   100
     Pandas      (5, 4)                 55   76

Listing 5-6Reshaping a DataFrame so that each column is an inspection using unstack

```

那么堆栈和非堆栈的性能如何呢？它们都复制内存，因为它们不是成本高昂的就地操作，因此实际上只应在数据规范化中使用。然而，它们转换数据的方式非常独特，所以除了 melt 之外，很难找到一种性能更好的替代方法，这是我们将在下一节探讨的。

## 熔化

清单 [5-7](#PC7) 中显示了一个使用 melt 的示例。请注意，这与堆栈示例非常相似。在这个例子中，我们实际上是在做我们在大约四行中所做的事情，stack 在一行中。虽然 melt 做的事情和 stack 一样，但它做的更好。这主要是因为它具有轻微的开销优势，因为它不调用高层的所有各种数据转换，这意味着 melt 不调用底层的 stack，而是直接在 stack 下面执行较低级别的数据操作，从而避免了中间代码层。如果将原始堆栈与 melt 进行比较，stack 大约快四倍。使用 stack 的缺点是它经常需要其他操作，比如设置索引、重命名列、将其转换回数据帧等等。这意味着在某些情况下，只使用 melt 更有效。

```py
>> df
     restaurant  location    0    1
     Diner       (4, 2)      90   100
     Pandas      (5, 4)      55   76
>> df = df.melt(
     id_vars=["restaurant","location"],
     value_vars=[0,1],
     value_name="score").drop(columns="variable")

>> df
     restaurant  location      score
     Diner       (4, 2)        90
                               100
     Pandas      (5, 4)        55
                               76

Listing 5-7Reshaping a DataFrame so that each row represents an inspection using melt

```

## 移项

转置是一个有用的技巧。它只是将列变成行，将行变成列。在列表 [5-8](#PC8) 中，有一个需要治疗某种疾病的患者列表和一个根据血型提供用于治疗该疾病的药物列表的表格。我们需要根据患者的血型将可用于治疗给定患者的药物列表添加到患者表中。第一步是按血型索引患者列表和药物表，然后我们可以做一个简单的连接，将药物数据添加到患者列表中。因为药物表的方向是血型跨列而不是行，所以我们首先进行转置。注意，当我们这样做时，在创建数据帧时默认提供的索引变成了列，而列直接变成了索引。这意味着在清单 [5-8](#PC8) 中，我们不需要显式地设置索引，因为转置已经为我们设置了血型索引。

```py
>> patient_list
                   id      history
     blood_type    
     0+            02394   hbp
     B+            02312   NaN
     0-            23409   lbp
>> drug_table
     index         0+   0-   A+   A-   B+   B-
     0             ADF  ADF  ACB  DCB  ACE  BAB
     1             GCB  RAB  DF   EFR       HEF
     2             RAB
>> drug_table = drug_table.transpose(copy=False)
>> drug_table
     blood_type   0     1      2
     0+           ADF   GCB    RAB
     0-           ADF   RAB
     A+           ACB   DF
     A-           DCB   EFR
     B+           ACE
     B-           BAB   HEF
>> patient_list.join(drug_table)

                     id       history    0      1      2
     blood_type
     0+               02394   hbp        ADF    GCB    RAB
     B+               02312   NaN               ACE
     0-               23409   lbp               ADF    RAB

Listing 5-8Using a transpose to reshape a DataFrame

```

Transpose 是为数不多的数据帧整形函数之一，它可以选择不复制数据(如果可能的话)。也就是说，copy=False 并不一定意味着数据没有重复，我们将在第 [9](9.html) 章中更详细地解释。数据是否被复制取决于许多因素，这些因素最终归结为数据的新形式是否可以按原样重用底层 NumPy 数组，或者是否必须创建新的 NumPy 数组。回想一下，NumPy 数组必须都是相同的类型。这意味着，如果您正在转置的数据帧的行和列具有相同的类型，那么它很可能能够重用现有的 NumPy 数组。否则，它将不得不复制内存并重建它们。这意味着转置应该只在绝对必要时使用，并且最好是作为数据规范化步骤的一部分。

查看所有这些数据转换函数的要点是，数据转换的成本非常高，在理想的程序中，应该只在规范化阶段进行。在数据分析过程中应该谨慎使用。如果您发现自己必须在每个数据分析步骤中进行大量转换，那么您应该重新考虑规范化数据框架的方向。在下一章中，我们将看看 apply 方法，并探索它何时应该使用，何时不应该使用，以及更高性能的替代方法。