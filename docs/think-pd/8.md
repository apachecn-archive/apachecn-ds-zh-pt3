# 8.熊猫之外的性能改进

您可能听过另一个 pandas 用户提到使用 eval 和 query 来加速 pandas 中表达式的求值。虽然使用这些函数可以加快表达式的求值速度，但是没有一个非常重要的库的帮助是不行的:NumExpr。在没有安装 NumExpr 的情况下使用这些函数实际上会导致性能下降。然而，为了理解 NumExpr 如何能够加速计算，我们需要深入了解计算机的架构。

## 计算机体系结构

CPU 被分成多个内核，每个内核都有一个专用的高速缓存。每个内核一次评估一条指令。与您可能在 Python 程序中看到的相比，这些指令是非常基本的。Python 的一行代码通常被分解成许多 CPU 指令。一些示例包括加载数据，如在循环时将数组值存储到临时变量中，在调用函数时跳转到新的指令位置，以及计算表达式，如将两个值相加。

![../images/487367_1_En_8_Chapter/487367_1_En_8_Fig1_HTML.jpg](../images/487367_1_En_8_Chapter/487367_1_En_8_Fig1_HTML.jpg)

图 8-1

五相流水线架构

在现代岩心中，评估分为许多阶段。这些多个阶段被称为流水线，其中每个指令评估通过一系列阶段进行，直到评估完成。现代英特尔 CPU 通常分为大约 15 个流水线阶段。图 [8-1](#Fig1) 显示了一个简单的五相流水线处理器的例子。首先，指令通常从专用的指令高速缓存中取出，或者如果不存在，则必须从更远的高速缓存或主存储器中取出。然后指令被解码。在解码阶段，每条指令都有一个特定的数字代码，可以解码成某种类型的指令，并产生某种行为，因此解码阶段负责解码指令，并从寄存器(您可以将它们视为一个非常小的专用内存缓存)收集数据，然后传递到执行阶段。在执行阶段，指令实际运行；这可能意味着两个值相加在一起，或者如果它是一个加载指令，只是一个内存地址被传递到下一个阶段。由于指令可能是跳转到不同的存储器位置，而不是顺序位置，所以评估阶段的一部分也是确定要通过流水线发送的下一条指令。在存储器访问阶段，需要为即将到来的指令从存储器加载到寄存器中的任何数据被取出，然后在写回阶段被加载到寄存器中。这意味着，如果您希望将两个值相加，则必须先用加载指令将这些值加载到两个不同的寄存器中，然后才能运行加法指令。因此，清单 [8-1](#PC1) 中的 Python 代码行由 CPU 内部的三条指令组成。

```py
a = b + c        load b
                 load c
                 add a, b, c

Listing 8-1Converting a line of Python code into pseudo-code CPU instructions

```

虽然清单 [8-1](#PC1) 中的 CPU 指令可能看起来类似于 Python 字节码，但重要的是要注意它们并不相同。记住字节码是在 Python 虚拟机上运行的，而 CPU 指令是在 CPU 上运行的。虽然您可以使用 dis 模块(dis 代表反汇编)来输出字节码，并且它可能会让您对机器码的样子有所了解，但它不是机器码。Python 虚拟机包含一个巨大的 switch 语句，它将字节码指令翻译成函数调用，然后函数调用执行 CPU 指令。因此，虽然我们可能认为 Python 是一种在软件虚拟机中运行字节码指令的解释语言，但事实是在某个时候 add 指令会到达 CPU。最终，加法变成了一系列 CPU 指令，如清单 [8-1](#PC1) 所示。

指令流水线的存储器访问阶段比所有其他流水线阶段花费更长时间是很常见的。不是使所有其他流水线阶段像存储器访问阶段一样慢或者插入 nop(通常称为无操作或无操作)，而是使用不依赖于被加载的数据的其他指令来填充时间。这使得处理器能够继续评估指令，即使指令的一个阶段可能需要数百个周期才能完成。编译器还通过重新排序指令，使得不依赖于存储器加载的指令出现在存储器加载指令和下一个依赖于已经加载的存储器的指令之间，从而在长指令加载期间保持处理器忙碌。在现代英特尔处理器中，重新排序也可以发生在 CPU 内部。当然，有时没有说明书来填补空白，所以 nop 被用作最后的手段。这可以确保内核的指令吞吐量仍然尽可能接近每时钟周期(相位)一条指令，这样您就不必等待数百个周期来完成内存加载。

这里的要点是，为了有效利用 CPU 并获得尽可能高的指令吞吐量，您必须确保在使用数据之前加载数据，并在您正在操作的数据和您需要的下一个数据之间进行足够的计算。

到目前为止，我们已经介绍了 CPU 如何在低级别上运行以评估指令，以及它如何工作以实现最佳性能；现在让我们更深入地了解一下内存访问阶段，以及为什么它经常成为瓶颈。图 [8-2](#Fig2) 显示了现代英特尔 CPU 的典型高速缓存架构。每个内核都有一个专用的 1 级数据、1 级指令和 2 级高速缓存。所有内核共享三级高速缓存和主内存。这些缓存中的每一个都被放置在离主板上的核心越来越远的地方。虽然内核速度与晶体管尺寸和速度密切相关，但内存速度与它们与主板上内核的物理距离相关。

![../images/487367_1_En_8_Chapter/487367_1_En_8_Fig2_HTML.png](../images/487367_1_En_8_Chapter/487367_1_En_8_Fig2_HTML.png)

图 8-2

高速缓存架构

当处理大型数据集时(这是 pandas 中的预期用例)，所有的数据都不能存储在缓存中。访问一级高速缓存通常需要大约三个时钟周期或指令阶段，并且在每一级，等待时间呈指数级增加。要访问 3 级高速缓存，大约需要 21 个时钟周期，如果我们希望加载的数据不在任何高速缓存中，它必须一直到主存储器才能加载，则需要 150 到 400 个时钟周期。在大约 21 个时钟周期时，访问三级高速缓存对性能的影响可能会超过内核中的流水线数量。如果我们必须延迟流水线中的指令，直到检索到数据，而没有重新排序来填补延迟，这可能会使我们的整个程序停止 21 个时钟周期。4 GHz 处理器上 21 个时钟周期的延迟约为 5.25 ns。这可能看起来无关紧要，如果我们在程序中只出现几次这种延迟的话。然而，请记住，我们通常在 pandas 中操作数兆字节的数据，因为不是所有的数据都适合缓存，所以我们可能会遇到很多这样的性能问题。事实上，如果在整个数据集上运行一个操作，我们甚至更有可能对主存的性能产生更大的影响。

高速缓存通常是为一般情况下的最佳性能而设计的。在软件中，这意味着像在序列数据结构的数组上循环这样的事情。正因为如此，当他们必须将一些东西加载到缓存中时，他们一次加载连续的内存块，称为缓存行。这有助于抵消将内容加载到缓存中对性能的影响。这个想法是典型的程序在顺序存储器上操作，因此通过加载内核现在需要的存储器之后的存储器，将节省以后加载该存储器的需要。

为了最有效地利用缓存，应该在很短的时间内重复引用内存中顺序放置或靠得很近的数据。顺序数据将导致更少的缓存负载。在短时间内重复引用相同的数据，可以防止新数据将旧数据从缓存中溢出，从而导致缓存未命中，需要将相同的数据再次加载到缓存中。正如我们在第 [3](3.html) 章中了解到的，数组是顺序数据类型，这意味着第一个元素出现在地址 A，最后一个元素出现在 A 加上数组的长度。当您在内存中创建一组具有许多指向其他对象并引用这些属性的属性的对象时，每个对象都有一个不连续的地址，因此您将无法利用您的缓存，因为您将从一组不同的内存位置加载一组不同的缓存行。图 [8-3](#Fig3) 展示了这两种类型的内存访问。

![../images/487367_1_En_8_Chapter/487367_1_En_8_Fig3_HTML.jpg](../images/487367_1_En_8_Chapter/487367_1_En_8_Fig3_HTML.jpg)

图 8-3

一段时间内的顺序内存访问与对象属性访问

## NumExpr 如何提高性能

NumExpr 通过在 pandas 数据帧的子集上运行计算来提高 pandas 的性能，pandas 数据帧的子集是缓存的大小。以(A+B)÷3 为例，其中 A 和 B 是熊猫数据帧。如果没有 NumExpr，A + B 的每一行都将被加在一起，存储到一个临时结构中，然后乘以 3。使用 NumExpr，可以放入缓存的前 n 行被加在一起并乘以 3，然后移动到下 n 行。通过这种方式，NumExpr 能够减少内存加载和存储的数量，我们在“计算机架构”一节中了解到，内存加载和存储是 CPU 的瓶颈，因此也是计算机程序的瓶颈。清单 [8-2](#PC2) 演示了这一点。

注意清单 [8-2](#PC2) 中的缓存是三条缓存线(足以容纳 64 行 A、B 和 C 数据)。虽然这比通常可以容纳大约 128 条高速缓存线的真实世界 1 级高速缓存小得多，但是它简化了示例。这意味着在计算 64 行 A + B 的结果后，必须将结果存回内存，以便为 A 和 B 的下 64 行及其结果腾出空间。请注意，通过使用 NumExpr 的方法在缓存大小的块上运行计算，我们减少了加载次数和存储次数。还要注意清单 [8-2](#PC2) 中的例子是按顺序编写的伪代码 CPU 指令(即，这些不是将在内核中执行的实际指令，它们很可能在现实世界中被重新排序，以抵消“计算机架构”一节中讨论的内存加载延迟)。

```py
# NumExpr is not installed.        # NumExpr is installed.
C = ( A + B ) * 3                  C = pd.eval("( A + B ) * 3")

load A[0:64]                       load A[0:64]
load B[0:64]                       load B[0:64]
add C[0], A[0], B[0]               add C[0], A[0], B[0]
                                   mult C[0], C[0], 3
add C[1], A[1], B[1]               add C[1], A[1], B[1]
                                   mult C[1], C[1], 3

.
.
add C[63], A[63], B[63]           add C[63], A[63], B[63]
                                  mult C[63], C[63], 3
store C[0:64]                     store C[0:64]
load A[64:128]                    load A[64:128]
load B[64:128]                    load B[64:128]
add C[64], A[64], B[64]           add C[64], A[64], B[64]
                                  mult C[64], C[64], 3
add C[65], A[65], B[65]           add C[65], A[65], B[65]
                                  mult C[65], C[65], 3
.
.
add C[127], A[127], B[127]        add C[127], A[127], B[127]
                                  mult C[127], C[127], 3
store C[64:128]                   store C[64:128]
load C[0:64]
mult C[0], C[0], 3
mult C[1], C[1], 3
.
.
mult C[3], C[63], 3
store C[0:64]
load C[64:128]
mult C[64], C[64], 3
.
.
mult [127], C[127], 3
store C[64:128]

Listing 8-2CPU pseudo-code instructions during evaluation of a pandas expression with and without NumExpr

```

请注意，为了在 pandas 数据帧的大块上同时运行这样的评估，我们必须在计算之前将整个表达式传达给 NumExpr。(A+B)∫3 必须以 NumExpr 知道它可以组合在一起的方式指定。这就是 query 和 eval 的用武之地。eval 允许您将一个复杂的表达式指定为一个字符串，以通知 NumExpr 它可以一次在一个数据帧块上运行。query 实际上是 eval 的另一种形式，因为它在底层调用 eval。

根据计算、数据的形状和大小、操作系统以及您使用的硬件，您可能会发现使用 NumExpr 和 eval 实际上会导致性能显著下降。在盲目地将计算合并到 eval 或查询中之前，进行性能比较总是好的。NumExpr 实际上只适用于超过三级缓存大小的计算。通常，这大于 256，000 个数组元素。正如我们在其他 pandas 函数中看到的那样，它还要求数据类型和计算能够很容易地转换成 c。例如，日期时间不会产生性能改进，因为它们不能在 NumExpr 中计算。同样值得注意的是，在 pandas 中直接使用 NumExpr 比使用 eval 或 query 要高效得多。清单 [8-3](#PC3) 展示了这样一个例子。

```py
import pandas as pd
import numpy as np
import numexpr as ne

nrows, ncols = 1000000, 1
df1, df2, df3, df4 = [pd.DataFrame(
     np.random.randn(nrows, ncols)) for _ in range(4)]

# Calculate the sum using normal syntax.
df_sum1 = df1 + df2 + df3 + df4

# Calculate the sum using eval so that NumExpr optimizes it.
df_sum2 = pd.eval("df1 + df2 + df3 + df4")

# Calculate the sum using NumExpr directly.
a1, a2, a3, a4 = (
     df1.to_numpy(), df2.to_numpy(), df3.to_numpy(), df4.to_numpy()
)
df_sum3 = ne.evaluate("a1 + a2 + a3 + a4")

Listing 8-3An example where eval is slower than the typical pandas syntax with NumExpr

```

df_sum1 的计算速度是 df_sum2 的两倍。这通常与我们预期的相反，因为 df_sum2 是使用 NumExpr 计算的。但是，如果我们直接使用 NumExpr，而不是通过熊猫 eval，我们发现 df_sum3 比 df_sum1 快 4 倍左右。这是因为 pandas eval 函数本身速度变慢了。在 eval 中，它将环境包装成一个局部和全局变量的字典，并使 NumExpr 可以访问它们。这包括将数据帧转换为 NumPy 数组。所有这些都需要大量的开销。以至于它实际上比不使用 eval 和 NumExpr 要慢。通常情况下，将数据帧显式转换为 NumPy 数组并对这些转换后的数据帧显式调用 NumExpr 会快得多。

既然我们已经看到了 NumExpr 如何在硬件级别提高 pandas 的组合计算性能，那么让我们看看 NumPy 和 NumExpr 的另一个依赖项 BLAS 如何利用硬件来优化其计算。

## 布拉斯和拉普卡

NumPy 使用基本的线性代数子程序(BLAS)来实现高性能的线性代数运算，如矩阵乘法和向量加法。这些子程序通常用汇编语言编写，汇编语言是一种非常低级的高性能语言，非常类似于 CPU 指令。线性代数软件包(LAPACK)提供了求解线性方程的例程。它通常用 Fortran 编写，就像 NumPy 一样，在底层调用 BLAS。BLAS 和 LAPACK 的实现有很多，比如 Netlib BLAS 和 LAPACK、OpenBLAS、英特尔 MKL、Atlas、BLIS 等等，每种都有各自的优缺点。但是，让我们更深入地探索 BLAS 如何提高 pandas 操作的性能。

BLAS 通过使用单指令多数据(SIMD)指令来优化矩阵运算，这些指令利用了硬件中的向量寄存器。所有的 CPU 都有寄存器来保存 CPU 指令需要操作的数据。向量寄存器只是这些寄存器中的一种特殊类型。它们允许在单个寄存器中存储多段数据，当对数据进行操作时，它会同时对寄存器中的每段数据进行操作。SIMD 指令的优势在于，您可以将一批数据加载到寄存器中，并对其同时运行相同的操作，而不必对每个元素连续运行相同的操作。通过使用 SIMD 指令，我们减少了完成计算所需的 CPU 时钟周期数。例如，如果向量寄存器能够保存四个数据元素，那么我们就将时钟周期数从四个减少到一个。这意味着如果你有一个 y 和 x 的点积，如清单 [8-4](#PC4) 所示，那么你可以将它指定为一系列 SIMD 指令，如清单 [8-5](#PC5) 所示。注意，y 和 x 数据首先载入矢量寄存器 r1 和 r2，然后计算点积并存储在寄存器 r1 中。

![../images/487367_1_En_8_Chapter/487367_1_En_8_Figa_HTML.jpg](../images/487367_1_En_8_Chapter/487367_1_En_8_Figa_HTML.jpg)

```py
product

Listing 8-4Dot 

```

```py
load vr2, Y1, Y2, Y3, Y4
load vr1, X1, X2, X3, X4
dot r1, vr2, vr1

Listing 8-5Dot product as SIMD pseudo-instruction

```

这里我们忽略了一个重要的细节，即通常情况下，如果数据在内存中是有序的，那么它只能被加载到向量寄存器中。这给大多数复杂的向量运算带来了一个小问题，这些运算通常发生在一个矩阵的行和另一个矩阵的列上，反之亦然。BLAS 与 Python 相反，它的数组以列为主，而不是以行为主。BLAS 也没有二维数组，它们存储为一维数组。清单 [8-6](#PC6) 展示了一个 Python 数组的例子，以及它如何存储在 BLAS 中。

```py
Python                   BLAS
y = [[1, 2], [3, 4]]     y = [1, 3, 2, 4]
y[row][col]              y[col * num_cols + row]

Listing 8-6Comparison of a matrix representation in Python vs. BLAS

```

所以，回到清单 [8-5](#PC5) 中的点积示例，因为这些数组都被表示为一维数组，尽管一个是一堆行，另一个是一堆列，但它们都有连续的内存地址，因此它们都可以被加载到向量寄存器中。只有在处理更复杂的矩阵和更复杂的运算时，连续内存地址的问题才会出现，所以让我们看一个更复杂的例子。

有许多方法可以执行矩阵乘法。一种方法是使用点积，如图 [8-4](#Fig4) 所示。将第一个矩阵的行与第二个矩阵的列进行点积，将得到矩阵乘法结果中单个元素的值。

![../images/487367_1_En_8_Chapter/487367_1_En_8_Fig4_HTML.jpg](../images/487367_1_En_8_Chapter/487367_1_En_8_Fig4_HTML.jpg)

图 8-4

使用点积的矩阵乘法

在图 [8-4](#Fig4) 中，我们现在遇到一种情况，由于存储器不连续，将第一个矩阵的一行加载到向量寄存器中是不可能的。但是，请注意，如果我们转置矩阵，使行成为列，那么内存是连续的，我们可以将第一个矩阵的行加载到向量寄存器中。

但是如果矩阵非常大会怎么样呢？如果我们转置一个 1000 乘 1000 的矩阵，它将无法全部放入缓存，并且当它必须到主内存中读写数据时，将会导致巨大的延迟。BLAS 通过像 NumExpr 一样将矩阵数据分解成块来优化这一点。示例如图 [8-5](#Fig5) 所示。通过这样做，BLAS 能够将转置矩阵全部保存在缓存中，并在每个块上重用该占位符转置缓冲区。这不仅有利于将转置的缓冲区保存在高速缓存中，还因为不必为每个块重新分配新的缓冲区。它只是用当前块的新转置数据覆盖前一个块的缓冲区。

![../images/487367_1_En_8_Chapter/487367_1_En_8_Fig5_HTML.png](../images/487367_1_En_8_Chapter/487367_1_En_8_Fig5_HTML.png)

图 8-5

将大矩阵分解成块

通过将问题分解成块，BLAS 还能够利用多个内核。它可以在不同的内核上运行每个模块，这也节省了时间。

BLAS 用来加速计算的另一项技术是循环展开。这是将一个循环转换成一系列重复指令的时候。循环展开消除了预测分支的需要，并且潜在地招致对分支预测失误的分支预测惩罚。回想一下，在数据流水线中，指令可能在条件指令检查的结果出现之前被加载和处理。因此，硬件在确定之前，会尽最大努力正确预测该条件的结果以及将采用哪个分支。循环展开还避免了必须将指令指针跳转到指令存储器中的新位置，这潜在地避免了高速缓存未命中以及必须到主存储器加载不在指令高速缓存中的指令。它还避免了每次迭代开始时的条件指令检查，从而节省了 CPU 周期。通过展开循环，您还可以对计算进行重新排序，以便将使用相同内存的计算放在一起，从而减少寄存器加载指令。

总之，BLAS 使用了许多技术来提高线性代数运算的性能:SIMD 指令、分块、循环展开、线程等等。BLAS 也有许多可用的实现，为某些类型的 pandas 程序选择一个更高性能的选项可能会产生巨大的影响。

如果您发现自己在用 pandas 做大量的线性代数运算，您可以考虑切换到一个更高性能的 BLAS 实现。np.config_show()将显示 NumPy 当前使用的 BLAS 实现。Netlib BLAS 实现并不完全支持多核，其性能往往比替代方案差得多。像 OpenBLAS 这样的其他实现完全支持多核，并且是开源和免费的。从 Anaconda 2.5 或更高版本开始，英特尔 MKL 是默认的 BLAS 库，尽管是专有的大型库，但经过了高度优化，可以免费获得。

通过确保 NumPy 使用优化的依赖项 NumExpr 和 BLAS，您可以显著提高某些 pandas 操作的性能。这些库针对您正在运行的特定硬件优化操作，以确保您获得最佳性能。但是要注意它们什么时候会提升性能，什么时候不会。在最后一章，我们将展望熊猫 1.0 及以后的未来。