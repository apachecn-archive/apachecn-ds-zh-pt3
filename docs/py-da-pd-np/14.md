# 14.用 OpenCV 实现图像分析和计算机视觉

在前几章中，数据分析完全集中在数字和表格数据上，而在前一章中，我们看到了如何处理和分析文本形式的数据。这本书以介绍数据分析的最后一个方面作为结束:*图像分析*。

在本章中，将介绍计算机视觉和人脸识别等主题。你会看到深度学习的技术是如何成为这种分析的基础的。再者，还会介绍另一个库，叫做`openCV`，一直是图像分析的参考点。

## 图像分析和计算机视觉

在整本书中，你已经看到了分析的目的是如何提取新的信息，从被研究的系统中得出新的概念和特征。你用数字和文本数据做到了这一点，但是同样的事情也可以用图像来完成。

这个分析分支叫做*图像分析*，它基于一些应用于它们的计算技术(图像过滤器)，你将在接下来的章节中看到。

近年来，特别是因为深度学习的发展，图像分析在解决以前不可能的问题方面有了巨大的发展，产生了一个新的学科，称为*计算机视觉*。

在第 [9](09.html) 章中，你学习了人工智能，它是计算的一个分支，处理解决纯“人类相关性”的问题。计算机视觉是其中的一部分，因为它的目的是再现人脑感知图像的方式。

事实上，看不仅仅是获取二维图像，更重要的是，它是对该区域内容的解释。捕捉到的图像被分解和细化成不同的表现层次，这些层次逐渐变得更加抽象(轮廓、图形、物体和文字)，因此可以被人脑识别。

同样，计算机视觉打算处理二维图像，并从中提取相同级别的表示。这是通过各种操作完成的，这些操作可分为以下几类:

*   *检测*:检测图像中的形状、物体或其他研究对象(例如寻找汽车)

*   *识别*:识别出的主题然后被引回到一般类别(例如，按品牌和类型细分汽车)

*   *标识*:标识前一个类的实例(例如，查找我的汽车)

## OpenCV 和 Python

*OpenCV(开源计算机视觉)*是一个用 C ++编写的专门用于计算机视觉和图像分析的库( [`https://opencv.org/`](https://opencv.org/) )。这个强大的库由 Gary Bradsky 设计，是英特尔的一个项目，2000 年发布了第一个版本。然后随着时间的推移，它在开源许可下发布，此后逐渐变得更加广泛，达到了 3.3 版本(2017)。此时，OpenCV 支持许多与计算机视觉和机器学习相关的算法，并且正在日益扩展。

它的有用和传播正是由于它的对手:MATLAB。事实上，那些需要使用图像分析的人只能遵循两种方式:购买 MATLAB 软件包或编译并安装 OpenCV 的开源版本。很容易理解为什么许多人选择了第二种选择。

## OpenCV 和深度学习

计算机视觉和深度学习之间有着密切的关系。由于 2017 年是深度学习发展的重要一年(在 [`http://www.meccanismocomplesso.org/en/2017-year-of-deep-learning-frameworks/`](http://www.meccanismocomplesso.org/en/2017-year-of-deep-learning-frameworks/) 阅读我关于它的文章)，OpenCV 3.3 新版本的发布已经看到了深度学习和神经网络的许多新功能。其实库里面有一个叫`dnn`(深度神经网络)的模块是专门做这方面的。这个模块是专门为许多深度学习框架开发的，包括 Caffe2、TensorFlow 和 PyTorch(有关这些框架的信息，请参见第 [9 章](09.html))。

## 安装 OpenCV

在很多操作系统(Windows、iOS、Android)上安装 OpenCV 包都是通过官网( [`https://opencv.org/releases.html`](https://opencv.org/releases.html) )完成的。

如果您使用 Anaconda 作为分发介质，我推荐使用这种方法。安装非常简单和干净。

```
conda install opencv

```

不幸的是，对于 Linux 系统，没有安装官方的 PyPI 包(pip 是明确的)。需要手动安装，这可能会因所使用的发行版和版本而异。互联网上有许多程序，有些或多或少是有效的。对于有 Ubuntu 16 的人，我推荐这个安装程序(见 [`https://github.com/BVLC/caffe/wiki/OpenCV-3.3-Installation-Guide-on-Ubuntu-16.04`](https://github.com/BVLC/caffe/wiki/OpenCV-3.3-Installation-Guide-on-Ubuntu-16.04) )。

## 图像处理和分析的初步方法

在本节中，您将开始熟悉 OpenCV 库。首先，您将开始了解如何上传和查看图像。然后你会给他们传递一些简单的操作，对两幅图像进行加减运算，看到一个图像融合的例子。所有这些操作将非常有用，因为它们将作为任何其他图像分析操作的基础。

### 开始前

一旦安装了 OpenCV 库，您就可以在 Jupyter QtConsole 或 Jupyter Notebook 上打开 IPython 会话。

然后在开始编程之前，需要导入`openCV`库。

```
import numpy as np
import cv2

```

### 加载并显示图像

第一，主要是因为 OpenCV 是对图片进行操作的，所以知道如何用 Python 在程序中加载图片，再次操作图片，最后查看图片以看到结果是很重要的。

您需要做的第一件事是使用 OpenCV 库读取包含图像的文件。您可以使用`imread()`方法来完成此操作。这种方法读取压缩格式(如 JPG)的文件，并将其转换为由对应于色阶和位置的数字矩阵组成的数据结构。

### 注意

你可以在这本书的源代码中找到图片和文件。

```
img = cv2.imread('italy2018.jpg')

```

如果你对更多的细节感兴趣，你可以直接看到一张图片的内容。您将注意到一个数组的数组，每个数组对应于图像的一个特定位置，每个数组的特征是 0 到 255 之间的数字。

事实上，如果你看到图像的第一个元素的内容，你会得到以下内容。

```
img[0]
array([[38, 43, 11],
       [37, 42, 10],
       [36, 41,  9],
       ...,
       [24, 37, 15],
       [22, 36, 12],
       [23, 36, 12]], dtype=uint8)

```

继续代码，现在您将使用`imshow()`方法创建一个窗口，其中图像加载到变量`img`中。这个方法有两个参数——窗口名和图像变量。一旦你创建了窗口，你可以使用`waitKey()`方法。

```
cv2.imshow('Image', img)
cv2.waitKey(0)

```

执行该命令，一个新窗口打开并显示图像，如图 [14-1](#Fig1) 所示。

![../images/336498_2_En_14_Chapter/336498_2_En_14_Fig1_HTML.jpg](../images/336498_2_En_14_Chapter/336498_2_En_14_Fig1_HTML.jpg)

图 14-1

意大利国家足球队训练时的照片

`waitKey()`方法开始显示窗口，并允许您在继续下一个命令之前控制程序的等待时间。这个例子使用 0 作为参数，这意味着只要您按下键盘上的任何键，等待将是无限的。

如果您想让窗口只打开一段时间，您需要将毫秒数作为一个参数写入。尝试替换程序中的值，例如 2000(两秒)，然后运行程序。

### 注意

这种行为可能因系统而异。有时，IPython 内核可能会出现问题。然后用`waitKey(0)`。

```
cv2.imshow('Image', img)
cv2.waitKey(2000)

```

带有图像的窗口(如图 [14-1](#Fig1) 所示)应该出现，然后在两秒钟后消失。

然而，对于更复杂的例子，直接控制窗口的关闭而不使用等待时间是有用的。`destroyWindow()`方法允许您通过将窗口的名称指定为参数来关闭所需的窗口(可能是几个打开的窗口)，在您的例子中是`Image`。

```
cv2.imshow('Image', img)
cv2.waitKey(2000)
cv2.destroyWindow('Image')

```

如果有多个打开的窗口，你想一次关闭它们，你可以使用一个命令，调用`destroyAllWindows()`方法。

### 使用图像

现在您已经看到了如何查看文件系统中的现有图像，您可以继续下一步:通过对图像执行操作来处理图像，并将结果保存到一个新文件中。

继续前面的例子，您将使用相同的代码。但是，这一次，您将执行一个简单的图像操作，例如，通过分解三个 RGB 通道。然后你会交换通道形成一个新的图像。这个新图像将会改变所有的颜色。

加载图像后，将其分解为三个 RGB 通道。您可以通过使用`split()`方法轻松做到这一点。

```
b,r,g = cv2.split(img)

```

现在重新组装三个通道，但是改变顺序，例如将红色通道与绿色通道交换。您可以使用`merge()`方法轻松重组通道。

```
img2 = cv2.merge((b,g,r))

```

新图像包含在`img2`变量中。在新窗口中与原件一起显示。

```
cv2.imshow('Image2', img2)
cv2.waitKey(0)

```

通过运行程序，出现一个改变了颜色的新窗口(如图 [14-2](#Fig2) )。

![../images/336498_2_En_14_Chapter/336498_2_En_14_Fig2_HTML.jpg](../images/336498_2_En_14_Chapter/336498_2_En_14_Fig2_HTML.jpg)

图 14-2

处理后的图像改变了颜色

### 保存新图像

最后，您必须通过保存文件系统来保存您的新映像。

在程序的最后，添加一个带有您想要保存的新文件名称的`imwrite()`方法，该文件也可以是另一种格式，比如 PNG。

```
cv2.imwrite('italy2018altered.png', img2)

```

执行这个命令，您会注意到工作区中有一个新的`italy2018altered.png`文件。

### 图像的基本运算

最基本的操作是两幅图像的相加。有了`openCV`库，这个操作非常简单，你可以使用`cv2.add()`函数来完成。获得的结果将是两幅图像的组合。

但是不要忘记，两幅图像必须有相同的尺寸才能加在一起。在这种情况下，图像都是 512x331 像素。

您需要做的第一件事是加载具有相同尺寸的第二个图像，在我们的例子中是`soccer.jpg`(您可以在源代码中找到它)。

```
img2 = cv2.imread('soccer.jpg')
cv2.imshow('Image2', img2)
cv2.waitKey(0)

```

通过执行代码，您将得到如图 [14-3](#Fig3) 所示的图像。

![../images/336498_2_En_14_Chapter/336498_2_En_14_Fig3_HTML.jpg](../images/336498_2_En_14_Chapter/336498_2_En_14_Fig3_HTML.jpg)

图 14-3

相同大小的新图像(512x331 像素)

现在你只需要使用`add()`函数将两幅图像相加。

```
img = cv2.add(img,img2)
cv2.imshow('Sum',img)

```

通过执行这段代码，您将收到两幅图像的组合(如图 [14-4](#Fig4) 所示)。可惜效果不是很吸引人。

![../images/336498_2_En_14_Chapter/336498_2_En_14_Fig4_HTML.jpg](../images/336498_2_En_14_Chapter/336498_2_En_14_Fig4_HTML.jpg)

图 14-4

通过将两个图像相加而获得的新图像

结果不是我们所期望的。白色的流行实际上是三个 RGB 值的简单算术和的结果，这是为每个单独的像素计算的。

事实上，您知道三个 RGB 分量中的每一个都取从 0 到 255 的值。因此，如果给定像素的值之和大于 255(这很有可能)，该值仍将是 255。因此，将图像相加的简单任务不会产生两者合并的图像，而是逐渐向白色移动。

稍后您将看到如何将两个图像相加来创建一个新图像的概念，该新图像是两个图像的一半(它不是算术和)。

你可以通过减去两幅图像来做同样的事情。该操作可通过`cv2.subtract()`功能执行。这一次，我们将期待一个越来越倾向于黑色的图像。用以下内容替换`cv2.add()`功能。

```
img3 = cv2.subtract(img, img2)
cv2.imshow('Sub1',img3)
cv2.waitKey(0)

```

运行程序你会发现一张趋向黑暗的图片(即使你看不到太多)，如图 [14-5](#Fig5) 所示。

![../images/336498_2_En_14_Chapter/336498_2_En_14_Fig5_HTML.jpg](../images/336498_2_En_14_Chapter/336498_2_En_14_Fig5_HTML.jpg)

图 14-5

从一幅图像中减去另一幅图像得到的新图像

请注意，如果反过来做，这种效果会更差。

```
img3 = cv2.subtract(img2, img)
cv2.imshow('Sub1',img3)
cv2.waitKey(0)

```

你得到一个黑色的图像，如图 [14-6](#Fig6) 所示。

![../images/336498_2_En_14_Chapter/336498_2_En_14_Fig6_HTML.jpg](../images/336498_2_En_14_Chapter/336498_2_En_14_Fig6_HTML.jpg)

图 14-6

从一幅图像中减去另一幅图像得到的新图像

但是，知道运算符的顺序对结果很重要是很有用的。

更具体地说，您已经看到用 OpenCV 库创建的 image 对象只不过是一个数组的数组，它完美地响应了 NumPy 的准则。因此，您可以使用 NumPy 提供的矩阵之间的运算，例如矩阵的加法。但是要小心，结果肯定不会一样。

```
img = img1 + img2

```

事实上，`cv2.add()`和`cv2.subtract()`函数保持 0 到 255 之间的值，不管操作符的值是多少。如果总和超过 255，结果会有不同的解释，从而产生非常奇怪的颜色效果(可能是 255 的模块)。当删除产生负值时，也会发生同样的情况；结果将是 0。算术运算没有这个功能。

不过，你可以直接试试。

```
img3 = img + img2
cv2.imshow('numpy',img3)
cv2.waitKey(0)

```

执行它，你会得到一个色彩对比度非常强的图像(它们是 255 以上的点)，如图 [14-7](#Fig7) 所示。

![../images/336498_2_En_14_Chapter/336498_2_En_14_Fig7_HTML.jpg](../images/336498_2_En_14_Chapter/336498_2_En_14_Fig7_HTML.jpg)

图 14-7

通过将两个图像相加作为两个 NumPy 矩阵而获得的图像

### 图像混合

在前面的示例中，您看到了两个图像的相加或相减不会在两个图像之间产生中间图像，而是将颜色更改为白色或黑色。

正确的操作叫做*融合*。也就是说，你可以考虑将两个图像叠加的操作，一个在另一个上面，使放置在上面的那个逐渐变得越来越透明。通过逐渐调整透明度，你可以得到两个图像的混合，创建一个新的中间图像。

混合运算并不对应于简单的加法，但是公式对应于下面的等式。

```
img = α · img1 + (1 – α ) · img2       with  0 ≥ α ≥ 1

```

从前面的等式中可以看出，两幅图像有两个数值系数，取值范围在 0 和 1 之间。随着α参数的增长，你将有一个从第一个图像到第二个图像的平滑过渡。

OpenCV 库提供了用`cv2.addWeighted()`函数进行混合的操作。

因此，如果您想在两个源图像之间创建一个中间图像，您可以使用下面的代码。

```
img3 = cv2.addWeighted(img, 0.3, img2, 0.7, 0)
cv2.imshow('numpy',img3)
cv2.waitKey(0)

```

结果将是如图 [14-8](#Fig8) 所示的图像。

![../images/336498_2_En_14_Chapter/336498_2_En_14_Fig8_HTML.jpg](../images/336498_2_En_14_Chapter/336498_2_En_14_Fig8_HTML.jpg)

图 14-8

通过图像混合获得的图像

## 映象分析

上一节中的例子的目的是为了理解图像只不过是 NumPy 数组。因此，这些数字矩阵可以被处理。因此，您可以实现许多数学函数来处理这些矩阵中的数字，以获得新的图像。这些从操作中获得的新图像将用于提供新的信息。

这是*图像分析*的基本概念。从一幅起始图像(矩阵)到一幅合成图像(矩阵)的数学运算称为图像滤波器(见图 [14-9](#Fig9) )。为了帮助你理解这个过程，你肯定会遇到一些图片编辑软件(比如 Photoshop)。无论如何，你肯定已经看到了可以应用于照片的滤镜。这些过滤器只不过是修改起始图像矩阵中的数值的算法(数学运算序列)。

![../images/336498_2_En_14_Chapter/336498_2_En_14_Fig9_HTML.jpg](../images/336498_2_En_14_Chapter/336498_2_En_14_Fig9_HTML.jpg)

图 14-9

作为图像分析基础的图像过滤器的表示

## 边缘检测和图像梯度分析

在前面的章节中，您看到了如何执行一些对图像分析有用的基本操作。在本节中，您将从一个名为*边缘检测*的真实图像分析案例开始。

### 边缘检测

在分析图像时，尤其是在计算机视觉期间，基本操作之一是理解图像的内容，例如物体和人。首先有必要了解图像中代表了哪些可能的形式。然而，为了理解所表示的几何图形，有必要识别出将一个物体与背景或其他物体分隔开的轮廓。这正是边缘检测的任务。

在边缘检测中，已经开发了大量的算法和技术，它们利用不同的原理来正确地确定对象的轮廓。这些技术中的许多是基于颜色梯度的原理，并利用图像梯度分析过程。

### 图像梯度理论

在可应用于图像的各种操作中，有图像的*卷积*，其中应用某些过滤器来编辑图像，以便获得信息或一些其他用途。您已经看到，图像被表示为一个大的数字矩阵，其中每个像素的颜色由矩阵中从 0 到 255 的数字表示。卷积通过应用数学运算(*图像过滤器*)处理所有这些数值，以在相同大小的新矩阵中产生新值。

这些操作之一是*导数*。简而言之，导数是一种数学运算，它可以让你得到表示数值变化速度(在空间、时间等方面)的数值。).

在图像的例子中，导数是如何重要的？这与颜色变化有关，称为*渐变*。

能够计算颜色的梯度是计算图像边缘的极好工具。事实上，由于一种颜色到另一种颜色之间的跳跃，你的眼睛可以分辨出图像中人物的轮廓。此外，你的眼睛可以感知深度，这要归功于从亮到暗的各种色调，这就是渐变。

综上所述，很明显，测量图像中的梯度对于能够检测图像的边缘至关重要。这是通过对图像进行简单的操作(过滤)完成的。

为了从数学的角度更好地理解它，请看图 [14-10](#Fig10) 。

![../images/336498_2_En_14_Chapter/336498_2_En_14_Fig10_HTML.jpg](../images/336498_2_En_14_Chapter/336498_2_En_14_Fig10_HTML.jpg)

图 14-10

图像梯度理论表示

如图 [14-10](#Fig10) 所示，边缘只不过是从一种色调到另一种色调的快速过渡。简单来说，0 是黑色，1 是白色。所有灰色阴影都是介于 0 和 1 之间的浮动值。

如果将所有对应的值绘制成梯度值的图表，就会得到函数`f()`。你可以看到，有一个从 0 到 1 的突然转变，这表明了边缘。

函数`f()`的导数产生函数`f'()`。如您所见，色调的最大变化导致值接近 1。所以当转换颜色时，你会得到一个白色表示边缘的图形。

### 利用图像梯度分析进行边缘检测的实例

转到实际部分，您将使用专门创建的两幅图像来测试轮廓分析，因为它们有几个重要的特征。

第一幅图像(如图 [14-11](#Fig11) 所示)由两个黑白箭头组成，对应于`blackandwhite.jpg`文件。在此图像中，颜色对比非常强烈，箭头轮廓具有所有可能的方向(水平、垂直和对角线)。该测试图像将用于评估黑白系统中边缘检测的效果。

![../images/336498_2_En_14_Chapter/336498_2_En_14_Fig11_HTML.jpg](../images/336498_2_En_14_Chapter/336498_2_En_14_Fig11_HTML.jpg)

图 14-11

代表两个箭头的黑白图像

第二幅图像`gradients.jpg`，显示了不同的灰度梯度，当将它们放在一起时，会产生矩形，其边缘具有所有可能的梯度和阴影组合(如图 [14-12](#Fig12) 所示)。此图像是评估系统真正边缘检测能力的良好测试。

![../images/336498_2_En_14_Chapter/336498_2_En_14_Fig12_HTML.jpg](../images/336498_2_En_14_Chapter/336498_2_En_14_Fig12_HTML.jpg)

图 14-12

一组相邻放置的灰色渐变

现在你可以开始开发边缘检测所需的代码了。您将使用 matplotlib 在同一窗口中显示不同的图像。在这个测试中，我们将使用`opencv`提供的两种不同类型的图像过滤器:*索贝尔*和*拉普拉斯*。事实上，它们的名称对应于对矩阵(图像)执行的数学运算的名称。`openCV`库提供了`cv2.Sobel()`和`cv2.Laplacian()`来应用这两种计算。

首先，分析应用于`blackandwhite.jpg`图像的边缘检测。

```
from matplotlib import pyplot as plt
%matplotlib inline
img = cv2.imread('blackandwhite.jpg',0)
laplacian = cv2.Laplacian(img, cv2.CV_64F)
sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5)
sobely = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=5)

plt.subplot(2,2,1),plt.imshow(img,cmap = 'gray')
plt.title('Original'), plt.xticks([]), plt.yticks([])
plt.subplot(2,2,2),plt.imshow(laplacian,cmap = 'gray')
plt.title('Laplacian'), plt.xticks([]), plt.yticks([])
plt.subplot(2,2,3),plt.imshow(sobelx,cmap = 'gray')
plt.title('Sobel Y'), plt.xticks([]), plt.yticks([])
plt.subplot(2,2,4),plt.imshow(sobely,cmap = 'gray')
plt.title('Sobel Y'), plt.xticks([]), plt.yticks([])
plt.show()

```

当你运行这段代码时，你会得到一个有四个框的窗口(如图 [14-13](#Fig13) 所示)。第一个框是黑白的原始图像，而其他三个框是应用于图像的三个滤镜的结果。

![../images/336498_2_En_14_Chapter/336498_2_En_14_Fig13_HTML.jpg](../images/336498_2_En_14_Chapter/336498_2_En_14_Fig13_HTML.jpg)

图 14-13

应用于 blackandwhite.jpg 图像的边缘检测的结果

关于索贝尔过滤器，边缘检测是完美的，即使水平或垂直有限。对角线在两种情况下都是可见的，因为它们具有水平和垂直分量，但是无论如何都检测不到 Sobel X 中的水平边缘和垂直 Sobel Y 中的水平边缘。

组合两个滤波器(计算两个导数)以获得拉普拉斯滤波器，边缘的确定是全方位的，但是具有一些分辨率损失。事实上，您可以看到边缘对应的波纹更加柔和。

灰色对于检测边缘和渐变非常有用，但是如果您只对检测边缘感兴趣，您必须在`cv2.CV_8U`中设置一个图像文件作为输出。

因此，您可以在前面代码的 filters 函数中将输出数据的类型从`cv2.CV_64F`更改为`cv2.CV_8U`。替换传递给两个图像过滤器的参数，如下所示。

```
laplacian = cv2.Laplacian(img, cv2.CV_8U)
sobelx = cv2.Sobel(img,cv2.CV_8U,1,0,ksize=5)
sobely = cv2.Sobel(img,cv2.CV_8U,0,1,ksize=5)

```

通过运行代码，您将得到类似的结果(如图 [14-14](#Fig14) 所示)，但这次只是黑白的，边缘在黑色背景上以白色显示。

![../images/336498_2_En_14_Chapter/336498_2_En_14_Fig14_HTML.jpg](../images/336498_2_En_14_Chapter/336498_2_En_14_Fig14_HTML.jpg)

图 14-14

应用于 blackandwhite.jpg 图像的边缘检测的结果

但是如果你仔细观察索贝尔滤镜 X 和 Y 的面板，你会马上注意到有什么地方不对劲。缺失的边缘在哪里？请注意图 [14-15](#Fig15) 中的问题。

![../images/336498_2_En_14_Chapter/336498_2_En_14_Fig15_HTML.jpg](../images/336498_2_En_14_Chapter/336498_2_En_14_Fig15_HTML.jpg)

图 14-15

blackandwhite.jpg 图像中缺失的边缘

事实上，转换数据时出现了问题。当从黑色变为白色时，具有`cv2.CV_64F`值的灰度中报告的梯度由正值(正斜率)表示。然而，当从白色切换到黑色时，它们由负值(负斜率)表示。在从`cv2.CV_64F`到`cv2.CV_8U`的转换中，所有的负斜率都减小到 0，然后与这些边缘相关的信息丢失。当程序将显示图像时，从白色到黑色的边缘将不会显示。

为了克服这一点，你应该将滤波器输出中的数据保存在`cv2.CV_64F`(而不是`cv2.CV_8U`)中，然后计算绝对值，最后在`cv2.CV_8U`中进行转换。

对代码进行这些更改。

```
laplacian64 = cv2.Laplacian(img, cv2.CV_64F)
sobelx64 = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5)
sobely64 = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=5)
laplacian = np.uint8(np.absolute(laplacian64))
sobelx = np.uint8(np.absolute(sobelx64))
sobely = np.uint8(np.absolute(sobely64))

plt.subplot(2,2,1),plt.imshow(img,cmap = 'gray')
plt.title('Original'), plt.xticks([]), plt.yticks([])
plt.subplot(2,2,2),plt.imshow(laplacian,cmap = 'gray')
plt.title('Laplacian'), plt.xticks([]), plt.yticks([])
plt.subplot(2,2,3),plt.imshow(sobelx,cmap = 'gray')
plt.title('Sobel Y'), plt.xticks([]), plt.yticks([])
plt.subplot(2,2,4),plt.imshow(sobely,cmap = 'gray')
plt.title('Sobel Y'), plt.xticks([]), plt.yticks([])
plt.show()

```

现在，如果您执行它，您将在箭头的黑色边缘获得正确的白色表示(如图 [14-16](#Fig16) 所示)。可以看到，边缘没有出现在 Sobel X 和 Sobel Y 中，因为它们平行于检测方向(水平和垂直)。

![../images/336498_2_En_14_Chapter/336498_2_En_14_Fig16_HTML.jpg](../images/336498_2_En_14_Chapter/336498_2_En_14_Fig16_HTML.jpg)

图 14-16

应用于 blackandwhite.jpg 图像的边缘检测的结果

除了边缘，你可以看到拉普拉斯和索贝尔过滤器也能够检测灰度的梯度水平。将你所看到的应用到`gradient.jpg`图像中。您必须对前面的代码进行一些更改，只留下一个图像(拉普拉斯)来显示。

```
from matplotlib import pyplot as plt
img = cv2.imread('gradients.jpg',0)
laplacian = cv2.Laplacian(img, cv2.CV_64F)
sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5)
sobely = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=5)

laplacian64 = cv2.Laplacian(img, cv2.CV_64F)
sobelx64 = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5)
sobely64 = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=5)

laplacian = np.uint8(np.absolute(laplacian64))
sobelx = np.uint8(np.absolute(sobelx64))
sobely = np.uint8(np.absolute(sobely64))

plt.imshow(laplacian,cmap = 'gray')
plt.title('Laplacian'), plt.xticks([]), plt.yticks([])
plt.show()

```

通过执行这段代码，您将获得一个在黑色背景上显示白色边框的图像(如图 [14-17](#Fig17) 所示)。

![../images/336498_2_En_14_Chapter/336498_2_En_14_Fig17_HTML.jpg](../images/336498_2_En_14_Chapter/336498_2_En_14_Fig17_HTML.jpg)

图 14-17

应用于 gradients.jpg 图像的边缘检测的结果

## 深度学习的一个例子:人脸检测

在本章的最后一节，你将把注意力转移到计算机视觉中另一个被高度研究和使用的案例，人脸检测。

这是一个比边缘检测复杂得多的情况，它基于识别图像中的人脸。鉴于问题的复杂性，人脸检测使用深度学习。事实上，在这项技术的基础上，有专门设计的神经网络来识别不同的对象，包括照片中的人脸。对象检测技术的工作原理也非常相似。因此，这个例子对于充分理解计算机视觉的核心，即解释照片中出现的主题非常有用。

在本例中，您将使用一个已经学习过的神经网络。事实上，为这类问题训练神经网络可能是一项复杂的操作，需要大量的时间和资源。

幸运的是，在网络上，已经有一些神经网络被训练来执行这些类型的操作，对于这个测试，你将使用一个使用`Caffe2`框架开发的模型(更多信息见第 [9 章](09.html))。

当您想要在 OpenCV 环境中使用具有 Caffe 模型的深度神经网络模块时，您需要两种类型的文件，如下所示:

*   一个 *prototxt* 文件，它定义了模型架构(即层本身)。你将使用一个从网上下载的`deploy.prototxt.txt`文件( [`https://github.com/opencv/opencv/blob/master/samples/dnn/face_detector/deploy.prototxt`](https://github.com/opencv/opencv/blob/master/samples/dnn/face_detector/deploy.prototxt) )。

*   第二种类型的文件是一个 *caffemodel* 文件，它包含深度神经网络中实际层的权重。这个文件是最重要的，因为它包含了执行给定任务的神经网络的所有“学习”。为了您的目的，在 [`https://github.com/opencv/opencv_3rdparty/tree/dnn_samples_face_detector_20170830`](https://github.com/opencv/opencv_3rdparty/tree/dnn_samples_face_detector_20170830) 有一个 caffemodel 文件。

### 注意

您也可以在本书的源代码中找到这些文件。

现在你已经有了你需要的一切，开始上传神经网络模型和所有关于你学习的信息。

OpenCV 库支持许多深度学习框架，其中有许多功能可以帮助您做到这一点。特别是(本章开头提到的)，OpenCV 有`dnn`模块，专门处理这类操作。

要加载已学习的神经网络，您可以使用`dnn.readNetFromCaffe()`功能。

```
net = cv2.dnn.readNetFromCaffe('deploy.prototxt.txt', 'res10_300x300_ssd_iter_140000.caffemodel')

```

作为测试图，可以使用与意大利国家队球员的合照，`italy2018.jpg`。这张图片是一个很好的例子，因为里面有很多张脸。

```
image = cv2.imread('italy2018.jpg')
(h, w) = image.shape[:2]

```

另外一个功能，叫做`dnn` ***。*** `blobFromImage()`，负责预处理图像以适应神经网络。例如，将图像的大小调整为 300x300 像素，以便 caffemodel 文件可以使用它，该文件已针对此大小的图像进行了定型。

```
blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))

```

然后用最佳值 0.5 定义一个置信度阈值。

```
confidence_threshold = 0.5

```

最后进行人脸检测测试。

```
net.setInput(blob)
detections = net.forward()

for i in range(0, detections.shape[2]):
    confidence = detections[0, 0, i, 2]
    if confidence > confidence_threshold:
        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])
        (startX, startY, endX, endY) = box.astype("int")
        text = "{:.2f}%".format(confidence * 100)
        y = startY - 10 if startY - 10 > 10 else startY + 10
        cv2.rectangle(image, (startX, startY), (endX, endY),(0, 0, 255), 2)
        cv2.putText(image, text, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)

cv2.imshow("Output", image)
cv2.waitKey(0)

```

通过执行代码，将出现一个窗口，显示人脸检测的处理结果(如图 [14-18](#Fig18) )。结果令人难以置信，因为所有球员的脸都被检测到了。你可以看到这些脸被一个红色的正方形包围着，这个正方形在图像中以一定的置信度高亮显示它们。对于我们在测试开始时指定的`confidence_threshold`参数，置信百分比都大于 50%。

![../images/336498_2_En_14_Chapter/336498_2_En_14_Fig18_HTML.jpg](../images/336498_2_En_14_Chapter/336498_2_En_14_Fig18_HTML.jpg)

图 14-18

国足球员的面孔都被准确地识别出来了

## 结论

在这一章中，你看到了一些简单的技术例子，它们构成了图像分析，尤其是计算机视觉的基础。事实上，您看到了如何通过图像过滤器处理图像，以及如何使用边缘检测构建一些复杂的技术。您还看到了计算机视觉如何通过使用深度学习神经网络来识别图像中的人脸(人脸检测)。

我希望这一章是你对这个问题进一步深入了解的良好开端。如果你有兴趣，你可以在我的网站 [`https://meccanismocomplesso.org`](https://meccanismocomplesso.org) 找到关于这个主题的深入信息。