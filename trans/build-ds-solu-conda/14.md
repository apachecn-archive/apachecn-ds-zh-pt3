

# 十一、调整超参数和模型版本化

数据科学家的旅程总是一个迭代的过程。了解如何创建可伸缩和可重复的过程，可以确保您能够顺利地通过数据清理和模型发现的所有阶段。

在这一章中，我们将介绍如何创建一个管道，将我们在整本书中学到的许多小步骤组合成一个更容易的流程。然后，我们将看到如何使用网格搜索来发现最佳的超参数，以确保您正在创建最佳的可能模型。然后，我们将向您展示如何创建已保存和版本化的模型，让您可以在任何时间点轻松地返回到先前的模型。所有这些技能将为您创建可维护过程的最终目标提供更大的可访问性和灵活性。

具体来说，我们将在本章中介绍以下内容:

*   创建一个`scikit-learn`管道
*   用`GridSearchCV`寻找最佳超参数
*   版本化和存储您的模型

# 技术要求

为了充分利用本章的内容，您需要安装 Anaconda 发行版。这将包括 Python、conda 和 Navigator。

还需要安装 conda 环境，并安装以下软件包:

*   `scikit-learn`版本 0.23.x
*   `pandas`
*   NumPy
*   `joblib`

最好在一开始就安装所有这些，但是你也可以在本章的必要部分安装。

有了这些部分，现在是创建管道的时候了。

# 创建 scikit-learn 渠道

如果在这本书里有一件事你可能已经注意到了，那就是我们已经看过的每个问题都有许多共同的步骤。我们现在将通过利用`scikit-learn`管道来构建一个简单的、可重复的过程，从而确保我们能够更容易地迭代数据和模型创建步骤。在本节中，我们将采用之前通常需要重复多次的工作流程，并将其转换为一个单元，与之前的流程相比，这将为您提供更大的灵活性并节省时间。如果你是从这一章开始，或者在阅读其他章节之前跳到这一章，你需要知道之前所涉及的基础概念对于理解仍然非常重要。

为了形象化地描述这个过程，你可以参考下面的图表。在左边，您将看到普通的数据输入被传递到管道对象中。在流水线中，你会发现 1 到 n 个变压器和一个估计器在最终输出之前的末端。我们将逐一介绍这些步骤是什么:

![Figure 11.1 – An example of a scikit-learn pipeline flow
](image/Figure_11.1.jpg)

图 11.1–sci kit-learn 管道流程示例

**管道**让你把东西拼凑起来，有点像乐高积木，因为每个输出都是下一步输入的预期格式。在这种情况下，它只是一个数据集。使用管道有几个优点，定义如下:

*   **便利**:由于几个独立步骤的组合，你可以简单地调用`fit()`一次，而不是在每个单独步骤的整个过程中。这可能是最明显的好处，因为替代方案可能是创建您自己的函数，以确保您能够以可预测的方式调用一切。本质上，这就是幕后发生的事情。
*   **再现性**:当您有新的数据集需要对其执行完全相同的步骤时，比如您的测试数据集或真实世界数据的情况，您可以确保您走的是相同的道路。这可确保您使用特定假设(例如如何进行缩放)训练的模型与使用此新数据的模型相同。你所需要做的就是将新数据输入管道。
*   模块化:你可以在一行中用新的部分或技术替换掉，而不必担心你是否在其他地方错过了实现的某个方面。

这种方法如此有效的原因是因为`scikit-learn`估计器是如何结合在一起的。我们现在就去看看。

## sci kit-学习估计器和变压器

当我们处理创建管道时，估计器和转换器是特别重要的两个元素，所以让我们进一步研究它们。

### 了解 sci kit-学习估计器

估计器是一个对象，它使用现有数据来估计数据的其他部分。估计就是这样的一个例子。它们构成了流水线中的所有部分，但也有称为变压器的特定类型的估计器；现在让我们看看这些是什么。

### 了解 sci kit-学习变形金刚

转换器是一种评估器，顾名思义，它对数据集进行转换。它必须实现`fit()`和`transform()`方法。

估计器和转换器的一个重要方面是它们都接受数据集作为输入，并从它们的`fit()`方法返回数据集。这样，你可以把结果串在一起，如果你想的话，甚至可以合并它们！

这听起来可能相当抽象，所以让我们来看一个动手操作部分，以创建我们的第一个管道，这可能有助于澄清事情。

## 创建 scikit-learn 渠道

我们将使用本书中之前使用的同一个加州价格数据集作为起点。你会发现这种方法与我们之前的尝试有所不同。

作为复习，下面是我们将要使用的功能:

![Table 11.1 – Features used from the California dataset
](image/table1.jpg)

表 11.1-加利福尼亚数据集中使用的要素

根据需要，使用上表作为参考。以下是创建`scikit-learn`管道所需的步骤:

1.  首先激活适当的 conda 环境，在那里你已经安装了*技术要求*部分提到的软件包，并加载你的 Jupyter 笔记本。现在，这应该是您的常用命令。我将我的环境命名为`dssw_anaconda`以纪念这本书，并且能够在我的其他环境中方便地引用它:

    ```
    conda activate dssw_anaconda
    ```

或者，您可以通过 Navigator 激活它。

1.  通过命令行或导航器启动你的 Jupyter 笔记本。确保你在安装了软件包的 conda 环境中，否则你会发现 Jupyter 找不到它们。

下面是启动笔记本的命令行参数:

```
jupyter notebook
```

1.  导入需要的包。为了能够专注于未来的工作，我们将在开始时导入必要的包。在笔记本的第一个单元格中，键入以下代码并运行该单元格:

    ```
    import pandas as pd
    import numpy as np

    from sklearn.pipeline import Pipeline
    from sklearn.preprocessing import StandardScaler
    from sklearn.model_selection import train_test_split
    from sklearn.datasets import fetch_california_housing

    from sklearn.impute import SimpleImputer

    from sklearn.linear_model import LinearRegression
    from sklearn.tree import DecisionTreeRegressor
    from sklearn.ensemble import RandomForestRegressor

    from sklearn.model_selection import GridSearchCV
    from sklearn import __version__ as scikit_version

    import pickle
    import joblib
    ```

2.  然后，我们将所需的数据作为`pandas`数据帧:

    ```
    cali_data = fetch_california_housing(as_frame=True)
    cali_data.data
    ```

    导入

您将看到熟悉的加州住房数据集，如下所示:

![Figure 11.2 – The California housing dataset
](image/Figure_11.2.jpg)

图 11.2–加州住房数据集

1.  得到目标和训练值，然后拆分训练数据。我们希望在对数据执行任何操作之前，始终确保我们分割了数据，这样我们就可以确保当我们测试时，测试数据的格式更接近于通过真实世界得到的任何格式。我们会拿出 20%的数据:

    ```
    training_data = cali_data.data
    target_value = cali_data.target
    X_train, X_test, y_train, y_test = train_test_split(training_data, target_value, test_size = 0.2, random_state=5)
    ```

2.  现在，我们准备创建管道。我们将使用一个简单的策略，用列的平均值填充任何空白记录。对于定标器，我们将利用`StandardScaler()`并对我们的算法使用线性回归。同样，出于举例的目的，这里的想法是保持事情简单。

使用以下代码创建此管道:

```
pipeline = Pipeline([
    ('imputer', SimpleImputer(missing_values=np.nan, strategy='mean')),
    ('std_scaler', StandardScaler()),
    ('algorithm_regression', LinearRegression())
    ])
```

我们现在有一个可以使用的管道了！但是我们还没有完成。

1.  现在，我们需要调用管道上的`fit()`方法。这就是神奇的地方，因为在幕后，它实际上调用第一个 transformer 上的同一个`fit`函数，然后使用一个函数的输出输入下一个函数。它重复这个步骤，直到回归模型结束:

    ```
    pipeline.fit(X_train, y_train)
    ```

2.  最后，我们可以对模型在最后一步的训练情况进行评分。我们将为此传递训练和测试数据，然后打印带有两位小数的输出:

    ```
    train_score = pipeline.score(X_train,y_train)
    test_score = pipeline.score(X_test,y_test)

    print(f"Training set score: {train_score:.2f}")
    print(f"Test  set score: {test_score:.2f}")
    ```

这将为您提供类似于以下内容的结果:

```
Training set score: 0.60
Test  set score: 0.61
```

好的是我们不需要对测试数据做任何新的东西。它将经历与训练数据集相同的估计和缩放步骤。

您的管道现在将看起来如下图所示:

![Figure 11.3 – The scikit-learn pipeline flow 
](image/Figure_11.3.jpg)

图 11.3–sci kit-learn 管道流程

我们已经讨论了一个步骤的输入是如何进入下一个步骤的。因此，无论您的最后一步是什么，都会告诉您在管道上可以调用哪些方法。此外，您可能只想为分类值创建一个数据转换管道，并为数字值创建另一个管道。您可以为每个管道创建管道，然后将这些管道提供给第三个管道来进行实际预测。如果你遵守以下规则，你可以做的事情有很大的灵活性:

*   除了最后一步，每一步都必须有一个`transform()`方法。这是因为`transform()`方法的输出是一个数据集，这是传递到另一个步骤所需要的。这些类型的步骤被称为变压器。
*   最后一步不必将数据集作为其输出。你可以把这变成很多事情；它只需要接受一个数据集并包含一个`fit()`方法。通常，这是一个预测步骤，如分类器或回归。

我们已经用线性模型创建了这个管道，但是我们怎么知道它是最好的方法呢？让我们测试更多的算法方法。

## 测试各种算法方法

现在让我们来看看建立管道的另一个主要好处，那就是能够快速尝试你的模型建立过程的变化。

我们可以定义一些不同的算法选择，然后简单地将它们输入到管道中，以确定哪一个具有更好的结果。我们将首先创建一个我们想要尝试的算法的简单列表:

```
alg_choices = [LinearRegression(),
               DecisionTreeRegressor(max_depth=5),
               RandomForestRegressor(max_depth=5)]
```

然后，我们将遍历所有的选择，并使用与我们之前使用的相同的管道，但是用算法选择代替了之前的静态方法。在同一个`for`循环中，我们将像平常一样执行同一个`fit`函数，然后使用该训练数据计算分数:

```
for alg in alg_choices:
    pipeline = Pipeline([
    ('imputer', SimpleImputer(missing_values=np.nan, strategy='mean')),
    ('std_scaler', StandardScaler()),
    ('algorithm_regression', alg)
    ])

    pipeline.fit(X_train, y_train) 
    train_score = pipeline.score(X_train,y_train)
```

我们将通过打印出结果并将输出限制到两位小数来结束`for`循环:

```
    print(f" For {str(alg)} the training set score is: {train_score :0.2f }") 
```

您将看到每个算法作为输出是如何执行的:

```
LinearRegression() training set score: 0.60
DecisionTreeRegressor(max_depth=5) training set score: 0.63
RandomForestRegressor(max_depth=5) training set score: 0.67
```

### 制作管道

前述的缩短版本将涉及使用`make_pipeline()`。这执行相同的步骤，但是您不必为每个单独的步骤命名。这看起来像下面这样:

```
pipeline = make_pipleline([
    (SimpleImputer(missing_values=np.nan, strategy='mean')),
    (StandardScaler()),
    (LinearRegression())
    ])
```

将为您选择名称，但是在本章的剩余部分，我们将坚持使用显式命名的管道。

### 访问管道步骤

如果您想查看组成特定管道的步骤，您可以使用以下内容:

```
pipleline.steps
```

您将看到包含步骤的 Python 列表，如下所示:

```
[('imputer', SimpleImputer()),
 ('std_scaler', StandardScaler()),
 ('algorithm_regression', LinearRegression())]
```

这个列表可以像所有 Python 列表一样被访问——通过传入您想要聚焦的`integer`索引，如下所示:

```
pipeline.steps[0]
```

在我们的例子中，这将是以下内容:

```
('imputer', SimpleImputer())
```

您可能会看到稍微不同的东西，这取决于您如何设置管道。

前面的命令只是一个字符串元组，由估计器的名称和类型组成。要访问实际的估计器对象本身，您可以跳过`steps`属性，而是通过使用以下语法访问第一个元素来访问顶层的列表:

```
pipeline[0]
```

这将返回步骤本身的对象，在本例中如下所示:

```
SimpleImputer()
```

您甚至可以通过检查我们之前设置的`strategy`属性来确认它是同一个对象:

```
pipeline[0].strategy
```

你会发现它给出了你所期望的意思:

```
'mean'
```

接下来，让我们确保我们知道如何根据需要将新数据输入管道。

## 将实时生产数据输入管道

也许创建这个管道的最大好处是，你现在有了一个可重复的变更流，需要对数据进行变更，以使其符合正确的形式。您所需要做的就是以与原始训练数据集相同的格式输入数据，您应该拥有所需的一切。

现在您已经了解了管道，让我们采取下一步，利用它们来改进我们的模型。

# 用 GridSearchCV 寻找最优超参数

由于我们已经创建了新的模型并尝试了各种数据处理技术，我们已经使用了许多不同的参数和函数自变量来确定我们如何设置问题。一个例子是`impute`方法。均值、中值或其他高级方法——我们如何知道我们应该采取哪种方法？一种简单的方法可能是简单地创建一个`for`循环并尝试每一种技术。我们可以计算每个的分数，并使用最好的一个。在前面的部分中，我们尝试了一种类似的方法来查看哪种算法会给我们带来最好的分数。

这可能是天真的，但永远不要忽视简单。这是一个非常好的方法，以至于`scikit-learn`决定将它打包在一起，并制作一个简单的方法来实现它。它甚至会执行一个 *k* 折叠交叉验证，以确保得到最佳解决方案。有几种不同的方法来调优超参数，但是我们将重点关注网格搜索。

一个**网格搜索**简单来说就是一个过程，通过这个过程你可以为每个超参数尝试不同的可能输入，看看哪个表现最好。这是一种简单易懂的方法，可以给你带来意想不到的效果。这并不总是最好的选择，因为它可能需要相当长的时间，但一个好处是，由于每次尝试都是完全独立的，因此会发生一些优化来并行化该过程。

在我们进一步讨论之前，最好先定义一下什么是超参数，以及它们与正常参数有何不同。

## 定义超参数和参数之间的差异

为了避免混淆，我们将花点时间来澄清超参数和参数之间的区别。具有讽刺意味的是，超参数可能比参数更重要，因为您需要更多地参与它们的设置。注意，当我们提到参数时，我们指的是模型参数，而不是更一般的方法参数。

我们打个比方。假设你正在开车，你想优化你的燃油效率。你有一个实时显示器，显示你的燃油经济性，你的成功是基于此。你调整与你前面的车的距离，加热器的使用，以及你加速的速度。汽车计算出发动机中正确的燃料混合物以及何时换挡。在我们的例子中，下面的距离、加热器和加速度将是您直接调整的超参数。混合燃料和你的档位是由汽车计算出来的参数。燃油效率评级就是分数，它是由您控制的超参数和您不控制的参数得出的结果。

让我们用更多特定于数据科学的示例来分别定义它们。

### 定义超参数

那么，是什么让超参数变得特殊呢？让我们列出一些属性，然后看一些例子。超参数通常如下:

*   由用户设置
*   很难根据给定的数据进行估计
*   只有在尝试过之后才能确定是好是坏

这些是超参数的例子:

*   一个 *k* 折叠交叉验证器所需的折叠数
*   在一个 *k* 最近邻算法中 *k* 的值
*   您的模型的学习率
*   缺失数据的估计技术
*   神经网络的激活函数和时期
*   c 代表**支持向量机** ( **支持向量机**)(这是`GridSearchCV`中常见的例子，也是`scikit-learn`在其文档中使用的例子)

当人们说他们正在执行超参数调整时，那是因为他们受益于人类的接触来发现最佳值。这并不意味着我们不能使用技术来设置它们，但是我们稍后会谈到这一点。

### 定义模型参数

或者，参数可以通过训练方法来发现，并且通常是模型在训练过程中实际试图得出的关键组成部分。如果你知道这些应该是什么，你一开始就不需要机器来告诉你！参数的某些方面如下:

*   它们是在训练过程中从您的数据集中学习到的。
*   它们不是由用户设置的。
*   它们成为模型本身的一个属性。

参数的一些例子包括:

*   回归模型的系数
*   神经网络的权重(通常被错误地称为超参数，但事实并非如此)
*   随机森林如何选择分割节点

这些是您可以查看的属性，有助于在更深层次上解释您的模型所做的选择，但它们不是明确的东西，您需要事先尝试、猜测或优化。

现在你知道什么是超参数和网格搜索，让我们看一个例子。

## 在随机森林管道上使用网格搜索

让我们回想一下我们已经按照以下顺序将当前管道放置到位:

1.  `SimpleImputer()`取名为`imputer`
2.  `StandardScaler()`取名为`std_scaler`
3.  名为`algorithm`的`RandomForestRegressor()`回归算法

请记住，前面所有的名称都是由我们设置的，我们可以按照自己的意愿命名它们，或者使用`make_pipeline`函数为它们命名。

如果我们想知道我们可以选择改变整个管道的哪些参数，我们可以通过下面的`get_params()`方法的用法来了解:

```
pipelines['RandomForestRegressor'].get_params()
```

您将看到一个字典，其中包含这些步骤以及所有参数选项和它们在这些步骤下的当前值。参数有一个简单的命名格式，即`[step name]__[parameter name]`:

```
{'memory': None,
 'steps': [('imputer', SimpleImputer()),
  ('std_scaler', StandardScaler()),
  ('algorithm', RandomForestRegressor())],
 'verbose': False,
 'imputer': SimpleImputer(),
 'std_scaler': StandardScaler(),
 'algorithm': RandomForestRegressor(),
 'imputer__add_indicator': False,
 'imputer__copy': True,
 'imputer__fill_value': None,
 'imputer__missing_values': nan,
 'imputer__strategy': 'mean',
 'imputer__verbose': 0,
…
```

假设我们想要测试不同的估计策略，以及随机森林中的一些其他超参数。您需要做的是首先创建一个字典，其中包含您想要试验的超参数和您想要循环的输入列表。

按原样在 Jupyter 单元格中键入以下代码，或者根据您的喜好减少可能的选择:

```
grid_parameters = {'imputer__strategy':['mean', 'median'],
                  'algorithm__criterion':['squared_error',
                  'absolute_error'],
                   'algorithm__n_estimators':[10,100],
                   'algorithm__max_depth':[5,10,None]
                  }
```

现在你已经有了你想要尝试的参数，你可以把它们输入到`GridSearchCV()`中并看到结果。

思考性能问题

由于网格搜索尝试了您指定的超参数的所有组合，您可以得到许多可能的组合。再加上 *k* -folds，你可能要等一段时间才能看到结果。在我们的例子中，我们有 24 种排列(2x2x2x3)，但只需添加几个参数，就可以很快变得更大。在我们的例子中，我们还需要考虑随机森林的深度，因为这也增加了训练时间。

这可能是一个很好的策略，只尝试一个参数，以了解某件事情需要多长时间，然后再添加几个参数，以了解你是否应该在等待的时候休息一下(或通宵运行某件事情)。

另外，请注意，您可以让 Jupyter 笔记本使用 GPU，但`scikit-learn`本身没有计划启用 GPU 支持，因为这可能会导致复杂的依赖关系和特定于平台的问题出现，并且有一个特定的设计选择来使`scikit-learn`尽可能简单。

您可以通过将`n_jobs`参数设置为`-1`来利用 CPU 提供的所有功能。这将允许`scikit-learn`创造尽可能多的平行工作来完成任务。这是可能的，因为超参数的组合都不依赖于另一个的输出。默认设置为`None`，表示一个任务。如果您不想占用本地机器的所有可用资源，您仍然应该至少将此设置为`3`，除非您的系统较旧且功能不足。你如何定义这是相对的，但我会从`3`开始，看看如果你关心的话会得到什么。

使用以下代码输入随机森林管道和我们设置的参数:

```
grid = GridSearchCV(pipelines['RandomForestRegressor'], grid_parameters, cv=3, n_jobs = -1)
grid.fit(X_train,y_train)
```

对于一个关于执行操作的时间的例子，在我的机器上，使用`-1`代替`n_jobs`，这将创建最大可能数量的作业，花费了 14 分 58 秒，并且将作业数量设置为`3`(它使用了我的 CPU 的 20%)，花费了 25 分钟。总是要有所取舍。

您现在可以打印出尝试所有组合时找到的最佳超参数和分数。`best_params`用于前者，`best_score_`用于后者:

```
print(f'The best parameters are:{grid.best_params_}')
print(f'The best score was:{grid.best_score_:.2f}')
```

您将得到类似如下的打印输出:

```
The best parameters are:{'algorithm__criterion': 'absolute_error', 'algorithm__max_depth': None, 'algorithm__n_estimators': 100, 'imputer__strategy': 'mean'}
The best score was:0.80
```

最佳模型被保存以便于检索，我们可以通过下面的`best_estimator_`属性获取它:

```
best_model =  grid.best_estimator_
```

然后，我们可以在测试数据集上对其进行测试，测试数据集将通过管道提供数据，并通过我们找到的最佳模型进行预测:

```
best_model = grid.best_estimator_
print(f'{best_model.score(X_test,y_test):.2f}')
```

我们得到以下结果:

```
.82 
```

这表明的结果比我们第一次迭代在任何优化之前提高了 61%。

我们现在明白了如何将管道作为另一个构建模块，作为网格搜索的一部分来创建更好的模型。我们研究了如何迭代超参数选项，以尝试并找到最佳组合。现在，让我们继续讨论如何对我们新优化的模型进行版本化。

# 版本化和存储您的模型

在我们阅读本书的过程中，有一个你可能已经注意到的突出问题——当你关闭集成开发环境、终端或 Jupyter 笔记本时，你的模型和数据不见了。我们不会深入探讨在数据库或其他持久层上工作和保存信息的更复杂的主题，但是您可以做一些非常简单的事情来创建保存点。

### 理解模型版本化的价值

在本书中，从数据工程到构建模型，你已经完成了所有的工作，你已经意识到有许多迭代发生。这被称为数据科学，但也有一种艺术来猜测一条道路，并试图知道接下来要去哪里。您已经尝试使用超参数和模型族进行有根据的猜测，并保持原始数据集打开，以便在需要时返回。万一你错了，这些都是需要的。这就是版本控制发挥作用的地方。

**版本化**是简单地标记和保存一些东西的状态，以便以后更容易检索或引用。毫无疑问，您对本书前面的包中的这个概念以及您的桌面或移动操作系统的最新版本很熟悉。

对模型进行版本化有许多原因:

*   如果您发现上周用于训练模型的超参数具有更好的性能，则创建检查点。这在您实际将某个产品推向生产环境或恢复到已经部署的产品之前会很有用。
*   出现重大问题时自动回滚。这就像拥有检查点，但是能够在生产时自动回滚到早期版本。
*   治理–这个是当被问到*“在生成这个结果的这个日期，您正在运行哪个模型？”时，根据需要进行审计的能力*
*   进行 A/B 测试的能力。这只是简单地比较和/或测试两种不同的方法。有了模型版本，你可以更容易地做到这一点，并确切地知道你在比较什么。
*   结果的再现性。不用担心你所使用的会或应该导致同样的行为。

有几种不同的方法可以对模型进行版本化，最基本的方法是用一个惟一的名称将其保存在本地文件系统上。我们现在就开始吧。

## 酸洗模型

假设您在实验阶段创建了一个简单模型，您只是想将其发送到一个学院，或者将其放入一个数据存储机制中，而不会产生大量开销。在 Python 中，有一个概念是 pickling 一个可以帮助你完成这项任务的对象。**pickle**简单地说就是将一个 Python 对象转换成一个字节流，这个字节流可以以一种简单的方式存储或通过网络发送。这个术语来源于腌制蔬菜或其他食物来保存它们的想法。

回到 Jupyter 笔记本，执行以下操作:

1.  指定要保存的文件名。我们将添加一个版本，让我们可以根据需要轻松地更改它。在最初的`import`语句中，`scikit_version`变量已经被重新设置。使用下面的代码来完成这个:

    ```
    model_version = "1"
    filename = f'random_forest_v{model_version}-{scikit_version}.pk1'
    ```

2.  接下来，使用这个文件名告诉`pickle`方法转储我们从`GridSearchCV`中找到的管道和模型，这是我们在上一节中创建的。这将让我们检索管道以及最佳参数。`wb`参数告诉 Python 在什么模式下打开文件。在这种情况下，是`write`和`binary` :

    ```
    pickle.dump(best_model, open(filename, 'wb'))
    ```

就是这样！现在，无论您位于哪个目录，您都会看到文件。也许下一次您保存您的模型时，您会想要用 v2、v3 等等来保存它。接下来让我们快速地了解一下如何加载 pickled 文件。

## 加载你的酸洗模型

装载你的腌渍模型相当简单。你所需要做的就是使用来自`pickle`模块的`load()`方法和你想要的文件名。我们还通过`r`和`b`分别将模式设置为`read`和`binary`:

```
pickle_file = pickle.load(open(filename, 'rb'))
pickle_file
```

您将看到您离开时的管道对象，如下所示:

```
Pipeline(steps=[('imputer', SimpleImputer()), ('std_scaler', StandardScaler()),
                ('algorithm',
             RandomForestRegressor(criterion='absolute_error'))])
```

请注意，酸洗可以在大多数 Python 对象上进行(有例外，但您很少会遇到这些情况)，因此模型或`scikit-learn`管道没有任何神奇之处。

关键安全性标注

就像如果你不知道软件来自哪里，你就不应该运行它一样，你也不应该解开你不信任的代码。当拆包过程发生时，有一种方法可以在执行拆包的计算机上运行恶意代码，因此请始终确保您信任您正在运行的程序。

还有另一种可能更好的打包模型的方法，我们现在将介绍这种方法。

## 使用 joblib 存储您的模型

有一种更好的方法来拯救模型和管道，那就是使用`joblib`库。`joblib`扩展了 pickle 的基本功能和实用角色，但是有一些额外的好处，比如更好地处理更大的 NumPy 数组和能够压缩文件，我们将看到这可以带来很大的不同。

您将看到与`pickling`流程非常相似的设置:

1.  指定型号版本和完整版本`filename`，以便稍后分别识别型号和`scikit-learn`版本:

    ```
    model_version = "1"
    filename = f'random_forest_joblib_v{model_version}-{scikit_version}.pk1'
    ```

2.  转储管道对象，并将压缩级别设置为`7` :

    ```
    joblib.dump(best_model, filename, compress=7)
    ```

现在，在您当前的工作目录中会有一个名为`random_forest_joblib_v1-1.0.2.pk1`的文件。

压缩可以达到第 9 级，但是使用超参数，不可能知道某件事要花多长时间，所以你可以随时根据需要增加。但是，最好开始时小一点，然后再增加。这有什么影响？作为比较，在我的机器上，pickled 文件是 125 MB,`joblib`文件是 25mb——只有它的五分之一大小！

在我们的练习中，我们保存了整个 pipeline 搜索对象，但是如果我们只想保存模型，那么它会小得多。仅随机森林模型就有 150 KB 左右。

正如你现在看到的，如果我们想的话，版本化和保存我们的模型甚至整个网格搜索是非常简单的。您可以放心地知道，如果您需要返回到以前的状态或只是与同事共享，您的超参数以及模型将可以安全地检索。

# 总结

在最后一章中，我们介绍了使用 Anaconda 作为基础，快速成为数据科学家所需的最后一批技能。

我们首先看到`scikit-learn`管道如何让您获取数据科学工作流的离散部分，并通过将评估者放在一起，像拼图一样，以更优雅的方式创建一个内聚的单元。我们也看到了这些如何包括诸如你的定标器和估计器，最终以一个算法类型结束。

然后我们明白了，我们在整本书中使用的许多论点，例如随机森林的深度，被称为超参数，它们是获得正确结果的重要组成部分。从`sckit-learn`看`GridSearchCV`，我们对可能的组合进行网格搜索，小心地平衡发现速度和最佳属性。

最后，我们看了用 pickling 和`joblib`对我们的模型进行版本控制的价值。我们将优化后的模型打包到两者中，并比较大小差异，发现由`joblib`完成的压缩有所不同。我们还使用了一些简单的方法来注入模型和`scikit-learn`版本，以便将来参考。

到目前为止，您应该感觉到您已经能够使用这些技术在一个更加可重复和迭代的过程中构建模型了。

# 关闭

无论你是一个寻求提高技能的经验丰富的老手，还是这个领域的新手，到目前为止，你都明白前景是广阔的，但旅程始于渺小。在这本书里，我们涵盖了很多领域，包括算法的类型，如何避免偏差，甚至评估开源工具。这只是对所有有待发现的事物的一种尝试，我想你会同意，在当今时代，没有比美妙的数据科学世界更值得了解或探索的技能了。