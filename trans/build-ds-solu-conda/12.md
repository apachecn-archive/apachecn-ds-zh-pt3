

# 九、使用 scikit-learn 构建回归模型

到目前为止，我们已经涵盖了从如何用 conda 安装包到决定使用哪种建模方法的所有内容。在这一章中，我们将通过一个真实世界的场景来了解所有的部分是如何组合在一起的，从而运用我们所学的知识。

在这个场景中，我们将假设我们拥有一个酿酒厂，我们希望预测我们最新的葡萄酒在质量测试中的得分，以确定我们是否应该以任何方式调整我们的种植方法。这需要我们做一些事情。

首先，我们将看看我们正在处理的问题空间，在这个例子中是酿酒。然后，我们将深入研究数据，以更好地理解它，并查看它是否有任何问题，以及我们可以从高层次上了解到什么。之后，我们将学习如何快速评估一些流行的回归算法，我们在 [*第七章*](B16589_07_ePub.xhtml#_idTextAnchor169) 、*选择最佳 AI 算法*中看到了这些算法，使用常见的评估技术来看看哪个可能最有前途。一旦我们知道使用什么算法，我们将训练模型，并用它来预测我们最新的葡萄酒在质量测试中的得分。

最后，我们将获取这些信息，并将其与手头的问题联系起来，以确定应该采取什么行动(如果有的话)来酿造最好的葡萄酒。

在本章中，我们将讨论以下主题:

*   走过数据科学工作流程
*   建立和理解问题空间
*   浏览和清理数据
*   创建和评估回归算法
*   使用 MSE 和 R2 分数评估潜在模型

首先，我们将概述当您遇到问题时将使用的工作流程，以便您知道从哪里开始以及如何进行。

# 技术要求

要完成本章中的练习，您需要进行以下设置:

*   Anaconda 发行版已安装。这包括康达和领航员。
*   Jupyter 笔记本安装在您的 conda 环境中。

# 走过数据科学工作流程

尽管在任何特定的问题中，你所走的道路都会有偏差，但你可以肯定，对于大多数问题，你都会遵循相同的大致轮廓。在下图中，您可以看到我们将在本章中使用的流程，它与您将在遇到的大多数问题中使用的流程相同:

![Figure 9.1 – Data science workflow
](image/Figure_9.1.jpg)

图 9.1–数据科学工作流程

*图 9.1* 由数据科学流程中的以下步骤组成:

1.  理解问题空间。
2.  数据探索/预处理/操作。我们将它们合二为一，但是我们将深入研究每一个的不同部分。
3.  特征选择/提取。
4.  预测建模。
5.  项目成果和结论。

在本章和接下来的章节中，你会对这些步骤非常熟悉。现在让我们看看这个旅程的第一步。

# 建立和理解问题空间

他们说成为百万富翁的最快方法是开一家酿酒厂……你必须先成为亿万富翁。我们希望避免这种假设，即我们创造世界上最好的葡萄酒总是会赔钱。我们希望采取分析的方法，以便比其他人获得更多的成功。

我们的目标是找出酿造优质葡萄酒需要哪些品质，以便最大限度地发挥我们的努力。我们将像数据科学家一样从头到尾研究这个问题，并确定在我们的最终质量分数中最重要的是什么。

葡萄酒是世界上最古老的饮料之一。它诞生于公元前 6000 年左右，是一种用发酵葡萄酿造的酒精饮料。类似于 AI/ML，有些人花了一生的时间试图完善和掌握这个领域的一个子集，但仍然有很多可以探索的地方。从确保你理解你正在做的事情开始总是好的。这将在以下步骤中帮助您发现数据中是否存在问题，以及您是否能够有效地使用该数据集。

引用

Cortez，p .，Cerdeira，a .，Almeida，f .，Matos，t .，和 Reis，J. (2009 年)。*通过物理化学性质的数据挖掘建立葡萄酒偏好模型*。决策支持系统，47(4)，547–553。`https://doi.org/10.1016/j.dss.2009.05.016`

在我们的例子中，我们将使用以下属性。对于本章和练习来说，深入了解所有这些属性并不重要，但当你在现实世界中工作时，很好地理解你的特定问题空间是非常有用的，而且可能是必要的。

以下是我们将使用的数据集的属性:

*   **固定酸度**–葡萄酒中的酸含量。
*   **挥发酸度**–乙酸的量。
*   **柠檬酸**——可以使*葡萄酒*保持更长时间的新鲜。有助于延长保质期
*   **残糖**—发酵完成后会有多少糖。这是你认为的。几乎每种酒都会含有一些糖。在我们的数据集中，你会看到大多数的含量很低，大约 1-3 克/升，极少数超过 25 克/升。超过 30 克/升的葡萄酒会被认为是非常甜的。
*   **氯化物**–含有多少盐。
*   **游离二氧化硫**——用于防止微生物生长。
*   总二氧化硫–高含量会在葡萄酒中产生明显的不良味道。
*   **密度**–液体的密度。
*   pH 值(T1)——葡萄酒的酸度。
*   硫酸盐-许多葡萄酒中的一种添加剂，用于防止有害微生物的生长。
*   **酒精**–葡萄酒中酒精含量的百分比。
*   **品质**(目标)–葡萄酒按照从 0(最差)到 10(优秀)的评分标准进行评级。这是基于专家确定的各种因素，但在高层次上是诸如味道、颜色、气味和其他主观测量。

你不需要知道所有这些细节，但是如果你在本章后面试图理解问题和答案，这将是一个很好的参考。现在让我们确保您的工作区设置正确。

## 设置您的工作空间

既然我们已经了解了问题领域，让我们确保我们的工具都已经准备好了，这样我们就可以专注于获得可能的最佳结果。我们将再次与 Anaconda 的 conda 包管理器一起运行 Jupyter 笔记本。

首先，我们将使用以下内容创建 conda 环境。

### 创造康达环境

与大多数类型的开发一样，您将希望从创建 conda 环境开始，这样您安装的所有东西都将在您期望的地方。如果您已经有了一个想要使用的环境，那么可以随意跳到下一步，即激活环境。

#### 用康达创造康达环境

您可以通过在终端中键入以下命令来创建一个环境:

```
$ conda create -n ch_10 python=3.9 scikit-learn
Collecting package metadata (current_repodata.json): done
[…]
The following NEW packages will be INSTALLED:
[…]
Proceed ([y]/n)?
```

输入`y`并按*键输入*。这将创建一个环境，然后我们可以通过以下方式激活它:

```
$ conda activate ch_10
```

你现在将处于那种环境中。或者，您可以使用**导航器**。

#### 用 Navigator 创建 conda 环境

加载导航器，选择左边的**环境**标签。然后选择**新建**。

你现在将处于新的康达环境中。回顾一下 conda 和 Navigator 如何与 conda 环境一起工作，参见第 3 章 ，*使用 Anaconda 发行版管理包*。

现在，让我们打开一个 Jupyter 笔记本，以便于工作和实时获得一些结果。

### 通过 conda 或 navigator 启动木星笔记本

我们可以从命令行或导航器启动 Jupyter Notebook。在命令行中，键入以下内容:

```
$ jupyter notebook
```

您将看到一些信息日志出现在终端上，如下所示:

```
[I 12:10:11.240 NotebookApp] Serving notebooks from local directory: C:\Users\Dan
[I 12:10:11.240 NotebookApp] Jupyter Notebook 6.4.6 is running at:
[I 12:10:11.240 NotebookApp] http://localhost:8888/?token=a352916aecb06fbec51e09ad79d4cf58ced4f0683a2df5cc
[…]
```

您的浏览器应该弹出笔记本运行。或者，您可以使用导航器。在导航器的主区域中找到并选择该图块:

![Figure 9.2 – Jupyter Notebook tile on Navigator
 
](image/Figure_9.2.jpg)

图 9.2–导航器上的 Jupyter 笔记本磁贴

这将把您放在文件视图中，有一个熟悉的文件结构。根据需要选择合适的文件夹或创建一个。当你进入所需的文件夹时，用你选择的名字创建一个笔记本。在我们的例子中，我们使用了`Ch_10`。

你将会看到一个空白的 Jupyter 笔记本准备去工作。现在，让我们加载所需的数据。

### 在数据集中加载

数据科学没有数据意义不大。这将是我们接下来要做的事情。我们将要使用的数据可以在网上获得，并且采用易于解析的通用格式。你会注意到有两个数据集，一个是红色的，一个是白色的。我们将在后面的步骤中合并它们，但是现在，我们将把它们都导入并保存为变量，以便以后使用。

**逗号分隔值** ( **CSV** )的意思是不同的字段用逗号分隔，因此得名，但是这个有分号，所以从技术上讲它不是 CSV 文件。您应该注意到，这通常仍被称为 CSV 文件。不要担心！pandas 的`read_csv()`方法允许我们指定想要使用哪个分隔符。

在我们的 Jupyter 笔记本单元格中，键入以下内容:

```
import pandas as pd
df_red =  pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv', sep=';')
df_white =  pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv', sep=';')
```

忘记添加分隔符

很容易忘记`read_csv()`方法中的`sep`参数，这会给你一个错误，`<<todo add>>`。默认情况下，逗号被用作分隔符(也称为*分隔符*)。如果您看到这个错误，您可以简单地检查您是否忘记了这个细节。

现在，`df_red`和`df_white`变量中的两个数据集已经可以使用了。但是我们怎么知道`sep`参数和它的作用呢？有一个方便的工具，我们可以用它来检查一个方法做什么。

#### 在 Jupyter 笔记本中显示文档字符串

有一个技巧可以让快速理解一个方法能做什么，那就是调出**文档串**。这种记录 Python 方法的常见且被接受的格式允许我们获得关于如何使用一个方法及其参数做什么的信息。

要在您的 Jupyter 笔记本中调出这个文档，只需将光标放在该方法中，然后按键盘上的 *Shift + Tab* 来显示这个文档字符串。请注意，您必须已经导入了该方法所来自的库才能做到这一点(在我们的例子中，是 pandas)。下面的 docstring 将会出现，您可以很快看到,`sep`参数用于定义我们想要的分隔符:

![Figure 9.3 – The docstring shortcut in Jupyter Notebook
](image/Figure_9.3.jpg)

图 9.3–Jupyter 笔记本中的文档字符串快捷方式

现在我们已经有了 CSV 数据，让我们更好地理解一下我们正在做什么。我们可以用`info()`的方法来看数据。在单元格中键入以下并运行它:

```
df_red.info()
```

除了数据帧有多大以及有多少非空值之外，我们还将看到诸如预期列之类的项目。我们没有显示空白数据的任何问题:

![Figure 9.4 – DataFrame red wine info
](image/Figure_9.4.jpg)

图 9.4–红酒信息数据框

我们现在想要检查与白葡萄酒相同的信息，以确保没有任何问题，并检查相对大小:

```
df_white.info()
```

我们将得到与之前完全相同的输出格式:

![Figure 9.5 – DataFrame white wine info
](image/Figure_9.5.jpg)

图 9.5–白葡萄酒信息数据框

你看我们有大约 1600 个红酒值和 5000 个白酒值。这可能是一个问题，但似乎每个数据集都有一个很高的数字，所以当我们查看我们的结果时，我们可能要记住这一点。根据我们的发现，看看为每种葡萄酒单独建立一个模型是否是一个好主意，这可能是一个好主意。

您还可以使用`shape()`来访问显示维度的属性，但是`info()`给出的是相同的数据和更多的上下文。如果您想要获取行数或列数并执行操作，那么`shape()`会更有用，因为它返回一个易于使用的元组。当我们只是试图理解数据时，`info()`是首选。

我们现在需要将这两个数据集合并成一个，使它们更容易使用。

## 合并两个 CSV 文件

我们有我们的红色和白色数据集，但我们希望能够一起评估它们，因为我们想要完整的图片。这将帮助我们评估红葡萄酒或白葡萄酒对我们来说是否是更好的商业投资:

1.  我们希望确保当我们组合这两个数据集时，我们保留关于它是红葡萄酒还是白葡萄酒的信息，为此我们将创建一个新列，`wine_type`。
2.  我们知道以后需要一次性编码这些信息，这样我们就可以节省精力，在合并数据集时就可以这样做。简单地拥有`red`和`white`是很浪费的，因为这将需要我们拥有两列，而我们只有一个二元分类器。我们可以通过将该列命名为`wine_type`来提高效率，这将简单地给出以下内容:
    *   `wine_type` = `0`:白酒
    *   `wine_type` = `1`:红酒
3.  现在，我们可以简单地在两个数据集中创建新的列，并使用下面的代码给它们正确的值:

    ```
    df_white["wine_type"] = 0
    df_red["wine_type"] = 1
    ```

接下来，我们将它们与以下内容连接起来:

```
df_raw = pd.concat([df_red,df_white])
```

然后，我们可以通过前两行和后两行快速检查它们是否正确组合:

```
df_raw.iloc[[0,1,-2,-1]]
```

这将为我们提供每种葡萄酒类型的两个示例，因为白葡萄酒数据集被附加到红葡萄酒数据集的末尾。我们将看到最后两行有预期的`wine_type`字段的 **0** 条目。

![Figure 9.6 – Result of appending two CSVs
](image/Figure_9.6.jpg)

图 9.6–附加两个 CSV 的结果

何时使用合并或追加

有一个名为`dataFrame.merge`的函数，但那是针对两个数据帧有重叠字段的情况。这将找到存在于两个数据帧中的元素并将它们编织成一个。在我们的例子中，我们知道情况并非如此，但是您可能希望/需要在某些时候使用它。

1.  您可以通过确认条目是正确的，仍然没有非空项，并且条目的总数符合预期来进一步验证串联【T2:】

下面显示了您应该在 Jupyter 笔记本中看到的输出:

![Figure 9.7 – Combined wine info
](image/Figure_9.7.jpg)

图 9.7-综合葡萄酒信息

现在我们已经加载了我们的数据，我们可以开始探索和清理它。

# 探索和清理数据

现在我们继续进行数据科学工作流程中最重要和最耗时的部分:探索和清理数据。我们将从获取现有数据的一些基本统计数据开始。

在另一个 Jupyter 笔记本单元格中键入以下内容并运行它:

```
df_raw.describe()
```

你会看到我们所有栏目的基本信息。注意在下面的例子中，我抓取了一个子集，只是为了在这里显示它的实际目的:

![Figure 9.8 – Combined wine basic statistics
](image/Figure_9.8.jpg)

图 9.8-综合葡萄酒基本统计数据

我们可以挑选出一些东西:一个是平均质量为 5.8，这是我们想要打破的数字，但如果我们希望达到葡萄酒质量的高端，我们会希望达到 6 以上的水平，这是第 75 个百分位数，没有任何东西超过 9，所以这可能是我们的崇高目标。

请注意，质量是 3-9 范围内的离散整数。我们应该一次性编码吗？它是一个分类特征，但是因为它是一个序数，所以我们不需要这样做。我们也不需要对白色或红色类型进行一次性编码，因为在前面的设置中，当我们合并两个数据集时，我们已经考虑到了这一点。

我们选择接受给定的序数值。例如，这对于随机森林来说很好，因为它们使用这些值作为标准来分割它们的分支。像**支持向量机(SVMs)** 这样的算法假设相邻值之间的距离是均匀分布的，但事实可能并非如此。在本章中，我们不会深入探讨这些技术，但是可以考虑一些其他的编码技术，如均值编码和 m 估计编码。更多信息请点击这里:[https://contrib . sci kit-learn . org/category _ encoders/mestimate . html](https://contrib.scikit-learn.org/category_encoders/mestimate.html)。

现在，让我们继续学习如何处理缺失值。

## 检查缺失值

你应该总是确认数据中没有任何缺失值。在我们的数据集中，我们已经表明不存在任何问题，但我们希望确保这是一种普遍情况，因此我们在这里包括了完整性检查。

为了检查这一点，我们将使用以下内容:

```
df_raw.isnull().sum()
```

我们可以看到并确认这没有任何问题，如以下结果所示:

![Figure 9.9 – Checking for missing values
](image/Figure_9.9.jpg)

图 9.9–检查缺失值

既然我们知道不必担心字段丢失，那么让我们深入分析一下质量细分，看看我们的竞争对手:

```
df_raw['quality'].value_counts()
```

大多数值为 6，只有极少数处于我们评级的边缘。

![Figure 9.10 – The count of quality scores
](image/Figure_9.10.jpg)

图 9.10-质量分数的计数

这似乎符合正态分布，我们可以检查这个专栏和其他专栏，以便更好地直观理解我们的数据。

### 创建特征直方图

我们在 [*第 5 章*](B16589_05_ePub.xhtml#_idTextAnchor101)*中看到，清理和可视化数据*，我们可以使用直方图来创建对数据的高级洞察，以提取信息。让我们现在做那件事。

在单元格中输入以下内容，并运行它以查看我们所有列的直方图:

```
import matplotlib.pyplot as plt
df_raw.hist(bins = 100, figsize = (10,12))
plt.show()
```

这将产生以下图形:

![Figure 9.11 – Histograms of all features
](image/Figure_9.11.jpg)

图 9.11–所有特征的直方图

我们可以从这些数据中得出以下几点观察结果:

*   质量并不像你想象的那样在 0-10 的范围内，而是一步一步来的。
*   许多数据属于钟形曲线/正态分布/高斯分布。这意味着大部分数据集中在中间，并向各个方向逐渐减少。
*   高斯分布模式上的例外是**残糖**，其在左/下界侧具有陡峭的尖峰。**总二氧化硫**也有更多的密度向左，并创造了更多的 M 形。这些观察结果现在可能不可行，但是它们可以帮助我们以后理解我们的结果。
*   对于其中的一些来说，将它们分解成 100 个箱会产生非常分散的数据。我们可以降低这个来获得更好的图像。

接下来，让我们看看，如果这些特性是多余的，我们是否可以删减一些。

## 检查冗余特征

我们总是想用最少的资源做最多的事情，你可能会发现你在训练时并不需要像你想象的那么多的数据特征。如果我们发现两个特征之间有很高的相关性，那么保留它们可能没有意义。我们还可以利用这些信息将我们的培训重点放在最能影响我们所寻找的功能上。

让我们首先使用`corr()`函数检查所有特性之间的相关性。这只是返回一个数据帧，因此我们可以对结果进行四舍五入，以便于查看:

```
corr_matrix = df_raw.corr().round(2)
```

您可以显示所有的值，但即使我们创建了热图，也很难解析。我们唯一担心的是当有很高的负相关或正相关时。为了实现这一点，我们可以使用遮罩来去除任何不大于 0.4 的值。我们很可能希望将实际截止值设得更高，但这仍会在去除最低值的同时为我们提供大量信息:

```
corr_matrix = corr_matrix.applymap(lambda x: abs(x))
corr_matrix[corr_matrix > .4].style.background_gradient(cmap='Reds')
```

这里显示了结果,涂黑的区域表示没有通过我们标准的单元格，因此可以忽略:

![Figure 9.12 – Correlation matrix of all features
](image/Figure_9.12.jpg)

图 9.12-所有特征的相关矩阵

我们可以看到**游离二氧化硫**与**总二氧化硫**的相关性很高，所以我们可以假设这是可以下降的东西。但是我们应该放弃哪一个呢？与目标具有最低相关性的那个将是可行的选择。使用下面的代码来显示我们正在比较的两列:

```
corr_matrix[['total sulfur dioxide','free sulfur dioxide']]
```

在下一张图中，您会发现这两个特性以及所有其他特性之间的相互关系。

![Figure 9.13 – Correlation matrix comparing total sulfur dioxide and free sulfur dioxide
](image/Figure_9.13.jpg)

图 9.13–对比总二氧化硫和游离二氧化硫的相关矩阵

由此我们看到**游离二氧化硫**与**质量**的相关性更高，所以我们应该保持这一点，降低**总二氧化硫**。注意 **wine_type** 和**总二氧化硫**之间也有很高的相关性。这是提醒您删除列并不总是一目了然的好地方。一些列可能会影响其他列，而这些列在开始时可能没有考虑到。

以下命令将删除我们确定对我们的目的没有价值的列:

```
df = df_raw.drop('total sulfur dioxide', axis = 1)
```

然后，我们可以通过快速检查第一行来确保它不再存在:

```
df.head(1)
```

以下是结果输出:

![Figure 9.14 – First row of the dataset after dropping the column
](image/Figure_9.14.jpg)

图 9.14–删除列后数据集的第一行

这表明它已经如预期的那样被丢弃了。既然我们已经去掉了一些多余的功能，我们可以专注于一些更重要的功能。

## 关注关键特性

我们已经删除了一些看起来多余的功能，但是我们真的需要剩下的所有功能吗？当我们酿造葡萄酒时，调整过程的每一个方面都极具挑战性。让我们以相关性为指导，再次看看什么与质量最相关。

输入以下内容，从我们已经计算的相关矩阵中提取适当的列:

```
corr_matrix['quality'].sort_values(ascending=False)
```

这向您展示了前四名比其余的具有更强的相关性。

![Figure 9.15 – Correlation between features and the target feature
](image/Figure_9.15.jpg)

图 9.15-特征和目标特征之间的相关性

一个快速的提醒，皮尔森分数测量特征之间的线性关系。可能还有其他更复杂的关系没有被捕捉到。换句话说，在这些特征之间可能有一种非常直接的关系，这一点没有被捕捉到，所以你不能完全依赖它。即便如此，我们可能希望专注于这些特性，以避免在没有帮助的数据上进行训练，这可能只会把水搅浑。

现在我们已经了解了问题空间，数据已经加载，并且处于干净的状态，是时候训练我们的模型了。在下一节中，我们将使用该数据集和适当的特征来开始训练我们的模型。

# 创建和评估回归算法

在前几章中，我们讨论了几种不同的算法。我们应该选择哪一个？每一种都有利弊，有时我们不清楚应该选择哪一种。在这一节中，我们将看看几个可能的算法，并快速检查一下，以确定每个算法的可行性。然后，我们将训练获胜者，最后通过查看一些评估技术来更深入地分析结果。在我们这样做之前，让我们确保我们正在寻找正确的问题家庭。

## 比较回归和分类

当我们查看目标数据和我们的目标时，我们看到质量是通过从 1 到 9 的离散值来衡量的。如果是这样的话，那么我们为什么不把它看作一个分类问题呢？简单的回答是我们可以。选择这个例子是为了让你思考数据科学可能出现的细微差别，你得到的答案取决于你如何设计这个问题。有时候你可能会遇到一个问题，你可以把它改造成分类或回归。事实上，当你遇到像这样的有界回归问题时，逻辑回归可以作为一种方法。

在这种情况下，我们看到的是相互之间有直接关系的序数值，了解我们有多接近是有价值的。换句话说，有一个客观的标准来衡量一个预测的错误程度。让我们来看两个假设模型的比较，看看我们的意思是什么。

这里，我们将看到一个假设场景的结果，其格式为*预测值-实际值*:

*   模型 1:
    *   5-6
    *   8-9
    *   4-5

在这个场景中，三分之零是正确的，这使得这个模型的准确率为 0%。这是一个可怕的模型吗？不，事实上已经很近了。让我们来看另一个例子，在这个例子中，一个模型被创建了，并且在三个正确的例子中得到零。

*   模型 2:
    *   1-6
    *   3-9
    *   8-4

这款做的怎么样？正如我们所说，它的正确率为零，但正如你所看到的，它客观上比模型 1 更差。这是我们把它设置为回归问题的主要原因。我们不想忽略我们想预测序数。

您可以简单地用这种方式评估结果，但是将它设置为回归也允许您预测值。

既然我们知道我们想把它设置成一个回归问题，我们将看看下面的三个算法:

*   线性回归
*   **K-最近邻居** ( **KNN** )
*   **SVM**

对于所有这些算法，如果我们要有一个训练有素的模型，仍然有几个步骤要对数据执行。现在让我们来看看这些步骤。

## 准备用于训练的数据

尽管你已经完成了数据清理步骤，但当你进入培训阶段时，还有一些步骤需要完成。之所以推迟到现在，只是因为人类的可读性，你很快就会更好地理解这一点。简而言之，如果数据的格式易于引用和识别，那么理解起来就容易多了。例如，在我们完成下一步后，数据将会缩小。酒精含量为 10%的葡萄酒是你的心理模型可以放在平均 T2 类别中的东西，但在它被缩小后，它可能会显示为你无法理解的东西。

首先，我们要分割数据，正如我们在前几章中所学的那样。

### 拆分为训练和测试拆分

分割数据，作为训练数据准备的第一步，允许我们在处理训练数据的同时保持测试数据的原始干净形式。保留测试数据可以让我们在最后尝试模型，并模拟当我们在现实世界中使用模型时它会如何出现。

回到我们的 Jupyter 笔记本，使用下面的代码取出独立变量`X`中的目标特性，然后保存它作为`y`单独使用:

```
X = df.drop(['quality'],axis=1)
y = df['quality']
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(df_scaled_X,y,test_size=0.2,random_state=33)
```

现在，您将把数据分成训练组和测试组，需要时可以通过它们的变量调用它们。现在让我们继续扩展数据。

### 缩放数据

当你有一些比其他值高得多的值时，模型所做的学习可能没有意识到具有较低值的特征同样重要。

如果你有一栋几万平方英尺的房子，与浴室的数量相比，它可能会错误地把房子的大小看得非常重要。

为了解决这个问题，我们通过标准化来减少数量。为此，我们将使用一个**最小最大**缩放器，它将在 0 和 1 之间缩放我们的值。这个定标器使用一个简单的等式将所有东西都缩小到这个范围，同时保持关系不变。

等式是这样的:对于任何值，减去在该值组中找到的最小值，然后减去范围。范围就是最高值减去最低值。这可以用下面的等式来更好地表达，其中 **x** 是要缩放的值:

![Figure 9.16 – MinMax equation
](image/Figure_9.16.jpg)

图 9.16–最小最大方程式

要使用这个缩放器，你需要先导入它。然后我们将分别创建我们的`X`和`y`变量，或者特征和目标特征:

```
from sklearn.preprocessing import MinMaxScaler
X = df.drop(['quality'],axis=1)
y = df['quality']
```

接下来，您将创建您的 scaler 对象，然后对您的数据使用`fit_transform()`。这意味着我们将把前面提到的等式应用到我们的葡萄酒数据中:

```
min_max_scaler = MinMaxScaler()
minmax_scaled_X = min_max_scaler.fit_transform(X)
```

您将得到介于 0 和 1 之间的所有值。为了使它更容易查看和使用，我们将把它放在一个 pandas 数据框架中。键入以下代码来实现这一点:

```
df_scaled_X = pd.DataFrame(scaled_X,columns=X.columns)
df_scaled_X.head()
```

您将看到以下内容，所有值都在 0 到 1 之间:

![Figure 9.17 – Scaled dataset using minmax
](image/Figure_9.17.jpg)

图 9.17–使用最小最大值的缩放数据集

我们已经得到了我们想要的数据！现在我们可以开始训练模特了。

# 使用 MSE 和 R2 分数评估潜在模型

总会有大量的潜在模型可供你尝试训练，你可以花大量的时间调整它们来优化它们。在你花大量时间做任何选择之前，了解哪一个能给你最好的结果是很有价值的。我们将使用 k-fold 验证来检查我们如何训练模型。这将获取我们的训练数据并创建 k 个部分。您可以将此想象为将一张纸折叠 k 次，然后轮流使用 k 个部分中的一个作为测试数据，其余部分作为训练数据:

1.  首先，我们想要导入我们在这个练习中需要的东西。下一段代码将进行训练，这样我们就可以看到哪个模型更适合。我们将像往常一样从导入我们需要的东西开始:

    ```
    from sklearn.model_selection import cross_val_score
    from sklearn.model_selection import StratifiedKFold
    from sklearn.linear_model import  LinearRegression
    from sklearn.svm import SVR
    from sklearn.neighbors import KNeighborsRegressor
    ```

2.  接下来，我们告诉计算机我们想如何使用`kfold`。注意，我们想要`3`分割。随机状态只是一颗种子，如果需要的话，它将允许我们复制同样的折叠:

    ```
    kfold = StratifiedKFold(n_splits=3, random_state=33, shuffle=True)
    ```

3.  最后，我们要进行实际训练。我们将训练三个独立的模型，线性回归、KNN 和 SVM:

    ```
    lr_cve = cross_val_score(LinearRegression(), X_train, y_train, cv=kfold, scoring='neg_mean_squared_error')
    knn_cve = cross_val_score(KNeighborsRegressor(), X_train, y_train, cv=kfold, scoring='neg_mean_squared_error')
    svm_cve = cross_val_score(SVR(), X_train, y_train, cv=kfold, scoring='neg_mean_squared_error')
    ```

我们将会看到每个人在每次跑步中的表现。在这种情况下，我们将有三个数字。取这些运行的平均值将会给我们一个很好的估计，所以让我们用下面的方法对每个运行进行估计:

```
print(Linear Regression MSE score: {lr_cve.mean()}')
print(f'KNN MSE score:{knn_cve.mean()}')
print(f'SVM MSE score: {svm_cve.mean()}')
```

这将输出如下内容:

```
Linear Regression MSE score: -0.5363356561285768
KNN MSE score:-0.5222757707446848
SVM MSE score: -0.4866814111612208
```

解释负 MSE

你可能想知道为什么(或如何)平均平方误差(MSE) 可以是负数。这是由于 scikit-learn 中的一个设计决策。当评分在 scikit-learn 中设置时，越大越好。拥有一个负的 MSE 允许它遵循这个模式，但是是反直觉的。为了更明确地向用户展示这是有意的，它的名字被改成了`neg_mean_squared_error`。

我们可以看到 SVM 会给我们最好的结果。在现实世界中，你可能会把所有的精力都放在使用 SVM 上，但是为了从本书中获得最大的收益，我们将逐一深入研究。

让我们从支持向量机开始，然后深入研究其他支持向量机来确认我们所看到的。

## 训练你的模特

我们现在开始关注和评估单个模型。在这里，你将开始看到你所有的劳动成果，并发现我们提出的东西是否会帮助我们解决最初的问题。Scikit-learn 在我们做了这么多准备工作之后，让工作变得非常简单。

### 训练 SVM

我们将从 SVM 模式开始。只需要几个步骤来训练然后测试模型，它们如下:

1.  使 SVR 算法适合训练数据。我们将使用缩放后的数据:

    ```
    svr_model = SVR().fit( df_std_scaled_X, y_train)
    ```

2.  对测试数据集运行预测。您还需要使用与训练数据相同的方法来缩放这些数据，因为这是模型所知道的。对此使用相同的`min_max_scaler`:

    ```
    test_X_scaled = min_max_scaler.fit_transform(X_test)
    ```

3.  接下来，我们将使用这些数据进行预测:

    ```
    y_pred_svr = svr_model.predict( test_X_scaled)
    ```

我们将保留最后一个`y_pred_svr`,这样我们就可以确定这个模型做得有多好。

## 用 MSE 和 R2 评分分析模型结果

有一些客观的方法来确定你正在创建的模型是否如它应该的那样运行。与分类不同，您没有要预测的离散类，因此您的预测有一个数值方面的远近。换句话说，有了分类，你的预测不是对就是错。使用回归，您试图预测一个数字，因此您需要一种方法来确定您与每个预测的接近程度。这就是 MSE 和 R2 参与进来的原因。现在让我们更深入地了解这两者。

### MSE 分数

**MSE** 分数是了解你的回归模型被训练得有多好的最常见方式。如果我们分解这个名字，我们可以了解它在做什么。MSE 是确定预测值与真实值之差的过程，称为*误差*。然后，我们计算这个误差的平方，并取平均值。

![Figure 9.18 – Equation for MSE
](image/Figure_9.18.jpg)

图 9.18-MSE 方程

前面等式中的符号分解如下:

*   MSE =均方差
*   n =数据点的数量
*   ![](image/B16589_09_001.png) =真值
*   ![](image/B16589_09_002.png) =预测值

幸运的是，scikit-learn 有一个很好的方法来计算这个。您可以使用以下内容:

```
from sklearn.metrics import mean_squared_error
MSE_svm = mean_squared_error(y_test,y_pred_svr)
print(MSE_svm)
```

这将告诉我们每个预测值与只差大约半个点！那还不错:

```
0.5176910605282448
```

让我们看看另一种方法来验证我们是如何与 R2 分数。

## R2 评分

另一个的主要衡量标准是 R2，或者如果你想用一个更花哨的术语来称呼，那就是决定系数。它用于根据自变量确定因变量的变化量。在我们的场景中，因变量(`y_train`)是葡萄酒质量，自变量(`x_train`)是硫和酒精含量等。

![Figure 9.19 – Equation for R2
](image/Figure_9.19.jpg)

图 9.19-R2 方程

分数 1 表示完全对齐，分数 0 表示输入要素与输出无关。

现在让我们训练 KNN 算法，它将遵循大致相同的流程。

## 训练 KNN 模型

KNN 模型将以与前一节中 SVM 模型非常相似的方式进行训练。因此，我们将在相同的步骤中进行训练和 MSE 计算，如下所示:

```
knn_model = KNeighborsRegressor().fit( minmax_scaled_X, y_train)
y_pred_knn = knn_model.predict( X_test_scaled)
MSE_knn = mean_squared_error(y_test,y_pred_knn)
print(MSE_knn)
```

这将打印出一个类似但不太好的分数 0.56:

```
0.5601846
```

尽管 KNN 在分类问题中更常见，但如果我们调整一些超参数，如`k`的值，我们很有可能获得更好的 KNN 模型，这些超参数将决定用于分类新数据点的邻居数量。我们将在 [*第 11 章*](B16589_11_ePub.xhtml#_idTextAnchor270) *、调优超参数和版本化您的模型*中详细讨论什么是超参数以及如何调优它们。

最后，我们将使用这一步的三种算法中的最后一种，即线性回归。

## 线性回归

到目前为止，你已经看过了 SVM 和 KNN。逻辑回归将遵循类似的步骤:

```
lr = LinearRegression().fit(X_train, y_train)
```

我们在这里暂停一下，记下您可能遇到的一个常见问题。如果出现错误**收敛警告:lbfgs 未能收敛(状态=1):停止:迭代总数达到限制**，请确保您已按上一节所述缩放数据。

这个消息仅仅意味着用来提出一个好模型的规划求解算法不能达到一个它认为足够好的点。它知道这一点，因为当它到达最后一次迭代时，它仍然得到一个与前一个足够不同的答案，它认为它仍然有许多工作要做。

当迭代停止得到一个非常不同的点时，算法确信它不会变得更好，因此增加迭代次数会给它更多的收敛机会。

在我们解决这个问题后，我们可以继续我们的预测:

```
y_pred = lr.predict(X_test)
MSE_wine = mean_squared_error(y_test,y_pred)
r2_wine = r2_score(y_test,y_pred)
 print(f'{MSE_lr:.2f}')
 print(f'{r2_wine:.2f}')
```

然后我们会看到 MSE 和 R2 分数:

```
0.58
0.28
```

我们得到了一个非常好的结果，但是看起来原始的 SVM 给了我们最好的结果，所以我们会保留它。

此时，我们已经有了模型，并准备好完成如何进一步发展的后续步骤。

## 利用我们的成果

有了我们的模型，我们现在可以在酿酒厂测试我们所有的葡萄酒，看看它们怎么样。我们仍有许多路可走，但主要的焦点仍是我们如何回答这个主要问题:知道是什么造就了好酒。虽然我们不会深入探讨，但您可以自己尝试这些建议，或者它可能会启发您改进我们的模型。

以下是您可以利用我们的结果做的一些事情:

*   打破红葡萄酒和白葡萄酒之间的模式，看看它们之间是否有任何重大差异，我们可能会看到我们可以缩小你现在可能想要运行的其他测试和事情。
*   添加不同地区葡萄酒的数据，检查是否有任何风味特征。
*   深入调查谁对这些葡萄酒进行了评级，看看质量评分中是否有任何偏差或偏好。
*   了解我们是否希望专注于为质量创造的收入，并确定数据收集是否可以改进。

这些只是一些建议，但是有无数种方法可以让你继续改进你得到的问题和答案。

# 总结

至此，您已经更好地掌握了如何看待现实世界的问题，并理解了需要发生的全部流程。

以酿造高品质葡萄酒为背景，你首先看到了更好地理解问题空间对于框定我们需要做的事情是多么重要，而实现这一点的一种方法是理解我们数据集中的每一列。

之后，我们研究了如何进一步探索和清理数据。您看到了数据清理阶段是如何被分成两个部分的，分界线是什么时候事情需要人类可读，以及什么时候您需要专注于构建一个好的模型。像缩放数据这样的事情应该发生在你觉得你已经理解了你正在看的东西之后。

在预训练数据阶段，我们确保设置了 conda 环境，其中包含我们需要的一切，包括 Jupyter 笔记本电脑。当我们加载它的时候，我们做的第一件事是得到我们的两个不同的数据集，并把它们合并成一个熊猫数据框架，以使事情更容易处理。我们使用直方图来检查值的分布，然后创建一个相关矩阵来了解每个特性如何相互关联。

当我们几乎准备好训练时，我们发现我们需要将数据分成训练集和测试集，就像我们在前面章节中所做的那样。在培训前的最后一步，我们确保缩放数据，以便让模型最好地收敛到一个好的解决方案。我们为此使用了`MinMax`，但是我们也可以使用其他算法。

最后，我们使用 k-fold 交叉验证来测试一些潜在的模型，它将数据分成`k`个部分，并交替将每个部分标记为测试段，以让我们很好地了解什么会工作得很好。利用这一点，我们看到 SVM 在小组中做得最好，我们继续训练和测试完整的模型，我们使用 MSE 和 R2 分数进行分析。

在下一章中，我们将关注当你有了一个满意的模型后该做什么。这将包括我们如何分享模型和数据集，向我们的同事展示我们的成果。您还将学习如何在想要运行管道时设置模型，包括数据缩放和其他您不想每次都重复的操作。