

# 八、网络分析

|   | “我敌人的敌人就是我的朋友。” |   |
|   | ——*古代谚语* |

本章关注的是数学意义上的图表，而不是视觉意义上的图表。图就是由边连接的一组顶点，这种抽象的简单性意味着图无处不在。它们是各种结构的有效模型，如网络的超链接结构、互联网的物理结构以及各种网络:道路、电信和社交网络。

因此，网络分析并不新鲜，但随着社交网络分析的兴起，它变得特别流行。网络上最大的网站是社交网络，谷歌、脸书、Twitter 和 LinkedIn 都利用大规模图形处理来挖掘用户数据。定向广告对网站盈利的巨大重要性意味着，有效推断互联网用户兴趣的公司将获得巨大的经济回报。

在这一章中，我们将使用公开可用的 Twitter 数据来演示网络分析的原理。我们将应用模式匹配技术(如三角形计数)来寻找图中的结构，并应用全图处理算法(如标签传播和 PageRank)来梳理图的网络结构。最终，我们将使用这些技术来识别一组 Twitter 社区中最有影响力的成员的兴趣。我们将使用 Spark 和一个名为 GraphX 的库来完成所有这些工作，该库使用 Spark 分布式计算模型来处理非常大的图形。

但是在我们扩大规模之前，我们将通过考虑一种不同的问题来开始我们对图的探索:图的遍历。为此，我们将利用 Clojure 库织机。

# 下载数据

本章使用了来自 Twitter 社交网络的追随者数据。这些数据是作为斯坦福大型网络数据集集合的一部分提供的。你可以从 https://snap.stanford.edu/data/egonets-Twitter.html 的[下载推特数据。](https://snap.stanford.edu/data/egonets-Twitter.html)

我们将同时使用`twitter.tar.gz`文件和`twitter_combined.txt.gz`文件。这两个文件都应该下载并解压缩到示例代码的数据目录中。

### 注意

本章的示例代码可在[https://github.com/clojuredatascience/ch8-network-analysis](https://github.com/clojuredatascience/ch8-network-analysis)获得。

像往常一样，已经提供了一个脚本来为您完成这项工作。您可以通过在项目目录中执行以下命令行来运行它:

```

script/download-data.sh

```

如果你想运行本章的例子，确保在继续之前下载数据。

## 检查数据

让我们来看看 Twitter 目录中的一个文件，具体来说就是`twitter/98801140.edges`文件。如果在文本编辑器中打开它，您会看到文件的每一行都由一对用空格分隔的整数组成。数据是所谓的边缘列表格式。这是存储图形的两种主要方式之一(另一种是邻接表格式，我们稍后会谈到)。下面的代码使用 Clojure 的`line-seq`函数一次读取一行文件，并将其转换为一个元组:

```
(defn to-long [l]

  (Long/parseLong l))

(defn line->edge [line]

  (->> (str/split line #" ")

       (mapv to-long)))

(defn load-edges [file]

  (->> (io/resource file)

       (io/reader)

       (line-seq)

       (map line->edge)))

(defn ex-8-1 []

  (load-edges "twitter/98801140.edges"))
```

如果您在 REPL 中执行`(ex-8-1)`或在命令行上运行以下命令，您应该会看到以下序列:

```

lein run –e 8.1

;;([100873813 3829151] [35432131 3829151] [100742942 35432131]

;;  [35432131 27475761] [27475761 35432131])

```

这个简单的数字对序列，每个数字对代表一条边，已经足以代表图形的本质。看边与边之间的关系并不直观，我们来形象化一下。

## 用织机可视化图形

在本章的前半部分，我们将使用 Loom([https://github.com/aysylu/loom](https://github.com/aysylu/loom))来处理我们的图形。Loom 定义了一个 API 来创建和操作图形。它还包含许多内置的图遍历算法。我们很快就会谈到这些。

首先，我们想要可视化我们的图表。为此，Loom 依赖于一个名为 GraphViz 的系统级库。如果你想复制本章中的许多图片，你需要现在就安装 GraphViz。如果您不确定是否已经安装，请尝试在命令行上运行以下命令:

```

dot –V

```

### 注意

GraphViz 可从 http://graphviz.org/ T2 获得，并有 Linux、MacOS 和 Windows 的安装程序。GraphViz 并不是运行本章中所有例子的必要条件，只是可视化图形的例子。

Loom 能够从一系列边中创建一个图形，就像我们对序列应用`loom/graph`函数时所得到的那样。在下面的例子中，我们将要求`loom.graph`为`loom`，而`loom.io`为`lio`。如果您安装了 GraphViz，请运行以下示例:

```
(defn ex-8-2 []

  (->> (load-edges "twitter/98801140.edges")

       (apply loom/graph)

       (lio/view)))
```

您应该会看到如下示意图所示的结果:

![Visualizing graphs with Loom](graphics/7180OS_08_100.jpg)

根据您的 GraphViz 版本，您可能不会获得与上一版本完全相同的布局，但这没关系。图像中节点和边的相对位置并不重要。关于图的唯一重要的事实是哪些节点连接到哪些其他节点。

作为一名 Clojure 程序员，您熟悉作为 S 表达式嵌套结构的树结构，并且您可能已经注意到这个图看起来很像一棵树。事实上，树只是一种特殊的图:不包含循环的图。我们称这样的图为**非循环的**。

在这个图中，只有四条边，而我们在第一个例子中看到的边列表中有五条。这是因为边缘可以被引导。它们从一个节点到另一个节点。我们可以使用`loom/digraph`函数用 Loom 加载有向图:

```
(defn ex-8-3 []

  (->> (load-edges "twitter/98801140.edges")

       (apply loom/digraph)

       (lio/view)))
```

此代码生成以下图像:

![Visualizing graphs with Loom](graphics/7180OS_08_110.jpg)

请注意向我们的边添加方向的行为是如何从根本上改变了我们阅读图表的方式。特别是，图显然不再是树。有向图在我们想要表示其他事物对某事物执行的动作的情况下非常重要。

例如，在 Twitter 的社交图中，一个帐户可能会关注一个帐户，但这种行为可能不是对等的。使用 Twitter 的术语，我们可以指一个账户的追随者或朋友。一个追随者代表一个输出边，而一个朋友代表一个输入边。例如，在上图中，账户 **382951** 有两个关注者:账户 **35432131** 和 **100873813** 。

现在在节点 **27475761** 和 **35432131** 之间有两条边。这意味着可以从一个节点回到另一个节点。我们称之为循环。像前面这样的图的技术术语是有向的，**循环**图。

### 注意

图中的一个循环意味着只向边的方向移动就可以回到一个节点。如果一个图不包含这样的环，那么这个图就被称为无环的。一个**有向** **非循环图** ( **DAG** )，是一个多种层次或有序现象的模型，例如依赖图、系谱树和文件系统层次。

我们已经看到，图可以是有向的，也可以是无向的。第三种主要类型的图是**加权**图。权重可以有效地与边相关联，以表示两个节点之间的连接强度。例如，如果图表代表一个社会网络，两个账户之间的权重可能是他们联系的强度(例如，他们的交流频率)。

我们可以用`loom/weighted-graph`或`loom/weighted-digraph`函数在`loom`中加载一个加权图:

```
(defn ex-8-4 []

  (->> (load-edges "twitter/98801140.edges")

       (apply loom/weighted-digraph)

       (lio/view)))
```

我们的输入图实际上并没有指定边的权重。Loom 所有边的默认权重是 **1** 。

![Visualizing graphs with Loom](graphics/7180OS_08_120.jpg)

图可以不同的另一个方面是它的顶点和边是否是类型化的，表示不同的实体或它们之间的连接。例如，脸书图包含许多类型的实体:特别是“页面”和“人”。人们可以“喜欢”网页，但是他们不能“喜欢”其他人。在异构图中，类型“A”的节点总是连接到类型“B”上，反之亦然(但从不互相连接)，该图被称为 **二分图**。二分图可以表示为两个不相交的集合，其中一个集合中的节点只链接到另一个集合中的节点。



# 用织机遍历图形

遍历算法关心的是以系统的方式探索图的方法。考虑到可以用图形建模的各种各样的现象，这样的算法可以有各种各样的用途。

我们将在接下来的几节中考虑的算法涉及一些最常见的任务，例如:

*   确定是否存在精确跟踪每条边一次的路径
*   确定两个顶点之间的最短路径
*   确定连接所有顶点的最短树

如果所讨论的图表示送货司机的一轮所覆盖的道路网络，则顶点可以表示交叉点。找到一条精确跟踪每条边一次的路径将是送货司机走过所有道路的方式，而不用折回或经过相同的地址两次。两个顶点之间的最短路径将是从一个地址导航到下一个递送的最有效方式。最后，连接所有顶点的最短的树将是连接所有顶点的最有效的方法:也许，为每个十字路口的灯铺设一条路边电线。

## 柯尼斯堡的七座桥

普鲁士的柯尼斯堡(现在的俄罗斯加里宁格勒)坐落在普列格尔河的两岸，包括两个大岛，这两个大岛通过七座桥相互连接并与大陆相连。柯尼斯堡的七座桥是一个历史上著名的数学问题，它奠定了图论的基础，预示了拓扑学的思想。Pregel 这个名字将在本章后面再次出现。

![The seven bridges of Königsberg](graphics/7180OS_08_150.jpg)

问题是要找到一条穿过城市的路，这条路要穿过每座桥一次，而且只能穿过一次。除了桥梁之外，没有任何路线可以到达这些岛屿，而且每次都必须完全跨越这些桥梁；一个人不可能走到桥的一半，然后转身从桥的另一边穿过另一半(尽管步行不需要在同一个地方开始和结束)。

欧拉意识到这个问题没有解决方案:不可能有通过桥梁的不可追溯的路线，这个困难导致了一种技术的发展，这种技术用数学的严谨性建立了这个断言。问题的唯一结构是桥梁和陆地之间的联系。问题的本质可以通过将桥表示为图中的边来保留。

![The seven bridges of Königsberg](graphics/7180OS_08_160.jpg)

欧拉观察到(除了在行走的终点)，一个人通过一条边进入顶点，通过另一条边离开顶点。如果每条边都恰好被遍历一次，那么每个节点的连接边的数量一定是偶数(其中一半将被“向内”遍历，另一半将被“向外”遍历)。

因此，对于存在于图中的欧拉旅行，所有节点(除了开始和结束节点之外)必须具有偶数个连接边。我们将连接边的数量称为节点的度数。因此，确定一个图中是否存在欧拉游只是简单地计算奇数度顶点的数量。如果有零个或两个顶点，那么可以从图中构建欧拉游。以下函数利用了 Loom 提供的两个实用函数`out-degree`和`nodes`，来检查是否存在欧拉游:

```
(defneuler-tour? [graph]

  (let [degree (partial loom/out-degree graph)]

    (->> (loom/nodes graph)

         (filter (comp odd? degree))

         (count)

         (contains? #{0 2}))))
```

在这段代码中，我们使用了 Loom 的`out-degree`函数来计算图中每个节点的度数。我们只过滤`odd`度的顶点，并验证计数是`0`还是`2`。如果是，欧拉游是存在的。



# 广度优先和深度优先搜索

前面的例子在历史上是值得注意的，但是在图遍历中更常见的愿望是从某个其他节点开始在图中找到一个节点。有几种方法可以应对这一挑战。对于未加权的图，比如我们的 Twitter follow 图，最常见的是广度优先和深度优先搜索。

广度优先搜索从一个特定的顶点开始，然后在它的每个邻居中搜索目标顶点。如果找不到顶点，它会依次搜索邻居的每个邻居，直到找到顶点或遍历完整个图。

下图显示了遍历顶点的顺序，从顶部开始，从左到右按层向下:

![Breadth-first and depth-first search](graphics/7180OS_08_130.jpg)

Loom 在`loom.alg`名称空间中包含了多种遍历算法。让我们在我们一直在研究的同一 Twitter 追随者图上执行广度优先搜索，为了方便起见，我们重复了一遍:

![Breadth-first and depth-first search](graphics/7180OS_08_135.jpg)

广度优先遍历作为`bf-traverse`函数提供。这将按照顶点被访问的顺序返回一系列顶点，这将使我们能够看到广度优先搜索是如何遍历图形的:

```
(defn ex-8-5 []

  (let [graph (->> (load-edges "twitter/98801140.edges")

                   (apply loom/digraph))]

    (alg/bf-traverse graph 100742942)))

;;(100742942 35432131 27475761 3829151)
```

我们使用`bf-traverse`函数执行图的遍历，从节点`100742942`开始。请注意响应是如何不包含节点`100873813`的。没有办法将图形遍历到这个顶点，只能沿着边的方向。到达顶点`100742942`的唯一方法是从那里开始。

另外，注意`35432131` 只列出一次，即使它同时连接到`27475761`和`3829151`。Loom 的广度优先搜索实现在内存中维护了一组访问过的顶点。一个顶点一旦被访问，就不需要再被访问。

广度优先搜索的另一种方法是深度优先搜索。该算法立即前进到树的底部，并按下图所示的顺序访问节点:

![Breadth-first and depth-first search](graphics/7180OS_08_140.jpg)

Loom 包含深度优先搜索，如`pre-traverse`:

```
(defn ex-8-6 []

  (let [graph (->> (load-edges "twitter/98801140.edges")

                   (apply loom/digraph))]

    (alg/pre-traverse graph 100742942)))

;;(100742942 35432131 3829151 27475761)
```

深度优先搜索的优势在于它比广度优先搜索具有更低的内存需求，因为它不需要存储每层的所有节点。这可能会降低大型图形的内存消耗。

然而，根据具体情况，深度优先或广度优先搜索可能更方便。例如，如果我们遍历一个家谱，寻找一个活着的亲戚，我们可以假设这个人会在树的底部，所以深度优先搜索可能会更快地到达目标。如果我们要寻找一个远古祖先，那么深度优先搜索可能会浪费时间来检查大量更近的亲属，并需要更长的时间才能到达目标。



# 寻找最短路径

前面介绍的算法逐个顶点地遍历图，并返回图中所有节点的惰性序列。它们便于说明导航图结构的两种主要方式。然而，更常见的任务是找到从一个顶点到另一个顶点的最短路径。这意味着我们只对它们之间的节点序列感兴趣。

如果我们有一个未加权的图，比如前面的图，我们通常将距离计算为“跳”的次数:一跳是两个相邻节点之间的距离。最短路径的跳数最少。在这种情况下，广度优先搜索通常是一种更有效的算法。

Loom 实现宽度优先最短路径作为`bf-path`函数。为了演示它，让我们加载一个更复杂的 Twitter 图表:

```
(defn ex-8-7 []

  (->> (load-edges "twitter/396721965.edges")

       (apply loom/digraph)

       (lio/view)))
```

这段代码生成了下图:

![Finding the shortest path](graphics/7180OS_08_145.jpg)

让我们看看是否能找出顶部和底部节点之间的最短路径: **75914648** 和 **32122637** 。该算法可以返回许多路径，但是我们想要识别通过点 **28719244** 和 **163629705** 的路径。这是跳数最少的一个。

```
(defn ex-8-8 []

  (let [graph (->> (load-edges "twitter/396721965.edges")

                   (apply loom/digraph))]

    (alg/bf-path graph 75914648 32122637)))

;;(75914648 28719244 163629705 32122637)
```

的确如此。

### 注意

Loom 还实现了双向广度优先最短路径算法`bf-path-bi`。这从源和目的地并行搜索，并且在某些类型的图上可能更快地找到最短路径。

如果图是加权的呢？在这种情况下，最少的跳数可能不对应于两个节点之间的最短路径，因为该路径可能与较大的权重相关联。在这种情况下，Dijkstra 算法是一种寻找两个节点之间最短成本路径的方法。该路径可能需要更多的跳数，但是遍历的边权重之和将是最低的:

```
(defn ex-8-9 []

  (let [graph (->> (load-edges "twitter/396721965.edges")

                   (apply loom/weighted-digraph))]

    (-> (loom/add-edges graph [28719244 163629705 100])

        (alg/dijkstra-path 75914648 32122637))))

;;(75914648 28719244 31477674 163629705 32122637)
```

在这段代码中，我们将图加载为一个加权有向图，并将节点`28719244`和`163629705`之间的边更新为权重为`100`。所有其他边的默认权重为 1。这具有将非常高的成本分配给最直接路径的效果，因此找到了替代路径。

Dijkstra 的算法对于寻路特别有价值。例如，如果图表模拟道路网络，则最佳路径可能是走主干道的路径，而不是走最少步骤的路径。或者，根据一天中的时间和道路上的交通量，与特定路线相关联的成本可能会发生变化。在这种情况下，Dijkstra 的算法将能够在一天中的任何时间确定最佳路线。

### 注意

一种叫做 **A*** (发音为 A-star)的算法通过允许一个启发式函数来优化 Dijkstra 的算法。它在 Loom 中实现为`alg/astar-path`。启发式函数返回目的地的预期成本。只要不高估真实成本，任何函数都可以用作试探法。这种启发式的使用允许 A*算法避免对图进行穷举搜索，因此，它可以更快。有关 A*算法的更多信息，请参考 https://en.wikipedia.org/wiki/A*_search_algorithm 的[。](https://en.wikipedia.org/wiki/A*_search_algorithm)

让我们继续考虑加权图，并询问如何构建一棵以最短成本连接所有节点的树。这种树被称为最小生成树。

## 最小生成树

在前面的算法的帮助下，我们考虑了如何在两点之间遍历图形。但是，如果我们想发现一条连接图中所有节点的路由呢？在这种情况下，我们可以使用最小生成树。我们可以把最小生成树看作是我们考虑过的全图遍历算法和我们最近看到的最短路径算法的混合。

最小生成树对于加权图特别有用。如果权重表示连接两个顶点的成本，则最小生成树找到连接整个图的最小成本。它们出现在网络设计等问题中。例如，如果节点代表办公室，边权重代表办公室之间的电话线的成本，则最小生成树将提供以最低总成本连接所有办公室的电话线集。

Loom 的最小生成树实现利用了 Prim 的算法，并作为`prim-mst`函数提供:

```
(defn ex-8-10 []

  (let [graph (->> (load-edges "twitter/396721965.edges")

                   (apply loom/weighted-graph))]

    (-> (alg/prim-mst graph)

        (lio/view))))
```

这将返回下图:

![Minimum spanning trees](graphics/7180OS_08_180.jpg)

如果我们再次将顶点 **28719244** 和 **163629705** 之间的边更新为 100，我们将能够观察到它对最小生成树的影响:

```
(defn ex-8-11 []

  (let [graph (->> (load-edges "twitter/396721965.edges")

                   (apply loom/weighted-graph))]

    (-> (loom/add-edges graph [28719244 163629705 100])

        (alg/prim-mst)

        (lio/view))))
```

此代码返回以下图表:

![Minimum spanning trees](graphics/7180OS_08_185.jpg)

这棵树已经被重新配置以绕过代价最高的边。

## 子图和连通分量

只能为 *连通图*指定最小生成树，其中所有节点都通过至少一条路径连接到所有其他节点。在图不相连的地方，我们显然无法构建最小生成树(尽管我们可以构建最小生成林)。

![Subgraphs and connected components](graphics/7180OS_08_190.jpg)

如果一个图包含一组内部相连但彼此不相连的子图，那么这些子图称为连通分量。如果我们加载一个更复杂的网络，我们可以观察到连接的组件:

```
(defn ex-8-12 []

  (->> (load-edges "twitter/15053535.edges")

       (apply loom/graph)

       (lio/view)))
```

本例生成如下图像:

![Subgraphs and connected components](graphics/7180OS_08_200.jpg)

由于图的布局，我们可以很容易地看到有三个连接的组件，Loom 将使用`connected-components`函数为我们计算这些组件。我们将在本章的后面看到如何实现一个算法来为我们自己计算这个:

```
(defn ex-8-13 []

  (->> (load-edges "twitter/15053535.edges")

       (apply loom/graph)

       (alg/connected-components)))

;;[[30705196 58166411] [25521487 34173635 14230524 52831025 30973

;; 55137311 50201146 19039286 20978103 19562228 46186400

;;14838506 14596164 14927205] [270535212 334927007]]
```

有向图是强连通的，如果从每个节点到其他节点都有一条路。一个有向图是弱连通的，如果只把所有的边都看作是无向的，那么从每个节点到其他节点都有一条路。

![Subgraphs and connected components](graphics/7180OS_08_210.jpg)

让我们将 same 图加载为一个有向图，看看是否有任何强连接的组件:

```
(defn ex-8-14 []

  (->> (load-edges "twitter/15053535.edges")

       (apply loom/digraph)

       (lio/view)))
```

本例生成如下图像:

![Subgraphs and connected components](graphics/7180OS_08_220.jpg)

和以前一样，有三个弱连接的组件。仅仅通过查看图表，很难直观地确定有多少强连接的组件。Kosaraju 的算法将计算一个图中强连通分量的数量。它由 Loom 实现为`alg/scc`函数:

```
(defn ex-8-15 []

  (->> (load-edges "twitter/15053535.edges")

       (apply loom/digraph)

       (alg/scc)

       (count)))

;; 13
```

Kosaraju 的算法利用了有趣的属性,即转置图——一个所有边都反转的图——与输入图具有完全相同数量的连通分量。响应包含所有强连通分量(甚至是仅包含一个节点的退化情况)作为序列向量。如果我们按长度降序排列，第一个组件将是最大的:

```
(defn ex-8-16 []

  (->> (load-edges "twitter/15053535.edges")

       (apply loom/digraph)

       (alg/scc)

       (sort-by count >)

       (first)))

;;[14927205 14596164 14838506]
```

最大的强连通分量仅仅是三个节点。

## SCC 与网页的蝴蝶结结构

弱连通和强连通分量可以提供理解有向图结构的信息方式。例如，对互联网的链接结构进行的研究表明，强连接的组件确实可以变得非常大。

### 注意

引用以下数字的论文可在[http://www9.org/w9cdrom/160/160.html](http://www9.org/w9cdrom/160/160.html)网站在线获取。

尽管下面的数字来自于 1999 年的一项研究，因此它们已经过时了，但是我们可以看到在网络的中心是一个由 5600 万个页面组成的大的强连接组件。这意味着从强连接组件中的任何页面，您都可以通过跟随出站超链接到达强连接组件中的任何其他页面。

![SCC and the bow-tie structure of the web](graphics/7180OS_08_230.jpg)

4400 万页链接到 SCC，但没有从它链接，4400 万页从 SCC 链接，但没有链接回来。只有极少数环节完全绕过了 SCC(上图中的“管道”)。



# 全图分析

让我们把注意力从我们一直在处理的小图转移到由文件提供的大图。这包含超过 240 万条边，将提供一个更有趣的样本来处理。

确定整个图形的最简单的度量之一是它的密度。对于有向图，这被定义为边的数量 *|E|* 、顶点的数量 *|V|* 乘以比自身小 1。

![Whole-graph analysis](graphics/7180OS_08_01.jpg)

对于连通图(其中每个顶点都通过一条边连接到其他每个顶点)，密度将是 1。相比之下，不连通的图(没有边的图)的密度为 0。Loom 实现图形密度作为`alg/density`功能。让我们计算一下更大的 Twitter 图表的密度:

```
(defn ex-8-17 []

  (->> (load-edges "twitter_combined.txt")

       (apply loom/digraph)

       (alg/density)

       (double)))

;; 2.675E-4
```

这看起来很少，但请记住，值 1 将对应于每个其他帐户之后的每个帐户,这显然不是社交网络的情况。一些帐户可能有许多联系，而另一些帐户可能根本没有联系。

让我们看看边是如何在节点间分布的。我们可以重用 Loom 的`out-degree`函数来计算每个节点的输出边数，并使用以下代码绘制分布直方图:

```
(defn ex-8-18 []

  (let [graph (->> (load-edges "twitter_combined.txt")

                   (apply loom/digraph))

        out-degrees (map #(loom/out-degree graph %)

                         (loom/nodes graph))]

    (-> (c/histogram out-degrees :nbins 50

                     :x-label "Twitter Out Degrees")

        (i/view))))
```

这会生成以下直方图:

![Whole-graph analysis](graphics/7180OS_08_240.jpg)

出度的分布看起来很像我们在第二章、*推论*中第一次遇到的指数分布。请注意，大多数人只有很少的学位，但也有少数人拥有超过一千个学位。

让我们也画出内度数的直方图。在 Twitter 上，入度对应于一个账户的粉丝数量。

![Whole-graph analysis](graphics/7180OS_08_250.jpg)

in-degrees 的分布更加极端:尾部比前一个直方图向右延伸得更远，第一个柱比以前更高。这相当于大多数账户只有很少的关注者，但少数账户有几千人。

将前面的直方图与我们生成边和节点的随机图时得到的度分布进行对比。接下来，我们使用 Loom 的`gen-rand`函数生成一个具有 10，000 个节点和 1，000，000 条边的随机图:

```
(defn ex-8-20 []

  (let [graph (generate/gen-rand (loom/graph) 10000 1000000)

        out-degrees (map #(loom/out-degree graph %)

                         (loom/nodes graph))]

    (-> (c/histogram out-degrees :nbins 50

                     :x-label "Random out degrees")

        (i/view))))
```

这会生成以下直方图:

![Whole-graph analysis](graphics/7180OS_08_260.jpg)

随机图显示，由一百万条边连接的一万个顶点的图的平均出度大约是 200。度数的分布近似呈正态分布。很明显，Twitter 图表不是由随机过程生成的。



# 无标度网络

Twitter 度直方图是幂律度分布的特征。与正态分布、随机生成的图形不同，Twitter 直方图显示少数顶点与大多数边相连。

### 注意

“无尺度网络”这个术语是由圣母大学的研究人员在 1999 年创造的，用来描述他们在万维网上观察到的结构。

在模拟人类互动的图表中，我们经常会观察到连通性的幂律。这也被称为 **Zipf** 尺度，它表明了所谓的“优先依附定律”，其中一个受欢迎的顶点更有可能发展出额外的连接。社交媒体网站是这种过程的典型例子，新用户倾向于追随已经受欢迎的用户。

在[第 2 章](ch02.html "Chapter 2. Inference")、*推断*中，当数据绘制在对数线性轴上时，我们通过寻找直线来确定指数分布。通过在双对数轴上寻找一条直线，我们最容易确定幂律关系:

```
(defn ex-8-21 []

  (let [graph (->> (load-edges "twitter_combined.txt")

                   (apply loom/digraph))

        out-degrees (map #(loom/out-degree graph %)

                         (loom/nodes graph))

        points (frequencies out-degrees)]

    (-> (c/scatter-plot (keys points) (vals points))

        (c/set-axis :x (c/log-axis :label "log(out-degree)"))

        (c/set-axis :y (c/log-axis :label "log(frequency)"))

        (i/view))))
```

此代码返回以下图形:

![Scale-free networks](graphics/7180OS_08_270.jpg)

虽然不是完美的线性，但之前的图表足以显示 Twitter 图表中的幂律分布在起作用。如果我们将图中节点和边之间的连接可视化，无标度网络就可以被识别出来，因为它们具有典型的“簇”形。流行的顶点周围往往有一圈其他顶点。

![Scale-free networks](graphics/7180OS_08_280.jpg)

扩大到完整的 Twitter 组合数据集导致前面的例子运行得更慢，即使这个图与许多社交网络相比很小。本章的其余部分将致力于一个运行在 Spark 框架之上的图形库，称为 **GraphX** 。GraphX 表达了我们在本章已经讨论过的许多算法，但是可以利用 Spark 分布式计算模型来处理更大的图形。



# 用 GraphX 实现分布式图形计算

GraphX([https://spark.apache.org/graphx/](https://spark.apache.org/graphx/))是一个分布式图形处理库，旨在与 Spark 一起工作。像我们在前一章中使用的 MLlib 库一样，GraphX 提供了一组构建在 Spark rdd 之上的抽象。通过将图的顶点和边表示为 rdd，GraphX 能够以可伸缩的方式处理非常大的图。

在前面的章节中，我们已经了解了如何使用 MapReduce 和 Hadoop 处理大型数据集。Hadoop 是数据并行系统的一个例子:数据集被分成并行处理的组。Spark 还是一个数据并行系统:rdd 分布在集群中，并行处理。

![Distributed graph computation with GraphX](graphics/7180OS_08_300.jpg)

当您的数据非常类似于一个表时，数据并行系统是扩展数据处理的合适方式。图形可能具有复杂的内部结构，用表格来表示不是最有效的。尽管图形可以表示为边列表，但是正如我们所看到的，处理以这种方式存储的图形可能会涉及复杂的连接和集群中过多的数据移动，因为数据是相互关联的。

图形数据不断增长的规模和重要性推动了许多新的图形并行系统的发展。通过限制可以表达的计算类型并引入划分和分布图形的技术，这些系统可以有效地执行复杂的图形算法，比一般的数据并行系统快一个数量级。

### 注意

几个库为 Hadoop 带来了图形并行计算，包括哈马、(【https://hama.apache.org/】)和吉拉夫([【http://giraph.apache.org/】](http://giraph.apache.org/))。

GraphX 库为 Spark 带来了图形并行计算。使用 Spark 作为图形处理引擎的一个优点是，它的内存计算模型非常适合许多图形算法的迭代性质。

![Distributed graph computation with GraphX](graphics/7180OS_08_310.jpg)

此图说明了在节点可能互连的情况下并行处理图形的挑战。通过在图拓扑中处理数据，GraphX 避免了过多的数据移动和重复。GraphX 扩展了 Spark 的 RDD 抽象，引入了弹性分布式图或 RDG，以及一组以结构感知方式查询和转换图的函数。

## 创造闪闪发光的 rdg

Spark 和 GraphX 是主要用 Scala 编写的库。在本章中，我们将使用 Clojure 库 blinking([https://github.com/henrygarner/glittering](https://github.com/henrygarner/glittering))与 GraphX 交互。与 Sparkling 在 Spark 周围提供了一个薄薄的 Clojure 包装器一样，blinking 在 GraphX 周围提供了一个薄薄的 Clojure 包装器。

我们的第一个任务将是创建一个图表。可以通过两种方式实例化图:要么提供两个 RDD 表示(一个包含边，另一个包含顶点)，要么简单地提供边的 RDD。如果只提供了边，那么我们将为每个节点提供一个默认值。接下来我们将看到如何做到这一点。

因为 GraphX 利用 Spark，所以每个作业都需要一个相关的 Spark 上下文。在前一章中，我们使用了 Sparkling 的`sparkling.conf/conf`默认配置。然而，在本章中，我们将使用由 blinking 提供的默认配置。blinking 用序列化和反序列化 GraphX 类型所需的配置扩展了 blinking 的默认设置。在下面的代码中，我们将把`glittering.core`作为`g`包含进来，并使用闪闪发光的图形构造函数创建一个只有三条边的小图形:

```
 (defn ex-8-22 []

  (spark/with-context sc (-> (g/conf)

                             (conf/master "local")

                             (conf/app-name "ch8"))

    (let [vertices [[1 "A"] [2 "B"] [3 "C"]]

          edges [(g/edge 1 2 0.5)

                 (g/edge 2 1 0.5)

                 (g/edge 3 1 1.0)]]

      (g/graph (spark/parallelize sc vertices)

               (spark/parallelize sc edges)))))

;; #<GraphImpl org.apache.spark.graphx.impl.GraphImpl@adb2324>
```

结果是一个 GraphX 图形对象。注意，边是作为`g/edges`的 RDD 提供的:`g/edge` 函数将创建一个给定源 ID、目的 ID 和可选边属性的边类型。Edge 属性可以是 Spark 可以序列化的任何对象。请注意，顶点也可以有属性(上例中的“A”、“B”和“C”)。

构建图形的另一种方式是使用`g/graph-from-edges`构造函数。这将返回一个仅基于边的 RDD 的图。Twitter 数据是以边缘列表格式提供的，所以这是我们将用来加载它的函数。在下一段代码中，我们将把完整的`twitter_combined.txt`作为文本文件加载，并通过映射文件的行来创建一个边缘列表。从每条线，我们将创建一个权重为 1.0 的边:

```
(defn line->edge [line]

  (let [[from to] (map to-long (str/split line #" "))]

    (g/edge from to 1.0)))

(defn load-edgelist [sc path]

  (let [edges (->> (spark/text-file sc path)

                   (spark/map line->edge))]

    (g/graph-from-edges edges 1.0)))

(defn ex-8-23 []

  (spark/with-context sc (-> (g/conf)

                             (conf/master "local")

                             (conf/app-name "ch8"))

    (load-edgelist sc "data/twitter_combined.txt")))

;;#<GraphImpl org.apache.spark.graphx.impl.GraphImpl@c63044d>
```

`graph-from-edges`函数的第二个参数是用作每个顶点的属性的默认值:顶点属性不能在边列表中提供。

## 用三角形计数测量图形密度

GraphX 附带了少量内置图形算法的选择，这在`glittering.algorithms`名称空间中是可用的。在更详细地介绍 blinking 的 API 之前，让我们在 Twitter follows 图中运行其中一个。我们将展示如何使用 blinking 创建一个简单的图形处理作业，然后展示如何使用 GraphX 的图形并行原语，使用更多的 blinking API 来实现我们自己的算法。

三角形计数是一种算法，用于测量每个节点附近的图形密度。这在原理上类似于计算度数，但也说明了我们的邻居之间的联系有多好。我们可以用这个非常简单的图表来描绘这个过程:

![Measuring graph density with triangle counting](graphics/7180OS_08_330.jpg)

在这个例子中，我们可以看到顶点 A、B 和 C 都参与一个三角形，而顶点 D 不参与任何三角形。B 和 C 都跟随 A，但 C 也跟随 B，在社交网络分析的背景下，三角形计数是衡量朋友的朋友中有多少人也认识对方。在紧密结合的社区中，我们期望三角形的数量很高。

GraphX 已经实现了三角形计数，并且可以作为名称空间`glittering.algorithms`中的`triangle-count`函数进行访问。在我们使用这个特定的算法之前，GraphX 要求我们做两件事:

1.  将边缘指向“标准”方向。
2.  确保图形已分区。

这两个步骤都是在 GraphX 中实现三角形计数的产物。GraphX 允许两个顶点之间有多条边，但是三角形计数只计算不同的边。前面的两个步骤确保 GraphX 能够在执行算法之前有效地计算不同的边缘。

边的规范方向总是从较小的节点 ID 指向较大的节点 ID。我们可以通过在首次构建边 RDD 时确保所有边都在该方向上创建来实现这一点:

```
(defn line->canonical-edge [line]

  (let [[from to] (sort (map to-long (str/split line #" ")))]

    (glitter/edge from to 1.0)))

(defn load-canonical-edgelist [sc path]

  (let [edges (->> (spark/text-file sc path)

                   (spark/map line->canonical-edge))]

    (glitter/graph-from-edges edges 1.0)))
```

通过在我们创建边之前排序 `from`和`to`ID，我们确保了`from` ID 总是低于`to` ID。这是提高重复边缘去除效率的第一步。第二步是为图选择一个划分策略。下一节描述我们的选择。

### GraphX 分区策略

GraphX 是为分布式计算而构建的，因此它必须在多台机器上划分图形。一般来说，有两种方法可以用来划分图:边割和顶点割。每一种都有不同的取舍。

![GraphX partitioning strategies](graphics/7180OS_08_340.jpg)

边割策略似乎是划分一个图的最“自然”的方式。通过沿边分割图形，可以确保每个顶点都被精确地分配到一个由灰色阴影表示的分区。这给跨分区的边的表示带来了问题。沿着边缘的任何计算必然需要从一个分区发送到另一个分区，最小化网络通信是实现高效图算法的关键。

GraphX 实现了“顶点切割”方法，这确保了边被分配给分区，并且顶点可以跨分区共享。这似乎只是将网络通信移到了图的不同部分——从边到顶点——但 GraphX 提供了许多策略，允许我们确保顶点以最适合我们希望应用的算法的方式进行分区。

blinking 提供了`partition-by`函数，它接受一个表示策略的关键字来划分图。可接受的值有`:edge-partition-1d`、`:edge-partition-2d`、`:canonical-random-vertex-cut`和`:random-vertex-cut`。

您对使用哪种分区策略的选择是基于图的结构和您将应用的算法。`:edge-partition-1d`策略确保具有相同源的所有边被一起分割。这意味着按源聚合边的操作(例如，对传出边进行计数)在一台单独的机器上拥有它们需要的所有数据。虽然这样可以最大限度地减少网络流量，但这也意味着幂律图中的一些分区可能会接收到大量的边。

`:random-vertex-cut`分割策略基于源顶点和目的顶点将一个图分割成多个边。这有助于以运行时性能为代价创建更平衡的分区，因为单个源或目标节点可能分布在集群中的许多机器上。即使是连接同一对节点的边也可能分布在两台机器上，这取决于边的方向。不管方向如何，我们都可以使用`:canonical-random-vertex-cut`对边进行分组。

最后，`:edge-partition-2d`使用一种更加复杂的分割策略，通过源顶点和目的顶点来分割边。与`:canonical-random-vertex-cut`一样，共享源和目的地的节点将被一起分区。此外，该策略对每个节点将跨越的分区数量设置了上限。在算法聚集关于共享源和目的地节点的边的信息的情况下，并且还独立地通过源或目的地聚集信息，这可能是使用的最有效的策略。

## 运行内置的三角形计数算法

我们已经看到了如何在规范方向上加载我们的边。下一步是选择分区策略，我们将选择`:random-vertex-cut`。以下示例显示了加载和划分图形、执行三角形计数以及使用 Incanter 可视化结果的完整序列:

```
(defn ex-8-24 []

  (spark/with-context sc (-> (g/conf)

                             (conf/master "local")

                             (conf/app-name "ch8"))

    (let [triangles (->> (load-canonical-edgelist

                          sc "data/twitter_combined.txt")

                         (g/partition-by :random-vertex-cut)

                         (ga/triangle-count)

                         (g/vertices)

                         (to-java-pair-rdd)

                         (spark/values)

                         (spark/collect)

                         (into []))

          data (frequencies triangles)]

      (-> (c/scatter-plot (keys data) (vals data))

          (c/set-axis :x (c/log-axis :label "# Triangles"))

          (c/set-axis :y (c/log-axis :label "# Vertices"))

          (i/view)))))
```

`triangle-count`的输出是一个新图形，其中每个顶点的属性是该顶点参与的三角形数量的计数。顶点的 ID 不变。我们只对三角形计数本身感兴趣——返回图形的顶点属性——所以我们从顶点中提取`values`。`spark/collect`函数将所有的值收集到一个 Clojure 序列中，所以这不是我们想要在一个非常大的图上做的事情。

收集了三角形的计数后，我们计算每个计数的频率，并使用 Incanter 在双对数散点图上可视化结果。输出如下所示:

![Running the built-in triangle counting algorithm](graphics/7180OS_08_350.jpg)

我们再一次看到幂律分布的效果。几个节点连接了大量的三角形。

运行一个内置算法已经让我们看到了如何创建和操作一个图形，但是 GraphX 的真正强大之处在于它让我们能够为自己高效地表达这种计算。在下一节中，我们将看到如何使用低级函数完成三角形计数。

## 用金光闪闪实现三角形计数

有许多方法来计算一个图中三角形的数量，但是 GraphX 以下面的方式实现了这个算法:

1.  计算每个顶点的邻居集。
2.  对于每条边，计算两端顶点的交点。
3.  将交点的计数发送给两个顶点。
4.  计算每个顶点的总数。
5.  除以二，因为每个三角形都要数两次。

下面的图显示了仅由一个三角形组成的简单图形上的步骤:

![Implement triangle counting with Glittering](graphics/7180OS_08_355.jpg)

该算法忽略边的方向，并且如前所述，期望任意两个节点之间的边是不同的。因此，我们将继续使用我们在上一节中定义的规范边来处理分区图。

执行三角形计数的完整代码不是很长，所以接下来会完整介绍。它代表了我们将在本章剩余部分讨论的大多数算法，因此，一旦我们展示了代码，我们将一次一个地完成每个步骤:

```
(defn triangle-m [{:keys [src-id src-attr dst-id dst-attr]}]

  (let [c (count (set/intersection src-attr dst-attr))]

    {:src c :dst c}))

(defn triangle-count [graph]

  (let [graph (->> (g/partition-by :random-vertex-cut graph)

                   (g/group-edges (fn [a b] a)))

        adjacent (->> (g/collect-neighbor-ids :either graph)

                      (to-java-pair-rdd)

                      (spark/map-values set))

        graph (g/outer-join-vertices

               (fn [vid attr adj] adj) adjacent graph)

        counters (g/aggregate-messages triangle-m + graph)]

    (->> (g/outer-join-vertices (fn  [vid vattr counter]

                                  (/ counter 2))

                                counters graph)

         (g/vertices))))
```

为了使算法工作，输入图需要有明显的边。一旦规范图被分割，我们通过在图上调用`(g/group-edges (fn [a b] a) graph)`来确保边是不同的。`group-edges`函数类似于`reduce`，它减少了共享相同开始和结束节点的边的集合。我们只是选择保持第一个优势。边的属性不影响三角形的计数，只影响三角形的存在。

### 第一步–收集邻居 id

在第一步，我们想要收集每个顶点的邻居 id。闪烁使该操作作为`g/collect-neighbor-ids`功能可用。我们可以选择分别用`:in`或`:out`只收集输入或输出的边，或者用`:either`只收集任一方向的边。

`g/collect-neighbor-ids`函数返回一对 RDD，其键是所讨论的顶点 ID，值是邻居 ID 序列。像上一章的 MLlib 一样，RDD 不是 Sparkling 期望的`JavaRDD`类，所以我们必须相应地转换它。一旦我们这样做了，将邻居 id 序列转换成一个集合就像对 RDD 对中的每个值调用`set`一样简单。第一步的结果是包含节点 ID 和邻居 ID 集的 PairRDD，因此我们将图展平为存储为`adjacent`值的一系列集。

### 注意

这种图形表示是一系列相连的顶点，通常称为邻接表。与边列表一起，它是表示图形的两种主要方法之一。

第二步要求我们给图的边赋值，所以我们希望保留图的结构。我们使用`g/outer-join-vertices`函数来组合`adjacent`和原始图形。给定一个图和一对由顶点 ID 索引的 RDD，`outer-join-vertices`允许我们提供一个函数，它的返回值将被指定为图中每个顶点的属性。该函数接收三个参数:顶点 ID、当前顶点属性以及与外部连接到图的 RDD 对中的顶点 ID 相关联的值。在前面的代码中，我们返回一组相邻的顶点作为新的顶点属性。

### 第二步、第三步和第四步——汇总信息

接下来的几个步骤由一个函数`g/aggregate-messages`处理，它是 GraphX 的图形并行实现的主要函数。它需要两个参数:一个消息发送函数和一个消息组合函数。在它们一起工作的方式中，这两个函数类似于 map 和 reduce，适用于图形并行计算的以顶点为中心的视图。

![Steps two, three, and four – aggregate messages](graphics/7180OS_08_360.jpg)

send message 函数负责沿边缘发送消息。该函数为每条边调用一次，但它可以向源顶点或目标顶点发送多条消息。该函数的输入是一个三元组(有两个相连顶点的边)，它用一系列消息来响应。消息是一个键/值对，其中键是`:src`或`:dst`之一，值是要发送的消息。在前面的例子中，这是用`:src`和`:dst`键实现的地图。

合并消息功能负责组合特定顶点的所有消息。在前面的代码中，每条消息都是一个数字，因此 merge 函数有一个要合并的数字序列。我们可以简单地通过将`+`作为合并函数来实现这一点。

### 第五步——划分计数

三角形计数的最后一步是将我们为每个顶点 ID 计算的计数除以 2，因为每个三角形计数两次。在前面的代码中，我们这样做的同时使用`outer-join-vertices`用三角形计数更新顶点属性。

## 运行自定义三角形计数算法

有了前面的所有步骤，我们就可以使用闪闪发光来运行我们的自定义三角形计数算法了。让我们首先在本章开始的一个 Twitter 关注图上运行它,看看我们得到的结果:

```
(defn ex-8-25 []

  (spark/with-context sc (-> (g/conf)

                             (conf/master "local")

                             (conf/app-name "triangle-count"))

    (->> (load-canonical-edgelist

          sc "data/twitter/396721965.edges")

         (triangle-count)

         (spark/collect)

         (into []))))

;; #sparkling/tuple [21938120 1] #sparkling/tuple [31477674 3]

;; #sparkling/tuple [32122637 0] ...]
```

结果是一系列元组，以顶点 ID 作为键，以连接的三角形数量作为值。

如果我们想知道整个 Twitter 数据集中有多少个三角形，我们可以从结果图中提取值(值)，将它们相加，然后除以 3。让我们现在就开始吧:

```
(defn ex-8-26 []

  (spark/with-context sc (-> (g/conf)

                             (conf/master "local")

                             (conf/app-name "triangle-count"))

    (let [triangles (->> (load-canonical-edgelist

                          sc "data/twitter_combined.txt")

                         (triangle-count)

                         (to-java-pair-rdd)

                         (spark/values)

                         (spark/reduce +))]

      (/ triangles 3))))
```

这个算法应该不会运行太久。我们的自定义三角形计数代码将具有足够的性能，可以在整个合并的 Twitter 数据集上运行。

如果`aggregate-messages` 就像 MapReduce 编程的一个步骤，我们通常会以迭代的方式结束。许多图形算法将会趋向收敛。事实上，GraphX 提供了一个替代函数，我们将能够在这种情况下使用这个函数，称为 **Pregel API** 。我们将在下一节详细讨论它。

## Pregel API

Pregel API 是 GraphX 的主要抽象，用于表达定制、迭代、图形并行计算。它是以谷歌运行大规模图形处理的内部系统命名的，他们在 2010 年发表了一篇论文。你可能还记得，柯尼斯堡也是在这条河上建立的。

谷歌的 Pregel 论文推广了图形并行计算的“像顶点一样思考”方法。Pregel 的模型基本上使用了组织成一系列步骤的图中顶点之间的消息传递，这些步骤被称为**超级步骤**。在每个超级步骤的开始，Pregel 在每个顶点上运行一个用户指定的函数，传递在前一个超级步骤中发送给它的所有消息。顶点函数有机会处理这些消息中的每一个，并依次向其他顶点发送消息。顶点也可以“投票停止”计算，当所有顶点都投票停止时，计算将终止。

由 blinking 实现的`pregel`函数实现了一种非常类似的图形处理方法。主要区别在于顶点不会投票决定停止:当不再有消息被发送时，或者当超过指定的迭代次数时，计算终止。

上一节中介绍的 aggregate-messages 函数使用两个共生函数来表达它的意图，而`pregel`函数使用三个相关的函数，迭代地应用，来实现图算法。前两个是我们之前遇到的消息函数和消息组合器，第三个是“顶点程序”:为每个顶点处理传入消息的函数。这个函数的返回值被指定为下一个超步骤的顶点属性。

让我们通过实现一个我们已经在本章中讨论过的算法来看看`pregel`函数在实践中是如何工作的:连通分量。

## 使用 Pregel API 连接组件

连通的分量可以表示为的一种迭代算法，如下所示:

1.  将所有顶点属性初始化为顶点 ID。
2.  对于每条边，确定源顶点属性或目标顶点属性是否最低。
3.  沿着每条边，将两个属性中较低的一个发送到对面的顶点。
4.  对于每个顶点，将属性更新为最低的传入消息。
5.  重复此操作，直到节点属性不再改变。

和以前一样，我们可以在一个简单的四节点图上可视化这个过程。

![Connected components with the Pregel API](graphics/7180OS_08_370.jpg)

我们可以看到，在六个步骤中，图如何收敛到一种状态，其中所有节点都以最小的连通顶点 ID 作为它们的属性。由于消息只沿着边传播，任何不共享任何边的节点将收敛到不同的值。因此，一旦算法收敛，共享相同属性的所有顶点将成为同一连通分量的一部分。让我们先看看完成的代码，然后我们将立即一步一步地浏览代码:

```
(defn connected-component-m [{:keys [src-attr dst-attr]}]

  (cond

    (< src-attr dst-attr) {:dst src-attr}

    (> src-attr dst-attr) {:src dst-attr}))

(defn connected-components [graph]

  (->> (glitter/map-vertices (fn [id attr] id) graph)

       (p/pregel {:vertex-fn (fn [id attr msg]

                               (min attr msg))

                  :message-fn connected-component-m

                  :combiner min})))
```

使用`g/pregel` 函数是实现迭代连通分量算法所需要的全部。

### 第一步——绘制顶点

将所有的顶点属性初始化为顶点 ID 是在`pregel` 函数之外由`g/map-vertices`函数处理的。我们传递给它两个参数的函数，顶点 ID 和顶点属性，它返回顶点 ID 作为顶点属性。

### 第二步和第三步——信息功能

blinking 的 `pregel`函数期望接收一个指定至少三个函数的映射:一个消息函数、一个组合器函数和一个顶点函数。我们稍后将更详细地讨论最后一个问题。然而，其中的第一个负责第二步和第三步:对于每条边，确定哪个连接的节点具有较低的属性，并将该值发送给相对的节点。

我们在本章前面介绍了消息函数和自定义三角形计数函数。该函数接收作为映射的边，并返回描述要发送的消息的映射。这一次，只发送一条消息:如果源属性较低，则发送给目的节点的`src-attr`属性；如果目的属性较低，则发送给源节点的`dst-attr`属性。

combiner 函数聚合一个顶点的所有传入消息。连接组件的组合函数就是`min`函数:我们只对发送给每个顶点的最小值感兴趣。

### 第四步——更新属性

在第四步中，每个顶点更新其属性，以等于其当前属性和所有接收到的消息的值中的最低值。如果它的任何传入消息低于其当前属性，它将更新其属性以等于最低值。这一步由顶点程序处理，这是 Pregel 的三个共生功能中的第三个。

连通组件的 vertex 函数也很简单:对于每个顶点，我们希望返回当前顶点属性和最低传入消息中的较低者(由上一步中的 combiner 函数确定)。返回值将被用作下一个超步骤的顶点属性。

### 第五步——迭代收敛

第五步是我们用`pregel`函数“免费”得到的东西。我们没有指定最大迭代次数，所以刚才描述的三个函数将重复运行，直到不再有消息要发送。出于这个原因(以及效率的原因)，我们的消息函数只在需要时发送消息是很重要的。这就是为什么我们在前面的消息函数中的`cond`值确保了如果源和目的属性已经相等，我们就不发送消息。

## 运行连接的组件

在实现了之前连接的组件函数后，我们在下面的例子中使用它:

```
 (defn ex-8-27 []

  (spark/with-context sc (-> (g/conf)

                             (conf/master "local")

                             (conf/app-name "cljds.ch8"))

    (->> (load-edgelist sc "data/twitter/396721965.edges")

         (connected-components)

         (g/vertices)

         (spark/collect)

         (into []))))

;; [#sparkling/tuple [163629705 21938120] #sparkling/tuple

;; [88491375 21938120] #sparkling/tuple [142960504 21938120] ...
```

通过将图转换回 RDD，我们可以以数据并行的方式进行分析。例如，我们可以通过计算共享相同属性的节点数量来确定所有连接组件的大小。

## 计算最大连通分量的大小

在下一个示例中，我们将使用相同连通分量函数，但是计算每个连通分量的大小。我们将通过 Sparkling 的`count-by-value`功能来实现这一点:

```
(defn ex-8-28 []

  (spark/with-context sc (-> (g/conf)

                             (conf/master "local")

                             (conf/app-name "ch8"))

    (->> (load-canonical-edgelist

          sc "data/twitter_combined.txt")

         (connected-components)

         (g/vertices)

         (to-java-pair-rdd)

         (spark/values)

         (spark/count-by-value)

         (into []))))

;; [[12 81306]]
```

前面例子中的代码是使用 GraphX 和 blinking 的最大好处之一。我们可以将平面数据表示为边列表，将其转换为图形结构以执行迭代图形算法，然后将结果转换回平面结构以计算聚合:所有这些都在单个管道中完成。

该示例的响应表明，我们所有的顶点(81，306 个)都在一个大的连通分量中。这表明图中的每个人都与其他人有联系，要么是朋友，要么是追随者。

虽然知道没有孤立的用户组是很有用的，但是理解用户在连接的组件中是如何组织的会更有趣。如果某些用户群倾向于更紧密地相互联系，那么我们可以认为这些用户形成了一个社区。

## 利用标签传播检测社区

社区可以被非正式地定义为一组顶点，这些顶点彼此之间的连接比它们与社区之外的顶点的连接更强。

### 注意

如果每个顶点都与社区中的其他顶点相连，那么我们称这个社区为团。

因此，社区在图中对应于增加的密度。我们可以把 Twitter 网络中的社区想象成一群追随者，他们倾向于追随彼此的追随者。较小的社区可能对应于友谊组，而较大的社区更可能对应于共同的兴趣组。

社区检测是一种通用技术，有许多算法能够识别社区。根据算法的不同，社区可能会重叠，以便用户可以与多个社区相关联。我们接下来要看的算法是称为**标签传播**，它将每个用户分配到最多一个社区。

标签传播可以通过以下步骤迭代实现:

1.  将所有顶点属性初始化为等于顶点 ID。
2.  对于每条边，将源和目标属性发送到相对的节点。
3.  对于每个顶点，计算每个引入属性的频率。
4.  对于每个顶点，将属性更新为最常见的传入属性。
5.  重复直到收敛或达到最大迭代次数。

接下来在一个有两个社区的图上显示了算法的步骤。每个社区也是一个小团体，但这并不是标签传播正常工作的必要条件。

![Detecting communities with label propagation](graphics/7180OS_08_380.jpg)

使用`pregel`函数进行标签传播的代码如下:

```
(defn label-propagation-v [id attr msg]

  (key (apply max-key val msg)))

(defn label-propagation-m [{:keys [src-attr dst-attr]}]

  {:src {dst-attr 1}

   :dst {src-attr 1}})

(defn label-propagation [graph]

  (->> (glitter/map-vertices (fn [vid attr] vid) graph)

       (p/pregel {:message-fn label-propagation-m

                  :combiner (partial merge-with +)

                  :vertex-fn label-propagation-v

                  :max-iterations 10})))
```

像以前一样，让我们一步一步地走过代码。

### 第一步——绘制顶点

标签传播的第一步与我们之前定义的连通分量算法的第一步相同。我们使用`g/map-vertices`函数来更新每个顶点属性，使其等于顶点 ID。

### 第二步——发送顶点属性

在第二步中，我们沿着每条边发送相反的顶点属性。第三步将要求我们计算最频繁出现的传入属性，因此每条消息都是属性值“1”的映射。

### 第三步——合计价值

组合器函数接收一个顶点的所有消息，并产生一个聚合值。由于消息是属性值到数字“1”的映射，我们可以使用 Clojure 的`merge-with`函数将消息与`+`组合在一起。结果将是属性到频率的映射。

### 第四步——顶点函数

第四步是由顶点函数处理的。给定所有传入属性的频率计数，我们想要挑选最频繁的一个。`(apply max-key val msg)`表达式从映射中返回与最大值(最高频率)相关的键/值对。我们将这个值传递给`key`以返回与这个值相关的属性。

### 第五步——设置最大迭代次数

与连通分量算法一样，当有消息要发送时，迭代是`pregel`函数的默认行为。与连通分量算法不同，我们在前面的`message`函数中没有条件子句。为了避免无限循环，我们将选项映射中 10 的`:max-iterations`传递给`pregel`。

## 运行标签传播

下面的示例利用前面的代码对整个 Twitter 数据集执行标签传播。我们用 Sparkling 的`count-by-value`函数计算每个社区的大小，并计算计数的频率。然后使用 Incanter 将生成的直方图显示在双对数散点图上，以显示群落大小的分布:

```
 (defn ex-8-29 []

  (spark/with-context sc (-> (g/conf)

                             (conf/master "local")

                             (conf/app-name "ch8"))

    (let [xs (->> (load-canonical-edgelist

                   sc "data/twitter_combined.txt")

                  (label-propagation)

                  (g/vertices)

                  (to-java-pair-rdd)

                  (spark/values)

                  (spark/count-by-value)

                  (vals)

                  (frequencies))]

      (-> (c/scatter-plot (keys xs) (vals xs))

          (c/set-axis :x (c/log-axis :label "Community Size"))

          (c/set-axis :y (c/log-axis :label "# Communities"))

          (i/view)))))
```

该代码生成如下图表:

![Running label propagation](graphics/7180OS_08_390.jpg)

正如我们可能已经预料到的，社区规模的分布也是一个幂律:小社区比大社区更常见。最大的社区大约有 10，000 名成员，而最小的社区只有一名成员。我们开始梳理 Twitter 图的结构:我们知道用户是如何分布到各个群体中的，我们可以假设更大的社区可能代表由共同兴趣组成的群体。

在这一章的最后几页，让我们看看我们是否能建立起将这些最大的群体联合起来的东西。有很多方法可以解决这个问题。如果我们可以访问推文本身，我们就可以进行文本分析，就像我们在第六章第一章第一章和第三章 T2 聚类中所做的那样，看看这些群体中是否有更频繁使用的特定单词或特定语言。

这一章是关于网络分析的，所以让我们使用图表的结构来识别每个社区中最有影响力的账户。十大最有影响力的账户列表可能会给我们一些提示，告诉我们是什么引起了他们追随者的共鸣。

## 使用 PageRank 衡量社区影响力

一种简单的测量社区影响力的方法是计算一个特定顶点有多少条边。在 Twitter 上，这相当于一个拥有大量追随者的账户。这样的账户代表了网络中最“受欢迎”的账户。

对传入边进行计数是测量影响的一种简单方法，因为它将所有传入边视为相等。在社交图中，情况往往并非如此，因为某些关注者本身就是受欢迎的账户，因此他们的关注比没有关注者的关注者更重要。

### 注意

PageRank 是由拉里·佩奇和谢尔盖·布林于 1996 年在斯坦福大学开发的，作为最终成为谷歌的研究项目的一部分。PageRank 通过计算一个页面链接的数量和质量来粗略估计网站的重要性。

因此，一个账户的重要性基于两点:关注者的数量和每个关注者的重要性。每个关注者的重要性也是以同样的方式计算的。因此，PageRank 有一个递归定义:似乎我们必须先计算关注者的重要性，然后才能计算帐户的重要性，以此类推。

## 流量公式

幸运的是，可以迭代计算 PageRank。首先，我们将所有顶点初始化为具有相同的权重。这可能是 1 的重量。在这种情况下，所有权重的总和等于顶点数 *N* 。或者，可以是一个![The flow formulation](graphics/7180OS_08_02.jpg)的权重；在这种情况下，所有权重的总和将等于 1。虽然它没有改变基本算法，但后者通常是首选，因为这意味着 PageRank 的结果可以被解释为概率。我们将实现前者。

这个初始权重就是算法开始时每个账户的 PageRank *r* 。在第一次迭代中，每个账户向它所关注的所有页面发送相同比例的排名。在这个步骤之后，账户 *j* 和 *r* j 的等级被定义为所有进入等级的总和。我们可以用下面的等式来表示:

![The flow formulation](graphics/7180OS_08_03.jpg)

这里，*r*I 是跟随者的等级， *ni* 是他们跟随者的账号数。帐户 *j* 从他们所有的追随者那里获得一定比例的等级![The flow formulation](graphics/7180OS_08_04.jpg)。

如果这就是 PageRank 的全部内容，那么没有追随者的帐户将已经没有排名，并且在每次迭代中，最受欢迎的页面将变得越来越受欢迎。因此，PageRank 还包括阻尼因子。这个因素确保了即使是最不流行的账户也会保留一些权重，并且算法能够收敛到稳定的值。这可以通过修改前面的等式来表示:

![The flow formulation](graphics/7180OS_08_05.jpg)

这里， *d* 是阻尼因子。常用的阻尼系数是 85%。

下图显示了一组 11 个帐户的阻尼系数的影响:

![The flow formulation](graphics/7180OS_08_400.jpg)

如果没有阻尼因素，所有的重量最终都会累积在账户 **A** 、 **B** 和 **C** 上。有了阻尼因子，即使是没有追随者的小账户也继续获得总权重的一小部分。即使账户 **E** 有更多的关注者，但账户 **C** 的排名更高，因为它后面是排名高的账户。

### 用金光闪闪实现 PageRank

我们在下面的示例代码中用`pregel`函数实现 PageRank。虽然我们将使用几个新的闪闪发光的函数，但是代码的结构现在对你应该很熟悉了:

```
(def damping-factor 0.85)

(defn page-rank-v [id prev msgsum]

  (let [[rank delta] prev

        new-rank (+ rank (* damping-factor msgsum))]

    [new-rank (- new-rank rank)]))

(defn page-rank-m [{:keys [src-attr attr]}]

  (let [delta (second src-attr)]

    (when (> delta 0.1)

      {:dst (* delta attr)})))

(defn page-rank [graph]

  (->> (glitter/outer-join-vertices (fn [id attr deg] (or deg 0))

                                    (glitter/out-degrees graph)

                                    graph)

       (glitter/map-triplets (fn [edge]

                               (/ 1.0 (glitter/src-attr edge))))

       (glitter/map-vertices (fn [id attr] (vector 0 0)))

       (p/pregel {:initial-message (/ (- 1 damping-factor)

                                      damping-factor)

                  :direction :out

                  :vertex-fn page-rank-v

                  :message-fn page-rank-m

                  :combiner +

                  :max-iterations 20})

       (glitter/map-vertices (fn [id attr] (first attr)))))
```

我们以通常的方式开始，使用`outer-join-vertices`将每个节点的`out-degrees`连接到自身。在这一步之后，每个节点的属性等于它的输出链接数。然后，我们使用`map-triplets`将所有的`edge`属性设置为它们的源顶点属性的逆。最终结果是每个顶点的等级在它的所有输出边中平均分配。

在这个初始化步骤之后，我们使用`map-edges`将每个节点的属性设置为默认值:两个零的向量。向量包含当前页面排名以及本次迭代的排名和前一次迭代的排名之间的差异。基于差异的大小，我们的`message`函数能够决定是否继续迭代。

### 按最高影响力排序

在我们对通过标签传播识别的社区运行 PageRank 之前，我们将实现一个效用函数，以降序列出排名前 10 的帐户。`top-n-by-pagerank`功能将允许我们只显示排名最高的账户:

```
(defn top-n-by-pagerank [n graph]

  (->> (page-rank graph)

       (g/vertices)

       (to-java-pair-rdd)

       (spark/map-to-pair

        (s-de/key-value-fn

         (fn [k v]

           (spark/tuple v k))))

       (spark/sort-by-key false)

       (spark/take n)

       (into [])))
```

同样，我们可以轻松地在数据的图形和表格表示之间进行转换，以实现这种数据操作，这是同时使用 blinking 和 Sparkling 进行图形分析的主要好处之一。

最后，有一个函数返回出现在第一行中最频繁的节点属性也很有用:

```
(defn most-frequent-attributes [graph]

  (->> (g/vertices graph)

       (to-java-pair-rdd)

       (spark/values)

       (spark/count-by-value)

       (sort-by second >)

       (map first)))
```

给定标签传播的输出，该函数将按照大小降序的顺序返回社区 id。

## 运行 PageRank 以确定社区影响者

最后，我们可以将所有早期的代码集合在一起，以识别标签传播所识别的社区的最有共鸣的兴趣。与目前为止我们用 blinking 实现的其他算法不同，我们是在 follow 方向上发送消息，而不是在规范方向上。因此，在下一个示例中，我们将使用`load-edgelist`来加载图形，这保持了跟随方向:

```
 (defn ex-8-30 []

  (spark/with-context sc (-> (g/conf)

                             (conf/master "local")

                             (conf/app-name "ch8"))

    (let [communities (->> (load-edgelist

                            sc "data/twitter_combined.txt")

                           (label-propagation))

          by-popularity (most-frequent-attributes 2 communities)]

      (doseq [community (take 10 by-popularity)]

        (println

         (pagerank-for-community community communities))))))
```

运行此代码需要一些时间，但最终会返回十个最流行的社区图中最重要的节点序列，如下例所示:

```
;;[#sparkling/tuple [132.8254006818738 115485051]

;;#sparkling/tuple [62.13049747055527 62581962]

;;#sparkling/tuple [49.80716333905785 65357070]

;;#sparkling/tuple [46.248688749879875 90420314] ...]
```

每个元组的第一个元素是我们为顶点计算的 PageRank，每个元组的第二个元素是节点 ID。Twitter 顶点 id 对应于 Twitter 自己的 id。账户没有被匿名，所以我们可以查找他们对应的 Twitter 账户。

### 注意

在写作的时候，我们可以通过 ID 使用在`https://twitter.com/intent/user?user_id={$USER_ID}`可用的 Twitter 的 Intent API 来查找 Twitter 账户。用`{$USER_ID}`替换 Twitter 的数字 ID 将返回基本的个人资料信息。

community one 中页面排名最高的帐户是美国漫画和脱口秀主持人柯南·奥布莱恩与巴拉克·奥巴马、菲丽西亚·戴和尼尔·帕特里克·哈里斯。我们可以大致把这些人归类为美国名人。在 Twitter 上，最大的社区聚集在一些拥有最广泛普遍吸引力的最大账户周围，这并不完全令人惊讶。

在列表中向下移动，第二大社区的特色是其最有影响力的乐队帕拉摩尔、其成员海莉和泰勒，以及 Lady Gaga。这个社区显然有一套非常具体的音乐兴趣。

社区三和社区四似乎都有强烈的游戏偏好，将 X-Box、PlayStation、Steam 和 Markus Persson(《《我的世界》》的创作者)作为他们的主要影响者。

请记住，我们已经确定，整个图是一个连通组件的一部分，所以我们没有看到不相交的用户集。结合使用标签传播和 PageRank，我们能够确定具有相关兴趣的 Twitter 用户群。



# 总结

在这一章中，我们学习了图形:一种对各种各样的现象建模的有用的抽象。本章开始时，我们使用 Clojure library Loom 来可视化和遍历 Twitter 追随者的小图。我们学习了两种不同的图遍历方法，深度优先和宽度优先搜索，以及改变边权重对 Dijkstra 算法和 Prim 算法发现的路径的影响。我们还观察了整个图的密度，并绘制了度分布，以观察随机图和无标度图之间的差异。

我们引入了 GraphX 和 Clojure 库 blinking，作为一种使用 Spark 以可伸缩的方式处理大型图形的方法。除了提供几个内置的图形算法，blinking 还公开了 GraphX 的 Pregel API:一组三个共生函数，以顶点为中心的方式表达图形算法。我们展示了这种替代计算模型可以用于表达三角形计数、连接组件、标签传播和最终的 PageRank 算法，并将我们的标签传播和 PageRank 步骤链接在一起，以确定一组 Twitter 社区的顶级影响者。

这是我们使用并行计算技术的最后一章。在下一章，我们将关注本地数据处理，但是我们将继续递归分析的思路。我们将介绍处理时间序列数据(按时间排序的观察序列)的方法，并演示如何使用递归函数进行预测。