<title>Chapter 6: Integrating Comet into DevOps</title> <link href="css/style-JRserifv5.css" rel="stylesheet" type="text/css">

# *第六章*:将慧星集成到 DevOps 中

模型**部署**和**监控**是数据科学项目生命周期的最后两步。前者允许您将项目从测试阶段转移到生产阶段，而后者为您提供了所有的策略和工具，以确保您的项目运行时没有错误、安全并得到更新。

您可以通过采用一种称为 **DevOps** 的特殊理念来实现模型部署。devo PS(**开发和运营**的缩写)是一组最佳实践，允许软件开发人员和运营团队在整个软件项目生命周期中协作，通过自动化技术提高软件开发、速度和效率。

正如您已经从前面的章节中了解到的，Comet 允许您跟踪和监控所有的实验，因此您可以在监控阶段使用它。因此，您可以轻松地将 Comet 集成到 DevOps 策略中，以便在生产阶段监控您的模型。

在本章中，您将回顾 DevOps 背后的基本概念，包括它们的原则和最佳实践。另外，你会复习一下 **MLOps** 的概念，也就是 DevOps 应用于**机器学习** ( **ML** )。然后，您将学习如何通过 REST API 的概念将 Comet 集成到 DevOps/MLOps 理念中。接下来，您将分析 Docker 和 Kubernetes，这是用于实现 DevOps 的两个最常见的工具和框架。最后，您将实现两个实际的例子，一个在 Docker 中，另一个在 Kubernetes 中，两者都集成了 Comet。

本章组织如下:

*   探索 DevOps 和 MLOps 原则和最佳实践
*   Comet 和 DevOps/MLOps 的结合
*   实现 Docker
*   实施 Kubernetes

在进行第一步之前，让我们安装运行本章中实现的代码所需的软件。

# 技术要求

本章中描述的示例使用了以下软件/工具:

*   计算机编程语言
*   码头工人
*   库伯内特斯

## Python

我们将使用 Python 3.8。你可以从官网([https://www.python.org/downloads/](https://www.python.org/downloads/)下载，选择版本 *3.8* 。

本章中描述的示例使用了以下 Python 包:

*   `pandas 1.3.4`
*   `scikit-learn 1.0`
*   `comet-ml 3.23.0`
*   `requests 2.27.1`
*   `Flask 2.1.1`

我们已经在 [*第一章*](B17530_01_ePub.xhtml#_idTextAnchor015) 、*慧星概述*中描述了前两个包以及如何安装它们，所以关于安装的更多细节请参考后面的内容。

`requests`是一个用于简单管理 HTTP 请求的 Python 包。您可以通过运行以下命令来安装它:

```
pip install requests
```

更多细节，你可以阅读`Requests`官方文档，可从以下链接获得:【https://docs.python-requests.org/en/latest/。

`Flask`是用于创建 HTTP 服务器的 Python 包。您可以通过运行以下命令来安装它:

```
pip install Flask 
```

更多细节，你可以阅读`Flask`官方文档，可从以下链接获得:【https://flask.palletsprojects.com/en/2.1.x/】T2。

## 码头工人

Docker 是一个用于构建和运行应用程序的开放平台。在本章中，我们将使用 Docker 桌面。你可以从 Docker 的官方网站下载 Docker 桌面，网址是:【https://docs.docker.com/get-docker/】T4。根据您的操作系统，您应该下载不同的文件，但程序总是相同的:您下载软件，安装它，然后运行它。一旦安装完毕，您就可以像平常运行其他应用程序一样运行它了。

如果你无法安装 Docker Desktop，你可以遵循 Docker 官方文档中描述的替代程序，可从以下链接获得:[https://docs.docker.com/desktop/](https://docs.docker.com/desktop/)、[https://docs.docker.com/engine/install/](https://docs.docker.com/engine/install/)和[https://docs.docker.com/desktop/windows/troubleshoot/](https://docs.docker.com/desktop/windows/troubleshoot/)。

## Kubernetes

Kubernetes 是一个开源的平台，用于管理容器化的应用。它的官方文档可以在以下链接获得:【https://kubernetes.io/docs/home/。

在本章中，我们将使用 Docker Desktop 提供的 Kubernetes 的本地版本。

一旦安装了 Docker Desktop，就可以启用 Kubernetes，如下所示:

1.  启动 Docker 桌面并访问其主仪表板。
2.  选择位于仪表板右上方的**设置**按钮。
3.  选择**立方** | **启用立方** | **应用&重启**。

现在，您应该能够在本地计算机上运行 Kubernetes 了。

现在，您已经安装了本章所需的所有软件，我们可以进入下一步，探索 DevOps 和 MLOps 原则和最佳实践。

# 探索 DevOps 和 MLOps 原则和最佳实践

将软件从测试转移到生产的传统方法包括两个独立的步骤:

1.  **开发**–开发人员实现他们的代码，并在他们的本地环境和条件下进行测试。
2.  **操作**–当代码准备好了，开发人员将代码发送给操作团队，他们负责在生产机器上安装和维护代码。

这种方法需要两个团队——开发人员和运营团队——付出巨大的努力，因为一方面，代码中的一点点变化需要在生产机器中进行新的安装和配置。另一方面，当运营团队发现代码中的异常时，他们应该与开发团队沟通以运行新的测试，然后这个过程可能会变得非常慢。

如果任务数量很少，手动过程可能是可以接受的，但是如果有数百万个任务，这种手动方法就不可行了。

这就是 DevOps 的用武之地。DevOps 是软件开发( **Dev** )和 IT 运营( **Ops** )的缩写。DevOps 是一种心态，一种方法，它试图定义一套最佳实践的,使开发和运营团队一起工作，只需一点努力，自动地和快速地，同时保持软件交付的高质量并保证软件的可伸缩性。

在 ML 环境中，DevOps 成为 MLOps，其目标是在生产中部署和维护 ML 模型。

在本节中，您将回顾以下概念:

*   DevOps 生命周期
*   从 DevOps 迁移到 MLOps

让我们从第一个开始，DevOps 生命周期。

## devo PS 生命周期

DevOps 生命周期包括八个阶段，如下图所示:

![Figure 6.1 – The DevOps life cycle

](image/B17530_06_001.jpg)

图 6.1–devo PS 生命周期

DevOps 生命周期将这八个阶段实现为一个连续的循环，其中每次迭代都通过添加新功能或解决一些问题来改进前一次迭代。八个阶段如下:

1.  **计划**–描述要做的工作
2.  **编码**–编写完成工作的代码
3.  **构建**–将代码编译成可运行的软件
4.  **测试**–通过运行一些测试来验证软件的正确性
5.  **发布**–将可运行的软件发布到一个共享且集中的存储库中
6.  **部署**–让用户可以使用软件
7.  **运营**–管理基础设施和软件平台
8.  **监控**–控制基础设施和软件状态

前四步(从计划到测试)指的是**开发**部分，后四步指的是**运营**部分(从发布到监控)。您已经在前面的章节中学习了如何实现开发部分。在本章中，您将学习如何实现部署、操作和监控阶段，而在 [*第 7 章*](B17530_07_ePub.xhtml#_idTextAnchor147) 、*用 Comet* 扩展 GitLab DevOps 平台中，您将学习关于发布。我们决定在单独的章节中讨论发布阶段，因为它构成了开发和运营部分之间的联系，需要数据科学家的特别关注。

通常，部署阶段包括将生成的软件封装到一个映像中，您可以在一个独立的容器中运行该映像。在本章中，您将使用 Docker 作为平台来构建图像和容器。操作阶段需要一个平台来协调所有可能的容器。在本章中，您将使用 Kubernetes 作为编排平台。监控阶段包括跟踪关键问题和类似方面的所有工具。在本章中，您将使用 Comet 来跟踪与 ML 模型相关的问题。

现在，您已经了解了 DevOps 生命周期，我们可以进入下一步，从 DevOps 过渡到 MLOps。

## 从 DevOps 迁移到 MLOps

**机器学习操作** ( **MLOps** )是 DevOps 在 ML 领域的一个专业化。因此，当 DevOps 是一个用于所有软件开发最佳实践的通用名称时，MLOps 特别关注 ML。

您可以认为 MLOps 和 DevOps 的生命周期非常相似。然而，MLOps 生命周期还包括两个额外的阶段:**数据争论**和**建模**，如下图所示:

![Figure 6.2 – The MLOps life cycle

](image/B17530_06_002.jpg)

图 6.2–m lops 生命周期

数据争论涉及数据收集、清理和准备，而建模阶段允许您测试不同的模型，然后选择候选模型以投入生产。您可以将候选模型作为输入提供给将在生产阶段使用它的预测应用程序或服务。例如，如果您想要制作一个图像识别系统，那么您需要定义一个对图像进行分类的模型，以及一个使用该模型来识别未知图像的预测服务。

这意味着您不仅要监控预测服务，还必须确保模型表现良好，不会随着时间的推移而退化。如果模型随时间退化，您必须实现一种自动技术来更新模型和使用它的预测服务。这就是彗星出现的地方。

在下一节中，您将学习如何在 DevOps/MLOps 生命周期中集成 Comet。

# Comet 与 DevOps/MLOps 的结合

您可以将 Comet 与部署流程集成起来，以监控和跟踪您的实验。除了前面章节描述的技术，Comet 还提供了 REST API 服务来访问您的项目、工作区、实验和资产。您可以轻松地将 REST API 服务与 DevOps 和 MLOps 平台提供的其他服务集成在一起，您将在本章后面看到这一点。

该部分的组织结构如下:

*   DevOps 生命周期中的彗星
*   设置 Comet REST API
*   使用 Comet REST API

先说第一点，DevOps 生命周期中的彗星。

## DevOps 生命周期中的彗星

让我们假设您已经构建了一个模型，现在您想要改进它，以提高它的性能。如果您不使用任何跟踪系统，那么很容易丢失代码中的更改，这些更改是您的模型的超参数，甚至是最终的工件。

保持项目进展有序的一个非常低级的解决方案可能是使用电子表格，您可以手动跟踪代码、超参数和工件中的所有变更。然而，这个过程可能会爆炸，直到它变得非常复杂和难以管理。

这就是彗星帮助你的地方。Comet 提供了工具来跟踪您的代码、实验等中的所有变更，以便轻松地与部署阶段集成。下图显示了如何将 Comet 与部署阶段集成在一起:

![Figure 6.3 – Comet integration with deployment

](image/B17530_06_003.jpg)

图 6.3–Comet 与部署的集成

您从构建、测试和评估您的候选模型开始。然后，您可以在 Comet 中保存您的实验，并比较它们以选择最佳模型。你可以将最好的模型保存在 Comet 注册表中，当它准备好时，你可以将的阶段标记为*生产*。从 Comet 注册表中，您可以下载最佳模型，并根据您的需要部署它。

要下载最佳模型，您可以使用在前面章节中已经学习过的技术或 Comet REST API 服务。在下一节中，您将学习如何使用 Comet REST API 服务。

## 设置 Comet REST API 服务

Comet REST API 服务可在以下网址获得:【https://www.comet.ml/api/rest/v2】T2。

为了与服务通信，您需要用 Comet API 密钥设置 HTTP 授权头。例如，如果您想通过`curl`在终端中访问 REST API 服务，您可以使用下面的命令:

```
COMET_API_KEY='<MY_COMET_API>'
```

```
COMET_WORKSPACE='<MY_COMET_WORKSPACE>'
```

```
curl -s "https://www.comet.ml/api/rest/v2/registry-model?workspaceName=$COMET_WORKSPACE" -H "Authorization: $COMET_API_KEY"
```

前面的代码访问与特定 Comet 工作区相关的注册表中包含的所有模型。

如果想通过 Python 访问 REST API 服务，可以使用`requests`包，如下:

```
import requests
```

```
COMET_API_KEY='<MY_COMET_API>' 
```

```
url = f"https://www.comet.ml/api/rest/v2/registry-model?workspaceName={COMET_WORKSPACE}"
```

```
headers = {"Authorization": f"{COMET_API_KEY}"}
```

```
response = requests.get(url, headers=headers)
```

```
models = response.json()
```

我们使用由`requests`包提供的`get()`函数，然后我们通过`json()`函数将响应解析为 JSON。

Comet REST API 服务提供了以下主要方法:

*   `/workspaces`–所有工作区的列表
*   `/projects?workspaceName=myWorkspace`–工作区内所有项目的列表
*   `/registry-model?workspaceName=myWorkspace`–工作区内所有注册管理机构模型的列表
*   `/registry-model/details?workspaceName=myWorkspace&modelName=myModelName`–与特定工作空间内的特定模型相关的详细信息
*   `/project?projectName=myProject&workspaceName=myWorkspace`–与特定工作空间内的特定项目相关的详细信息
*   `/experiments?projectId=myProjectId&archived=false`–项目内的实验
*   `/experiment/metadata?experimentKey=myExperimentAPIKey`–与特定实验相关的元数据
*   `/registry-model/item/download?workspaceName=myWorkspace&modelName=myModel&version=myVersion`–下载特定型号

您可以在 Comet 官方文档中找到 Comet REST API 服务提供的所有方法的列表，可通过以下链接获得:[https://www.comet.ml/docs/v2/api-and-sdk/rest-api/overview/](https://www.comet.ml/docs/v2/api-and-sdk/rest-api/overview/)。

既然您已经学习了一些关于 Comet REST API 服务的基本概念，让我们来看一个实际的例子。

## 使用 Comet REST API

您将实现一个使用 Comet REST API 从模型注册中心下载*生产*模型的场景。生产模型有一个为生产设置的阶段。作为一个例子，我们将使用保存在 Comet 注册表中的模型，在第三章[*中实现，在 Comet* 中*模型评估。你可以从这本书的官方资源库下载这个例子的代码，可以从以下链接获得:*](B17530_03_ePub.xhtml#_idTextAnchor063)*[https://github . com/packt publishing/Comet-for-Data-Science/tree/main/06/Comet-rest-API](https://github.com/PacktPublishing/Comet-for-Data-Science/tree/main/06/comet-rest-api)。*

让我们开始吧:

1.  首先，我们导入所有需要的库，如下:

    ```
    import os
    import requests
    import zipfile
    ```

2.  然后，我们导入 Comet 配置参数作为环境变量:

    ```
    COMET_API_KEY = os.environ.get("COMET_API_KEY")
    COMET_WORKSPACE = os.environ.get("COMET_WORKSPACE")
    ```

我们本来可以使用经典的配置文件方法，但是使用环境变量将在以后派上用场，正如我们在使用 Kubernetes 时将看到的那样。

1.  我们定义了每个模型的基本名称，以及要下载的模型列表:

    ```
    base_project = "diamonds"
    models = ["model", "color-feature-label-encoder","clarity-feature-label-encoder","scaler", "label-encoder"]
    output_dir = "models"
    ```

我们还将输出目录名设置为`models`。

1.  对于每个模型，我们搜索与阶段生产相关的模型版本，然后我们下载与该版本相关的压缩文件，解压缩该文件，并将模型保存在`output_dir`中。最后，我们删除原始的压缩文件。下面这段代码实现了所描述的步骤:

    ```
    for model_name in models:
        model_name = f"{base_project}-{model_name}"
        url = f"https://www.comet.ml/api/rest/v2/registry-model/details?workspaceName={COMET_WORKSPACE}&modelName={model_name}"
        headers = {"Authorization": f"{COMET_API_KEY}"}
        response = requests.get(url, headers=headers)
        model_details = response.json()
        for version in model_details['versions']:
            for stage in version['stages']:
                if stage == 'production':
                    model_version = version['version']
                    link = f"https://www.comet.ml/api/rest/v2/registry-model/item/download?workspaceName={COMET_WORKSPACE}&modelName={model_name}&version={model_version}"
                    path = f"{output_dir}/model.zip"
                    model_resp = requests.get(link, headers=headers)
                    with open(path, 'wb') as f:
                        f.write(model_resp.content)
                    with zipfile.ZipFile(path,"r") as zip_ref:
                        zip_ref.extractall(output_dir)
                    os.remove(path)
         break
    ```

以下是对前面代码的一些注释:

*   我们使用`https://www.comet.ml/api/rest/v2/registry-model/details?workspaceName={COMET_WORKSPACE}&modelName={model_name}`调用来检索与特定模型相关的所有细节。目标是检索与生产阶段相对应的模型版本。
*   对于给定的模型，我们循环所有可用的版本和所有可用的阶段，以检查是否至少有一个阶段对应于生产。如果是的话，我们下载它并把它放在`output_dir`中。
*   一旦我们下载了一个模型，我们通过`zipfile`标准 Python 包提供的`ZipFile()`类解压它，并把它放在`output_dir`中。我们还通过`os.remove()`函数删除原始的压缩文件。

1.  可以将脚本另存为`get_models.py`。要运行它，首先需要配置环境变量，如下所示。打开一个终端，编写下面的代码:

    ```
    export COMET_API_KEY=<MY_API_KEY>
    export COMET_WORKSPACE=<MY_WORKSPACE>
    ```

2.  现在，您可以创建一个名为`models`的目录，您的脚本将在其中保存模型。从您的工作目录中，您可以运行以下命令:

    ```
    python get_models.py
    ```

3.  在`models`目录中，您应该会看到下载的模型。

既然您已经学习了如何使用 Comet REST API 服务，我们可以进入下一步，实现 Docker。

# 实现 Docker

Docker 是最流行的容器化平台之一，它构成了运行 DevOps 应用程序的基本构建模块。 **Podman** 和 **BuildKit** 是其他受欢迎的集装箱化平台，可作为 Docker 的替代品。通常，容器化平台允许您在隔离的环境中运行单个应用程序。在 Docker 中，这是通过将您的应用程序包装在一个 **Docker 容器**中实现的，该容器包含您的代码、操作系统和您的代码使用的所有必需的库。在Docker 容器中，您可以运行 **Docker 映像**，它是您的文件系统中包装您的应用程序的对象。

作为 Docker 的替代方案，您可以使用虚拟机，它也为您的应用程序提供了一个隔离的环境和一个随时可以运行的代码。然而，Docker 比虚拟机小得多，也更容易移植。

与任何应用程序一样，Comet 实验也可以在 Docker 容器中启动。在这个部分，您将实现一个结合了 Comet 和 Docker 的实际例子。

本节组织如下:

*   Docker 概述
*   在 Docker 容器中运行 Comet

先说第一点，Docker 的概述。

## Docker 概述

Docker 平台是基于客户端-服务器的架构，如下图所示:

![Figure 6.4 – The Docker architecture

](image/B17530_06_004.jpg)

图 6.4–Docker 架构

Docker 平台由以下主要组件组成:

*   **Docker 客户端**–系统的客户端，运行基于命令行的界面或使用 Docker API。Docker 客户端运行四个主要命令:
    *   `docker build`–建立码头工人形象
    *   `docker pull`–从注册表中提取图像
    *   `docker push`–从注册表推送图像
    *   `docker run`–将图像作为容器运行
*   **Docker 引擎**，构建镜像，管理和运行容器。它包含 **Docker 守护进程**，它是正在运行的服务器，以及创建的容器和图像。您可以使用同一个映像运行多个容器。例如，图像 1 与容器 1 和容器 3 都相关联。
*   **注册表**，包含公共和私有 Docker 映像。注册中心由 **Docker Hub** 和私有注册中心组成，前者包含公共存储库和映像，后者包含私有存储库和映像，您也可以使用它们与您的团队共享。

现在我们已经回顾了一些关于 Docker 的基本概念，我们可以实现一个实际的例子，将 Comet 包装在 Docker 容器中。

## 在 Docker 容器中运行 Comet

作为用例，我们使用在 [*第三章*](B17530_03_ePub.xhtml#_idTextAnchor063)*中实现的示例的简化版本，在慧星*中进行模型评估。目标是构建一个独立的应用程序，测试四种不同的分类模型(随机森林、决策树、高斯朴素贝叶斯和 k-最近邻)，根据一些输入参数将切割钻石分为两类(黄金和白银)。此外，应用程序在 Comet 中记录所有的模型。作为辅助函数，我们使用第三章 、*中描述的那些在慧星*中的模型评估。

您可以从该书的 GitHub 存储库中下载这个示例的代码，可以从以下链接获得:[https://GitHub . com/packt publishing/Comet-for-Data-Science/tree/main/06/docker-example](https://github.com/PacktPublishing/Comet-for-Data-Science/tree/main/06/docker-example)。

此示例遵循下图所示的工作流程:

![Figure 6.5 – The workflow followed by the use case

](image/B17530_06_005.jpg)

图 6.5–用例遵循的工作流

有以下四个步骤:

*   **编写应用程序**:您可以在这里编写代码，比较四个分类模型，并将它们记录在 Comet 中:

1.  由于您不能将秘密封装在 Docker 映像中，所以您应该在运行时将它们传递给容器。在这个例子中，我们创建了一个名为`env.list`的环境文件，包含 Comet 的所有配置参数，如下:

    ```
    COMET_API_KEY=MY_COMET_API_KEY
    COMET_PROJECT=MY_COMET_PROJECT_NAME
    COMET_WORKSPACE=MY_COMET_WORKSPACE
    ```

2.  现在，您已经准备好编写应用程序了。我们创建一个名为`compare-models.py`的文件，编辑如下。首先，我们导入所有需要的库:

    ```
    import os
    from comet_ml import Experiment
    from sklearn.model_selection import train_test_split
    # Import the scikit-learn models
    import pandas as pd
    ```

你应该确保在任何 ML 库之前导入`comet_ml`。

1.  然后，我们检索环境变量:

    ```
    COMET_API_KEY = os.environ.get("COMET_API_KEY")
    COMET_WORKSPACE = os.environ.get("COMET_WORKSPACE")
    COMET_PROJECT = os.environ.get("COMET_PROJECT")
    ```

我们使用`os.environ`对象来检索环境变量。

1.  现在，我们在文件内复制第三章[](B17530_03_ePub.xhtml#_idTextAnchor063)**中描述的所有函数，在慧星*中进行模型评估。我们只修改`run_experiment()`函数，让 Comet 读取环境变量:

    ```
    experiment = Experiment(
            api_key=COMET_API_KEY,
            project_name=COMET_PROJECT,
            workspace=COMET_WORKSPACE,
        )
    ```* 

 *当我们创建实验时，我们传递给它配置参数并从环境变量中读取。

1.  最后，我们如下构建`main`函数:

    ```
    if __name__ == "__main__":
        df = pd.read_csv('source/diamonds.csv')
        df = df.drop(["Unnamed: 0"], axis=1)
        df['target'] = df['cut'].apply(lambda x: set_target(x))
        df.drop("cut", axis = 1,inplace=True)
        X = df.drop("target", axis = 1)
        y = df["target"]
        encode_labels(X)
        scale_numerical(X)
        label_encoder = LabelEncoder()
        y = label_encoder.fit_transform(y)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)
        run_experiment(RandomForestClassifier, 'RandomForest')
        run_experiment(DecisionTreeClassifier, 'DecisionTreeClassifier')
        run_experiment(GaussianNB, 'GaussianNB')
        run_experiment(KNeighborsClassifier, 'KNeighborsClassifier')
    ```

我们已经在 [*第三章*](B17530_03_ePub.xhtml#_idTextAnchor063) 中描述了代码，在彗星中*模型评估。唯一不同的是，我们添加了行`if __name__ == "__main__":`来运行代码*，如果它被直接调用的话。**

*   **构建 DOCKER 镜像**:你可以创建一个名为`docker-example`的新目录，然后把`compare-models.py`脚本放到那个目录中。要将应用程序转换成 Docker 映像，需要在同一个目录下定义两个文件:`requirements.txt`和 Dockerfile。

1.  `requirements.txt`文件包含要安装的 Python 包的列表。在我们的例子中，文件包含以下库:

    ```
    comet_ml
    numpy
    pandas
    scikit-learn
    ```

请注意，您不需要在您的本地机器上安装这些库，因为 Docker 会为您完成！

1.  `Dockerfile`文件包含码头工人用来构建码头工人形象的指令。在我们的示例中，Dockerfile 非常简单，如下面的代码所示:

    ```
    FROM python:slim
    WORKDIR /code
    COPY requirements.txt ./
    RUN pip install --no-cache-dir -r requirements.txt
    COPY . .
    CMD ["python", "./compare-models.py"]
    ```

以下是对上述代码的一些注释:

*   `FROM`指令指定了 Docker 应该在其上构建映像的基础映像。在我们的例子中，我们使用从 Docker Hub 下载的`python:slim`。你可以在以下链接查看 Docker Hub 提供的所有官方 Python 图片:[https://hub.docker.com/_/python](https://hub.docker.com/_/python)。
*   `WORKDIR`指令指定了应用程序在容器中执行的目录。如果目录不存在，该指令首先创建该目录，然后将它移动到创建的目录中。
*   `COPY`指令将源复制到目的地。在我们的例子中，它将文件系统的当前目录中包含的文件复制到 Docker 映像的`code`目录中。
*   `RUN`指令在构建过程中执行指定的命令。在我们的例子中，它安装包含在`requirements.txt`文件中的包。
*   `CMD`指令指定在容器中运行图像时要运行的入口命令。在我们的例子中，它运行的是`compare-models.py`应用程序。

1.  一旦配置了参数，您就可以通过在`docker-example`目录中运行以下命令来构建 Docker 映像:

    ```
    docker build -t compare-models .
    ```

`–t`部分指定图像名称。不要忘记还要指定包含应用程序的目录，在我们的例子中是由最后的`.`(点)指定的。通过运行以下命令，可以查看本地 Docker 注册表中包含的所有图像的列表:

```
docker images
```

下面这段代码显示了我们示例中命令的输出:

```
REPOSITORY      IMAGE ID     CREATED   SIZE    TAG
compare-models df9200aae1d2  5 minutes ago  497MB latest
```

您可以注意到图像的大小，为 497 MB。如果我们使用另一个基本图像，比如 Python 3.8 图像，图像的大小会大得多。

*   **在 DOCKER 容器中运行 DOCKER 映像**:现在，您可以使用下面的命令从文件系统的任何地方运行应用程序:

    ```
    docker run --rm --env-file /path/to/env.list --name running-compare-models compare-models
    ```

以下是关于`docker run`命令参数的一些注释:

*   `--rm`参数指定容器一旦停止运行就必须被移除。
*   `--env-file`参数指定了先前定义的环境文件的路径。
*   `-–name`参数指定容器名。

*   **在 COMET** 中显示比较结果:最终，您可以像往常一样通过访问 COMET 仪表盘。选择项目，您将看到结果，如下图所示:

![Figure 6.6 – The output of the application in Comet

](image/B17530_06_006.jpg)

图 6.6–Comet 中应用程序的输出

可以看到在 Comet 中使用 Docker 并不影响最终结果！

*   **在 Docker Hub 中保存 DOCKER 映像**:最后一步是将 DOCKER 映像推送到 DOCKER HUB 中:

1.  首先，你需要在以下链接创建一个免费账户:[https://hub.docker.com/](https://hub.docker.com/)。
2.  在命令行中，通过以下命令登录 Docker Hub:

    ```
    docker login
    ```

该命令要求您输入用户名和密码。

1.  给你的图片添加至少一个标签，如下:

    ```
    docker tag compare-models compare-models:v1
    ```

我们已经添加了`v1`标签。使用标签允许您下载图像的特定版本。如果您没有指定任何标签，`latest`标签会自动添加到您的图像中。

1.  您还应该在 Docker Hub 中标记 Docker 图像，如下所示:

    ```
    docker tag compare-models:v1 my_account/compare-models:v1
    ```

2.  最后，您可以在 Docker Hub 中保存 Docker 图像，如下:

    ```
    docker push my_account/compare-models:v1
    ```

3.  您可以通过下面的命令下载 Docker 镜像:

    ```
    docker pull my_account/compare-models
    ```

现在您已经将 Comet 应用程序与 Docker 集成在一起，我们可以进入下一步，实现 Kubernetes。

# 实施 Kubernetes

Kubernetes 是一个开源平台，用于管理容器并确保它们正常一致地运行。它使用 Docker 的原理来帮助您协调容器和工作负载。Kubernetes 可以管理一组容器，并使它们相互通信。此外，它可以选择运行容器的最佳位置，确保它们总是在正确的位置，以便在失败时可以恢复。

本节组织如下:

*   库伯内特建筑
*   配置 Kubernetes
*   部署本地 Kubernetes 集群

让我们从第一步开始，Kubernetes 架构。

## 库伯内特建筑

下图显示了 Kubernetes 的基本架构:

![Figure 6.7 – The Kubernetes basic architecture

](image/B17530_06_007.jpg)

图 6.7–Kubernetes 基本架构

Kubernetes 集群由两个主要组件组成:一个**主节点**，它是，负责主要的编排和基础设施管理，以及一个或多个**工作节点**，它们运行应用程序和服务。每个 worker 节点都包含一个 Docker 引擎，它将应用程序作为容器运行。每个工作节点运行一个或多个 pod。一个**吊舱**是 Kubernetes 中最小的可展开物体。它可以运行一个或多个容器。

现在您已经学习了基本的 Kubernetes 架构，我们可以进入下一步，配置 Kubernetes。

## 配置库比涅斯

在 Kubernetes 中，你可以使用 YAML 语言配置不同类型的对象。在这一章中，我们考虑两种类型的对象:部署和服务。

### 部署

您可以使用**部署**到来配置如何更新 Pod:

1.  要在 YAML 文件中定义部署，您应该编写以下代码:

    ```
    apiVersion: apps/v1
    kind: Deployment
    ```

2.  您可以指定当前部署的副本(pod)数量，以及在集群中查找部署的标准(例如，匹配标签):

    ```
    spec:
      replicas: <NUMBER_OF_REPLICAS>
      selector: <CRITERION_TO_FIND_THE_DEPLOYMENT>
    ```

3.  在`spec`选择器下，您还可以指定部署的模板，如下:

    ```
    template:
       spec:
          containers: <DETAILS_ON_THE_CONTAINERS>
    ```

4.  在`containers`选择器下，您可以指定任意数量的容器。对于其中的每一个，您应该提供名称和 Docker 图像，如下所示:

    ```
    - name: <CONTAINER_NAME>
      image: <CONTAINER_IMAGE>
    ```

接下来，我们将看看服务选项。

### 服务

一个**服务**允许你将一个运行在一个或多个容器上的应用程序公开为一个网络服务:

1.  要在 YAML 文件中定义服务，您应该编写以下代码:

    ```
    apiVersion: v1
    kind: Service
    ```

2.  通常，YAML 包含`spec`选择器，它指定向外部世界公开的端口，以及服务的类型:

    ```
    spec:
      ports:
        - port: <EXTERNAL_PORT>
          protocol: TCP
          targetPort: <CONTAINER_PORT>
      type: <TYPE_OF_SERVICE>
    ```

`type`选择器指定要实现的服务类型。类型的例子包括`LoadBalancer`和`ClusterIP`。更多详情可以参考 Kubernetes 官方文档，可从以下链接获得:[https://Kubernetes . io/docs/concepts/services-networking/service/](https://kubernetes.io/docs/concepts/services-networking/service/)。

现在您已经学习了 Kubernetes 背后的基本概念，我们可以转到一个实际的例子，它部署了一个本地 Kubernetes 集群。

## 部署本地 Kubernetes 集群

作为一个用例，您将实现一个基于一些输入特征预测钻石切割(银或金)的 web 服务。web 服务下载包含在 Comet 注册表中的模型，通过本章中实现的代码，在*使用 Comet REST API* 部分。

您可以从本书的官方 GitHub 资源库下载本示例中使用的代码，该资源库位于以下链接:[https://GitHub . com/packt publishing/Comet-for-Data-Science/tree/main/06/kubernetes-example](https://github.com/PacktPublishing/Comet-for-Data-Science/tree/main/06/kubernetes-example)。

下图显示了已实现用例的架构:

![Figure 6.8 – The scenario architecture

](image/B17530_06_008.jpg)

图 6.8–场景架构

从图的右上角开始，您可以看到 Comet 注册表，它存储了所有更新的模型。`get_models.py`脚本从 Comet 注册表下载最佳模型(对应于生产阶段)。您已经使用 Comet REST API 实现了上一节*的`get_models.py`脚本中包含的代码。这个脚本将下载的模型存储在本地文件系统中。`app.py`脚本实现了一个 web 服务器，它从 web 界面接收钻石特征，然后从本地文件系统加载模型，并预测钻石切割。`get_models.py`和`get_models.py`脚本，以及本地文件系统，被打包到一个 Docker 映像中，您可以用它来构建一个 Docker 容器，该容器然后被打包到一个 Pod 中。最后，您可以只用一个 Pod 构建一个 Kubernetes 集群。负载均衡器也包含在 Kubernetes 集群中，它为`app.py`脚本将外部 HTTP 连接转发到本地 HTTP 连接。*

现在，您已经准备好实现所描述的架构了。要部署它，您可以执行以下步骤:

*   编写预测服务。
*   将预测服务包装在 Docker 映像中。
*   创建 Kubernetes 集群。

让我们从第一步开始，编写预测服务。

### 编写预测服务

预测服务由`app.py`脚本实现:

1.  首先，我们导入所有需要的包:

    ```
    import pandas as pd
    import pickle
    import os
    from flask import Flask, render_template, request
    ```

我们导入`flask`包，因为您将在`flask`中实现 web 服务器。

1.  然后，我们定义一个辅助函数，它从文件系统加载一个模型，如下:

    ```
    def load_model(file_name):
        f = open(file_name, 'rb')
        unpickler = pickle.Unpickler(f)
        model = unpickler.load()
        f.close()
        return model
    ```

该函数接收文件名作为输入，并返回其中包含的模型。

1.  我们初始化`Flask` app:

    ```
    app = Flask(__name__)
    app.config["TEMPLATES_AUTO_RELOAD"] = True
    ```

我们将`TEMPLATES_AUT_RELOAD`配置参数设置为`True`，以确保在每次页面加载时都重新加载模板。这可以防止模板缓存。

1.  现在，我们加载所有的模型:

    ```
    base_dir = os.path.abspath(os.path.dirname(__file__))
    color_label_encoder = load_model(f"{base_dir}/models/colorFeatureLabelEncoder.pkl")
    clarity_label_encoder = load_model(f"{base_dir}/models/clarityFeatureLabelEncoder.pkl")
    scaler = load_model(f"{base_dir}/models/scaler.pkl")
    model = load_model(f"{base_dir}/models/model.pkl")
    label_encoder = load_model(f"{base_dir}/models/labelEncoder.pkl")
    ```

我们提取项目基本目录，然后我们访问`models`目录来检索所有的模型。

1.  现在，我们将 web 服务器的主页定义如下:

    ```
    @app.route('/')
    def home():
        return render_template('index.xhtml')
    ```

我们通过`@app.route('/')`语句设置路由到`/`(网站主页面)。`home()`函数只是呈现包含在`index.xhtml`页面中的模板。这个 HTML 页面定义了一个表单，用户可以在其中插入所有的菱形特征。您将在本节的后面看到该文件的内容。

1.  包含在`index.xhtml`页面上的表单的**提交**按钮触发对网络服务器的调用，以计算钻石切工并向用户显示结果。我们将提交按钮的处理函数定义如下:

    ```
    @app.route('/predict', methods=['GET', 'POST'])
    def predict():
        params = request.form.to_dict()
        df = pd.DataFrame(params, index=[1])
        num_cols = df.columns.tolist()
        cat_cols = ['color', 'clarity']
        for col in cat_cols:
            num_cols.remove(col)
        df[num_cols] = df[num_cols].apply(pd.to_numeric, errors='coerce')
       # prepare data
        df['color'] = color_label_encoder.transform(df['color'])
        df['clarity'] = clarity_label_encoder.transform(df['clarity'])
        df[df.columns] = scaler.transform(df[df.columns]) 
        target = model.predict(df)
        label = label_encoder.inverse_transform(target)
        return render_template('predict.xhtml', target=label[0] )
    ```

`predict()`函数通过`request.form.to_dict()`函数提取表单参数，然后用所有的参数构建一个数据帧，将数值转换成数字，并通过应用编码器和缩放器来转换数据。

接下来，它通过模型提供的`predict()`方法计算目标类，并通过应用标签编码器的`inverse_transform()`方法提取原始类。最后，它在`predict.xhtml`模板中设置目标变量，并将其作为结果返回。

1.  最后，您可以编写运行完整应用程序的代码:

    ```
    if __name__ == "__main__":
        app.run(host="0.0.0.0")
    ```

你让应用程序在机器上所有可用的地址上运行。

`app.py`脚本呈现两个模板:`index.xhtml`和`predict.xhtml`。您可以将`index.xhtml`和`predict.xhtml`文件放在一个名为`templates`的目录中，该目录位于`app.py`脚本的同一层。我们来描述一下这两个，从第一个开始，`index.xhtml`。

1.  `index.xhtml`文件创建具有所有菱形特征的 HTML 表单，如下:

    ```
    <div class="textbox">
          <form action="{{ url_for('predict') }}" method='POST'>
            ...

                    <div class="btn-block">
              <button type="submit" href="/">CLASSIFY</button>
            </div>
          </form>
        </div>
    ```

表单的`action`属性包含下面的代码:`"{{ url_for('predict') }}"`，这意味着`flask`服务器将自动用为`predict()`函数创建的 URL 替换它。

1.  您可以在表单中创建每个数字特征作为一个`input`标签，如下:

    ```
    <div class="item">
       <label for="name">Carat<span>*</span></label><br/>
       <input id="carat" type="text" name="carat" required/>
    </div>
    ```

我们指定输入标签是一个文本(`type="text"`)并且是必需的。

1.  您可以通过一个`select`标签用来表示分类特征，如下面这段代码所示:

    ```
    <div class="item">
       <label for="name">Color<span>*</span></label><br/>
       <select name="color">
          <option selected value="" disabled selected></option>
          <option value="D" >D</option>
          <option value="E">E</option>
          <option value="F">F</option>
          <option value="G">G</option>
          <option value="H">H</option>
          <option value="I">I</option>
          <option value="J">J</option>
       </select>
    </div>
    ```

为了简单起见，我们在代码中连接了该类别所有可能的值。

1.  `predict.xhtml`文件简单地呈现了预测的类，如下:

    ```
    <div class="textbox">
       <div class="mainbox">
          <h2>Diamond Classification</h2>
              <div id="target" class="target">
                 {{ target }}
              </div>
        </div> 
     </div>
    ```

`flask`服务器将用预测的实际值替换`{{ target }}`变量。

1.  应用程序已经准备好了。您可以通过在与您的应用程序位于同一目录的终端中运行以下命令来测试是否有效:

    ```
    flask run
    ```

默认的 web 服务器应该运行在以下链接:`http://localhost:5000`。如果您将浏览器指向此链接，您应该会看到类似下面的屏幕截图:

![Figure 6.9 – The app running in the browser

](image/B17530_06_009.jpg)

图 6.9–浏览器中运行的应用程序

注意

我们在表单中添加了一些 CSS 样式，所以如果您的表单没有上图中显示的样式，请不要担心。

到目前为止，您已经构建了您的应用程序。现在是时候将它包装成 Docker 映像了。

### 将预测服务包装在 Docker 映像中

要将你的应用包装成 Docker 映像，你可以如下进行:

1.  为此，我们构建了一个名为`run.sh`的辅助脚本，它同时运行`get_models.py`和`app.py`脚本，如下所示:

    ```
    #!/bin/sh
    python get_models.py
    flask run --host=0.0.0.0
    ```

我们已经指定`flask`应用程序将可用于所有可用的地址。

1.  现在，你需要定义`requirements.txt`文件，如下:

    ```
    flask
    pandas
    requests
    scikit-learn
    ```

2.  您还需要定义 Dockerfile，如下:

    ```
    FROM python:slim
    WORKDIR /app
    COPY . .
    RUN pip install --no-cache-dir -r requirements.txt
    CMD ["./run.sh"]
    ```

Docker 文件与上一节*中描述的在 Docker 容器*中运行 Comet 的文件非常相似，所以您可以参考它来了解更多细节。

下图显示了包含应用程序的文件夹的最终结构:

![Figure 6.10 – The structure of the app folder

](image/B17530_06_010.jpg)

图 6.10–应用程序文件夹的结构

除了您已经实现的内容之外，还有一个静态文件夹，其中包含用于为 HTML 模板提供布局的 CSS 样式文件。

1.  您可以运行`docker build`命令来构建您的 Docker 映像:

    ```
    docker build –t diamonds-prediction .
    ```

2.  您可以通过运行以下命令来测试应用程序是否正常工作:

    ```
    docker run --rm --env-file ../../env.list -p 6002:5000 --name cp diamonds-prediction
    ```

`–p`参数指定了容器中的本地端口(`5000`)和主机中的外部端口(`6002`)之间的映射。

最后，创建 Kubernetes 集群的一切准备就绪！让我们进入最后一步，创建一个 Kubernetes 集群。

### 创建 Kubernetes 集群

要让应用程序在 Kubernetes 中运行,您需要创建三个 YAML 配置文件:

*   `comet-secrets.yaml`
*   `deployment.yaml`
*   `app-service.yaml`

让我们分别分析每个配置文件，从第一个文件`comet-secrets.yaml`开始。

#### comet-secrets.yaml

这个配置文件存储了访问 Comet 的秘密。我们认为有两个秘密，`COMET_API_KEY`和`COMET_WORKSPACE`:

1.  首先，我们通过在终端中运行以下命令来加密它们:

    ```
    echo -n 'MY_COMET_API_KEY' | base64
    ```

您可以复制该命令的输出。您可以对 Comet 工作区运行相同的命令:

```
echo -n 'MY_COMET_WORKSPACE' | base64
```

1.  现在，您可以编写`comet-secrets.yaml`文件，如下:

    ```
    apiVersion: v1
    data: 
      comet_api_key: MY_ENCRYPTED_COMET_API_KEY
      comet_workspace: MY_ENCRYPTED_COMET_WORKSPACE
    kind: Secret
    metadata: 
      name: comet-secrets
    type: Opaque
    ```

下面是对前面代码的一些注释:

*   您应该用小写字母指定所有机密的名称。
*   您将使用在`metadata`选择器下指定的名称，从其他配置文件中检索秘密。

1.  要创建秘密，您可以在终端中运行下面的命令:

    ```
    kubectl create -f comet-secrets.yaml
    ```

2.  您可以通过以下命令检查系统是否创建了部署:

    ```
    kubectl get secrets
    ```

我们继续吧。

#### 部署. yaml

这个配置文件定义了 Pod 和相关的容器。下面的代码显示了`deployment.yaml`文件的一个可能的实现:

```
apiVersion: apps/v1
```

```
kind: Deployment
```

```
metadata:
```

```
  name: diamonds
```

```
  labels:
```

```
    app: dc
```

```
spec:
```

```
  replicas: 1
```

```
  selector:
```

```
    matchLabels:
```

```
      app: dc
```

```
  template:
```

```
    metadata:
```

```
      labels:
```

```
        app: dc
```

```
    spec:
```

```
      containers:
```

```
        - name: prediction
```

```
          image: diamonds-prediction
```

```
          ports:
```

```
            - containerPort: 5000
```

```
          imagePullPolicy: Never
```

```
          env:
```

```
            - name : COMET_API_KEY 
```

```
              valueFrom: 
```

```
                secretKeyRef: 
```

```
                  key: comet_api_key
```

```
                  name: comet-secrets
```

```
            - name : COMET_WORKSPACE 
```

```
              valueFrom: 
```

```
                secretKeyRef: 
```

```
                  key: comet_workspace
```

```
                  name: comet-secrets
```

以下是对前面代码的一些注释:

*   部署名称为`diamonds`，其关联标签为`dc`(菱形分类)。
*   在`spec`选择器下，我们将副本的数量设置为`1`。这意味着我们这个项目只有一个 Pod。为了选择这个 Pod，我们使用了基于标签的匹配标准(`matchLabels: app: dc`)。
*   Pod 只包含一个名为`prediction`的容器。它的映像是从本地注册表中下载的(`imagePullPolicy: Never`)。
*   容器在`5000` ( `containerPort: 5000`)端口接受连接。
*   容器接收三个环境变量作为输入，它们的值取自 Kubernetes 的秘密。

让我们一步一步来。

1.  要创建部署，您可以在终端中运行以下命令:

    ```
    kubectl create -f deployment.yaml
    ```

2.  您可以通过以下命令检查系统是否创建了部署:

    ```
    kubectl get deployments
    ```

您应该看到以下输出:

```
NAME       READY   UP-TO-DATE   AVAILABLE   AGE
diamonds   1/1     1            1           40h
```

接下来，我们将看看服务。

#### app-service.yaml

这个配置文件定义了与应用相关的服务。这个文件将 web 服务器暴露给外部世界，因此它只包含内部容器端口(容器监听的端口)和外部端口之间的映射。下面这段代码显示了一个`app-service.yaml`文件的例子:

```
apiVersion: v1
```

```
kind: Service
```

```
metadata:
```

```
  name: diamonds
```

```
  labels:
```

```
    app: dc
```

```
spec:
```

```
  ports:
```

```
    - port: 6002
```

```
      protocol: TCP
```

```
      targetPort: 5000
```

```
  type: LoadBalancer
```

```
  selector:
```

```
    app: dc
```

以下是对前面代码的一些注释:

*   `kind`选择器指定我们正在定义一个服务。
*   在`ports`选择器下，我们将容器端口(`t` `argetPort`)映射到外部端口(`port`)。
*   我们将服务类型设置为`LoadBalancer`。

让我们走一遍。

1.  要创建部署，可以在终端中运行以下命令:

```
kubectl create -f app-service.yaml
```

1.  您可以通过以下命令检查系统是否已创建部署:

```
kubectl get services
```

您应该会看到以下输出:

```
NAME         TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE
diamonds     LoadBalancer   10.108.230.69   localhost     6002:32590/TCP   41h
```

当您已经创建了所有的秘密、部署和服务后，您就可以使用您的应用程序了。您可以将浏览器指向以下地址:`http://localhost:6002`。

作为进一步的练习，您可以尝试将上一节*实现 Docker* 中部署的映像集成到 Kubernetes 中。

# 总结

我们刚刚完成了将您的模型从测试转移到生产的旅程，并使用 Comet 来保持您的模型是最新的！

在本章中，您已经回顾了与 DevOps 和 MLOps 以及 DevOps 和 MLOps 生命周期相关的一些基本概念。您还学习了如何在 DevOps/MLOps 生命周期中集成 Comet，以及如何使用它来跟踪最佳模型。

您还了解了 Docker 和 Kubernetes 这两个构建 DevOps 应用程序的流行平台背后的基本概念。最后，您实现了两个例子:第一个例子将 Comet 集成在 Docker 映像中，第二个例子将 Comet 与部署在 Kubernetes 中的应用程序集成在一起。

在下一章中，您将回顾发布软件背后的一些基本概念，特别关注 GitLab 以及如何将其与 Comet 集成。

# 延伸阅读

*   阿伦德尔和多明戈斯(2019 年)。*使用 Kubernetes 的云原生 DevOps:在云中构建、部署和扩展现代应用*。奥莱利媒体。
*   Gift N .，Behrman，k .，和 Deza，A. (2019) *Python for DevOps:无情地学习有效的自动化*。奥莱利媒体。
*   Treveil，m .，Omont，n .，Stenac，c .，Lefevre，k .，Phan，d .，Zentici，j ....和 Heidmann，L. (2020)。*介绍 MLOps* 。奥莱利媒体。*