

# 四、工作空间、项目、实验和模型

Comet 是一个实验平台，允许您跟踪、监控和比较数据科学项目中的实验。到目前为止，您已经学习了一些基本概念，包括如何创建和处理工作区、项目、实验、面板和报告。您还学习了如何比较实验、定制面板以及在 Comet 注册表中存储模型。

在本章中，您将加深对有关 Comet 的一些概念的理解，包括如何将协作者添加到您的工作区或项目中，如何发布您的项目，管理实验的高级技术，以及如何在 Comet 中执行参数优化。此外，您将学习如何使用 R 或 Java 作为主要编程语言来实现 Comet 实验。最后，您将使用本章中学习到的高级概念扩展在 [*第 1 章*](B17530_01_ePub.xhtml#_idTextAnchor015) 、*Comet 概述、*中实现的基本示例。

具体来说，本章的组织结构如下:

*   探索 Comet 用户界面(UI)
*   使用实验和模型
*   探索 Comet 支持的其他语言
*   第一个用例——离线和现有实验
*   第二个用例——模型优化

在描述 Comet 背后的高级概念之前，让我们安装运行本章包含的代码和实验所需的所有包。

# 技术要求

我们将使用 Python、R 和 Java 运行本章中的实验和代码。我们将分别描述每种编程语言所需的包，从 Python 开始。

## Python

对于 Python，我们将使用 Python 3.8。可以在[https://www.python.org/downloads/](https://www.python.org/downloads/)官网下载，选择 3.8 版本。

本章中描述的示例使用了以下 Python 包:

*   `comet-ml 3.23.0`
*   `matplotlib 3.4.3`
*   `numpy 1.19.5`
*   `pandas 1.3.4`
*   `scikit-learn 1.0`

我们已经在 [*第一章*](B17530_01_ePub.xhtml#_idTextAnchor015) 、*Comet 概述*中描述了前五个包以及如何安装它们，所以关于安装的更多细节请参考后面的内容。

## R

r 是一种非常流行的统计计算语言。你可以把它作为 Python 的有效替代品，因为它也为机器学习和数据科学提供了许多库。你可以从 R 官网下载，链接:【https://cran.rstudio.com/index.xhtml[。你应该选择适合你的操作系统的版本，并安装它。](https://cran.rstudio.com/index.xhtml)

我们将使用以下 R 包:

*   `caret`
*   `cometr`
*   `Metrics`

`caret`(简称**分类回归训练**)是 ML 的 R 包。您可以通过从 R 终端运行以下命令来安装它:

```
install.packages('caret')
```

`cometr`是 Comet 提供的在 R 中使用 Comet 的官方包，你可以从 R 终端运行以下命令来安装:

```
install.packages("cometr")
```

关于如何安装`cometr`的更多细节，你可以参考 Comet 官方文档，可从以下链接获得:【https://github.com/comet-ml/cometr。

`Metrics`是一个 R 包，实现了一些评估指标。您可以通过从 R 终端运行以下命令来安装它:

```
install.packages("Metrics")
```

关于如何安装`Metrics`的的更多细节，你可以参考`Metrics`官方文档，可从以下链接获得:[https://cran.r-project.org/web/packages/Metrics/index.xhtml](https://cran.r-project.org/web/packages/Metrics/index.xhtml)。

## Java

Java 是一种用于构建应用程序的编程语言。虽然它本身不支持数据科学，但也可以用来实现数据科学项目。存在许多 Java 的实现。本章我们将使用 Oracle 提供的 Java **标准版** ( **SE** ) **软件开发包 17.0.2** ( **SDK 17** )。它可以在甲骨文**免费条款和条件** ( **NFTC** )许可下使用。你可以从这个链接下载 JavaSDK:[https://www.oracle.com/java/technologies/downloads/#java17](https://www.oracle.com/java/technologies/downloads/#java17)。要使其工作，您应该遵循此链接中提供的安装说明:[https://docs . Oracle . com/en/Java/javase/17/install/overview-JDK-installation . XHTML # GUID-8677 a 77 f-231 a-40f 7-98 B9-1 FD 0 b 48 c 346 a](https://docs.oracle.com/en/java/javase/17/install/overview-jdk-installation.xhtml#GUID-8677A77F-231A-40F7-98B9-1FD0B48C346A)。

为了便于安装本章中用到的各种包，我们还安装了 **Apache Maven** ，这是一个构建、管理和运行 Java 应用程序的工具。你可以从这个链接下载 Apache Maven 的最新版本:[https://maven.apache.org/download.cgi](https://maven.apache.org/download.cgi)。为了让 Apache Maven 正常工作，请确保正确设置了您的`JAVA_HOME`环境变量。

我们将使用以下 Java 包:

*   `comet-java-sdk-1.1.10`
*   `weka 3.8.6`

`comet-java-sdk-1.1.10`是 Comet 提供的用于与 Comet 平台交互的 Java 包。你可以从 Comet 官方仓库下载它，可以从以下链接获得:[https://github.com/comet-ml/comet-java-sdk/releases](https://github.com/comet-ml/comet-java-sdk/releases)。你应该下载源文件。

下载后，您可以执行以下操作:

1.  将文件放在文件系统中您喜欢的任何地方。
2.  解压文件。
3.  输入解压缩后的目录。
4.  运行以下命令:

    ```
    mvn clean install
    ```

由于对示例目录中某些外部文件的依赖，安装可能会失败。如果是这种情况，您可以通过注释下面一行来编辑`pom.xml`文件:

```
<module>comet-examples</module>
```

1.  最后，保存文件并再次运行前面的命令。

`weka`是一个针对 ML 的 Java 包。要安装它，你可以遵循`weka`官方文件，可在此链接:【https://waikato.github.io/weka-wiki/maven/】T2。然后，进行如下操作:

1.  你可以从 Maven Central 下载`weka`**Java ARchive**(**JAR**)文件，可以从这个链接获得:[https://search.maven.org/search?q=a:weka-stable](https://search.maven.org/search?q=a:weka-stable)。
2.  然后，从放置 JAR 文件的目录中，您可以在终端中运行以下命令:

    ```
    mvn install:install-file \
     -Dfile=weka-stable-3.8.6.jar \
     -DgroupId= nz.ac.waikato.cms.weka:weka-stable:3.8.6 \
     -DartifactId=weka-stable \
     -Dversion=3.8.6 \
     -Dpackaging=jar \
     -DgeneratePom=true
    ```

这个命令将把`weka`库添加到 Maven 存储库中。

既然您已经通过安装所有需要的包建立了环境，我们可以进入下一步:探索 Comet UI——包括工作区和项目。

# 探索 Comet UI

Comet UI 提供了一个非常有用的仪表板，可以用来组织和跟踪实验。正如在 [*第一章*](B17530_01_ePub.xhtml#_idTextAnchor015) 、*Comet 概述*中已经描述的，Comet UI 被组织成工作区和项目。从概念上讲，工作空间是相似项目的容器，而项目是涉及相同任务的实验的容器。

在本节中，您将学习一些关于工作区和项目的高级概念。所以，让我们从第一个开始:工作空间。

## 工作区

Comet 工作空间是项目的集合。在 [*第 1 章*](B17530_01_ePub.xhtml#_idTextAnchor015) ，*Comet*概述中，您已经学习了如何创建一个新的工作区，以及如何向现有的工作区添加一个新项目。在本节中，您将学习如何向工作区添加协作者。

要将合作者添加到工作空间，你需要至少注册一个**团队**计划，或者，一个**学术**计划，这是免费的，如 [*第一章*](B17530_01_ePub.xhtml#_idTextAnchor015)*Comet 概述*中所述。根据您的计划，您可以将许多协作者添加到您的工作区。

要添加新的协作者，请执行以下操作:

1.  在 Comet dashboard 中，您可以点击屏幕右上角的用户名头像。您应该确保您的工作空间是当前工作空间。如果没有，可以按照第一章 、*Comet 概述*中描述的步骤进行更改。
2.  从下拉菜单中点击**设置**。然后，点击**合作者**|**+合作者**。应该会打开一个弹出窗口，如下面的屏幕截图所示:

![Figure 4.1 – Popup to add new collaborators

](img/B17530_04_001.jpg)

图 4.1–添加新合作者的弹出窗口

您有两种选择来添加新的协作者:通过电子邮件邀请他们或通过用户名搜索他们。在最后一种情况下，您还可以指定他们的角色:**管理员**或**成员**。

1.  点击**邀请**按钮。协作者将收到邀请通知。当他们接受时，他们准备好与你合作。

既然您已经学习了如何向工作区添加新的协作者，那么让我们继续回顾一些关于项目的高级概念。

## 项目

Comet 项目是一系列实验的集合。在 [*第一章*](B17530_01_ePub.xhtml#_idTextAnchor015) 、*Comet*概述中，你已经学习了如何创建一个新项目。在本节中，我们将描述如何执行以下操作:

*   设置项目可见性。
*   共享项目。

要设置项目可见性，请执行以下操作:

1.  访问包含项目的工作区。
2.  选择与您的项目对应的齿轮形状按钮，如下图所示:

![Figure 4.2 – Gear shape button corresponding to the pandas-profiles project

](img/B17530_04_002.jpg)

图 4.2-对应熊猫轮廓项目的齿轮形状按钮

该按钮位于定义项目的行的最后一列。

1.  选择**编辑**菜单项。
2.  选择项目可见性并点击**更新**。你可以选择**私立**或者**公立**。如果您选择公开您的项目，该项目将通过以下链接提供:`https://www.comet.ml/<WORKSPACE NAME>/<PROJECT NAME>/view`。

与工作区一样，您可以决定与协作者共享单个项目。同样，你至少需要一个**团队**或者一个**学术**计划。

要与协作者共享项目，请执行以下操作:

1.  从项目的主仪表板中，选择**管理**选项卡。
2.  如果您想以只读模式与您的合作者共享您的项目，您可以点击**创建可共享链接**。在这种情况下，他们只能读取项目；他们将无法编辑它。
3.  或者，您可以单击**+协作者**按钮与一个或多个协作者共享项目，他们也可以编辑您的项目。该过程类似于为工作空间描述的过程。

现在你已经学习了一些关于项目和工作空间的高级概念，我们可以继续研究实验和模型的其他方面。

# 利用实验和模型

实验和模型是 Comet 项目的核心，因为它们允许您跟踪和监控所有的数据科学项目。你已经在 [*第一章*](B17530_01_ePub.xhtml#_idTextAnchor015)*【Comet 总览】*和 [*第三章*](B17530_03_ePub.xhtml#_idTextAnchor063)*Comet*中了解了实验和模型背后的基本概念。在本节中，您将学习一些涉及离线和现有实验以及模型优化的高级主题。

本节组织如下:

*   实验
*   模型

先说第一点:实验。

## 实验

Comet 实验是一个过程,它允许你在基本条件改变时跟踪你的变量。你已经在 [*第一章*](B17530_01_ePub.xhtml#_idTextAnchor015)*Comet 概述*中学习了 Comet 实验背后的基本概念。您已经看到了`Experiment`类，它允许您通过可用的互联网连接直接与 Comet 连接。然而，可能会发生这样的情况:在某个时间，由于某种原因，您的互联网连接不可用，或者您需要停止您的实验，然后在给定的一段时间后继续进行。为了处理这些情况，Comet 提供了三个附加实验类，如下所示:

*   **离线实验**—如果您没有互联网连接，您可以创建一个`OfflineExperiment()`对象，它允许您将您的实验存储在您的文件系统上。然后，您可以在第二个实例中将实验上传到 Comet。你可以像这样创建一个离线实验:

    ```
    from comet_ml import OfflineExperiment
    experiment = OfflineExperiment(offline_directory="PATH/TO/THE/OUTPUT/DIRECTORY")
    ```

`offline_directory`参数指定保存实验的输出目录。一旦您创建了一个实验，您就可以像通常使用标准的`Experiment`类一样使用它。当实验结束时，输出目录将包含一个压缩文件。您可以通过命令行实用程序来上传它，如下所示:

```
comet upload PATH/TO/THE/ZIP/FILE
```

*   **现有实验**—您可以通过创建一个`ExistingExperiment()`对象来继续一个现有实验，该对象接收作为输入的实验密钥以继续。当您想要将实验的训练和测试阶段分开时，或者如果您想要改进以前的实验时，这尤其有用。您可以像这样创建一个现有的实验:

    ```
    from comet_ml import ExistingExperiment
    experiment = ExistingExperiment(previous_experiment= "EXPERIMENT_KEY ")
    ```

要使用`ExistingExperiment()`对象，您需要预先知道实验密钥，您可以通过`previous_experiment`输入参数来指定。

*   **离线现有实验**—可以离线继续现有实验。这是前两个案例的结合。在这种情况下，您应该创建一个`ExistingOfflineExperiment()`对象，如下面的代码所示:

    ```
    from comet_ml import ExistingOfflineExperiment
    experiment = ExistingOfflineExperiment(offline_directory= "PATH/TO/THE/OUTPUT/DIRECTORY", previous_experiment= "EXPERIMENT_KEY ")
    ```

您必须指定`offline_directory`参数和实验密钥。如果您想在 Comet 中上传一个实验，您应该从终端运行以下命令:

```
comet upload PATH/TO/THE/ZIP/FILE
```

你将在本章末尾练习不同类型的实验，届时我们将扩展第一章[](B17530_01_ePub.xhtml#_idTextAnchor015)**中描述的第一个用例*。*

 *现在你已经学习了一些关于实验的高级概念，我们可以进入下一点:模型。

## 车型

Comet 模型是一种算法，从已知数据中学习模式，并使用它对未知数据进行预测。你可以为不同的目的建立你的模型，包括数据分类、回归、**、自然语言处理** ( **、NLP** )、时间序列预测等等。

你已经在 [*第三章*](B17530_03_ePub.xhtml#_idTextAnchor063) ，*模型* *Comet*评测中学会了如何在 Comet 中跟踪和组织模型。Comet 还提供了一个额外的特性，允许您优化您的模型。这个特性被称为**优化器**。在本节中，我们将描述如何在 Comet 中构建优化器，而在 [*第八章*](B17530_08_ePub.xhtml#_idTextAnchor169)*Comet 用于机器学习*[*第九章*](B17530_09_ePub.xhtml#_idTextAnchor192)*Comet 用于自然语言处理*[*第十章*](B17530_10_ePub.xhtml#_idTextAnchor216)*Comet 用于深度学习*[*第十一章*](B17530_11_ePub.xhtml#_idTextAnchor236)

您可以使用 Comet 优化器来调整您的模型的超参数，方法是选择一种支持的优化算法:**网格**、**随机**和**贝叶斯**。如果你想了解更多关于优化算法的细节，你可以参考 Comet 官方文档，可以从以下链接获得:[https://www . Comet . ml/docs/python-SDK/introduction-optimizer/# optimizer-algorithms](https://www.comet.ml/docs/python-sdk/introduction-optimizer/#optimizer-algorithms)。

遵循以下步骤:

1.  你可以像这样创建一个 Comet 优化器:

    ```
    from comet_ml import Optimizer
    optimizer = Optimizer(config)
    ```

我们创建一个`Optimizer`对象，它接收一些配置参数作为输入，这些参数包括最大化/最小化的度量、试验次数、优化算法和要测试的参数。

1.  您可以这样定义配置参数:

    ```
    config = {"algorithm": <MY_OPTIMIZATION_ALGORITHM>,
           "spec": {
           "objective": <MINIMIZE/MAXIMIZE>,
           "metric": <METRIC>,
              },
       "trials":  <NUMBER OF TRIALS>,
       "parameters": [LIST OF PARAMETERS],
       "name": <OPTMIZER NAME>
    }
    ```

`config`对象是一个包含所有配置参数的字典。除了前面代码中列出的参数，您还可以定义其他参数，如 Comet 官方文档中所指定的。

1.  参数列表包括所有要测试的特定参数，对于每个参数，您必须指定一个可能值的范围(整数、分类等)。根据参数的类型，语法会有所不同。对于一个`integer`类型，您应该指定最小和最大值，以及缩放类型，如下面的代码所示:

    ```
    {<PARAMETER-NAME>:
      {"type": "integer",
       "scalingType": "linear" | "uniform" | "normal" | "loguniform" | "lognormal",
       "min": <MIN-VALUE>,
       "max": <MAX-VALUE>,
      }
    ```

`PARAMETER-NAME`的值取决于的具体算法。例如，对于一个 **K 近邻** ( **KNN** )分类器，您可能需要超调邻居的数量。

1.  如果你想超调一个分类参数，你可以使用下面的语法:

    ```
    {<PARAMETER-NAME>:
      {"type": "categorical",
       "values": ["LIST", "OF", "CATEGORIES"]
      }
    }
    ```

`"values"`键包含所有可能测试的类别列表。

当您创建一个`Optimizer`对象时，系统将为配置中包含的每个参数组合创建一个实验。您可以通过执行以下代码来访问实验列表:

```
optimizer.get_experiments():
```

通过迭代实验列表，您可以访问每个参数，并使用它来拟合不同的模型，如下所示:

```
for experiment in opt.get_experiments():
   param1 = experiment.get_parameter("param1")
   # create, fit and test the model with param 1
```

前面的代码显示了如何检索每个参数，您可以根据需要使用这些参数来创建、拟合和测试您的首选模型。注释行表示在检索参数后您应该编写的代码取决于您想要实现的模型。

一旦你完成了所有的实验，你将会在 Comet 中看到结果。您将在本章末尾的*第二个用例——模型优化*部分实现一个实际用例。

现在您已经学习了一些关于实验和模型的高级概念，我们可以进入下一步了:Comet 支持的其他语言。

# 探索 Comet 支持的其他语言

到目前为止，你已经学会了如何在 Python 中使用 Comet。然而，Comet 也支持其他编程语言。到目前为止在实验、面板等方面学到的概念对于 Comet 支持的其他语言也是有效的。

在本节中，您将把在前面章节中已经学到的概念应用到 R 和 Java 语言中。所以，如果你对这些语言的编程不感兴趣，可以跳过这一节，直接进入下一节，*第一个用例——离线和现有实验*。

在本节中，您将学习如何使用以下语言构建和运行实验:

*   稀有
*   Java 语言(一种计算机语言，尤用于创建网站)

先说第一种语言:r。

## R

假设你已经在 Comet 中创建了一个新项目，并获得了一个**应用编程接口** ( **API** ) key，如 [*第一章*](B17530_01_ePub.xhtml#_idTextAnchor015) 、*Comet 概述*所述。如那一章中所述，您应该定义一个名为`.comet.yml`的配置文件，它应该包含所有配置参数，如下面这段代码所示:

```
COMET_WORKSPACE: MY_WORKSPACE
```

```
COMET_PROJECT_NAME: MY_PROJECT_NAME
```

```
COMET_API_KEY: MY_API_KEY
```

配置文件应该包含工作空间名称、项目名称和 API 键。您应该将文件保存在工作目录或主目录中。

在本节中，您将使用`caret`包在 r 中执行一个 ML 任务。

*   探索`cometr`包
*   查看`caret`包
*   运行一个实际例子

先说第一部分:探索`cometr`包。

### 探索 cometr 包

`cometr`包提供了与 Comet 平台交互的功能。要获得可用函数的列表，您可以参考 Comet 官方文档，可通过以下链接获得:【https://www.comet.ml/docs/r-sdk/getting-started/。以下是最常见的函数列表:

*   `create_experiment()`/`create_project()`—创建新的实验/项目
*   `get_experiments()`/`get_projects()`/`get_workspaces()`—获取实验/项目/工作空间的列表

您可以使用`create_experiment()`函数创建一个`experiment()`对象。一旦创建了一个`experiment()`对象，就可以记录参数、指标和对象，就像在 Python 中通常做的那样。要获得可用方法的列表，您可以参考 Comet 官方文档，可通过以下链接获得:【https://www.comet.ml/docs/r-sdk/Experiment/。以下是`experiment()`对象最常用的方法列表:

*   `log_metric()`/`log_parameter()`/`log_html()`/`log_code()`/`log_graph()`/`log_other()`—记录度量、参数、超文本标记语言**(**HTML**)页面、代码、图表或其他对象**
***   `upload_asset()`—将资产上传到 Comet 平台**

 **现在你已经学习了`cometr`包提供的基本函数和方法，我们可以简单回顾一下`caret`包。

### 查看插入符号包

`caret`包提供了在 R 中执行 ML 的以下主要特性:

*   **预处理**，它允许你清理、规格化和居中你的数据集，以及执行其他预处理操作。要执行预处理，可以使用`preProcess()`函数，如下:

    ```
    X_preprocessed <- preProcess(X, method = c("center", "scale"))
    ```

该函数将数据集以及要执行的操作列表作为输入。在示例中，我们执行了居中和缩放。

*   **数据分割**，它允许你将你的数据分割成训练集和测试集。您可以使用`createPartition()`函数将数据集分成训练集和测试集，如下面的代码所示:

    ```
    index <- createDataPartition(dataset, p = .8, 
               list = FALSE, 
               times = 1)
    ```

`p`参数根据概率指定训练集的大小。设置`list = FALSE`参数可以避免将数据作为列表返回，而`times`参数设置要返回的分割数。该函数返回属于第一个分区的索引列表。因此，您需要创建两个变量—一个用于训练集，另一个用于包含所选索引的测试集，如下所示:

```
training <- df[index,] 
test <- df[-index,]
```

`df`是作为数据帧加载的原始数据集。

*   **模型训练**允许你训练特定的模型。`caret`包提供了`train()`方法来训练一个模型，如下面这段代码所示:

    ```
    model <- train(class ~ ., method='knn', data = training, metric='Accuracy') 
    ```

第一个参数是预测器，它允许您选择输出。您还可以通过`method`参数、输入数据和要计算的度量来指定模型的类型。您甚至可以设置超参数调整的训练控制。关于这方面的更多细节，可以参考`caret`官方文档，可从以下链接获得:[https://top EPO . github . io/caret/model-training-and-tuning . XHTML # model-training-and-parameter-tuning](https://topepo.github.io/caret/model-training-and-tuning.xhtml#model-training-and-parameter-tuning)。

*   **模型预测**，它允许你预测新的未知数据的输出。您可以像这样使用`predict()`函数:

    ```
    y_pred <- predict(model, X_test)
    ```

*   **模型评估**，允许您评估模型的性能。根据具体的任务，您可以计算不同的指标。更多细节，可以参考`caret`官方文档，可从以下链接获得:[https://topepo.github.io/caret/measuring-performance.xhtml](https://topepo.github.io/caret/measuring-performance.xhtml)。由于`caret`包没有提供计算精度的直接方法，在下一节描述的例子中，我们将使用`Metrics`包来计算精度。

现在您已经学习了在`caret`中构建模型的基本概念，您可以实现一个实际的用例了。

### 运行一个实际例子

我们将使用*蘑菇分类*数据集，在**知识共享零** ( **CC0** )公共许可证下可在 Kaggle([https://www.kaggle.com/uciml/mushroom-classification](https://www.kaggle.com/uciml/mushroom-classification))上获得。我们的目标是建立一个分类模型，预测蘑菇是可食用的还是有毒的。(你可以在该书的 GitHub 资源库中找到这个例子的完整代码，可以从以下链接获得:[https://GitHub . com/packt publishing/Comet-for-Data-Science/tree/main/04/r-example](https://github.com/PacktPublishing/Comet-for-Data-Science/tree/main/04/r-example)。)

以下是我们将采取的步骤:

1.  首先，我们导入所有需要的库，如下:

    ```
    library(cometr)
    library(caret)
    library(Metrics)
    ```

2.  然后，我们将数据集作为数据帧加载，如下所示:

    ```
    df <- read.csv('mushrooms.csv')
    ```

数据集包含 8，124 行和 23 列。下面的屏幕截图显示了数据集的前 10 行:

![Figure 4.3 – An extract of the mushrooms dataset

](img/B17530_04_003.jpg)

图 4.3-蘑菇数据集的摘录

1.  数据集的第一列包含目标类。我们还可以注意到，数据集的所有列都包含分类变量。因此，我们将它们转换成数值，如下面这段代码所示:

    ```
    for(i in 2:ncol(df)) {       
      df[ , i] <-  as.numeric(factor(df[ , i], levels = unique(df[ , i]), exclude = NULL))
    }
    ```

在`for`循环中，我们从第二列开始，因为第一列是目标类。

1.  现在，我们对目标类进行编码，如下:

    ```
    df$class <- as.factor(df$class)
    ```

对于前面的代码，我们没有将类转换成数值。

1.  我们通过执行下面的代码创建一个 Comet 实验:

    ```
    experiment <- create_experiment()
    ```

2.  现在，我们准备创建一个模型。其思想是将数据集分成几批，并跟踪模型在每一步的表现。我们使用 KNN 分类器来执行分类任务。下面的代码片段展示了我们如何训练和测试模型，以及我们如何在 Comet 中记录所有的指标:

    ```
    set.seed(10)
    n <- dim(df)[1]
    burst <- 1000
    for (i in seq(200, n+burst, by=burst)) {
      if(i > n)
        i = n
      dft <- df[c(1:i),]
      index <- createDataPartition(y = dft$class, times = 1, p = 0.7, list = FALSE)
      training <- dft[index,]
      test <- dft[-index,]

      model <- train(class ~ ., method='knn', data = training, metric='Accuracy')
      test$pred <- predict(model, test)

      acc <- accuracy(test$class, test$pred)
      test$factor_pred <- as.factor(test$pred)
      test$factor_truth <- as.factor(test$class)

      precision <- posPredValue(test$factor_truth, test$factor_pred)
      recall <- sensitivity(test$factor_truth, test$factor_pred)

      F1 <- (2 * precision * recall) / (precision + recall)
      experiment$log_metric("accuracy", acc, step=i)
      experiment$log_metric("precision", precision, step=i)
      experiment$log_metric("recall", recall, step=i)
      experiment$log_metric("F1", F1, step=i)
    }
    ```

首先，我们将种子设置为 10，以使实验具有可重复性。对于每一批，我们通过由`caret`库提供的`createDataPartition()`函数将数据集分成训练和测试。然后，我们通过`train()`函数训练模型。我们还指定要优化精度。现在，我们通过`predict()`函数测试模型性能，并计算准确度、精确度、召回率和 F1 分数。最后，我们通过`experiment`类的`log_metric()`方法在 Comet 中记录所有计算的指标。

1.  最后，我们终止实验，如下:

    ```
    experiment$stop()
    ```

2.  我们从 R 控制台的运行代码，如下:

    ```
    setwd('/PATH/TO/THE/DIRECTORY/CONTAINING/YOUR/CODE')
    source('script.R')
    ```

首先，我们需要通过`setwd()`函数改变目录，然后我们通过`source()`函数运行代码。

1.  现在，该实验在 Comet 中可用，如下截图所示:

![Figure 4.4 – Output of the experiment in Comet

](img/B17530_04_004.jpg)

图 4.4–Comet 中实验的输出

*图 4.4* 显示了 Comet 中实验的输出，重点是准确度、精确度、召回率和 F1-score 曲线。

现在您已经学习了如何用 R 构建一个 Comet 实验，我们可以进入下一步:用 Java 构建一个 Comet 实验。

## Java

让我们假设你已经在 Comet 中创建了一个新项目，并且你已经有了一个 API key，如 [*第 1 章*](B17530_01_ePub.xhtml#_idTextAnchor015) ，*Comet*概述中所述。让我们进一步假设您已经用一个`pom.xml`文件创建了一个 Maven 项目，采取以下步骤:。

1.  您应该将 Comet 库添加到您的`pom.xml`文件的`dependency`部分，如下所示:

    ```
    <dependency>
          <groupId>ml.comet</groupId>
          <artifactId>comet-java-client</artifactId>
          <version>1.1.10</version>
     </dependency>
    ```

在前面的代码片段中，我们已经将`comet-java-client`版本 1.1.10 添加到我们的项目中。

1.  您还应该配置一个名为`application.conf`的文件，如下所示:

    ```
    comet {
         baseUrl = "https://www.comet.ml"
         apiKey = "YOUR API KEY"
         project = "YOUR PROJECT NAME"
         workspace = "YOUR EXPERIMENT"
    }
    ```

该文件包含访问 Comet 平台的配置参数。

1.  您应该将`application.conf`文件添加到项目类路径的`pom.xml`文件中，如下所示:

    ```
    <resources>
            <resource>
                <directory>PATH/TO/THE/CONF/FILE</directory>
            </resource>
    </resources>
    ```

在本节中，您将使用`weka`包在 Java 中执行一个 ML 任务。该段分为以下几个部分:

*   探索`ml.comet`包
*   查看`weka`包
*   运行一个实际例子

让我们从第一部分开始:探索`ml.comet`包。

### 探索 ml.comet 包

`ml.comet`包提供了函数来与 Comet 平台交互。要获得可用类和函数的列表，您可以参考 Comet 官方文档，可通过以下链接获得:【https://www.comet.ml/docs/java-sdk/getting-started/。Comet 提供了`OnlineExperimentBuilder`类来创建实验，并提供了`OnlineExperiment`接口来管理实验。您可以通过运行以下代码来创建一个新的实验:

```
import ml.comet.experiment.ExperimentBuilder;
```

```
import ml.comet.experiment.OnlineExperiment;
```

```
OnlineExperiment experiment = ExperimentBuilder.OnlineExperiment().build();
```

前面的代码创建了一个新的`experiment()`对象，您可以用它来记录和跟踪您的实验。

类似于为其他编程语言定义的`experiment`类，`OnlineExperiment`接口也提供了以下方法:

*   `logMetric()`/`logModel()`/`logArtifact()`/`logParameter()`—记录指标、模型、工件或参数
*   `setEpoch()`/`setStep(`)—设置实验的当前时期/步骤
*   `nextEpoch()`/`nextStep()`—增加实验的当前时期/步骤

前面的方法列表包含了由`OnlineExperiment`接口提供的最重要的方法。您可以参考 Comet 官方文档以获得完整的方法列表。

现在你已经学习了`ml.comet`包提供的基本功能和方法，我们可以简单回顾一下`weka`包。

### 审查 weka 一揽子计划

`weka`包包含许多执行 ML 任务的子包。其中，我们将使用以下几种:

*   `core`，包含主要的类和函数，为进一步的分析准备数据。具体来说，你可以加载一个**逗号分隔值** ( **CSV** )文件，如下:

    ```
    CSVLoader loader = new CSVLoader(); 
    loader.setSource(new File("/path/to/csv/file.csv")); 
    Instances dataset = loader.getDataSet();
    ```

*   `classifiers`，包含所有用于执行**监督学习** ( **SL** )的算法。与回归相关的算法可以在`classifiers.functions`子包中找到。要构建一个分类器并训练它，可以运行下面的代码:

    ```
    MyModel model = new MyModel();  
    model.buildClassifier(training);
    ```

`MyModel()`类是由`classifiers`子包提供的类之一，比如用于实现 KNN 分类器的`IBk()`。`classifiers` 包还包含一个名为`Evaluation`的类，您可以使用它来执行模型评估。在下一节中，您将看到一个如何使用它的实际例子。

既然您已经查看了由`weka`包提供的基本包，我们可以进入下一步:实现一个实际的用例。

### 运行一个实际例子

我们将使用*蘑菇分类*数据集，可以在 CC0 公共许可证下的 ka ggle([https://www.kaggle.com/uciml/mushroom-classification](https://www.kaggle.com/uciml/mushroom-classification))上获得。我们已经在前面的部分使用过了。我们将实现与上一节相同的用例，即构建一个分类模型，预测蘑菇是可食用的还是有毒的。我们将使用`weka`包来执行 ML 任务。

(你可以在该书的 GitHub 知识库中找到这个例子的完整代码，可以从以下链接获得:[https://GitHub . com/packt publishing/Comet-for-Data-Science/tree/main/04/Java-example](https://github.com/PacktPublishing/Comet-for-Data-Science/tree/main/04/java-example)。)

以下是我们将采取的步骤:

1.  首先，我们创建一个名为`KNN.java`的新 Java 脚本，并设置包名，如下:

    ```
    package packt.comet;
    ```

2.  然后，我们导入所有需要的类，就像这样:

    ```
    import ml.comet.experiment.ExperimentBuilder;
    import ml.comet.experiment.OnlineExperiment;
    import weka.core.Instances;
    import weka.core.converters.CSVLoader;
    import weka.classifiers.Classifier;
    import weka.classifiers.lazy.IBk;
    import weka.classifiers.Evaluation;
    import java.util.Random;
    import java.io.File;
    ```

从`ml.comet`开始，我们已经导入了与 Comet 交互所需的类；从`weka`中，我们导入了加载 CSV 文件和执行分类所需的类，从`java`中，我们导入了一些实用函数。

1.  现在，我们定义一个包含代码的名为`KNN`的类，如下:

    ```
    public class KNN {
        public static void main( String[] args )
        {...}
    }
    ```

我们还定义了一个`main()`方法，它将包含以下所有代码。

1.  在`main()`方法中，我们创建一个新的实验，如下:

    ```
    OnlineExperiment experiment = ExperimentBuilder.OnlineExperiment().build();
    experiment.setExperimentName("KNN");
    ```

我们还通过`setExperimentName()`方法设置了实验名称。

1.  我们将文件作为一个`Instances`对象加载，如下:

    ```
    try {
       CSVLoader loader = new CSVLoader();
       loader.setSource(new 
          File("src/main/resources/mushrooms.csv"));
       Instances data = loader.getDataSet();
        data.setClassIndex(0);
    } catch (Exception ex) {
       System.err.println("Exception occurred! " + ex);
    }
    ```

我们还通过由`Instances`类提供的`setClassIndex()`方法将目标类设置为第一列。

1.  现在，我们准备创建一个模型。与上一节类似，我们将数据集分成几批，对于每一批，我们计算模型的性能。我们使用 KNN 分类器来执行分类任务。下面的代码展示了我们如何训练和测试模型，以及我们如何在 Comet 中记录所有的指标:

    ```
    int n = data.numInstances();
    for (int i = 200; i < n+1000; i+=1000) {
      if(i > n) i = n;
      Instances current_data = new Instances(data, 0, i);
      // train test splitting
      int seed = 10;
      current_data.randomize(new Random(seed));
      int trainSize = (int) Math.round(current_data.numInstances() * 0.7);
      int testSize = current_data.numInstances() - trainSize;
      Instances train = new Instances(current_data, 0, trainSize);
      Instances test = new Instances(current_data, trainSize, testSize);
      // train the model
      IBk model = new IBk(); 
      model.buildClassifier(train);
      // evaluate the model
      Evaluation eval = new Evaluation(test);
      eval.evaluateModel(model,test);
      double accuracy = eval.pctCorrect()/100;
      experiment.logMetric("accuracy", accuracy);
      experiment.setStep(i);
    }
    ```

我们使用由`weka`提供的`IBk`类来创建 KNN 分类器，并使用`Evaluation`类来评估模型。

1.  最后，我们终止实验，如下:

    ```
    experiment.end();
    ```

2.  从项目根目录，我们运行代码，如下:

    ```
    mvn clean compile exec:java -Dexec.mainClass="packt.comet.KNN"
    ```

在前面的代码中，我们首先编译项目，然后运行它。

1.  我们可以在 Comet 中直接访问实验结果，如下图截图所示:

![Figure 4.5 – The Comet dashboard after running the Java experiment

](img/B17530_04_005.jpg)

图 4.5–运行 Java 实验后的 Comet 仪表板

*图 4.5* 显示了 Comet 主仪表盘，带有与 KNN 实验相关的精确度图表。

现在您已经学习了一些关于 Comet 的高级概念，您可以通过两个实际的用例来实践它们。先说第一个用例:离线和现有实验。

# 第一个用例——离线和现有实验

在 [*第 1 章*](B17530_01_ePub.xhtml#_idTextAnchor015) 、*Comet*概述中，您构建了一个简单的用例，允许您在 Comet 中跟踪图像。示例使用了意大利与**国内生产总值** ( **GDP** )相关的 52 个时间系列指标，构建了 52 个图像，上传到 Comet。

在实验过程中，你肯定会注意到 Comet 中图像的加载非常慢，这取决于你的互联网连接的可用带宽。在这个例子中，您将看到如何使用离线和现有实验的概念来使加载过程更加顺畅。您还将看到如何在以后改进现有的实验。

在这个例子中，我们假设在第一个用例的 [*第一章*](B17530_01_ePub.xhtml#_idTextAnchor015) 、*Comet 概述、*中实现的代码正在运行。因此，请参考它的进一步细节。

这个例子的完整代码可以在 GitHub 存储库中找到，链接如下:[https://GitHub . com/packt publishing/Comet-for-Data-Science/tree/main/04/first-use-case-advanced](https://github.com/PacktPublishing/Comet-for-Data-Science/tree/main/04/first-use-case-advanced)。

具体来说，该示例组织如下:

*   运行离线实验
*   继续现有的实验
*   离线改进现有实验

让我们从第一阶段开始:运行一个离线实验。

## 运行离线实验

这里的思路是将 [*第一章*](B17530_01_ePub.xhtml#_idTextAnchor015)*【Comet 总览】*中描述的线上实验转化为线下实验。一旦实验完成，这将允许你在后台上传 Comet 中的图像。

要执行此操作，您只需更改以下代码行:

```
from comet_ml import Experiment
```

```
experiment = Experiment()
```

您的代码现在应该如下所示:

```
from comet_ml import OfflineExperiment
```

```
experiment = OfflineExperiment(offline_directory="output")
```

显然，您需要在当前工作目录中创建一个名为`output`的目录。运行实验后，您的输出目录将包含一个类似于以下屏幕截图所示的文件:

![Figure 4.6 – Directory containing the offline experiment

](img/B17530_04_006.jpg)

图 4.6–包含离线实验的目录

现在，你可以将离线实验上传到 Comet，如本章的*使用实验和模型*部分所述。你还应该记得配置`.comet.config`文件以使实验工作，如 [*第 1 章*](B17530_01_ePub.xhtml#_idTextAnchor015) 、*Comet 概述*中所述。

现在您已经构建了一个离线实验，我们可以进入下一步:继续一个现有的实验。

## 继续现有的实验

将实验分成两部分可能是之前节省网络带宽策略的替代方案。因此，我们可以建立一个实验，向 Comet 上传第一批 *N 张*图像，然后继续上传剩余的图像。

我们将这样做:

1.  首先，我们将现有的构建图形的代码封装到一个函数中，就像这样:

    ```
    def run_experiment(df, experiment, indicators = df.columns):
        for indicator in indicators:
            ts = df[indicator]
            ts.dropna(inplace=True)
            ts.index = ts.index.astype(int)
            fig = plot_indicator(ts,indicator)
            experiment.log_image(fig,name=indicator, image_format='png')
    ```

`run_experiment()`函数接收`df`数据帧、实验和指标列表作为输入，对于每个指标，它构建并记录相应的图。

1.  现在，像往常一样构建一个实验，如下所示:

    ```
    from comet_ml import Experiment, ExistingExperiment
    experiment = Experiment()
    experiment.set_name('Track Indicators - first part')
    ```

我还通过`set_name()`函数设置了实验的名称。

1.  然后，您通过跟踪前 10 个实验来运行实验，如下所示:

    ```
    N = 10
    run_experiment(df,experiment, indicators=df.columns[0:N])
    ```

2.  您检索实验密钥以便稍后继续实验，如下面的代码片段所示:

    ```
    experiment_key = experiment.get_key()
    ```

如果你在 Comet 中访问这个实验，你可以看到一个名为`Track Indicators – first part`的实验，在**图形**菜单项下，你会看到前 10 个图形。你会注意到上传过程非常快。

1.  现在，您可以通过定义一个`ExistingExperiment()`对象继续之前的实验，如下:

    ```
    from comet_ml import ExistingExperiment
    experiment = ExistingExperiment(previous_experiment=experiment_key)
    experiment.set_name('Track Indicators - final')
    ```

您还更改了实验的名称，以跟踪 Comet 仪表板中的变化。

1.  现在，您可以使用剩余的指标运行实验，如下所示:

    ```
    run_experiment(df,experiment, columns=df.columns[N:])
    ```

如果你现在进入 Comet 仪表板，你可以看到一个不同名称的实验，`Track Indicators – final`，在**图形**部分，你会看到所有的图形。

既然你已经学会了如何继续一个现有的实验，我们可以进入下一步:离线改进一个现有的实验。

## 离线改进现有实验

让我们假设对于每个指标，您还想绘制一条趋势线，显示该指标是上升还是下降的趋势。在实践中，对于每个指标，您应该计算一个线性回归模型，然后绘制结果线。由于这个操作可能很耗时，您可以决定离线执行，然后在后台将结果上传到 Comet 中。我们还假设你知道与你的实验相关的实验密钥。

以下是我们将采取的步骤:

1.  首先，我们创建一个`ExistingOfflineExperiment()`对象，如下:

    ```
    from comet_ml import ExistingOfflineExperiment
    experiment = ExistingOfflineExperiment(offline_directory="output",previous_experiment=experiment_key)
    ```

我们已经指定了脱机目录和实验密钥。

1.  然后，我们修改第一章[](B17530_01_ePub.xhtml#_idTextAnchor015)**Comet 总览*中定义的`plot_indicator()`函数，以同样绘制趋势线，如下:

    ```
    def plot_indicator(ts, indicator,trendline):
        fig_name = 'images/' + indicator.replace('/', "") + '.png'
        xmin = np.min(ts.index)
        xmax = np.max(ts.index)
        plt.figure(figsize=(15,6))
        plt.plot(ts)
        plt.plot(ts.index,trendline)
        plt.title(indicator)
        plt.grid()
        plt.savefig(fig_name)
        return fig_name
    ```* 
**   之后，对于每个指标，我们实现一个线性回归模型，我们通过之前定义的`plot_indicator()`函数绘制时间序列和预测输出。代码如下面的代码片段所示:

    ```
    from sklearn.linear_model import LinearRegression
    for indicator in df.columns:
        ts = df[indicator]
        ts.dropna(inplace=True)
         ts.index = ts.index.astype(int)
        X = ts.index.factorize()[0].reshape(-1,1)
        y = ts.values 
        model = LinearRegression()
        model.fit(X,y)
        y_pred = model.predict(X)

        fig = plot_indicator(ts,indicator,y_pred)
        experiment.log_image(fig,name=indicator, image_format='png', overwrite = True)
    ```* 

 *注意，我们已经使用了由`scikit-learn`提供的`LinearRegression()`类来实现线性回归模型。对于每个指标，我们构建了一个类似于下图所示的图表:

![Figure 4.7 – Graph produced for the “Agriculture, forestry, and fishing, value added” indicator

](img/B17530_04_007.jpg)

图 4.7-为“农业、林业和渔业，附加值”指标制作的图表

*图 4.7* 用橙色显示趋势线，用蓝色显示指示线。

1.  最后，一旦实验完成，我们把它上传到 Comet，就像这样:

    ```
    comet upload PATH/TO/THE/ZIP/FILE
    ```

如果您访问 Comet 仪表板，对应于您的实验，在 **Graphics** 菜单项下，您将看到所有更新的图形，如下面的屏幕截图所示:

![Figure 4.8 – Updated graphs under the Graphics menu item

](img/B17530_04_008.jpg)

图 4.8–图形菜单项下的更新图形

既然您已经完成了第一个用例，我们可以继续第二个用例。

# 第二个用例——模型优化

在 [*第 1 章*](B17530_01_ePub.xhtml#_idTextAnchor015) 、*Comet*概述中，您构建了一个简单的用例，允许您定义一个简单的回归模型并在 Comet 中显示结果。该示例使用了由`scikit-learn`库提供的糖尿病数据集，并且计算了不同种子值的**均方误差** ( **MSE** )。

在实验过程中，你肯定会注意到平均 MSE 大约是 3000。在本例中，我们展示了如何使用优化器的概念来降低 MSE 值。由于线性回归模型不提供任何要优化的参数，因此在本例中，我们将构建一个梯度推进回归模型，并调整它提供的一些参数。

在这个例子中，我们假设第一章*【Comet 概述】*中实现的代码正在运行。因此，请参考它的进一步细节。

这个例子的完整代码可以在 GitHub 存储库中找到，链接如下:[https://GitHub . com/packt publishing/Comet-for-Data-Science/tree/main/04/second-use-case-advanced](https://github.com/PacktPublishing/Comet-for-Data-Science/tree/main/04/second-use-case-advanced)。

具体来说，该示例是这样组织的:

*   创建和配置优化程序
*   优化模型
*   在 Comet 中显示结果

让我们从第一阶段开始:创建和配置优化器。

## 创建和配置优化程序

我们将通过超调以下参数来优化梯度推进回归器模型:

*   `n_estimators`—森林中树木的数量。我们将测试从 100 到 110 的值。
*   `max_depth`—每棵树的叶子数量。我们将测试从 4 到 6 的值。
*   `loss`—要优化的损失函数。我们将测试两种损失函数:`squared_error`和`absolute_error`。

为了配置 Comet 优化器，我们执行以下步骤:

1.  我们定义一个参数列表，如下:

    ```
    params = {  
       'n_estimators':{
           "type"         : "integer",
           "scalingType"  : "linear",
           "min"          : 100,
           "max"          : 110
        },
        'max_depth':{
           "type"         : "integer",
           "scalingType"  : "linear",
           "min"          : 4,
           "max"          : 6
        },
       'loss': {
           "type"         : "categorical",
           "values"       : ['squared_error', 'absolute_error']
       }
    }
    ```

对于每个参数，我们指定类型和其他属性，这些属性依赖于参数的类型(分类或整数)。

1.  我们定义一个配置变量，作为 Comet `Optimizer`类的输入，如下所示:

    ```
    config = {
        "algorithm": "grid",
        "spec": {
           "maxCombo": 0,
           "objective": "minimize",
           "metric": "loss",
           "minSampleSize": 100,
           "retryLimit": 20,
           "retryAssignLimit": 0,
        },
       "trials": 1,
       "parameters": params,
       "name": "GB Optiimizer"
    }
    ```

我们选择`grid`作为优化算法，并且我们指定我们想要最小化损失函数。我们还将`parameters`键设置为之前定义的`params`变量。

1.  我们构建 Comet 优化器，如下:

    ```
    from comet_ml import Optimizer
    opt = Optimizer(config) 
    ```

我们将之前定义的变量`config`作为输入参数传递给`Optimizer`类。

现在我们已经设置了 Comet 优化器，我们准备好优化模型了。

## 优化模型

假设您已经加载了糖尿病数据集，如 [*第 1 章*](B17530_01_ePub.xhtml#_idTextAnchor015) 、*Comet 概述*中所述。现在，我们将为优化器返回的每个参数组合构建一个实验。对于每个实验，我们将计算不同种子值的 MSE，正如已经在 [*第 1 章*](B17530_01_ePub.xhtml#_idTextAnchor015) 、*Comet 概述*中执行的。

以下是我们将采取的步骤:

1.  对于 Comet Optimizer 通过`get_experiments()`方法返回的实验列表中包含的每个实验，我们构建了一个`GradientBoostingRegressor()`对象，使用为当前实验定义的参数进行初始化。
2.  然后，对于种子列表中的每个`seed`实例，我们将数据集分成训练集和测试集，并拟合当前模型。
3.  最后，我们通过`log_metric()`方法计算 MSE 并记录在 Comet 中。

以下代码实现了前面描述的步骤:

```
for experiment in opt.get_experiments():
```

```
    model = GradientBoostingRegressor(
```

```
          n_estimators=experiment.get_parameter("n_estimators"),
```

```
          max_depth=experiment.get_parameter("max_depth"),
```

```
          loss=experiment.get_parameter("loss"),
```

```
    )
```

```
    for seed in seed_list:
```

```
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=seed)
```

```
        model.fit(X_train, y_train)
```

```
        y_pred = model.predict(X_test)
```

```
        mse = mean_squared_error(y_test,y_pred)
```

```
        experiment.log_metric("MSE", mse, step=seed)
```

运行前面的代码后，您就可以在 Comet 中看到结果了。所以，让我们进入最后一步:在 Comet 中显示结果。

## 在 Comet 上显示结果

我们总共进行了 40 次实验。我们可以通过增加 MSE 来排序实验，如 Comet 中的 [*第三章*](B17530_03_ePub.xhtml#_idTextAnchor063)*模型评估所述。结果如以下截图所示:*

![Figure 4.9 – The Comet dashboard after ordering the experiments by increasing MSE

](img/B17530_04_009.jpg)

图 4.9–通过增加 MSE 对实验排序后的 Comet 仪表板

`mushy_amberjack_2424`是 MSE 最低的实验。如果我们点击这个实验，我们可以在**超参数**部分查看它的参数，如下图所示:

![Figure 4.10 – Hyperparameters menu item in the Comet dashboard

](img/B17530_04_010.jpg)

图 4.10–Comet 仪表板中的超参数菜单项

*图 4.10* 仅显示了参数的子集。

可选地，我们可以记录所有的模型，将它们保存在注册表中，然后选择最佳的模型发送到生产中，如 Comet 中的 [*第 3 章*](B17530_03_ePub.xhtml#_idTextAnchor063) 和*模型评估中所述。*

此示例还绘制了 MSE 度量与种子的关系，如下面的屏幕截图所示:

![Figure 4.11 – MSE metric for the different experiments

](img/B17530_04_011.jpg)

图 4.11–不同实验的 MSE 度量

Comet 在运行过程中自动产生之前的输出。

# 总结

我们刚刚通过 Comet 中的高级概念完成了旅程！

在本章中，您学习了如何与您的协作者共享项目和工作区，以及如何将其公开或私有。此外，你还学到了一些关于实验和模型的高级概念。

关于实验，您了解了离线实验的概念，离线实验允许您在互联网连接不可用的情况下进行实验。此外，您还学习了现有实验的概念，它允许您继续进行实验，例如，通过丰富或扩展实验。

关于模型，您学习了如何通过 Comet 优化器的概念来优化模型参数。使用 Comet 优化器可以很容易地为给定的模型选择最佳参数。

最后，你用本章描述的概念扩展了第一章*【Comet 概述】*中定义的基本例子。

在下一章，你将回顾一些关于数据叙述的概念以及如何在 Comet 中执行它。

# 延伸阅读

*   巴蒂亚和卡鲁扎(2018 年)。Java 中的机器学习:用 Java 设计、构建和部署强大的机器学习应用的有用技术。帕克特出版有限公司
*   兰茨，B. (2019)。*带 R 的机器学习:预测建模的专家技术*。帕克特出版有限公司****