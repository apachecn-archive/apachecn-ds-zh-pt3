

# 八、用于机器学习的Comet

**人工智能** ( **AI** )是计算机执行通常由人类完成的操作和任务的能力。人工智能包括不同的子领域，如机器学习、自然语言处理、深度学习和时间序列分析。在这一章中，我们将重点讨论机器学习，在接下来的章节中，您将回顾 AI 的其他子领域，包括自然语言处理( [*第九章*](B17530_09_ePub.xhtml#_idTextAnchor192) *，Comet用于自然语言处理*)，深度学习( [*第十章*](B17530_10_ePub.xhtml#_idTextAnchor216) *，Comet用于深度学习*)，时间序列分析( [*第十一章*](B17530_11_ePub.xhtml#_idTextAnchor236) *，Comet用于时间序列分析*)。

机器学习旨在使用计算算法将数据转换为可用的模型。换句话说，机器学习试图建立从数据中学习的模型。您可以将机器学习算法用于不同的目的和不同的领域，例如描述一种现象、预测未来值或检测正在研究的现象中的异常。你已经在前面几章学习了一些关于机器学习的概念，包括探索性数据分析( [*第二章*](B17530_02_ePub.xhtml#_idTextAnchor043) *、Comet中的探索性数据分析*)和模型评估( [*第三章*](B17530_03_ePub.xhtml#_idTextAnchor063) *、Comet中的模型评估*)。在这一章中，我们将着重于模型训练，它包括建立正确的模型来表示给定的现象。

近年来，不同的开源库和工具可用于构建机器学习模型。在本章中，我们将重点介绍 scikit-learn 和 **XG-Boost** 。你应该已经熟悉了`scikit-learn`，因为你已经在前几章描述的例子中使用过它。您还学习了如何将 Comet 与`scikit-learn`集成。在本章中，您将实现一个完整的用例，这将允许您在 Comet 中实现一个完整的机器学习管道。

本章组织如下:

*   机器学习简介
*   回顾主要的机器学习模型
*   查看 scikit-learn 包
*   构建从设置到报告的机器学习项目

在进入第一步之前，让我们看看运行本章所用软件的技术要求。

# 技术要求

我们将使用 Python 3.8 运行本章中的所有实验和代码。可以在[https://www.python.org/downloads/](https://www.python.org/downloads/)官网下载，选择 3.8 版本。

本章中描述的示例使用了以下 Python 包:

*   `comet-ml 3.23.0`
*   `matplotlib 3.4.3`
*   `numpy 1.19.5`
*   `pandas 1.3.4`
*   `scikit-learn 1.0`
*   `shap 0.40.0`

我们已经在 [*第一章*](B17530_01_ePub.xhtml#_idTextAnchor015) 、*Comet概述*中描述了前五个包以及如何安装。因此，请参考后面的安装细节。

## 形状

**shap** 是一个 Python 包，它允许你计算 Shapley 值并绘制一些相关的图形。要安装`shap`包，您可以在终端中运行以下命令:

```
pip install shap
```

关于`shap`包的更多细节，你可以参考它的官方文档，可从以下链接获得:【https://shap-lrjball.readthedocs.io/en/latest/index.xhtml。

现在你已经安装了本章需要的所有软件，让我们继续学习如何使用 Comet 进行机器学习，从回顾机器学习的一些基本概念开始。

# 机器学习简介

机器学习是人工智能的一个子领域，旨在建立从数据中自动学习的模型。您可以将这些模型用于不同的目的，例如描述一个特定的现象、预测未来值或检测观察到的现象中的异常。近年来，由于来自不同来源(如社交媒体、开放数据、传感器等)的大量数据的传播，机器学习变得非常流行。

该部分的组织结构如下:

*   探索机器学习工作流程
*   机器学习系统的分类
*   探索机器学习的挑战
*   解释机器学习模型

先说第一步:探索机器学习工作流程。

## 探索机器学习工作流程

下图显示了最简单的机器学习工作流程:

![Figure 8.1 – The simplest machine learning workflow

](image/B17530_08_001.jpg)

图 8.1–最简单的机器学习工作流程

如果你已经知道你想要解决的问题，有四个步骤:

1.  **数据预处理**:通过执行所有的清理操作来准备数据，包括处理缺失值和异常、规范化、标准化和删除重复项。在这个阶段，您还将数据划分为训练集、开发集和测试集。
2.  **特征工程**:您选择数据中的一组特征作为模型的输入。
3.  **模型训练**:你在训练集上训练你的模型，重点是调优模型参数(超参数调优)。在这个阶段，通常要应用交叉验证。
4.  **模型评估**:您通过选择评估度量的集合来评估您的模型在 dev 集合上的性能。你已经在 [*第三章*](B17530_03_ePub.xhtml#_idTextAnchor063) ，*Comet*中学习了如何进行模型评估。

我们将在本章后面的*查看 scikit-learn 包*部分查看如何允许您实现前面的步骤。

现在你已经回顾了最简单的机器学习工作流程，我们可以进入下一步:对机器学习系统进行分类。

## 机器学习系统分类

您可以根据以下三个主要标准对机器学习系统进行分类:

*   *要解决的问题的性质*(监督、非监督、半监督和强化学习)
*   *使用的学习技术*(批量和在线学习)
*   *算法的内在本质*(基于实例和基于模型的学习)

让我们分别研究每个标准，从第一个标准开始:要解决的问题的性质。

### 要解决的问题的性质

在 [*第三章*](B17530_03_ePub.xhtml#_idTextAnchor063) *中，Comet*中的模型评估，你已经遇到了两种类型的机器学习模型:监督学习和非监督学习。还有一种技术，叫做半监督学习。以下是每项技术的主要目标:

*   **监督学习**的主要目的是学习输入和输出值之间的映射函数。在监督学习中，对于训练集中的每个输入值，您也知道输出值，目标是建立一个模型来学习从输入到输出的映射函数。输出值也称为标签。一旦构建了模型，就可以使用它来预测新的和不可见的输入值的标注。有两种类型的监督学习:分类和回归。你在 [*第三章*](B17530_03_ePub.xhtml#_idTextAnchor063) *回顾了分类和回归背后的基本概念，Comet*中的模型求值。
*   **无监督学习**的主要目的是基于相似性的一些标准对输入值进行分组。无监督学习的主要类型包括聚类、异常检测和降维。你在 [*第 3 章*](B17530_03_ePub.xhtml#_idTextAnchor063) 中回顾了集群背后的基本概念。我们将在*查看 scikit-learn 包*一节中查看其他两种类型的无监督学习。
*   **半监督学习**与监督学习具有相同的目标。然而，在半监督学习中，只有输入值的子集被标记，因此模型应该结合监督和非监督学习技术来预测输出值。

现在你已经学会了如何根据要解决的问题的性质对机器学习模型进行分类，我们可以继续下一个标准:使用的学习技术。

### 使用的学习技巧

如果考虑使用的学习技术，可以将机器学习系统分为以下两种类型:

*   **批量学习系统**:你离线执行训练过程，只需一次。你不能即时更新模型。通常，这种技术需要大量的计算资源。
*   **在线学习系统**:你可以对系统进行增量训练。通常，在每一步中，你向系统提供一小批数据，也称为*小批*。当您有可以提供给模型的连续数据流时，可以使用这种技术。

既然你已经学会了如何根据所使用的学习技术对机器学习模型进行分类，我们就可以继续讨论最后一个标准:算法的内部性质。

### 算法的内在本质

根据算法的内部性质，您可以进行以下类型的学习:

*   **基于实例的学习**:算法从训练集中的数据中学习，以找到可用于未来预测的数据模式。在实践中，该算法根据与训练集中数据的相似性来预测新样本的输出。这种类型的算法保留了每次预测时使用的原始定型集。这类算法的主要缺点是，如果训练集规模很大，模型规模可能会很大。例如，k-最近邻分类器就属于这类算法。
*   **基于模型的学习**:算法建立一个数学模型，近似训练集中的数据。一旦算法建立了模型，就可以删除原始数据集。决策树分类器是基于模型学习的一个例子。这类算法的主要缺点是在这种情况下你几乎不能应用在线学习。

既然你已经简要回顾了如何对机器学习系统进行分类，我们可以进入下一步:探索机器学习的挑战。

## 探索机器学习的挑战

当您构建一个机器学习模型时，您可能会遇到不同的挑战和问题，这些挑战和问题可以归为以下两大类:

*   数据挑战
*   模型挑战

让我们分别调查每个家庭，从第一个开始:数据挑战。

### 数据挑战

下表显示了最常见的数据挑战:

![](image/B17530_08_Table1.jpg)

图 8.2–最常见的数据挑战

该表还描述了应对上述挑战的一些可能对策。例如，如果数据量不足，可以搜索新数据，或者用新数据甚至合成数据来丰富数据集。

### 模型挑战

下表显示了最常见的模型挑战:

![](image/B17530_08_Table2.jpg)

图 8.3–最常见的模型挑战

与数据挑战相比，模型挑战更难解决，因为它们取决于您使用的特定模型。应对模型挑战的最佳方式是尝试不同的模型，并选择性能最佳的模型。

现在你已经简要回顾了主要的机器学习挑战，我们可以进入下一步:解释机器学习模型。

## 解释机器学习模型

通常，你会将机器学习模型视为一个黑盒，它将一些特征作为输入，并产生一个输出(也称为目标)。黑盒内部发生的事情取决于您使用的特定算法。要了解每个要素如何影响模型中的输出，您可以使用不同的技术。在这一部分，你将了解 SHAP。

**沙普利加法解释** ( **SHAP** )算法使用了沙普利值的概念，这个概念来源于博弈论，其中你有一个游戏和许多玩家。在机器学习中，游戏是模型的输出，玩家是输入特征。Shapley 值计算每个玩家对游戏的贡献。换句话说，它计算每个输入要素的贡献来构建模型的最终预测。

对于训练集中的每个观察，您有一个不同的游戏，因此您每次都可以使用 Shapley 值来分析单个输出。

Python 提供了一个名为`shap`的包，用于计算 Shapley 值并绘制一些有用的图表，这些图表有助于您了解每个输入要素对输出的贡献。`shap`库与 Comet 完全集成。

在本节的剩余部分，您将学习以下主题:

*   使用`shap`库
*   在 Comet 中集成`shap`库

让我们从第一个主题开始:使用`shap`库。

### 使用 shap 库

要计算的 Shapley 值，需要执行以下步骤:

1.  首先，您应该创建一个`Explainer`对象。`shap`库提供了不同类型的`Explainer`对象，包括但不限于`TreeExplainer`、`GradientExplainer`、`DeepExplainer`等。每个`Explainer`都与具体实现的算法相关。`Explainer`对象接收训练好的模型作为输入，如下面这段代码所示:

    ```
    import shap
    shap.initjs()
    explainer = TreeExplainer(model)
    ```

您导入库，然后需要调用`initjs()`函数，最后，您可以构建`Explainer`对象。在这种情况下，我们创造了一个`TreeExplainer`。

1.  一旦创建了对象，你就可以计算单个观察或多个观察的 Shapley 值，如下:

    ```
    shap_values = explainer.shap_values(X)
    ```

如果模型代表一个分类任务，`shap_values()`方法返回一个包含每个目标类的 Shapley 值的列表。

1.  使用计算出的 Shapley 值，可以绘制不同的图形，包括条形图、决策图、摘要图等。有关可用地块的完整描述列表，您可以参考以下链接中的`shap`官方文档:[https://shap . readthedocs . io/en/latest/API _ examples . XHTML # plots](https://shap.readthedocs.io/en/latest/api_examples.xhtml#plots)。

现在您已经看到了`shap`包的概述，我们可以研究如何在 Comet 中集成用`shap`生成的图形。

### 在 Comet 中集成 shap 库

要在 Comet 中集成一个或多个由`shap`库生成的图形，您可以执行以下步骤:

1.  在导入`shap`之前导入 Comet 库，如下面这段代码所示:

    ```
    from comet_ml import Experiment
    import shap
    shap.initjs()
    ```

2.  创建一颗Comet`Experiment`和一个`Explainer`物体，如下:

    ```
    experiment = Experiment()
    explainer = shap.Explainer()
    ```

3.  使用`shap`提供的任何一个函数绘制一个图形如下:

    ```
    shap_values = explainer.shap_values(X_test)
    shap.summary_plot(shap_values, X_test)
    ```

上述代码绘制了作为输入参数传递的 Shapley 值的汇总图。该图形将自动记录在 Comet 的**图形**部分下。

既然你已经学习了一些关于`shap`库的基本概念以及如何将它集成到 Comet 中，我们可以继续下一步:回顾主要的机器学习模型。

# 回顾主要的机器学习模型

机器学习模型是一种算法，它可以根据从一些训练数据中学习到的东西，对一些看不见的数据进行预测。如前一节所述，您可以将机器学习模型分为两类，这取决于您想要解决的特定任务:监督模型和非监督模型。

文献中存在许多机器学习模型。在本节中，您将回顾用于执行监督学习和非监督学习的最流行的模型。我们将详细关注以下模型:

*   监督学习
*   无监督学习

在本节的剩余部分，您将回顾最流行的机器学习模型的介绍。更多细节，你可以阅读*延伸阅读*部分推荐的书籍。先说第一类模型:监督学习。

## 监督学习

监督算法接收样本作为输入，执行一些计算，并返回预测值作为输出。如果输出是连续变量，你会有一个回归问题，但是如果输出是离散变量，比如一个类标签，你会有一个分类问题。

以下监督算法是一些最受欢迎的算法:

*   **线性回归**:算法搜索最适合输入样本的直线。
    *   **逻辑回归**:算法使用逻辑单元对输入样本建模。与名字所暗示的相反，逻辑回归被用来解决分类问题。
    *   **支持向量机** ( **SVM** ):该算法搜索一个超平面，该超平面由根据共同特征对训练数据进行分组。
    *   **朴素贝叶斯**:算法假设输入特征是独立的。它使用贝叶斯定理来产生结果。
    *   **决策树**:算法用一棵树来预测的输出。树的每个节点代表一个输入特征，而树的叶子代表可能的输出。
    *   **K-最近邻**:算法使用邻近度对输入样本进行分组并预测输出。
    *   **随机森林**:算法使用多棵树来预测输出。

在简要概述了监督学习的最流行算法之后，我们可以继续回顾非监督学习的算法。

## 无监督学习

无监督的算法旨在对相似的对象进行分组。无监督学习的一个典型例子是聚类。

无监督学习最流行的算法之一是 **k-means** ，它试图将数据集分成 k 个不重叠的子组。

现在你已经学习了主要的机器学习模型，我们可以进入下一个话题:对`scikit-learn`包的回顾。

# 查看 scikit-learn 包

`scikit-learn`是一个非常流行的用于机器学习的 Python 包。您已经在前面的章节中遇到了这个包。特别是，您关注了一些使用监督学习和模型选择的例子。但是`scikit-learn`包还提供了其他的类和方法，如下图所示:

![Figure 8.4 – An overview of the scikit-learn package

](image/B17530_08_004.jpg)

图 8.4–sci kit-learn 包概述

该包被分成以下子包:

*   预处理
*   降维
*   型号选择
*   监督学习
*   无监督学习

让我们简单地研究一下每个子包，从第一个开始:预处理。要更深入地分析每个子包，可以参考本章末尾的*进一步阅读*部分。

## 预处理

预处理包含所有允许我们在将数据集作为机器学习模型的输入之前对其进行操作的类和方法。您还可以使用 pandas 提供的方法来替代预处理子包中提供的几乎所有类和方法。

预处理包括以下类:

*   **特征缩放**进行数据标准化和规范化
*   **特征二进制化**将特征转换成二进制值
*   **特征编码**将分类特征转换成数值
*   **非线性变换**将非线性变换应用于特征，如功率变换
*   **其他类**执行其他特定的转换

既然您已经简要回顾了预处理包提供的最重要的类,我们可以分析下一个子包:维度缩减。

## 降维

降维是将输入特征的数量从高维空间降低到低维空间的一种技术。

当您有数百万个输入要素时，降维尤其有用，这会减慢模型训练过程。然而，虽然使用降维技术加快了训练过程，但仍然会导致信息的丢失。

降维对于数据可视化也很有用，因为如果您将要素数量减少到两三个，您可以轻松地绘制它们并执行可视化探索性数据分析。

*图 8.4* 显示了`scikit-learn`提供的执行维度缩减的最重要技术。其中最受欢迎的技术是**主成分分析** ( **PCA** )。下面这段代码展示了如何在`scikit-learn`中实现 PCA:

```
from sklearn.decomposition import PCA
```

```
pca = PCA(n_components=2)
```

```
X_reduced = pca.fit_transform(X)
```

我们使用了`PCA`类，它接收最终的特征维度作为输入(`n_components`)。要获取缩减的要素数据集，应该对输入要素调用`fit_transform()`方法(`X`)。

既然您已经看到了降维包的概述，我们可以分析下一个子包:模型选择。

## 型号选择

型号选择包括以下技术，帮助您为您的问题选择最佳型号:

*   交叉验证
*   超参数调谐
*   度量和曲线

让我们研究前两种技术，从交叉验证开始。

度量和曲线

您记得模型选择还包括模型评估的度量和曲线的研究。我们在 [*第三章*](B17530_03_ePub.xhtml#_idTextAnchor063) *中回顾了这方面的内容，Comet*中的模型评估，详细内容可以参考那个。

### 交叉验证

**交叉验证**是一种允许你在数据集上计算机器学习算法性能的技术。k 倍交叉验证是最流行的执行交叉验证的技术之一。它将数据集分成 k 个不重叠的褶皱，然后拟合 k 个模型，并计算每个模型的性能。在每次迭代中，它使用 k-1 个折叠作为训练集，剩余的折叠作为测试集，如下图所示:

![Figure 8.5 – k-fold cross-validation with k = 6

](image/B17530_08_005.jpg)

图 8.5–k = 6 时的 k 倍交叉验证

该图显示了在 k = 6 的情况下，k-fold 交叉验证算法如何在每次迭代中构建训练集和测试集。k 的通常值是 10，但是，通常，您应该运行个不同的测试来计算 k 的最个合适的值。在本章的最后一节，您将在一个实际的例子中学习一个计算 k 的最佳值的实用策略。

模型的性能计算为 k 个模型结果的平均值。

`scikit-learn`提供了`KFold`类来执行基本的 k-fold 交叉验证。该类接收以下参数作为输入:

*   `n_splits`:折叠次数，代表参数 k。
*   `shuffle`:一个布尔值，表示在将数据集拆分成多个折叠之前是否对其进行洗牌。
*   `random_state`:如果`shuffle`是`True`，`random_state`影响`shuffle`如何进行。

`scikit-learn`还提供了其他类来进行交叉验证，比如`StratifiedKFold`和`GroupKFold`。关于它们的更多细节，你可以参考`scikit-learn`官方文档，可从以下链接获得:[https://sci kit-learn . org/stable/modules/cross _ validation . XHTML](https://scikit-learn.org/stable/modules/cross_validation.xhtml)。

既然您已经回顾了交叉验证背后的基本概念，我们可以继续下一点:超参数调优。

### 超参数调谐

超参数调整允许您搜索特定机器学习算法的最佳参数。通常，您结合交叉验证来执行超参数调优。您已经在 [*第四章*](B17530_04_ePub.xhtml#_idTextAnchor081) 、*工作区、项目、实验和模型*中学习了如何在 Comet 中执行超参数调优。在本章中，您将回顾由`scikit-learn`提供的类和方法来执行超参数调整。

一般来说，定义一个要测试的参数网格，并将其作为算法的输入进行传递，该算法适用于与不同参数组合一样多的模型。最后，算法计算出性能最好的模型，并将其作为最佳模型返回。

`scikit-learn`实施不同的算法来执行超参数调整，包括但不限于以下算法:

*   `GridSearchCV`:算法测试所有可能的参数组合。
*   `RandomizedSearchCV`:算法对参数进行随机搜索。
*   `HalvingGridSearchCV`:该算法首先测试一个小数据集上的所有参数，然后迭代地丢弃性能最低的参数，并通过向数据集添加新样本来继续对其余参数进行测试。

在本章的最后一节，你会看到一个使用`GridSearchCV`算法的实际例子。有关如何使用其他算法的更多详细信息，可以参考以下链接中的`scikit-learn`官方文档:[https://scikit-learn . org/stable/modules/classes . XHTML # module-sk learn . model _ selection](https://scikit-learn.org/stable/modules/classes.xhtml#module-sklearn.model_selection)。

既然您已经回顾了超参数调整背后的基本概念，我们可以继续下一点:监督和非监督学习。

## 监督和非监督学习

`scikit-learn`实现了最流行的算法来执行监督学习和非监督学习。在所有情况下，要实现一个模型，你应该执行以下步骤:

1.  创建模型如下:

    ```
    model = MyModel()
    ```

你应该用`scikit-learn`提供的特定类替换`MyModel()`类，比如`KNeighborsClassifier`或者`LinearRegression`。

1.  用训练集拟合模型如下:

    ```
    model.fit(X_train, y_train)
    ```

2.  使用训练好的模型预测看不见的输入的输出，如下:

    ```
    y_pred = model.predict(X_test)
    ```

前面的步骤描述了构建机器学习模型时应该执行的最基本的操作。在本章的下一节，您将实现一个更复杂的例子，该例子还考虑了交叉验证和超参数调优以及与 Comet 的集成。那么，让我们继续这个实际的例子。

# 构建从设置到报告的机器学习项目

在本节中，您将进一步完善在 [*第三章*](B17530_03_ePub.xhtml#_idTextAnchor063) 、*Comet*中模型评估中描述的钻石切工的实际示例，并部署在 [*第六章*](B17530_06_ePub.xhtml#_idTextAnchor126) 、*将Comet集成到 DevOps* 中。在这一章中，你将着重于以下几个方面:

*   回顾情景
*   选择最佳模型
*   计算 SHAP 值
*   构建最终报告

让我们从第一步开始:回顾场景。

## 回顾场景

作为我们的用例，我们将使用 ggplot2 在麻省理工学院许可(【https://ggplot2.tidyverse.org/reference/diamonds.xhtml】)下提供的`diamonds`数据集，该数据集在 Kaggle 上以 CSV 文件()的形式提供。相对于第三章 中*图 3.3* 中已经描述的原始版本，我们使用同一章中制作的清理版本，如下图所示:

![Figure 8.6 – The cleaned version of the diamonds dataset

](image/B17530_08_Table3.jpg)

图 8.6–钻石数据集的清理版本

数据集包含 53，940 行和 10 列。该场景的目标是构建一个分类模型，当给定一组输入特征时，该模型预测目标类别(金、银)。我们假设输入特征存储在名为`X`的变量中，目标存储在名为`y`的变量中，如下面这段代码所示:

```
X = df.drop("target", axis = 1)
```

```
y = df["target"]
```

我们假设数据集是作为`pandas`数据帧加载的。我们通过编码标签和缩放数值来预处理数据集。关于如何执行这些操作的更多细节，可以参考第三章[*。*](B17530_03_ePub.xhtml#_idTextAnchor063)

现在，您已经查看了所采用的数据集，我们可以进入下一步:选择最佳模型。

## 选择最佳模型

为了选择最佳模型，我们比较了以下四种分类算法的性能，如已经在 [*第 3 章*](B17530_03_ePub.xhtml#_idTextAnchor063) *中描述的，Comet* 中的模型评估:随机森林、决策树、高斯朴素贝叶斯和 k-最近邻。对于每种算法，我们通过执行以下步骤来搜索最佳模型:

*   搜索交叉验证的最佳折叠数
*   使用交叉验证执行超参数调整

我们将为每个执行的测试构建一个 Comet 实验。我们使用准确性作为衡量标准来选择最佳模型。

让我们从第一步开始:寻找交叉验证的最佳折叠数。

### 搜索交叉验证的最佳折叠数

为了熟悉交叉验证，我们首先运行一个简单的实验，在固定折叠数(10)的情况下，比较使用和不使用交叉验证的每个算法的性能。当您在没有交叉验证的情况下建立模型时，应该使用定型/测试拆分操作来拟合定型集上的模型，并在测试集上对其进行评估。另一方面，如果使用交叉验证构建模型，则可以使用整个数据集，因为交叉验证已经执行了训练/测试拆分。执行以下步骤，找到交叉验证的最佳折叠数:

1.  我们将数据集分为训练集和测试集，如下所示:

    ```
    from sklearn.model_selection import train_test_split
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)
    ```

我们为测试集保留 10%的记录，其余的为训练集保留。

1.  我们定义一个名为`run_experiment()`的函数，它在 Comet 中构建一个`Experiment`，然后在 Comet 中记录作为参数传递的模型的准确性，无论是否使用交叉验证，如下所示:

    ```
    from sklearn.model_selection import KFold
    from sklearn.model_selection import cross_val_score
    from sklearn.metrics import accuracy_score 
    import numpy as np
    def run_experiment(ModelClass, name, n_splits):
        experiment = Experiment()
        experiment.set_name(name)
        experiment.add_tag(name)

        cv = KFold(n_splits=n_splits, random_state=1, shuffle=True)
        model = ModelClass()
        # calculating accuracy with KFold
        scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv)
        experiment.log_metric('accuracy-cv', np.mean(scores))

        # calculating accuracy without KFold
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        experiment.log_metric('accuracy', accuracy_score(y_test, y_pred))
    ```

我们使用带有参数`shuffle=True`的`KFold()`来执行数据集的初始混洗。为了计算 k 倍情况下的精度，我们使用了`cross_val_score()`函数。我们将通过交叉验证获得的准确度记录为`accuracy-csv`，将未通过交叉验证获得的准确度记录为`accuracy`。

1.  现在，我们可以简单地通过调用以下四种算法的`run_experiment()`函数来运行实验:

    ```
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.tree import DecisionTreeClassifier
    from sklearn.naive_bayes import GaussianNB
    from sklearn.neighbors import KNeighborsClassifier

    n_splits = 10
    run_experiment(RandomForestClassifier, 'RandomForest',n_splits)
    run_experiment(DecisionTreeClassifier, 'DecisionTreeClassifier',n_splits)
    run_experiment(GaussianNB, 'GaussianNB',n_splits)
    run_experiment(KNeighborsClassifier, 'KNeighborsClassifier',n_splits)
    ```

我们将拆分的数量设置为 10，因此对于 K-Fold 的每次迭代，数据集的 90%保留给训练集，10%保留给测试集。

1.  现在我们可以在Comet上看到结果。我们进入 Comet 仪表盘，点击**实验**标签。然后，我们通过单击**列**按钮，然后单击**持续时间**、**精度-CV** 和**精度**，选择以下列来显示结果。下图显示了此操作的结果:

![Figure 8.7 – The results of experiments in Comet

](image/B17530_08_007.jpg)

图 8.7–Comet 中的实验结果

我们注意到，总的来说，所有的算法在交叉验证的情况下都表现得更好。高斯朴素贝叶斯是最快的算法，而随机森林是最慢的。

1.  现在我们构建一个**平行坐标图**，它显示了每个算法在两个指标上的行为，**精确度-cv** 和**精确度**。Comet提供了平行坐标图作为内置面板，你只需点击**添加** | **新建面板** | **内置** | **平行坐标图**即可添加。当弹出窗口打开时，您可以选择**精度**作为目标变量，并在 **Y 轴**上添加**精度-cv** 。下图显示了生成的面板:

![Figure 8.8 – The parallel coordinates chart for accuracy with and without cross-validation

](image/B17530_08_008.jpg)

图 8.8–有交叉验证和无交叉验证的准确度平行坐标图

到目前为止，我们已经将折叠数设置为 10。然而，这可能不是最佳选择。为了选择折叠次数的最佳值，我们需要在下面的步骤中改进前面的代码。

1.  我们定义了一个名为`run_experiment_kfold_numbers()`的函数，它接收的最大折叠数作为输入，并在折叠数变化时计算作为参数传递的模型的精度。然后，该函数返回得分最高的折叠数。下面这段代码实现了所描述的操作:

    ```
    def run_experiment_kfold_numbers(ModelClass, name, max_n_splits):
        experiment = Experiment()
        experiment.set_name(name + '-kfold')
        experiment.add_tag(name + '-kfold')
        experiment.add_tag('kfold')

        scores_list = []
        min_n_splits = 2
        for n_splits in range(min_n_splits, max_n_splits):
            model = ModelClass()
            # calculating accuracy with KFold
            cv = KFold(n_splits=n_splits, random_state=1, shuffle=True)
            scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv)
            mean_scores = np.mean(scores)
            scores_list.append(mean_scores)
            experiment.log_metric('accuracy-cv', mean_scores, step = n_splits)

        # get the best number of folds
        best_score_value = np.max(scores_list)
        return scores_list.index(best_score_value) + min_n_splits
    ```

我们已经创建了一颗Comet`experiment`，并为其添加了`kfold`标签。此外，我们将最小折叠数设置为`2`，以使交叉验证在最小条件下工作。

1.  现在我们可以为每个模型调用如下函数:

    ```
    max_n_splits = 20
    random_forest_kfold_value = run_experiment_kfold_numbers(RandomForestClassifier, 'RandomForest',max_n_splits)
    decision_tree_kfold_value = run_experiment_kfold_numbers(DecisionTreeClassifier, 'DecisionTreeClassifier',max_n_splits)
    gaussian_nb_kfold_value = run_experiment_kfold_numbers(GaussianNB, 'GaussianNB',max_n_splits)
    knn_kfold_value = run_experiment_kfold_numbers(KNeighborsClassifier, 'KNeighborsClassifier',max_n_splits)
    ```

我们已经将最大折叠数(`max_n_splits`)设置为`20`。

1.  运行实验后，我们准备在 Comet 中看到结果。例如，您可以选择`KNeighborsClassifier-kfold`并在改变折叠次数的同时分析精度趋势，如下图所示:

![Figure 8.9 – Accuracy versus the number of folds for the k-nearest neighbor classifier

](image/B17530_08_009.jpg)

图 8.9-k-最近邻分类器的准确度与折叠数的关系

1.  现在我们可以比较所有生产的模型。由于当前的 Comet 项目不仅包含刚刚完成的实验，还包含在本节开始时执行的那些实验，我们需要构建一个过滤器，只显示最新的实验。这些实验有一个等于`kfold`的标签。我们可以在 Comet 仪表板中建立一个过滤器，如第 4 章 中的 [*所述，只选择那些实验。您可以选择**滤镜**按钮，然后**添加滤镜** | **标签** | **为**|**kfold**|**Done**。您应该只能看到与可变折叠数相关的实验，如下图所示:*](B17530_04_ePub.xhtml#_idTextAnchor081)

![Figure 8.10 – The experiments with a tag equal to kfold shown in the Comet dashboard

](image/B17530_08_010.jpg)

图 8.10–Comet 仪表板中显示的标签等于 kfold 的实验

1.  在 Comet 中，您可以添加一个新面板，显示所有实验中与折叠次数相比的精确度。可以点击**添加** | **新增面板** | **内置** | **折线图**。在 **Y 轴**上，您可以选择**精度-cv** ，然后将其他字段保留为默认值。最后，点击**完成**。下图显示了生成的面板:

![Figure 8.11 – Accuracy versus the number of folds for all of the algorithms

](image/B17530_08_011.jpg)

图 8.11-所有算法的精确度与折叠次数的关系

该面板是交互式的，因此如果您单击一行，您应该会看到相关模型的名称。

实现的代码返回每个模型的最佳折叠数；因此，我们可以使用获得的值来执行模型优化。因此，您已经准备好进入下一步:使用交叉验证执行超参数调优。

### 使用交叉验证执行超参数调整

在 [*第四章*](B17530_04_ePub.xhtml#_idTextAnchor081) *、工作空间、项目、实验和模型*中，您已经学习了 Comet Optimizer 的概念，它允许您执行模型优化。在本节中，您将使用`scikit-learn`提供的`GridSearchCV()`类来调整每个模型的超参数。

我们将执行以下步骤:

1.  我们定义了以下名为`run_experiment_grid_search()` :

    ```
    from sklearn.model_selection import GridSearchCV
    def run_experiment_grid_search(ModelClass, name, n_splits, params):
        model = ModelClass()
        clf = GridSearchCV(model, params, cv = n_splits)
        clf.fit(X_train, y_train)

        for i in range(len(clf.cv_results_['params'])):
            experiment = Experiment()
            experiment.add_tag(name + '-gs')
       experiment.add_tag('gs')
            for k,v in clf.cv_results_.items():
                if k == "params":
                    experiment.log_parameters(v[i])
                else:
                    experiment.log_metric(k,v[i])
    ```

    的函数

该函数接收与`run_experiment()`函数相同的参数以及要调整的参数字典。然后，它使用作为参数传递的模型构建一个`GridSearchCV()`对象，并对其进行拟合。最后，对于每个被测试的模型，该函数构建一个 Comet 实验，并记录它的参数和度量。

1.  我们运行实验，然后访问 Comet 中的相关项目。由于我们已经将实验保存在与交叉验证示例相同的项目中，我们需要构建一个过滤器，只显示与超参数调整相关的实验。在 Comet 仪表盘中，您可以选择**滤镜**按钮，然后**添加滤镜** | **标签**|**is**|**GS**|**Done**。
2.  现在我们按模型分组实验。要执行此操作，您可以通过按钮点击**组，然后**标记** | **完成**。**
3.  您可以通过单击 columns 按钮并添加您喜欢的列来选择要显示的列。例如，您可以选择您已经调整的参数。
4.  最后，您可以通过点击**排序**按钮降低平均测试分数来对结果进行排序，然后选择平均测试分数作为标准。您也可以单击底部箭头来设置递减顺序。您还应该通过点击 **X** 按钮来删除弹出窗口中出现的所有其他参数。下图显示了决策树分类器的部分结果屏幕:

![Figure 8.12 – The results of experiments in Comet for the decision tree classifier

](image/B17530_08_012.jpg)

图 8.12–Comet 中决策树分类器的实验结果

上图显示了使用决策树分类器的每个实验的持续时间、主要测试分数(准确性)和测试标准。通过降低平均测试分数来对实验进行排序，从而使得识别最佳模型变得容易。

1.  最终，我们可以从我们测试的不同算法中选择最适合我们目的的模型。对于示例，我们可以选择平均测试分数大于 0.94 且持续时间小于或等于 1 秒的最佳模型。您可以在 Comet 中轻松执行这项任务，如下所示:
    1.  您可以选择**滤镜**按钮，去掉当前滤镜，然后选择**添加滤镜**|**mean _ test _ score**|**大于等于**|**0.9465660707805703**|**Done**。
    2.  然后，您可以添加同一个弹出窗口中剩余的另一个过滤器，并单击**添加过滤器** | **持续时间** | **小于或等于** | **1 秒** | **完成**。您应该会看到最佳模型，如下图所示:

![Figure 8.13 – The best model of the experiments

](image/B17530_08_013.jpg)

图 8.13–实验的最佳模型

最佳模型是平均测试分数等于 0.946 且持续时间为 1 秒的决策树。

现在你已经学会了如何使用 Comet 选择最佳模型，我们可以进入的下一步:计算 SHAP 值。

## 计算 SHAP 值

在 Comet 仪表板中，您已经看到最佳模型是具有以下参数的决策树:

*   `min_samples_split=4`
*   `criterion='gini'`

我们可以为这个模型建立一个新的实验，并计算单次观察的 Shapley 值。

我们进行如下操作:

1.  首先，我们导入所有需要的库并构建一个 Comet 实验，如下:

    ```
    from comet_ml import Experiment
    import shap
    shap.initjs()
    experiment = Experiment()
    experiment.set_name('BestModel')
    ```

2.  然后，我们建立并训练模型如下:

    ```
    from sklearn.tree import DecisionTreeClassifier
    import numpy as np
    model = DecisionTreeClassifier(min_samples_split=4, criterion='gini')
    model.fit(X_train,y_train)
    ```

3.  因为模型是决策树，我们创建一个`TreeExplainer`对象如下:

    ```
    explainer = shap.TreeExplainer(model)
    ```

4.  为了简单起见，我们决定计算与测试集中的第一个样本相关的 Shapley 值，因此我们将其提取如下:

    ```
    sample = X_test.iloc[0]
    ```

5.  现在我们生成决策图。由于我们的模型是一个分类器，我们应该计算每个目标类的 Shapley 值。因此，我们定义了一个函数，它接收目标类(0 或 1)作为输入，并绘制决策图，如下所示:

    ```
    def decision_plot(target):
        print(f"target: {target}")
        shap_values = explainer.shap_values(sample)[target]
        print(f"expected value: {explainer.expected_value[target]}")
        shap.decision_plot(explainer.expected_value[target], shap_values, sample)
    ```

该函数通过调用解释器的`shap_values()`方法来计算 Shapley 值。然后，它调用`decision_plot()`函数，该函数接收期望值、Shapley 值和原始样本作为输入。

1.  我们为每个目标类调用`decision_plot()`函数如下:

    ```
    decision_plot(0)
    decision_plot(1)
    ```

下图显示了结果图:

![Figure 8.14 – The decision plot

](image/B17530_08_014.jpg)

图 8.14-决策图

左边是与目标类 0 相关的决策图，而右边是目标类 1 的图。垂直线代表每个类别的预测值。您可以看到目标类 0 的预测值大于目标类 1 的预测值。这对应于实际类别为 0 的测试集中的真实数据。决策图显示了每个特性(在图的左边)对最终结果的贡献。红线表示正贡献，而蓝线表示负贡献。

1.  现在，我们构建一个概要图如下:

    ```
    shap_values = explainer.shap_values(X_test)
    shap.summary_plot(shap_values, X_test)
    ```

首先，我们通过`shap_values()`方法从解释器中提取 Shapley 值，然后我们为测试集中的所有观察值调用`summary_plot()`函数。下图显示了结果图:

![Figure 8.15 – The summary plot

](image/B17530_08_015.jpg)

图 8.15–汇总图

前面的图显示了测试集中所有观察值的平均 Shapley 值如何依赖于输入特征。你可以看到**深度**是最有影响力的特征，其次是**克拉**和**价格**。不太重要的特性是**清晰度**。

1.  我们运行实验，可以在 Comet 的**图形**部分看到结果，如下图所示:

![Figure 8.16 – The logged Shapley graphs in Comet

](image/B17530_08_016.jpg)

图 8.16–Comet 中记录的 Shapley 图

Comet实验类已经自动记录了`shap`产生的图。

既然您已经学习了如何计算 Shapley 值并将其记录到 Comet 中，我们可以继续进行最后一步:构建最终报告。

## 建筑最终报告

现在你已经准备好构建最终报告了。在这个示例中，我们将使用刚刚生成的图表构建一个简单的报告。作为进一步的练习，你可以通过应用在 [*第五章*](B17530_05_ePub.xhtml#_idTextAnchor105) 、*中学习的概念来改进它们，在Comet*中建立一个叙述。您将创建包含以下三个部分的报告:

*   交叉验证
*   超参数调谐
*   沙普利值

让我们从的第一部分开始:交叉验证。

### 交叉验证

在 Comet 仪表板中，您可以执行以下操作:

1.  点击**报告**选项卡，然后在**新报告**上添加报告名称，如*选择钻石切工预测的最佳模型*。最后，点击**保存**。
2.  只需单击位于屏幕左上角的路径栏上的项目名称，即可返回到主项目，如下图所示:

![Figure 8.17 – A quick way to come back to the main project through the path bar

](image/B17530_08_017.jpg)

图 8.17–通过路径栏返回主项目的快捷方式

1.  在**面板**部分，您应该能够看到*图 8.8* 和*图 8.11* 中描述的图表。如果没有，您可以通过删除所有过滤器来查看它们。
2.  点击**添加**按钮，然后**添加到报告**，然后你的报告名称。包含图表的新部分将添加到您的报告中。如果您访问该报告，您可以自定义我们刚刚创建的部分。

### 超参数调谐

要在超参数调整报告中添加新的部分，您可以执行以下操作:

1.  您可以在报告中创建一个与超参数调整相关的新部分。要添加新的部分，只需点击前一部分的末尾。出现一个名为**的新按钮，在这里添加部分**。你可以点击它来添加一个新的部分。
2.  在**实验下**部分的新建部分，你可以选择**添加滤镜** | **标签** | **被** | **gs** 。我们只是重复上一节中为交叉验证执行的步骤，这次是为了超参数调整。如果您想将所有的实验添加到面板中，您应该点击位于该部分右下方的**显示 1-25** 文本按钮附近的箭头，并选择`50`。
3.  然后，点击**添加面板** | **内置** | **条形图** | **添加**。现在，您可以通过选择 **Y 轴**的 **mean_test_score** 以及选择 **Y 轴范围**来定制您的图表。最后，点击**完成**按钮。

### 沙普利值

您可以向报告添加一个新的部分，如前一部分所述。然后，在这个新部分中，您可以执行以下操作:

1.  在**实验**部分的新建部分，你可以选择**添加滤镜** | **名称** | **是** | **BestModel** 。
2.  现在你可以通过点击**添加面板**按钮来添加面板，然后**精选** | **显示图片** | **添加** | **完成**。
3.  一个新的面板被添加到报告中，包含图 8.16 中描述的数字。

报告终于准备好了。您可以通过应用前面章节中描述的技术来进一步改进它。

# 总结

我们刚刚完成了在`scikit-learn`中建立机器学习模型并在 Comet 中跟踪它的旅程！

在本章中，我们描述了一些关于机器学习的一般概念以及`scikit-learn`包的主要结构。我们还阐述了一些重要的概念，比如交叉验证、超参数调整和 Shapley 值。

在本章的最后一部分，您实现了一个实际的用例，向您展示了如何在 Comet 中跟踪一些机器学习实验，以及如何用实验结果构建一个报告。

在下一章，我们将回顾与自然语言处理相关的基本概念，以及如何在 Comet 中执行它。

# 延伸阅读

*   Géron，A. (2019)。使用 Scikit-Learn、Keras 和 TensorFlow 进行机器学习:构建智能系统的概念、工具和技术。奥赖利媒体公司。
*   Raschka，S. Liu，Y.H .和 Mirjalili V. (2022 年)。 *P 机器学习用 PyTorch 和 Scikit-Learn* 。帕克特出版有限公司