<html xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" lang="en" xml:lang="en" xsi:schemalocation="http://www.w3.org/2002/06/xhtml2/ http://www.w3.org/MarkUp/SCHEMA/xhtml2.xsd">
<head>
    <title>Unknown</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="../stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="../page_styles.css" rel="stylesheet" type="text/css"/>
</head>
  <body class="calibre">
© Joshua Cook 2017
Joshua CookDocker for Data Science<a href="02.html" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">https://doi.org/10.1007/978-1-4842-3012-1_2</a>

<!--Begin Abstract--><h1 class="chaptertitle" xml:lang="en">2.码头工人</h1>

Joshua Cook<sup class="calibre5">1 </sup>
(1)Santa Monica, California, USA

 


<!--End Abstract-->Docker is a way to isolate a process from the system on which it is running. It allows us to isolate the code written to define an application and the resources required to run that application from the hardware on which it runs. We add a layer of complexity to our software, but in doing so gain the advantage of ensuring that our local development environment will be identical to any possible environment into which we would deploy the application. If a system can run Docker, a system can run our process. With the addition of a thin layer of abstraction we become hardware independent. On its face, this would seem to be an impossible task. As of 2014, there were 285 actively maintained Linux distributions and multiple major versions of both OS X and Windows. How could we possibly write a system to allow for all possible development, testing, and production environments?
Docker solves this problem via 
            containerization
            
            
          . We will never be able to guarantee that our remote environments will be running the same OS as we are locally. We often know for a fact that it never will (I develop using Mac OS X and usually deploy to systems running Ubuntu). That said, as visualized in Figure <a href="#Fig1" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">2-1</a>, we can guarantee that both our development and deployment environments will be able to run the Docker engine. We write our application to be run as a container by the Docker engine—we containerize our application—and thus ensure compatibility across platforms. We are not concerned about the underlying operating system or hardware, only that it is running the Docker engine.<img src="Images/A439726_1_En_2_Fig1_HTML.jpg" alt="A439726_1_En_2_Fig1_HTML.jpg" class="calibre40"/>
Figure 2-1.Deploying across heterogenous infrastructure
                
              . Note that the technology stack might be completely different across systems, but we deploy an identical container.



    
Using the suite of Docker tools we build our applications to run as a Docker container. Once built, we verify our images by running them on our local system. Having confirmed this, it is trivial to deploy our containerized application to a remote machine that is running the Docker engine. We run the system in exactly the same way regardless of operating system or hardware. Docker lets developers be OS agnostic.
<h2 class="heading2">Docker 不是一个虚拟机</h2>
Docker is not a Virtual Machine (VM)
         technology
        .<a href="#Fn1" id="Fn1_source" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1"><sup class="calibre6">1</sup></a> That said, it is useful to briefly look at what VM technology is. Many will be familiar with VM technology, especially as a VM being run using a tool such as VirtualBox. Using one of these tools, a single computer, the host runs many VM instances, guests. Each guest uses a large file on disk to define its isolated operating and file system. Each guest runs as a single, resource-intensive process on the host CPU.
For the purposes of most users, the guest behaves as a stand-alone computer, very similar in practical use to the host machine on which it runs. In other words, a VM feels like 
              virtualized hardware
              
            . Downsides to VM technology include the consumption of large swaths of hard drive space to store a bulky operating system and the consumption of considerable CPU resources in maintaining all of the processes required of a full OS.

<h2 class="heading2">集装箱化</h2>
Containerization is a virtualization method
        , but containers are not VMs in the way that most think of them. The confusion is understandable. Like containers, it is even possible to define VMs using the software Vagrant. But to be clear, a VM is using one kind of virtualization. Containerization is a different type of virtualization altogether.
The <a href="https://linuxcontainers.org/lxc/introduction/" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">Linux Containers</a> (LXC) project
         is a vendor-neutral project designed to provide a native set of tools and libraries for the containment of processes from the broader Linux system on which they are being run. LXC runs in the same operating system as its host. The stated goal of LXC is “to create an environment as close as possible to a standard Linux installation but without the need for a separate kernel.” Put another way, LXC allows processes to be containerized.
Containerization seeks to virtualize processes
          
        . Thus, a containerized process is running in an environment optimized for its purposes, but is being run using the system resources of the host computer. The LXC library has been carefully designed to allow a containerized process to run as a virtualized process (see Figure <a href="#Fig2" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">2-2</a>) on its host system without the need to run a full operating system. LXCs have low overheads and better performance compared to VMs.<img src="Images/A439726_1_En_2_Fig2_HTML.jpg" alt="A439726_1_En_2_Fig2_HTML.jpg" class="calibre41"/>
Figure 2-2.A virtualized process
                  
                
              



      
In June of 2015, Docker helped to launch the <a href="https://www.opencontainers.org/about" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">Open Container Project</a>. Docker donated its library runc to serve as an iteration upon LXC. While Docker is no longer running LXC at its core, the principle remains: <a href="https://blog.docker.com/2016/03/containers-are-not-vms/" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">Docker is not a virtual machine</a>. Docker is leveraging virtualization technology to achieve the isolation of processes or services from the host systems.
Throughout this text, you will be consistently faced with two problems in running your processes via Docker: networking (connecting to your processes) and maintaining the persistence of data. With these latest innovations in managing containers, Docker is now moving toward stronger tools for managing both issues. With Docker managing networking and persistence, once these processes have been abstracted or containerized they can be run at will on any system.

<h2 class="heading2">容器化的应用程序</h2>
On top of providing a method for running a containerized application
          
        , Docker also provides a set of tools for building applications as microservices. Docker’s build system provides a system for packaging an application with all of its dependencies. Those who are comfortable with working with Ruby’s bundler and Gemfile system or Python’s conda and environment.yml system will be right at home in using a Dockerfile to define the requirements of their system using a minimal text file. Using this Dockerfile, stateless and immutable applications are defined to run as “compiled” processes on a host system running the Docker engine. In doing so, Docker attempts to liberate the software engineer from dependency on the hardware on which their code will run.

<h2 class="heading2">Docker 容器生态系统</h2>
You begin looking at Docker by focusing on the ecosystem of the container. Later, you will leverage Docker’s tools for composing larger systems with the containers you have built. In the immediate ecosystem (see Figure <a href="#Fig3" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">2-3</a>) of the Docker container, it is important to keep track of the following concepts
          
        
        
              
              
            :<img src="Images/A439726_1_En_2_Fig3_HTML.jpg" alt="A439726_1_En_2_Fig3_HTML.jpg" class="calibre42"/>
Figure 2-3.The Docker ecosystem
                  
                
              



<ul class="unorderedlistmarkbullet"><li class="calibre15">docker cli 客户端</li>
<li class="calibre15">主持人</li>
<li class="calibre15">Docker 引擎或守护进程</li>
<li class="calibre15">码头工人形象</li>
<li class="calibre15">码头集装箱</li>
<li class="calibre15">Docker 注册中心，通常是 Docker Hub</li>
<li class="calibre15">复合坞站</li>
</ul>

      
Note
You will eschew completely the use of the GUI tool Kitematic in favor of a wholly command line-oriented approach to managing Docker.

<h3 class="heading3">码头客户</h3>
The Docker client
            
           is a command line interface used to give instructions to the Docker engine regardless of the details of the engine’s implementation on your system. This is similar to the client-server architecture of the Web, in which a client system uses an interface (typically a web browser, but possibly a RESTful API) to interact with a remote server. In the case of Docker, the Docker client talks to the Docker engine that performs the work of containers and containerization.
While you work through this text, you will be using the Docker command line interface as your client and the engine will be running on your local system or on a t2.micro as recommended in Chapter <a href="01.html" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">1</a>. Using the Docker client, you tell the Docker daemon to pull an image from a registry. You can then tell the Docker daemon to run that image. Having done so, you might ask the engine which ps or containers are currently running.<a href="#Fn2" id="Fn2_source" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1"><sup class="calibre6">2</sup></a>
        
To list commands available to the Docker client, either run docker with no parameters or execute docker help. Depending on your Docker system configuration, you may be required to preface each docker command with sudo. To avoid having to use sudo with the docker command, your system administrator can create a Unix group called docker and add users to it.

<h3 class="heading3">主持人</h3>
The host
            
           is a machine on which you will run the Docker daemon/engine. Locally, the host will depend upon your Docker configuration. If you are running Docker for Linux, Docker for Mac, or Docker for Windows, the host will be your system itself. If you are running Docker Toolbox, the host will be a virtual machine running on Oracle’s VirtualBox software. The Docker Toolbox provides tools to assist in the proper creation of this virtual machine. You might also set up a remote machine to serve as your host. The important thing is that while you will always need a host, the details of this host are irrelevant. The host might be a virtual machine on your Mac, a c4.8xlarge EC2 instance on Amazon Web Services, or a bare metal server in your university basement. Regardless, your application will behave the same.
In certain situations, it may be necessary to identify the IP address of the host. This is typically not necessary with Docker for Linux, Docker for Mac, or Docker for Windows, in which Docker is running either natively (Linux) or native-like (Mac, Windows). In other cases, the IP address of the host can be identified using the docker-machine command line tool, specifically, docker-machine ls (see Listing <a href="#Par28" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">2-1</a>).

              $ docker-machine ls
NAME      ACTIVE   DRIVER      STATE     URL       SWARM   DOCKER    ERRORS
default   -        virtualbox  Running   tcp://192.168.99.100:2376  v1.13.0
Listing 2-1.Display Docker Hosts Associated with the Running Attached Docker Engine



            

<h3 class="heading3">Docker 引擎</h3>
The Docker engine is a persistent process that manages containers. It is running as a background service or daemon on the host. In fact, the engine is occasionally referred to as the Docker daemon. The Docker engine does the core work of Docker: building, running, and distributing your Docker containers. In this text, you will interact with the engine directly but will do so through the Docker client. The power of Docker lies in your ability to work with the engine via the Docker client. You will hand the managing of your processes over to the Docker engine. If you can do so on one system, you can count on any work you do to behave the same when on any other machine that is capable of running the Docker engine.

<h3 class="heading3">Docker 图像和 Docker 容器</h3>
Docker images are read-only. This is not to say that we can’t make changes to an image, but that once we have made changes, what we have is a new kind of image. I like to think about languages with immutable data structures such as tuples in Python. Once you define a tuple, you can’t modify it, although you can define a new tuple that takes the original and modifies it in some way.
The Docker engine has several methods for building our own images. These include the Docker client and via a domain-specific language (DSL)
           known as the Dockerfile. We can also download images that other people have created.
Docker containers are instances of Docker images. They are stand-alone, containing everything a single instance of an application needs to run (OS, dependencies, source, metadata), and can be run, started, stopped, moved, and deleted. They are also isolated and secure.
It is helpful to think of Docker images and containers in terms of object-oriented programming. An image is a defined “class” of container that we might create. A container is then an “instance” or “object” of that class. The Docker engine will manage multiple containers running on the host. When the engine runs a container from an image, it adds a read-write layer on top of the image in which our application can run.
Truthfully, however, this analogy of the image-container relationship as object-oriented programming is a weak analogy. A stronger analogy is the analogy of Docker as a compiled language. In this analog, we might think of a Dockerfile as source code, an image as a compiled binary, and a running container as a running process. It is clearly an intended analog considering that we use the command docker ps to display currently running containers. This analogy is helpful in a few ways. For one, it brings the build process to the forefront of our understanding of working with Docker. For another, it helps to reinforce the idea that containers are ephemeral, just like running processes. When they end their lifecycle, their state is effectively lost.

<h3 class="heading3">码头登记处</h3>
Docker registries hold images
            
          . These are public or private stores from which you upload or download images. For the purposes of this book, you will use the public Docker registry at Docker Hub.<a href="#Fn3" id="Fn3_source" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1"><sup class="calibre6">3</sup></a> Docker Hub is the source of the official images of the major open source technologies you will be using including Jupyter, PostgreSQL, Redis, and MongoDB.
<h4 class="heading5">复合坞站</h4>
Docker Compose is a tool for assembling microservices and applications consisting of multiple containers. These microservices and applications are designed using a single YAML file and can be built, run, and scaled, each via a single command. Docker Compose is particularly useful for the data scientist in building standalone computational systems comprised of Jupyter and one or more data stores (e.g. Redis).



<h2 class="heading2">获取码头工人</h2>
As of the writing of this text there are four core ways to install Docker across the major operating systems:
<ul class="unorderedlistmarkbullet"><li class="calibre15">Linux 坞站</li>
<li class="calibre15">Mac 坞站</li>
<li class="calibre15">Windows</li>
<li class="calibre15">Docker 工具箱</li>
</ul>

      
It is recommended that systems be configured to use at least 2GB of RAM. I have not encountered significant issues in allowing the Docker engine to use all available resources, like CPUs and RAM.
Note
I once more recommend that the reader use a sandbox system on a t2.micro as outlined in Chapter <a href="01.html" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">1</a>. Chapter <a href="01.html" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">1</a> contains instructions for configuring an AWS instance running Ubuntu.

<h3 class="heading3">Linux 坞站</h3>
Docker for Linux runs natively on most major Linux operating systems. It is driven from the command line using bash or similar shell. It is useful to note that running Docker for Linux is the most common configuration used on remote servers. It is a worthwhile exercise for Mac and Windows developers to familiarize themselves with this configuration. That said, the experience is very similar across platforms. Detailed instructions for a list of available operating systems are available at https://docs.docker.com/engine/installation/. Here, I focus on installation instructions for an Ubuntu system. For installation on other Linux distributions, readers should refer to the link for specific instructions.
<h4 class="heading5">在 Ubuntu 系统上安装 Docker</h4>
Installing Docker from the command line provides the highest degree of flexibility. On an Ubuntu system (here, I use Ubuntu 16.04.2), this can be done via the apt tool.
Note
These instructions are for installing Docker on Ubuntu. Users wishing to install Docker on another Linux variant should refer to the specific instructions for their system at <a href="https://docs.docker.com/engine/installation/" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">
                      https://docs.docker.com/engine/installation/
                    </a>.

In Listing <a href="#Par49" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">2-2</a>, you use apt search to examine the packages associated with Docker that are available for installation via apt. You run apt update first to ensure that you have the latest list of available packages.

                $ apt update
$ apt search docker
Sorting... Done
Full Text Search... Done

...

docker/xenial 1.5-1 amd64
  System tray for KDE3/GNOME2 docklet applications

docker-compose/xenial 1.5.2-1 all
  Punctual, lightweight development environments using Docker

docker-doc/xenial-updates 1.12.6-0ubuntu1∼16.04.1 all
  Linux container runtime -- documentation

docker-registry/xenial 2.3.0∼ds1-1 amd64
  Docker toolset to pack, ship, store, and deliver content

docker.io/xenial-updates 1.12.6-0ubuntu1∼16.04.1 amd64
  Linux container runtime

...

Listing 2-2.Display Docker Packages Available for Installation



              
The package in which you have the most interest is the docker.io package. This package contains both the Docker daemon, also known as the Docker container runtime, and the Docker command line interface (CLI) executable. In Listing <a href="#Par51" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">2-3</a>, you use apt policy to display meta-information available for the docker.io package. As of the writing of this text, the docker.io package available via apt is version 1.12.6.

                $ apt policy docker.io
docker.io:
  Installed: (none)
  Candidate: 1.12.6-0ubuntu1∼16.04.1
  Version table:
     1.12.6-0ubuntu1∼16.04.1 500
        500 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial-updates/universe amd64 Packages
     1.10.3-0ubuntu6 500
        500 http://us-west-2.ec2.archive.ubuntu.com/ubuntu xenial/universe amd64 Packages
Listing 2-3.Display Meta-Information for docker.io Package



              
Note
The 500 preceding each policy statement is a priority number and signifies that the package is “installable” on the system.

You begin your installation by ensuring that you have no older versions of docker installed (Listing <a href="#Par54" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">2-4</a>). If you receive the message “Package ‘docker’ is not installed, so not removed,” this means docker is not installed and you can proceed.

                $ sudo apt remove docker
Reading package lists... Done
Building dependency tree
Reading state information... Done
Package 'docker' is not installed, so not removed
0 upgraded, 0 newly installed, 0 to remove and 43 not upgraded.
Listing 2-4.Remove Previous Installations of docker
                  



              

<h4 class="heading5">配置 Docker 存储库</h4>
To install Docker, you will use the Docker recommended best practice of installing from the Docker repository. In order to do this, you will first need to set up the repository. You will be doing so for Docker CE. First, in Listing <a href="#Par56" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">2-5</a>, you will allow apt to use a repository over HTTPS.

                $ sudo apt-get install \
&gt;     apt-transport-https \
&gt;     ca-certificates \
&gt;     curl \
&gt;     software-properties-common
Reading package lists... Done
Building dependency tree
Reading state information... Done
ca-certificates is already the newest version (20160104ubuntu1).
apt-transport-https is already the newest version (1.2.19).
curl is already the newest version (7.47.0-1ubuntu2.2).
software-properties-common is already the newest version (0.96.20.5).
0 upgraded, 0 newly installed, 0 to remove and 43 not upgraded.
Listing 2-5.Allow apt to Use a Repository Over HTTPS



              
Then, in Listing <a href="#Par58" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">2-6</a>, you will add Docker’s official GPG key.

                $ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
OK
$ sudo apt-key fingerprint 0EBFCD88
pub   4096R/0EBFCD88 2017-02-22
      Key fingerprint = 9DC8 5822 9FC7 DD38 854A  E2D8 8D81 803C 0EBF CD88
uid                  Docker Release (CE deb) &lt;docker@docker.com&gt;
sub   4096R/F273FCD8 2017-02-22
Listing 2-6.Add Docker’s Official GPG Key



              
Finally, in Listing <a href="#Par60" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">2-7</a>, you add the appropriate Docker repository for your system architecture.

                $ sudo add-apt-repository \
&gt;    "deb [arch=$(dpkg --print-architecture)] https://download.docker.com/linux/ubuntu \
&gt;    $(lsb_release -cs) \
&gt;    stable"
Listing 2-7.Add Your System’s Specific Docker Repository



              

<h4 class="heading5">从 Docker 存储库安装</h4>
Having configured the Docker repository, you can install using the canonical apt update (Listing <a href="#Par62" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">2-8</a>) and apt install (Listing <a href="#Par63" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">2-9</a>).

                $ sudo apt update
...
Get:6 https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages [1,479 B]
...
43 packages can be upgraded. Run 'apt list --upgradable' to see them.
Listing 2-8.Update the apt Registry



              

                $ sudo apt install -y docker-ce
Reading package lists... Done
...
Preparing to unpack .../docker-ce_17.03.1∼ce-0∼ubuntu-xenial_amd64.deb ...
Unpacking docker-ce (17.03.1∼ce-0∼ubuntu-xenial) ...
...
Processing triggers for ureadahead (0.100.0-19) ...
Listing 2-9.Install docker.



              

<h4 class="heading5">以非超级用户身份管理 Docker</h4>
On Linux systems, the Docker engine binds to a Unix port rather than a TCP port. This port is typically owned by root and must be accessed via sudo in order to receive commands from the Docker client. A common pattern for Docker users on Linux systems is to create a docker group and add users to the group, as demonstrated in Listing <a href="#Par65" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">2-10</a>. When the Docker daemon is restarted, it makes the port bound to the Docker engine read/writeable by the docker group. The outcome is that users are able to issue commands to the engine without prepending sudo to their commands. Note that this is not, strictly speaking, necessary.

                $ sudo groupadd docker $ sudo usermod -aG docker $USER
Listing 2-10.Create a docker Group on Linux Systems



              
Log out and back in to see the changes take effect. At this point, users will be able to issues commands to the engine via docker without issuing sudo.


<h3 class="heading3">Mac 坞站</h3>
Docker for Mac runs Docker using the HyperKit<a href="#Fn4" id="Fn4_source" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1"><sup class="calibre6">4</sup></a> VM. It is driven from the command line using bash or similar shell. Detailed instructions as well as specific system requirements are available at <a href="https://docs.docker.com/docker-for-mac/" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">
                  https://docs.docker.com/docker-for-mac/
                </a>. The stable channel for installation is recommended.
Scripts for bash completion come prepackaged with the Docker for Mac application. To activate bash completion, simply symlink these files to your bash_completion.d/ directory (see Listing <a href="#Par70" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">2-11</a>).

              $ ln -s /Applications/Docker.app/Contents/Resources/etc/docker.bash-completion /usr/local/etc/bash_completion.d/docker
$ ln -s /Applications/Docker.app/Contents/Resources/etc/docker-machine.bash-completion /usr/local/etc/bash_completion.d/docker-machine
$ ln -s /Applications/Docker.app/Contents/Resources/etc/docker-compose.bash-completion /usr/local/etc/bash_completion.d/docker-compose
Listing 2-11.Symlink Bash Completion Files on Mac OS X



            

<h3 class="heading3">Windows</h3>
Docker for Windows runs using Microsoft Hyper-V. It is driven from the command line using PowerShell. Detailed instructions as well as specific system requirements are available at <a href="https://docs.docker.com/docker-for-windows/" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">
                  https://docs.docker.com/docker-for-windows/
                </a>. Installing Docker for Windows can be somewhat challenging. It should be noted that Docker for Windows can only be used on Windows 10 Pro or Enterprise 64-bit operating systems and requires
<ul class="unorderedlistmarkbullet"><li class="calibre15">具有二级地址转换的 64 位处理器(SLAT)</li>
<li class="calibre15">最低 4GB 系统内存</li>
<li class="calibre15">BIOS 级硬件虚拟化支持</li>
</ul>

        
The following notes have been helpful during past installations:
<ul class="unorderedlistmarkbullet"><li class="calibre15">如果在 Docker 安装期间提示启用 Hyper-V，请确保按下 OK。</li>
<li class="calibre15">从 Docker 设置中选择“共享驱动器”,并确保共享 C:驱动器。这可以通过 Docker 设置来完成(图<a href="#Fig4" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1"> 2-4 </a>)。<img src="Images/A439726_1_En_2_Fig4_HTML.jpg" alt="A439726_1_En_2_Fig4_HTML.jpg" class="calibre43"/>图 2-4。访问 Docker 设置</li>
<li class="calibre15">如有必要，禁用防火墙或创建例外。</li>
<li class="calibre15">确保使用 Windows PowerShell 访问引擎的发布命令。</li>
</ul>

        

<h3 class="heading3">Docker 工具箱</h3>
Docker Toolbox is available for older Mac or Windows systems that do not meet the requirements of the more natively implemented Docker for Mac or Docker for Windows. Docker Toolbox includes several tools:
<ul class="unorderedlistmarkbullet"><li class="calibre15">用于运行对接机命令的对接机</li>
<li class="calibre15">用于运行 Docker 命令的 docker 引擎</li>
<li class="calibre15">Docker Compose 用于运行 docker-compose 命令</li>
<li class="calibre15">Kitematic，Docker GUI</li>
<li class="calibre15">为 Docker 命令行环境预先配置的 shell</li>
<li class="calibre15">Oracle VirtualBox</li>
</ul>

        
Installation instructions are available here: <a href="https://docs.docker.com/toolbox/overview/" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">
                  https://docs.docker.com/toolbox/overview/
                </a>. Docker Toolbox users will need to use the Docker Quickstart Terminal command line environment to issue commands to the Docker engine. Installation of Docker Toolbox will create a local docker-machine using VirtualBox that serves as the host.


<h2 class="heading2">你好，码头工人！</h2>
Minimally, using Docker to run your code consists of the following:
<ol class="calibre7"><li class="listitem">1.从 docker 文件中提取预编译的映像或构建映像。</li>
<li class="listitem">2.将图像作为新容器运行。</li>
</ol>

      
If you have just installed Docker for this first time, you might try some minimal commands as verification that the Docker client is correctly installed and available on your path. Listings <a href="#Par92" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">2-12</a>, <a href="#Par94" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">2-13</a>, and <a href="#Par95" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">2-14</a> demonstrate three ways that this can be done: docker version, docker help, or which docker work well as a minimal test.

            $ docker version
sudo docker version
Client:
 Version:      17.03.1-ce
 API version:  1.27
 Go version:   go1.7.5
 Git commit:   c6d412e
 Built:        Mon Mar 27 17:14:09 2017
 OS/Arch:      linux/amd64

Server:
 Version:      17.03.1-ce
 API version:  1.27 (minimum version 1.12)
 Go version:   go1.7.5
 Git commit:   c6d412e
 Built:        Mon Mar 27 17:14:09 2017
 OS/Arch:      linux/amd64
 Experimental: false

Listing 2-12.Display the Docker Version



          
Note
Running this command gives information on the version of docker running on both the Docker client and the server.


            $ docker help

Usage: docker COMMAND

A self-sufficient runtime for containers

...

Listing 2-13.Display Docker Help



          

            $ which docker
/usr/local/bin/docker
Listing 2-14.Display the Location of the Docker Binary.



          
Having verified that the Docker client is properly installed, you can move on to the canonical “Hello, World!” as demonstrated in Listing <a href="#Par97" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">2-15</a>.

            $ docker run hello-world
Unable to find image 'hello-world:latest' locally
latest: Pulling from library/hello-world
78445dd45222: Pull complete
Digest: sha256:c5515758d4c5e1e838e9cd307f6c6a0d620b5e07e6f927b07d05f6d12a1ac8d7
Status: Downloaded newer image for hello-world:latest

Hello from Docker!

Listing 2-15.Run the hello-world Image



          
This message shows that your installation appears to be working correctly.
To generate this message, Docker took the following steps:
<ol class="calibre7"><li class="listitem">1.Docker 客户端联系了 Docker 守护程序。</li>
<li class="listitem">2.Docker 守护进程从 Docker Hub 中提取 hello-world 映像。</li>
<li class="listitem">3.Docker 守护进程从该映像创建了一个新的容器，它运行可执行文件，生成您当前正在阅读的输出。</li>
<li class="listitem">4.Docker 守护进程将输出流式传输到 Docker 客户机，客户机将输出发送到您的终端。</li>
</ol>

      
To try something more ambitious, you can run an Ubuntu container with

             $ docker run -it ubuntu bash

          
Share images, automate workflows, and more with a free Docker ID from <a href="https://cloud.docker.com/" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">
                https://cloud.docker.com/
              </a>.
For more examples and ideas, visit <a href="https://docs.docker.com/engine/userguide/" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">
                https://docs.docker.com/engine/userguide/
              </a>
        .
      
And with that, you have verified that Docker is correctly installed and functioning. When you execute this command, the Docker client sends the run hello-world command to the Docker engine. The Docker engine then does the following:
<ol class="calibre7"><li class="listitem">1.在本地图像缓存中检查 hello-world 图像。</li>
<li class="listitem">2.如果映像不在本地，则从 Docker Hub 下载映像。</li>
<li class="listitem">3.使用图像创建新容器。</li>
<li class="listitem">4.分配文件系统并在映像顶部添加读写层。</li>
<li class="listitem">5.为系统设置 IP 地址。</li>
<li class="listitem">6.按照映像 Dockerfile 文件中的指定执行 shell 命令/hello。</li>
<li class="listitem">7.完成此过程后，将终止容器并关闭。</li>
</ol>

      
Listing <a href="#Par124" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">2-16</a> demonstrates sort of an elemental Docker command: run the latest Ubuntu image, (run ubuntu) and connect to it via a bash shell (-i -t /bin/bash). When you execute this command, the Docker client sends the command to the Docker engine. The Docker engine does the following:
<ol class="calibre7"><li class="listitem">1.在本地图像缓存中检查 ubuntu 图像。</li>
<li class="listitem">2.从 Docker Hub 下载图像，除非图像存在于本地。</li>
<li class="listitem">3.使用图像创建新容器。</li>
<li class="listitem">4.分配文件系统并在映像顶部添加读写层。</li>
<li class="listitem">5.为系统设置 IP 地址。</li>
<li class="listitem">6.在容器内执行进程/bin/bash。</li>
<li class="listitem">7.通过您当前的终端连接到正在运行的/bin/bash 进程。</li>
</ol>

      

            $ docker run -it ubuntu  /bin/bash
root@eb5f4278d040:/#
Listing 2-16.Run the Base ubuntu Image and Connect to It Via Shell



          
You will be connected to the running ubuntu container until you shut down. You can interact (see Listing <a href="#Par126" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">2-17</a>) with this process as though it were your native Ubuntu system to which you were connected via a bash shell.

            root@8b9461e1d7dd:/# ls
bin   dev  home  lib64  mnt  proc  run   srv  tmp  var
boot  etc  lib   media  opt  root  sbin  sys  usr
root@8b9461e1d7dd:/# ps
  PID TTY          TIME CMD
    1 ?        00:00:00 bash
   12 ?        00:00:00 ps
root@8b9461e1d7dd:/# ps aux
USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
root         1  0.0  0.1  18240   3212 ?       S&lt;s  04:00   0:00 /bin/bash
root        13  0.0  0.1  34424   2808 ?       R&lt;+  04:01   0:00 ps aux
root@8b9461e1d7dd:/# exit
joshuacook@LOCALHOST:∼$
Listing 2-17.Interact with Ubuntu Running as a Docker Container.



          
Here, you ended our session by typing Ctrl+D as if you were connected to a remote system via ssh. In doing so, you have control returned to your local system, the host on which Docker is running.
It is useful to take note of the state while your Ubuntu image was running. It is not unusual that ls would show a complete standard Linux filesystem. It is not unusual that ps would return just a few items. It is highly unusual that ps aux would return two items. ps aux shows (a) processes for all users, (u) showing the owner of the process, and (x) including processes that are not attached to any terminal. In other words, in running ps aux, you have effectively shown all of the processes currently running on the system. Again, it is highly unusual that only processes running on the system are the shell through which you have connected (PID 1 /bin/bash) and the ps aux you are using to display running processes (PID 13 ps aux). Let that sink in. Essentially, your Docker container is running one process. More on this later.
<h3 class="heading3">Docker 中的基本网络</h3>
The final introductory piece you will examine before proceeding is networking in Docker. Many of the containers you will be working with will need to be accessed from the host using a network protocol such as TCP or HTTP. Luckily, Docker handles networking for us. In a minimal sense, you will manage networking via Docker by publishing ports.
In publishing a port, you explicitly bind a port or range of ports from a running container to the host. This is done via the (lowercase p) –p flag. This command makes explicit a connection between the host and the container. As such, it can only be defined as an argument passed to the Docker engine.
The pattern used in publishing a port is –p host_port:container_port. Let’s say, for example, that I run a Flask<a href="#Fn5" id="Fn5_source" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1"><sup class="calibre6">5</sup></a> app, defined in a container called my_flask_app, on port 5000, via the command docker run –p 7777:5000 my_flask_app. In this case, I am publishing the port 5000 in the container on the port 7777 on the host. In other words, whatever is available on the container at port 5000 will be available on the host at port 7777. The effect of this to me as the local end user is that I can access the Flask app I have defined in my browser at http://localhost:7777 (or port 7777 on the host’s IP if I am using Docker Toolbox).
The Python module 
                SimpleHTTPServer
                
                
               can be used to run a file server to the directory from which it is launched. In Listing <a href="#Par134" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">2-18</a>, you use a single command to launch a file server via a Docker container. The Docker daemon pulls the python image and uses it to run the Python module using the command python -m SimpleHTTPServer. The server runs on the default port of 8000 within the container. You link this to the port 5000 on your host and are able to access the file server through the browser (Figure <a href="#Fig5" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">2-5</a>) at http://localhost:8000.<img src="Images/A439726_1_En_2_Fig5_HTML.jpg" alt="A439726_1_En_2_Fig5_HTML.jpg" class="calibre44"/>
Figure 2-5.Local file servers available via browser



        

              $ docker run -v ∼:/home -p 5000:8000 python:2.7 python -m SimpleHTTPServer
Unable to find image 'python:2.7' locally
2.7: Pulling from library/python
6d827a3ef358: Already exists
2726297beaf1: Pull complete
7d27bd3d7fec: Pull complete
44ae682c18a3: Pull complete
824bd01a76a3: Pull complete
69702776c399: Pull complete
7be4e7612dd4: Pull complete
Digest: sha256:bda277274d53484e4026f96379205760a424061933f91816a6d66784c5e8afdf
Status: Downloaded newer image for python:2.7
172.17.0.1 - - [16/Apr/2017 14:58:54] "GET / HTTP/1.1" 200 -
Listing 2-18.Launch the File Server Via the Docker Container
                    
                  
                



            
Note
There are subtle nuances to running Docker on disparate systems. In most cases, Docker Toolbox users will be able to access the simple file server at http://192.168.99.100:5000. Docker for Linux/Mac/Windows users should use http://localhost:5000.



<h2 class="heading2">摘要</h2>
In this chapter, I formally introduced Docker and its ecosystem. I defined containerization and how it is useful to our work. I provided instructions for installing Docker on a few popular operating systems. Finally, you ran the Docker hello-world image and the Docker python image, using the latter to run a simple web server.
Having completed this chapter, I hope that you have an understanding of what exactly Docker is and some understanding of why it exists. I hope that you are aware of the various components of the Docker ecosystem. Readers should be able to run basic commands via the Docker client such as docker help, docker ps, and docker run.
In the next chapter, I will formally introduce Jupyter. As with everything in this text, I will be doing so using Docker. In subsequent chapters, you will explore in greater depth individual components of the Docker ecosystem, such as the Docker engine (or daemon), the Dockerfile, and Docker Hub.

Footnotes
<a href="#Fn1_source" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">1</a>
                <a href="https://blog.docker.com/2016/03/containers-are-not-vms/" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">
                    https://blog.docker.com/2016/03/containers-are-not-vms/
                  </a>
              

 

<a href="#Fn2_source" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">2</a>This command is a descendent of the bash command ps. In bash, this command lists running processes, whereas in Docker this command lists running containers. This fits with our understanding of the Docker container as a virtualized process.

 

<a href="#Fn3_source" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">3</a>
                  <a href="https://hub.docker.com" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">
                      https://hub.docker.com
                    </a>
                

 

<a href="#Fn4_source" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">4</a>
                  <a href="https://github.com/docker/HyperKit/" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">
                      https://github.com/docker/HyperKit/
                    </a>
                

 

<a href="#Fn5_source" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">5</a>
                  <a href="http://flask.pocoo.org" class="calibre3 pcalibre pcalibre4 pcalibre3 pcalibre2 pcalibre1">
                      http://flask.pocoo.org
                    </a>
                

 




</body>
</html>