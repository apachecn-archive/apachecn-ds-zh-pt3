<html lang="en">
<head><title>Basic Statistics</title>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<link href="../css/springer_epub.css" rel="styleSheet" type="text/css"/>
</head>
<body>
 
<!--Begin Abstract--><h1 class="ChapterTitle" lang="en">12.基本统计</h1>

 
<!--End Abstract--><p class="Para" id="Par2">统计学是数学的一个分支，研究数据的收集、组织、分析、解释和表达。研究中使用了两种主要的统计方法。描述性统计字段总结并描述样本数据的属性。推断统计学领域得出关于总体的结论并做出预测。群体是我们想要研究并得出结论的一整套数据，已知的和未知的，可观察的和不可观察的。总体样本集是我们拥有(观察到的)数据的总体的子集。人口没有变化。样本集因我们收集数据的方式而异。每次收集数据时，样本集可能会有所不同。样本的大小总是小于总体的大小，并且总是有限的。人口规模可以很大，甚至是无限的。推断统计学领域从样本的描述性统计中得出关于总体的结论。例如，为了估计整个宇宙中星系的数量，我们用望远镜拍摄的天空部分，比如说哈勃。然后，利用天空碎片与整个宇宙的比率，我们估算出宇宙中星系的数量。这种抽样和推断过程是统计分析的核心。这就是我们如何估计宇宙中原子的数量，地球上奶牛的数量(我们通常不计算和命名其中的 15 亿)，以及许多其他测量结果，即使我们没有看到(意味着有数据)所有这些。统计学几乎应用于所有科学学科，如物理和社会科学，以及商业、人文、政府和制造业。</p>
<p class="Para" id="Par3">NM Dev 库有一大套统计工具来进行数据分析。它涵盖了描述性统计，许多单变量和多变量概率分布，回归分析，时间序列分析，多变量分析，数据过滤，假设检验，随机数生成，模拟，等等。这些是我们将在接下来的几章中涉及的主题。</p>
<h2 class="Heading">12.1 随机变量</h2>
<p class="Para" id="Par4">随机变量的概念是统计学的基础。说统计学的数学就是研究随机变量(可能)不算太错。非随机变量，例如，<em class="EmphasisTypeItalic "> x </em> = 1，是一个每次我们查看时都取相同值的变量，在本例中为 1。总是一样的。相比之下，随机变量可能在我们每次观察或取样时取不同的值。直到我们看到它，我们才知道它的价值。假设我们把掷硬币的正面(<em class="EmphasisTypeItalic "> H </em>)标为 1，反面(<em class="EmphasisTypeItalic "> T </em>)标为 0。那么一个随机变量，<em class="EmphasisTypeItalic "> X </em>，代表每次我们抛硬币(或者取一个样本)时，抛硬币的结果可以是 1 或者 0。假设我们掷硬币五次，得到{ <em class="EmphasisTypeItalic "> H </em>，<em class="EmphasisTypeItalic "> H </em>，<em class="EmphasisTypeItalic "> T </em>，<em class="EmphasisTypeItalic "> T </em>，<em class="EmphasisTypeItalic "> H </em> }。那么本次实验的<em class="EmphasisTypeItalic "> X </em>的样本为{<em class="EmphasisTypeItalic ">X</em>T22】1= 1，<em class="EmphasisTypeItalic "> x </em> <sub> 2 </sub> = 1，<em class="EmphasisTypeItalic "> x </em> <sub> 3 </sub> = 0，<em class="EmphasisTypeItalic "> x </em> <sub> 4 </sub> = 0，<em class="EmphasisTypeItalic "> x </em> <sub> 5 </sub> = 1}。根据实验的结果，每个样本或观察值可以给出不同的值。</p>
<p class="Para" id="Par5">更正式地说，随机变量<em class="EmphasisTypeItalic "> X </em>是一个函数，它将一个域(称为样本空间ω)中的结果映射到一些实数(范围<em class="EmphasisTypeItalic "> E </em>)。例如，结果<em class="EmphasisTypeItalic ">ω</em>∈ω可能取决于一些不可预测的物理过程。抛硬币的情况下，结果是ω= {<em class="EmphasisTypeItalic ">H</em>，<em class="EmphasisTypeItalic "> T </em> }，随机变量<em class="EmphasisTypeItalic "> X </em>映射到<em class="EmphasisTypeItalic "> E </em> = {1，0}。</p>
<p>此外，随机变量具有概率分布 P，其指定随机变量取某个值或多个值的概率。它等于结果变成与这些值相对应的事件的可能性。例如，对于一次公平的掷硬币，这三个量具有相同的值:表示为 P( <em class="EmphasisTypeItalic "> X </em> = 1)的<em class="EmphasisTypeItalic "> X </em> = 1 的概率，或者结果为<em class="EmphasisTypeItalic "> H </em>的可能性，或者 50%。一个离散的随机变量只能取有限个或可数个值，例如在掷硬币的例子中的{1，0}。离散随机变量的概率分布称为概率质量函数。公平抛硬币的随机变量和概率质量函数如下:<p> <img alt="$$ \left\{\begin{array}{c}\mathrm{X}\left(\omega =H\right)=1\\ {}\mathrm{X}\left(\omega =T\right)=0\end{array}\right. $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equa.png" style="width:7.92em"/> </p></p>
<p>又如下:<p> <img alt="$$ \left\{\begin{array}{c}\mathrm{P}\left(X=1\right)=P\left(\omega =H\right)=0.5\\ {}\mathrm{P}\left(X=0\right)=P\left(\omega =T\right)=0.5\end{array}\right. $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equb.png" style="width:13.95em"/> </p></p>
<p>图<a href="#Fig1"> 12-1 </a>显示了样本空间ω、随机变量范围<em class="EmphasisTypeItalic "> E </em>(与概率函数的定义域相同)、随机变量<em class="EmphasisTypeItalic "> X </em>与概率 p 之间的关系</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig1_HTML.png" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig1_HTML.png" style="width:28.45em"/></p>
<p>图 12-1</p><p class="SimplePara">公平抛硬币的随机变量</p>



<h2 class="Heading">12.2 样本统计</h2>
<p class="Para" id="Par9">给定一个随机变量<em class="EmphasisTypeItalic "> X </em>的一组样本(<em class="EmphasisTypeItalic "> x </em> <sub> 1 </sub>，<em class="EmphasisTypeItalic "> x </em> <sub> 2 </sub>，…，<em class="EmphasisTypeItalic "> x </em> <sub> <em class="EmphasisTypeItalic "> n </em> </sub>)，我们可以用样本统计或描述统计来描述该集合的统计性质。其中一些度量数据的集中趋势(或位置)，如均值。一些测量样本的可变性(或分布),如方差。有些强调变量之间的潜在关系，如协方差。还有其他人。值得注意的是，样本统计数据不一定等于基础人群的相应统计数据。如果样本量<em class="EmphasisTypeItalic "> n </em>足够大，它们可能是很好的近似值。</p>
<p>在 NM Dev 中，所有从数据集或样本中计算统计数据的类都继承自<code>Statistic</code>接口。签名如下:</p>
<pre>/**
 * A statistic (singular) is a single measure of some attribute of a sample
 * (e.g., its arithmetic mean value). It is calculated by applying a function
 * (statistical algorithm) to a sample, i.e., a set of data.
 *
 * @author Haksun Li
 * @see &lt;a href="http://en.wikipedia.org/wiki/Statistic"&gt;Wikipedia:
 * Statistic&lt;/a&gt;
 */
public interface Statistic {

    /**
     * Get the value of the statistic.
     *
     * @return the statistic
     */
    public double value();

    /**
     * Get the size of the sample.
     *
     * @return the sample size
     */
    public long N();

    /**
     * Recompute the statistic with more data, incrementally if possible.
     *
     * @param data an array of new items
     */
    public void addData(double... data);

}

</pre>
<p class="Para" id="Par11">函数<code>value()</code>计算统计数据。函数<code>N()</code>返回样本大小。</p>
<h3 class="Heading">平均值</h3>
<p>最简单的样本统计是数据的样本平均值或算术平均值，表示为<img alt="$$ \overline{x} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq1.png" style="width:0.78em"/>。它测量数据集的中心位置。它是所有样本的总和，除以样本大小或计数。数学上，样本均值定义如下:<p> <img alt="$$ \overline{x}=\frac{\sum \limits_{i=1}^n{x}_i}{n} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equc.png" style="width:4.22em"/> </p></p>
<p>大数定律说，如果样本是从总体均值或期望值为 E( <em class="EmphasisTypeItalic "> X </em> ) = <em class="EmphasisTypeItalic "> μ </em>(且方差有限)的总体<em class="EmphasisTypeItalic "> X </em>中随机抽取的，那么样本均值收敛于总体均值。即:<p> <img alt="$$ \underset{n\to \infty }{\lim}\overline{x}=\mu $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equd.png" style="width:4.36em"/> </p></p>
<p>例如，对于样本<em class="EmphasisTypeItalic "> X </em> = {2，3，3，1}，样本均值如下:<p> <img alt="$$ \overline{x}=\frac{\sum \limits_{i=1}^4{x}_i}{4}=\frac{2+3+3+1}{4}=2.25 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Eque.png" style="width:14.44em"/> </p></p>
<p>在 NM Dev 中，类<code>Mean</code>计算数据集的样本均值。以下代码为前面的示例计算:</p>
<pre>// the sample data set
double[] X1 = new double[]{2, 3, 3, 1};

// compute the mean of the data set
Mean mean = new Mean(X1);
System.out.println("sample size = " + mean.N());
System.out.println("sample mean = " + mean.value());

</pre>
<p>输出如下所示:</p>
<pre>sample size = 4
sample mean = 2.25

</pre>

<h3 class="Heading">加权平均值</h3>
<p>样本均值假设每个数据点对最终平均值的贡献相等。加权样本均值允许一些数据点比其他数据点贡献更多。即每个数据点可以有不同的权重，<em class="EmphasisTypeItalic "> w </em> <sub> <em class="EmphasisTypeItalic "> i </em> </sub>。数学上，加权样本均值定义如下:<p> <img alt="$$ {\overline{x}}^{\ast }=\frac{\sum \limits_{i=1}^n{w}_i{x}_i}{\sum \limits_{i=1}^n{w}_i} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equf.png" style="width:5.55em"/> </p></p>
<p>假设学生每门课的成绩分别为<em class="EmphasisTypeItalic "> X </em> = {82，94，90，83，87}，每门课的学分分别为<em class="EmphasisTypeItalic "> W </em> = {1，4，8，4，4}。然后综合评分，即加权样本均值如下:<p> <img alt="$$ {\overline{x}}^{\ast }=\frac{1\times 82+4\times 94+8\times 90+4\times 83+4\times 87}{1+4+8+4+4}=88.48. $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equg.png" style="width:25.1em"/> </p></p>
<p>在 NM Dev 中，类<code>WeightedMean</code>计算数据集的加权样本均值。以下代码计算前一个示例的加权样本平均值:</p>
<pre>// the sample data set
double[] X2 = new double[]{82, 94, 90, 83, 87};
double[] W2 = new double[]{1, 4, 8, 4, 4};

// compute the mean of the data set
WeightedMean weighted_mean = new WeightedMean(
        X2, // the data
        W2 // the weights
);
System.out.println("sample size = " + mean.N());
System.out.println("weighted sample mean = " + weighted_mean.value());

</pre>
<p>输出如下所示:</p>
<pre>sample size = 4
weighted sample mean = 88.47619047619048

</pre>

<h3 class="Heading">差异</h3>
<p>样本方差衡量一组数字与其平均值相差多远。换句话说，就是分散度，或者说数据分散了多少。在估计的上下文中，估计量可以被视为一个随机变量。估计量的样本均值就是估计值。那么，估计量的样本方差就是估计的不确定程度。例如，如果我们取五个温度读数，那么样本平均值就是温度的测量值；样本方差是我们测量的不确定性。见图<a href="#Fig2"> 12-2 </a>。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig2_HTML.jpg" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig2_HTML.jpg" style="width:35.45em"/></p>
<p>图 12-2</p><p class="SimplePara">均值相同但方差不同的两个样本</p>


<p class="Para" id="Par22">图<a href="#Fig2"> 12-2 </a>显示了样本均值相同但样本方差不同的两个样本。红色样本的均值为 100，方差为 100(标准差= 10)，而蓝色样本的均值为 100，方差为 2500(标准差= 50)。很明显，蓝色样本中的数据比红色样本分散得多。蓝色的数据离平均值更远。</p>
<p>数学上，样本方差定义如下:<p> <img alt="$$ {s}^2=\frac{\sum \limits_{i=1}^n{\left({x}_i-\overline{x}\right)}^2}{n} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equh.png" style="width:7.38em"/> </p></p>
<p>或者，无偏版本如下:<p> <img alt="$$ {s}^2=\frac{\sum \limits_{i=1}^n{\left({x}_i-\overline{x}\right)}^2}{n-1} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equi.png" style="width:7.38em"/> </p></p>
<p class="Para" id="Par25">样本标准差<em class="EmphasisTypeItalic "> s </em>，是样本方差的平方根。从公式中很容易看出，样本方差是数据与样本均值的平方距离的平均值。</p>
<p>对于样本<em class="EmphasisTypeItalic "> X </em> = {2，3，3，1}，样本方差如下:<p> <img alt="$$ {s}^2=\frac{\sum \limits_{i=1}^4{\left({x}_i-\overline{x}\right)}^2}{4-1}=\frac{{\left(2-2.25\right)}^2+{\left(3-2.25\right)}^2\times 2+{\left(1-2.25\right)}^2}{3}=0.9167 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equj.png" style="width:31.18em"/> </p></p>
<p>样本标准差如下:<p> <img alt="$$ s=\sqrt{0.9167}=0.9574 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equk.png" style="width:10.12em"/> </p></p>
<p>在 NM Dev 中，类<code>Variance</code>计算数据集的样本方差。以下代码计算前一个示例的样本方差:</p>
<pre>// the sample data set
double[] X3 = {2, 3, 3, 1};

// compute the biased and unbiased vairances and standard deviations
Variance var1 = new Variance(X3, false); // biased
System.out.println("sample standard deviation (biased) = " + var1.standardDeviation());
System.out.println("sample variance (biased) = " + var1.value());
Variance var2 = new Variance(X3, true); // unbiased
System.out.println("sample standard deviation (unbiased) = " + var2.standardDeviation());
System.out.println("sample variance (unbiased) = " + var2.value());

</pre>
<p>输出如下所示:</p>
<pre>sample standard deviation (biased) = 0.9574271077563381
sample variance (biased) = 0.9166666666666666
sample standard deviation (unbiased) = 0.9574271077563381
sample variance (unbiased) = 0.9166666666666666

</pre>

<h3 class="Heading">加权方差</h3>
<p>同样，一个样本集的加权样本方差可以定义如下:<p> <img alt="$$ {s}^2=\frac{\sum \limits_{i=1}^n{w}_i{\left({x}_i-{\overline{x}}^{\ast}\right)}^2}{V_1} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equl.png" style="width:8.73em"/> </p></p>
<p>无偏版本如下:<p> <img alt="$$ {s}^2=\frac{V_1}{V_1^2-{V}_2}\sum \limits_{i=1}^n{w}_i{\left({x}_i-{\overline{x}}^{\ast}\right)}^2 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equm.png" style="width:12.64em"/> </p></p>
<p>其中:<p> <img alt="$$ {V}_2=\sum \limits_{i=1}^n{w_i}^2 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equn.png" style="width:5.55em"/> </p></p>
<p>在 NM Dev 中，类<code>WeightedVariance</code>计算数据集的加权样本方差。以下代码计算第 12.2.2 节中学生成绩示例的加权样本方差:</p>
<pre>// the sample data set
double[] X2 = new double[]{82, 94, 90, 83, 87};
double[] W2 = new double[]{1, 4, 8, 4, 4};

// compute the biased and unbiased vairances and standard deviations
WeightedVariance wvar1 = new WeightedVariance(
        X2, // the data
        W2, // the weights
        false); // biased
System.out.println("sample weighted standard deviation (biased) = " + wvar1.stdev());
System.out.println("sample weighted variance (biased) = " + wvar1.value());
WeightedVariance wvar2 = new WeightedVariance(
        X2, // the data
        W2, // the weights
        false); // unbiased
System.out.println("sample standard deviation (unbiased) = " + wvar2.stdev());
System.out.println("sample variance (unbiased) = " + wvar2.value());

</pre>
<p>输出如下所示:</p>
<pre>sample weighted standard deviation (biased) = 3.849787225030045
sample weighted variance (biased) = 14.820861678004535
sample standard deviation (unbiased) = 3.849787225030045
sample variance (unbiased) = 14.820861678004535






</pre>

<h3 class="Heading">偏斜度</h3>
<p>样本偏度是数据关于其均值分布的不对称性的度量。偏斜值可以是正数、零或负数。对于单峰分布(具有单峰的分布)，负偏斜通常表示尾部在分布的左侧，正偏斜表示尾部在右侧。零偏斜值意味着平均值两侧的尾部总体平衡。对称分布总是零偏斜。但这也适用于不对称分布，即一条尾巴长而细，另一条尾巴短而粗。见图<a href="#Fig3"> 12-3 </a>。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig3_HTML.jpg" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig3_HTML.jpg" style="width:42.7em"/></p>
<p>图 12-3</p><p class="SimplePara">与单峰分布的均值/中值/众数相关的偏斜度示例</p>


<p>数学上，样本偏度(或 Fisher-Pearson 偏度系数)定义如下:<p> <img alt="$$ {g}_1=\frac{\frac{1}{n}\sum \limits_{i=1}^n{\left({x}_i-\overline{x}\right)}^3}{{\left(\frac{1}{n-1}\sum \limits_{i=1}^n{\left({x}_i-\overline{x}\right)}^2\right)}^{\frac{3}{2}}} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equo.png" style="width:10.3em"/> </p> <p> <img alt="$$ =\frac{\frac{1}{n}\sum \limits_{i=1}^n{\left({x}_i-\overline{x}\right)}^3}{s^3} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equp.png" style="width:6.9em"/> </p></p>
<p>其中<em class="EmphasisTypeItalic "> s </em>是使用<em class="EmphasisTypeItalic "> n </em>而不是(<em class="EmphasisTypeItalic ">n</em>1)计算的样本标准偏差。<p> <img alt="$$ s=\sqrt{\frac{\sum \limits_{i=1}^n{\left({x}_i-\overline{x}\right)}^2}{n}} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equq.png" style="width:8.16em"/> </p></p>
<p>调整后的 Fisher-Pearson 偏度系数定义如下:<p> <img alt="$$ {G}_1=\frac{\sqrt{n\left(n-1\right)}}{n-2}{g}_1 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equr.png" style="width:8.4em"/> </p></p>
<p>对于样本<em class="EmphasisTypeItalic "> X </em> = {1，1，2，1，2，3，2，1，0}和样本均值<img alt="$$ \overline{x}=1.4444 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq2.png" style="width:5.01em"/>，样本偏度如下:<p> <img alt="$$ {g}_1=\frac{\frac{1}{9}\sum \limits_{i=1}^9{\left({x}_i-1.4444\right)}^3}{{\left(\frac{1}{8}\sum \limits_{i=1}^9{\left({x}_i-1.4444\right)}^2\right)}^{3/2}}=0.147986 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equs.png" style="width:17.82em"/> </p></p>
<p>在 NM Dev 中，类<code>Skewness</code>计算数据集的样本偏斜度。以下代码计算前一个示例的样本偏斜度:</p>
<pre>// the sample data set
double[] X4 = {1, 1, 1, 1, 2, 2, 2, 3, 0};

// compute the skewness of the data set
Skewness skewness = new Skewness(X4);
System.out.println("sample mean = " + skewness.mean());
System.out.println("sample standard deviation = " + sqrt(skewness.variance()));
System.out.println("sample skewness = " + skewness.value());

</pre>
<p>输出如下所示:</p>
<pre>sample mean = 1.4444444444444444
sample standard deviation = 0.8819171036881968
sample skewness = 0.14798608996128484

</pre>

<h3 class="Heading">峰度</h3>
<p>样本峰度是对分布“尾部”的一种度量。标准正态分布的峰度是 3。通常将分布的峰度与该值进行比较。峰度小于 3 的分布称为细尾分布。这意味着与正态分布相比，该分布产生的异常值更少、更不极端。细尾分布的一个例子是均匀分布，它不会产生异常值。峰度大于 3 的分布称为重尾或厚尾。厚尾分布的一个例子是拉普拉斯分布，它的尾部比高斯分布更慢地接近零，因此比正态分布产生更多的异常值。通常，我们使用超额峰度来提供与标准正态分布的比较，超额峰度定义为峰度<em class="EmphasisTypeItalic "> κ </em>减 3。数学上，样本超额峰度定义如下:<p> <img alt="$$ {g}_2=\kappa -3=\frac{\frac{1}{n}\sum \limits_{i=1}^n{\left({x}_i-\overline{x}\right)}^4}{{\left(\frac{1}{n-1}\sum \limits_{i=1}^n{\left({x}_i-\overline{x}\right)}^2\right)}^2}-3 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equt.png" style="width:15.38em"/> </p> <p> <img alt="$$ =\frac{\frac{1}{n}\sum \limits_{i=1}^n{\left({x}_i-\overline{x}\right)}^4}{s^4}-3 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equu.png" style="width:8.59em"/> </p></p>
<p>1986 年，摩尔给出了峰度的解释。定义 z 分数如下:<p> <img alt="$$ Z=\frac{X-\mu }{\sigma } $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equv.png" style="width:4.8em"/> </p></p>
<p class="Para" id="Par44">其中<em class="EmphasisTypeItalic "> X </em>为随机变量，<em class="EmphasisTypeItalic "> μ </em>为均值，<em class="EmphasisTypeItalic "> σ </em>为标准差。z-score 将随机变量或数据归一化为数字单位<em class="EmphasisTypeItalic "> σ </em>。z 得分通常用于比较不同分布的随机变量，因此它们具有“相同”的单位。</p>
<p>根据峰度和恒等式的定义，我们有这样的:<p><img alt="$$ \mathrm{E}\left({Z}^2\right)=\operatorname{var}(Z)+{\left(\mathrm{E}(Z)\right)}^2 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equw.png" style="width:11.21em"/></p><p><img alt="$$ \kappa =\mathrm{E}\left({Z}^4\right)=\operatorname{var}\left({Z}^2\right)+{\left[\mathrm{E}\left({Z}^2\right)\right]}^2 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equx.png" style="width:14.26em"/></p><p><img alt="$$ =\operatorname{var}\left({Z}^2\right)+{\left(\operatorname{var}(Z)\right)}^2 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equy.png" style="width:9.57em"/></p><p><img alt="$$ =\operatorname{var}\left({Z}^2\right)+1 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equz.png" style="width:6.27em"/></p></p>
<p class="Para" id="Par46">峰度现在可以被视为<em class="EmphasisTypeItalic "> Z </em> <sup> 2 </sup>围绕其期望值的离差的度量。或者，它可以被视为围绕+1 和-1 的<em class="EmphasisTypeItalic "> Z </em>的离差的度量。<em class="EmphasisTypeItalic "> κ </em>在对称两点分布中达到最小值。就原始变量<em class="EmphasisTypeItalic "> X </em>而言，峰度是<em class="EmphasisTypeItalic "> X </em>围绕两个值<em class="EmphasisTypeItalic ">μ</em>T14】σ的离差的度量。</p>
<p><em class="EmphasisTypeItalic "> κ </em>在这两种情况下具有高值:</p>
<ul class="UnorderedListMarkBullet"><li><p class="Para" id="Par48">概率质量集中在均值附近，分布产生远离均值的偶然值。</p></li>
<li><p class="Para" id="Par49">概率质量集中在分布的尾部。</p></li>
</ul>

<p>图<a href="#Fig4"> 12-4 </a>显示了低峰度和高峰度的区别。左侧分布的峰度比右侧大，因为左侧分布中的数据向更宽的范围展开(或分散)，即更多的异常值和极端样本。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig4_HTML.jpg" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig4_HTML.jpg" style="width:29.78em"/></p>
<p>图 12-4</p><p class="SimplePara">厚尾分布与薄尾分布</p>


<p>对于样本<em class="EmphasisTypeItalic "> X </em> = {1，1，2，1，2，3，2，1，0}，样本峰度如下:<p> <img alt="$$ {g}_2=\frac{\frac{1}{9}\sum \limits_{i=1}^9{\left({x}_i-1.4444\right)}^4}{{\left(\frac{1}{8}\sum \limits_{i=1}^9{\left({x}_i-1.4444\right)}^2\right)}^2}-3=-1.04384 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equaa.png" style="width:18.96em"/> </p></p>
<p>在 NM Dev 中，类<code>Kurtosis</code>计算数据集的样本峰度。以下代码计算前一个示例的样本峰度:</p>
<pre>// the sample data set
double[] X4 = {1, 1, 1, 1, 2, 2, 2, 3, 0};

// compute the kurtosis of the data set
Kurtosis kurtosis = new Kurtosis(X4);
System.out.println("sample mean = " + kurtosis.mean());
System.out.println("sample standard deviation = " + sqrt(kurtosis.variance()));
System.out.println("sample kurtosis = " + kurtosis.value());

</pre>
<p>输出如下所示:</p>
<pre>sample mean = 1.4444444444444444
sample standard deviation = 0.8819171036881968
sample kurtosis = -1.043839758125472

</pre>

<h3 class="Heading">12.2.7 时刻</h3>
<p>均值、方差、偏斜度和峰度是通过以某种(非线性)方式组合数据来查看数据的方式。我们可以把这些概念推广到高阶矩。数学上，对于所有的<em class="EmphasisTypeItalic "> k </em>，第<em class="EmphasisTypeItalic "> k </em>个原始样本时刻定义如下:<p> <img alt="$$ {\overline{x}}_n^k=\frac{1}{n}\sum \limits_{i=1}^n{x}_i^k $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equab.png" style="width:5.84em"/> </p></p>
<p class="Para" id="Par55">很容易看出，第一个样本矩就是样本均值。</p>
<p class="Para" id="Par56">可以看出，对于任何样本量<em class="EmphasisTypeItalic "> n </em>，原始样本矩的期望值等于总体的第<em class="EmphasisTypeItalic "> k </em>个原始矩，如果该矩存在的话。因此，它是一个无偏的估计量。</p>
<p>第<em class="EmphasisTypeItalic "> k </em>个中心样本矩定义如下:<p> <img alt="$$ {M}_n^k=\frac{1}{n}\sum \limits_{i=1}^n{\left({x}_i-{\overline{x}}_n^1\right)}^k $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equac.png" style="width:9.38em"/> </p></p>
<p class="Para" id="Par58">其中<img alt="$$ {\overline{x}}_n^1 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq3.png" style="width:1.18em"/>或简称为<img alt="$$ {\overline{x}}_n $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq4.png" style="width:1.18em"/>是平均值或第一个原始样本矩。</p>
<p class="Para" id="Par59">很容易看出，第一个样本中心时刻<img alt="$$ {M}_n^1=0 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq5.png" style="width:3.46em"/>。</p>
<p class="Para" id="Par60">还有，<img alt="$$ {M}_n^2={s}^2 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq6.png" style="width:3.8em"/>，未调整的样本方差。</p>
<p class="Para" id="Par61">高阶矩是超过四阶矩的矩。与方差、偏度和峰度一样，这些都是高阶统计量，是数据的非线性组合。它们可用于描述或估计形状参数。矩越高，就越难估计，因为要获得类似质量的估计值，需要更大的样本。这是由于高阶消耗了过多的自由度。此外，它们可能很难理解。解释高阶的一种方法是根据低阶来讨论它们。例如，四阶矩(峰度)可以被解释为“在引起分散时尾部相对于肩部的相对重要性”(对于给定的分散，高峰度对应于重尾部，而低峰度对应于宽肩部)。第五个矩可以解释为测量“尾部相对于中心(模态，肩部)在引起偏斜中的相对重要性。”(对于给定的偏斜，高的五阶矩对应于重的尾部和模态的少量运动，而低的五阶矩对应于肩部的更多变化。)</p>
<p>在 NM Dev 中，类<code>Moments</code>计算数据集的样本矩。这里有一个例子:</p>
<pre>// compute moments of a data set
Moments moments = new Moments(6); // up to the 6th moments

// data generated using rexp in R with λ = 1
moments.addData(new double[]{
    1.050339964176429, 0.906121669295144, 0.116647826876888,
    4.579895872370673, 1.714264543643022, 0.436467861756682,
    0.860735191921604, 1.771233864044571, 0.623149028640023,
    1.058291583279980
});
System.out.println("sample size = " + moments.N());
System.out.println("1st central moment = " + moments.centralMoment(1)); // ok
System.out.println("2nd central moment = " + moments.centralMoment(2)); // ok
System.out.println("3rd central moment = " + moments.centralMoment(3)); // off, // not enough data
System.out.println("4th central moment = " + moments.centralMoment(4)); // way off, // not enough data
System.out.println("5th central moment = " + moments.centralMoment(5)); // meaningless, not enough data
System.out.println("6th central moment = " + moments.centralMoment(6)); // meaningless, not enough data

</pre>
<p>输出如下所示:</p>
<pre>sample size = 10
1st central moment = 1.3117147406005016
2nd central moment = 1.422300520892388
3rd central moment = 3.217342528890056
4th central moment = 11.708334307448762
5th central moment = 36.97401011137275
6th central moment = 122.20276981014138

</pre>

<h3 class="Heading">等级</h3>
<p class="Para" id="Par64">排名是一组项目之间的排序，使得对于任何两个项目，第一个项目要么“排名高于”、“排名低于”，要么“排名等于”第二个项目。如果在排序中可以有并列，则该排序称为弱序。否则，如果没有平手，就叫共单。通过将详细的度量减少到序数序列，排名使得根据某些标准评估复杂信息成为可能。例如，互联网搜索引擎可以根据对其相关性的估计对其找到的页面进行排名，使得用户能够快速选择他们可能想要查看的页面。在统计学中，排序是数据的转换，即在对数据进行排序时，将数值或序数值分配给数据。例如，假设观察到数值数据 3.4、5.1、2.6 和 7.3。对这些数据项排序后，它们的等级将分别是 2、3、1 和 4。对于另一个例子，顺序数据热、冷、暖将由 3、1、2 代替。在这些示例中，等级按升序分配给值。(在其他一些情况下，使用降序排列。)</p>
<p class="Para" id="Par65">在 NM Dev 中，类<code>Rank</code>用于对一组数据进行排序。它返回值的样本等级。可以用几种方式处理平局(即相等的值)和缺失值。<code>FIRST</code>方法产生一个排列，每个系的索引集的值递增，类似地<code>LAST</code>的值递减。<code>RANDOM</code>方法将这些数据随机排序，而默认的<code>AVERAGE</code>用它们的平均值代替，而<code>MAX</code>和<code>MIN</code>分别用它们的最大值和最小值代替，后者是典型的运动排名。方法<code>AS_26</code>通过跟随弗里曼(1970)打破平局。它会将每个重复项目的排名增加 0.5。这是我们的默认实现。</p>
<p>这里有一个例子:</p>
<pre>double[] x = new double[]{3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5};
System.out.println("ranking: " + Arrays.toString(x));

Rank rank = new Rank(x, Rank.TiesMethod.AS_26); // default implementation
System.out.println("AS_26 rank: " + Arrays.toString(rank.ranks()));

rank = new Rank(x, Rank.TiesMethod.AVERAGE);
System.out.println("AVERAGE rank: " + Arrays.toString(rank.ranks()));

rank = new Rank(x, Rank.TiesMethod.FIRST);
System.out.println("FIRST rank: " + Arrays.toString(rank.ranks()));

rank = new Rank(x, Rank.TiesMethod.LAST);
System.out.println("LAST rank: " + Arrays.toString(rank.ranks()));

rank = new Rank(x, Rank.TiesMethod.MAX);
System.out.println("MAX rank: " + Arrays.toString(rank.ranks()));

rank = new Rank(x, Rank.TiesMethod.MIN);
System.out.println("MIN rank: " + Arrays.toString(rank.ranks()));

rank = new Rank(x, Rank.TiesMethod.RANDOM);
System.out.println("RANDOM rank: " + Arrays.toString(rank.ranks()));

</pre>
<p>输出如下所示:</p>
<pre>AS_26 rank: [4.5, 1.5, 6.0, 1.5, 8.0, 11.0, 3.0, 10.0, 8.0, 4.5, 8.0]
AVERAGE rank: [4.5, 1.5, 6.0, 1.5, 8.0, 11.0, 3.0, 10.0, 8.0, 4.5, 8.0]
FIRST rank: [4.0, 1.0, 6.0, 2.0, 7.0, 11.0, 3.0, 10.0, 8.0, 5.0, 9.0]
LAST rank: [5.0, 2.0, 6.0, 1.0, 9.0, 11.0, 3.0, 10.0, 8.0, 4.0, 7.0]
MAX rank: [5.0, 2.0, 6.0, 2.0, 9.0, 11.0, 3.0, 10.0, 9.0, 5.0, 9.0]
MIN rank: [4.0, 1.0, 6.0, 1.0, 7.0, 11.0, 3.0, 10.0, 7.0, 4.0, 7.0]
RANDOM rank: [4.0, 1.0, 6.0, 2.0, 9.0, 11.0, 3.0, 10.0, 7.0, 5.0, 8.0]

</pre>
<h4 class="Heading">12.2.8.1 分位数</h4>
<p class="Para" id="Par68"><em class="EmphasisTypeItalic ">q</em>-分位数是将有限的有序数据集划分为(几乎)相等大小的<em class="EmphasisTypeItalic "> q </em>子集的值。分位数是标记连续子集之间边界的数据值。有<em class="EmphasisTypeItalic "> q </em>的<em class="EmphasisTypeItalic ">q</em>1 个分位数，每个满足 0&lt;T10】kT12】q 的整数<em class="EmphasisTypeItalic "> k </em>一个分位数。将数据视为来自随机变量的样本，随机变量的第<em class="EmphasisTypeItalic ">k</em>-第<em class="EmphasisTypeItalic ">q</em>-分位数为值<em class="EmphasisTypeItalic "> x </em>，使得样本或随机变量小于<em class="EmphasisTypeItalic "> x </em>的概率最多为<img alt="$$ \frac{k}{q} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq7.png" style="width:0.76em"/>，样本或随机变量大于<em class="EmphasisTypeItalic "> x </em>的概率最多为<img alt="$$ \frac{q-k}{q} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq8.png" style="width:1.59em"/>。最小的观察对应于概率 0，最大的概率 1。</p>
<p class="Para" id="Par69">分位数也可以应用于连续分布(见 12.3 和 12.3.1 节)，提供了一种将秩统计推广到连续变量的方法。当随机变量的累积分布函数已知时，<em class="EmphasisTypeItalic ">q</em>-分位数是分位数函数(累积分布函数的反函数，CDF)对值<img alt="$$ \left\{\frac{1}{q},\frac{2}{q},\cdots, \frac{q-1}{q}\right\} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq9.png" style="width:6.27em"/>的应用。</p>
<p>在 NM Dev 中，类<code>Quantile</code>计算数据集的分位数。Hyndman &amp; Fan (1996)中描述了九种不同的分位数定义和实现。简而言之，它们如下。默认实现是<code>APPROXIMATELY_MEDIAN_UNBIASED</code>。</p>
<ol><li class="ListItem"><p class="Para" id="Par71"><code>INVERSE_OF_EMPIRICAL_CDF</code>:经验分布函数的逆。</p>
 </li>
<li class="ListItem"><p class="Para" id="Par72"><code>INVERSE_OF_EMPIRICAL_CDF_WITH_AVERAGING_AT_DISCONTINUITIES</code>:在不连续处求平均的经验分布函数的逆。</p>
 </li>
<li class="ListItem"><p class="Para" id="Par73"><code>NEAREST_EVEN_ORDER_STATISTICS</code>:SAS 中最接近的偶数阶统计量。</p>
 </li>
<li class="ListItem"><p class="Para" id="Par74"><code>LINEAR_INTERPOLATION_OF_EMPIRICAL_CDF</code>:经验 CDF 的线性插值。</p>
 </li>
<li class="ListItem"><p class="Para" id="Par75"><code>MIDWAY_THROUGH_STEPS_OF_EMPIRICAL_CDF</code>:分段线性函数，其中节点是经验 CDF 步骤中间的值。</p>
 </li>
<li class="ListItem"><p class="Para" id="Par76"><code>MINITAB_SPSS</code>:Minitab 和 SPSS 中的定义。</p>
 </li>
<li class="ListItem"><p class="Para" id="Par77"><code>S</code>:s 中的定义。</p>
 </li>
<li class="ListItem"><p class="Para" id="Par78"><code>APPROXIMATELY_MEDIAN_UNBIASED</code>:无论样本的分布如何，得到的分位数估计值都是近似中值无偏的。</p>
 </li>
<li class="ListItem"><p class="Para" id="Par79"><code>APPROXIMATELY_UNBIASED_IF_DATA_IS_NORMAL</code>:如果样本是正态分布的，那么得到的分位数估计对于期望的顺序统计量是近似无偏的。</p>
 </li>
</ol>

<p>这里有一个例子:</p>
<pre>double[] x = new double[]{0, 1, 2, 3, 3, 3, 6, 7, 8, 9}; // with repeated observations
double[] qs = new double[]{1e-10, 0.1, 0.15, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 1.}; // quantiles

System.out.println("APPROXIMATELY_MEDIAN_UNBIASED");
Quantile stat1 = new Quantile(
        x,
        Quantile.QuantileType.APPROXIMATELY_MEDIAN_UNBIASED
);
System.out.println("number of samples = " + stat1.N());
for (double q : qs) {
    System.out.println(String.format("Q(%f) = %f", q, stat1.value(q)));
}

System.out.println("NEAREST_EVEN_ORDER_STATISTICS");
Quantile stat2 = new Quantile(
        x,
        Quantile.QuantileType.NEAREST_EVEN_ORDER_STATISTICS);
System.out.println("number of samples = " + stat2.N());
for (double q : qs) {
    System.out.println(String.format("Q(%f) = %f", q, stat2.value(q)));
}

</pre>
<p>输出如下所示:</p>
<pre>APPROXIMATELY_MEDIAN_UNBIASED
number of samples = 10
Q(0.000000) = 0.000000
Q(0.100000) = 0.366667
Q(0.150000) = 0.883333
Q(0.200000) = 1.400000
Q(0.300000) = 2.433333
Q(0.400000) = 3.000000
Q(0.500000) = 3.000000
Q(0.600000) = 4.600000
Q(0.700000) = 6.566667
Q(0.800000) = 7.600000
Q(0.900000) = 8.633333
Q(0.950000) = 9.000000
Q(1.000000) = 9.000000
NEAREST_EVEN_ORDER_STATISTICS
number of samples = 10
Q(0.000000) = 0.000000
Q(0.100000) = 0.000000
Q(0.150000) = 1.000000
Q(0.200000) = 1.000000
Q(0.300000) = 2.000000
Q(0.400000) = 3.000000
Q(0.500000) = 3.000000
Q(0.600000) = 3.000000
Q(0.700000) = 6.000000
Q(0.800000) = 7.000000
Q(0.900000) = 8.000000
Q(0.950000) = 9.000000
Q(1.000000) = 9.000000

</pre>

<h4 class="Heading">12.2.8.2 中位数</h4>
<p>数据集的中值定义为不超过一半的数据值大于中值，不超过一半的数据值小于中值。虽然算术平均值通常用于报告集中趋势，但它不是一个稳健的统计数据，这意味着它受异常值(比大多数值大得多或小得多的值)的影响很大。对于偏斜分布，如少数人的收入远大于大多数人的收入分布，算术平均值可能不符合一个人的“中间”概念，稳健统计，如中位数，可能提供对集中趋势的更好描述。数学上，它是 50%的分位数，即<em class="EmphasisTypeItalic "> Q </em> (0.5)。见图<a href="#Fig5"> 12-5 </a>。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig5_HTML.png" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig5_HTML.png" style="width:11.8em"/></p>
<p>图 12-5</p><p class="SimplePara">比较概率分布的中值和平均值</p>


<p>这里有一个例子:</p>
<pre>double[] x = new double[]{0, 1, 2, 3, 3, 3, 6, 7, 8, 9}; // with repeated observations

System.out.println("APPROXIMATELY_MEDIAN_UNBIASED");
Quantile stat1 = new Quantile(
        x,
        Quantile.QuantileType.APPROXIMATELY_MEDIAN_UNBIASED
);
System.out.println("the median = " + stat1.value(0.5));

System.out.println("NEAREST_EVEN_ORDER_STATISTICS");
Quantile stat2 = new Quantile(
        x,
        Quantile.QuantileType.NEAREST_EVEN_ORDER_STATISTICS);
}
System.out.println("the median = " + stat2.value(0.5));

</pre>
<p>输出如下所示:</p>
<pre>APPROXIMATELY_MEDIAN_UNBIASED
the median = 3.0
NEAREST_EVEN_ORDER_STATISTICS
the median = 3.0

</pre>

<h4 class="Heading">12.2.8.3 最大值和最小值</h4>
<p>最大值是数据集中的最大值，而最小值是数据集中的最小值。在数学上，它们相当于 100%分位数和最小分位数，比如 1e-10%分位数、<em class="EmphasisTypeItalic "> Q </em> (1)和<em class="EmphasisTypeItalic ">Q</em>(1e-10)。但是结果可能受所使用的插值方法的影响。在 NM Dev 中，类<code>Max</code>和<code>Min</code>分别用于计算最大值和最小值。这里有一个例子:</p>
<pre>double[] x = new double[]{0, 1, 2, 3, 3, 3, 6, 7, 8, 9}; // with repeated observations
System.out.println("APPROXIMATELY_MEDIAN_UNBIASED");
Quantile stat1 = new Quantile(
        x,
        Quantile.QuantileType.APPROXIMATELY_MEDIAN_UNBIASED
);
System.out.println("the 100% quantile = " + stat1.value(1.));
System.out.println("the maximum = " + new Max(x).value());

System.out.println("NEAREST_EVEN_ORDER_STATISTICS");
Quantile stat2 = new Quantile(
        x,
        Quantile.QuantileType.NEAREST_EVEN_ORDER_STATISTICS);
System.out.println("the 1e-10 quantile = " + stat2.value(1e-10));
System.out.println("the minimun = " + new Min(x).value());

</pre>
<p>输出如下所示:</p>
<pre>APPROXIMATELY_MEDIAN_UNBIASED
the 100% quantile = 9.0
the maximum = 9.0
NEAREST_EVEN_ORDER_STATISTICS
the 1e-10 quantile = 0.0
the minimun = 0.0

</pre>


<h3 class="Heading">协方差</h3>
<p>协方差是两个样本或两个随机变量的联合可变性的度量。如果一个样本/变量的大值对应于另一个样本/变量的大值，并且同样适用于较小的值(也就是说，变量往往表现出相似的行为)，则协方差为正。见图<a href="#Fig6"> 12-6 </a>。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig6_HTML.png" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig6_HTML.png" style="width:7.98em"/></p>
<p>图 12-6</p><p class="SimplePara">正协方差</p>


<p>在相反的情况下，当一个样本/变量的大值通常对应于另一个样本/变量的较小值时(即变量往往表现出相反的行为)，协方差为负。见图<a href="#Fig7"> 12-7 </a>。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig7_HTML.png" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig7_HTML.png" style="width:7.98em"/></p>
<p>图 12-7</p><p class="SimplePara">负协方差</p>


<p>同样，如果一个样本/变量中的值不能预测另一个样本/变量中的值，则协方差为零。见图<a href="#Fig8"> 12-8 </a>。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig8_HTML.png" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig8_HTML.png" style="width:7.98em"/></p>
<p>图 12-8</p><p class="SimplePara">零协方差</p>


<p class="Para" id="Par90">因此，协方差的符号表示变量之间线性关系的趋势。协方差的大小不容易解释，因为它不是归一化的，因此取决于变量的大小。然而，被称为相关系数的协方差的标准化版本通过其大小显示线性关系的强度。</p>
<h4 class="Heading">12.2.9.1 样本协方差</h4>
<p>数学上，两个样本<em class="EmphasisTypeItalic "> X </em>和<em class="EmphasisTypeItalic "> Y </em>的样本协方差如下:<p> <img alt="$$ \operatorname{cov}\left(X,Y\right)=\mathrm{E}\left(X-\mathrm{E}(X)\right)\mathrm{E}\left(Y-\mathrm{E}(Y)\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equad.png" style="width:16.94em"/> </p> <p> <img alt="$$ =\frac{1}{N-1}\sum \limits_{i=1}^N\left({X}_i-\overline{X}\right)\left({Y}_i-\overline{Y}\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equae.png" style="width:12.87em"/> </p></p>
<p><img alt="$$ \overline{X} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq10.png" style="width:0.98em"/>是<em class="EmphasisTypeItalic "> X </em>的样本均值。<img alt="$$ \overline{Y} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq11.png" style="width:0.92em"/>是<em class="EmphasisTypeItalic "> Y </em>的样本均值。这里我们使用分母<em class="EmphasisTypeItalic ">N</em>1 而不是<em class="EmphasisTypeItalic "> N </em>来使估计量无偏，因为我们在计算中使用样本均值而不是总体均值。如果总体均值已知，那么无偏估计量如下:<p> <img alt="$$ \operatorname{cov}\left(X,Y\right)=\frac{1}{N}\sum \limits_{i=1}^N\left({X}_i-\mathrm{E}(X)\right)\left({Y}_i-\mathrm{E}(Y)\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equaf.png" style="width:18.36em"/> </p></p>
<p>样本方差是协方差的一种特殊情况，其中两个样本/变量相同(即其中一个变量总是与另一个变量取相同的值):<p> <img alt="$$ \operatorname{var}(X)=\operatorname{cov}\left(X,X\right)={\sigma}^2(X)={\sigma}_X^2 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equag.png" style="width:15.03em"/> </p></p>
<p>样本标准差是 var 的平方根(<em class="EmphasisTypeItalic "> X </em>)。【T2<img alt="$$ {\sigma}_X=\sqrt{\sigma_X^2} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equah.png" style="width:5.13em"/></p>

<h4 class="Heading">12.2.9.2 相关</h4>
<p>两个样本的相关系数定义为协方差除以它们的标准差的乘积。样本相关也称为 Spearman 等级相关。它本质上是协方差的归一化测量，因此结果值始终介于 1 和 1 之间。与协方差本身一样，该度量只能反映变量的线性相关性，而忽略了许多其他类型的关系或相关性。参见图<a href="#Fig9"> 12-9 </a>。【T2<img alt="$$ \mathrm{corr}\left(X,Y\right)={\rho}_{XY}=\frac{\operatorname{cov}\left(X,Y\right)}{\sigma_X{\sigma}_Y} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equai.png" style="width:13.18em"/></p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig9_HTML.jpg" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig9_HTML.jpg" style="width:42.82em"/></p>
<p>图 12-9</p><p class="SimplePara">具有不同相关系数值的散点图示例</p>


<p>在 NM Dev 中，类<code>SpearmanRankCorrelation</code>计算两个样本集之间的样本相关性。这里有一个例子:</p>
<pre>// the sample data sets
double[] X5 = new double[]{106, 86, 100, 101, 99, 103, 97, 113, 112, 110};
double[] X6 = new double[]{7, 0, 27, 50, 28, 29, 20, 12, 6, 17};
// compute the sample correlation of the data sets
System.out.println("the sample correlation = " + new SpearmanRankCorrelation(X5, X6).value());

</pre>
<p>输出如下所示:</p>
<pre>the sample correlation = -0.17575757575757575

</pre>

<h4 class="Heading">12.2.9.3 协方差矩阵和相关矩阵</h4>
<p class="Para" id="Par98">对于两个以上的样本，协方差矩阵是给出每对样本之间的协方差的方阵。任何协方差矩阵都是对称且半正定的。主对角线上的条目是样本的方差。直观上，协方差矩阵将方差的概念推广到多维。作为一个例子，二维空间中随机样本集合的变化不能完全用单个数字来表征，在<em class="EmphasisTypeItalic "> x </em>和<em class="EmphasisTypeItalic "> y </em>方向上的变化也不能包含所有必要的信息；包含协方差和方差的 2 × 2 矩阵对于完全描述二维变化是必要的。</p>
<p>数学上，对于多个变量的随机样本的一列向量<em><strong class="EmphasisTypeBoldItalic ">x</strong></em>=(<em class="EmphasisTypeItalic ">x</em><sub>1</sub>，<em class="EmphasisTypeItalic "> X </em> <sub> 2 </sub>，<em class="EmphasisTypeItalic ">x</em><sub><em class="EmphasisTypeItalic ">n</em></sub>)<sup><em class="EmphasisTypeItalic ">t</em></sup>，每一个都具有有限的方差和期望值 e(<em class="EmphasisTypeItalic ">x</em><sub><em class="EmphasisTypeItalic ">I<sub> 然后协方差矩阵<strong class="EmphasisTypeBold ">σ</strong><sub><em><strong class="EmphasisTypeBoldItalic ">X</strong></em></sub>是一个矩阵，其(<em class="EmphasisTypeItalic "> i </em>，<em class="EmphasisTypeItalic "> j </em>)项是协方差 cov(<em class="EmphasisTypeItalic ">X</em><sub><em class="EmphasisTypeItalic ">I</em></sub>，<em class="EmphasisTypeItalic "> X </em> <sub> <em class="EmphasisTypeItalic "> j </em> </sub>)。 也就是<p> <img alt="$$ {\left({\boldsymbol{\Sigma}}_{\boldsymbol{X}}\right)}_{ij}=\operatorname{cov}\left({X}_i,{X}_j\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equaj.png" style="width:8.98em"/> </p> <p> <img alt="$$ =\mathrm{E}\left({X}_i-\mathrm{E}\left({X}_i\right)\right)\mathrm{E}\left({X}_j-\mathrm{E}\left({X}_j\right)\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equak.png" style="width:13.95em"/> </p></sub></em></sub></p>
<p class="Para" id="Par100">对角线的条目是<img alt="$$ {\sigma}_{X_i}^2 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq12.png" style="width:1.68em"/>。</p>
<p class="Para" id="Par101">同样，相关矩阵是其(<em class="EmphasisTypeItalic "> i </em>，<em class="EmphasisTypeItalic "> j </em>)项为相关系数<img alt="$$ {\rho}_{X_i{X}_j} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq13.png" style="width:2.26em"/>的矩阵。对角线上的条目都是 1。相关矩阵必须是对称的半正定矩阵。此外，如果没有一个变量的所有值都可以精确地生成为其他变量值的线性函数，则相关矩阵是严格正定的。</p>
<p class="Para" id="Par102">例如，假设我们有五个数据集。</p>
<p class="Para" id="Par103"><em class="EmphasisTypeItalic "> X </em> <sub> 1 </sub> = {1.4022225，–0.2230975，0.6939930，0.6939930，0.6939930，–2.5275280 }</p>
<p class="Para" id="Par104"><em class="EmphasisTypeItalic ">X</em><sub>2</sub>= {–0.04625344，0.91561987，1.94611387，0.18818663，–0.10749210，0.64942255}</p>
<p class="Para" id="Par105"><em class="EmphasisTypeItalic "> X </em> <sub> 3 </sub> = {1.26176112，1.17086252，–0.82939259，–0.29040783，3.2737632，0.07506224}</p>
<p class="Para" id="Par106"><em class="EmphasisTypeItalic ">X</em><sub>4</sub>= {–1.8394428，0.2282348，1.0905923，0.693785，0.5141217，–1.0787524 }</p>
<p class="Para" id="Par107"><em class="EmphasisTypeItalic "> X </em> <sub> 5 </sub> = {0.7182637，0.0690674，0.1458883，0.466452，0.76958，1.6217606}</p>
<p>样本协方差如下:<p> <img alt="$$ {\boldsymbol{\Sigma}}_{\boldsymbol{X}}=\left[\begin{array}{ccccc}1.891462&amp;amp; -0.094053&amp;amp; 0.665669&amp;amp; 0.176962&amp;amp; -0.487023\\ {}-0.094053&amp;amp; 0.600273&amp;amp; -0.742584&amp;amp; 0.404512&amp;amp; -0.173547\\ {}0.665669&amp;amp; -0.742584&amp;amp; 2.167306&amp;amp; -0.250672&amp;amp; 0.085099\\ {}0.176962&amp;amp; 0.404512&amp;amp; -0.250672&amp;amp; 1.301751&amp;amp; -0.385892\\ {}-0.487023&amp;amp; -0.173547&amp;amp; 0.085099&amp;amp; -0.385892&amp;amp; 0.317301\end{array}\right] $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equal.png" style="width:30.78em"/> </p></p>
<p class="Para" id="Par109">请注意，每个样本集(或每个变量)都是按列排列的。有五列对应于五个变量。每组有六个样本/观察值/数值。每行是五个变量的一个观察值。例如，一行中的数字，如{1.4022225，0.04625344，1.26176112，1.8394428，0.7182637}应该放在一起观察。所以，数字的顺序很重要。因此，得到的协方差矩阵是一个 5 × 5 的矩阵。</p>
<p>在 NM Dev 中，类<code>SampleCovariance</code>计算数据集的样本协方差。以下代码重现了前面的示例:</p>
<pre>// each column is a sample set; there are 5 data sets
Matrix X7 = new DenseMatrix(new double[][]{
    {1.4022225, -0.04625344, 1.26176112, -1.8394428, 0.7182637},
    {-0.2230975, 0.91561987, 1.17086252, 0.2282348, 0.0690674},
    {0.6939930, 1.94611387, -0.82939259, 1.0905923, 0.1458883},
    {0.6939930, 0.18818663, -0.29040783, 0.6937185, 0.4664052},
    {0.6939930, -0.10749210, 3.27376532, 0.5141217, 0.7691778},
    {-2.5275280, 0.64942255, 0.07506224, -1.0787524, 1.6217606}
});
// compute the sample covariance of the data sets
Matrix cov = new SampleCovariance(X7); // a 5x5 matrix
System.out.println("sample covariance =\n");
System.out.println(cov);

</pre>
<p>输出如下所示:</p>
<pre>sample covariance =
5x5
        [,1] [,2] [,3] [,4] [,5]
[1,] 1.891462, -0.094053, 0.665669, 0.176962, -0.487023,
[2,] -0.094053, 0.600273, -0.742584, 0.404512, -0.173547,
[3,] 0.665669, -0.742584, 2.167306, -0.250672, 0.085099,
[4,] 0.176962, 0.404512, -0.250672, 1.301751, -0.385892,
[5,] -0.487023, -0.173547, 0.085099, -0.385892, 0.317301,

</pre>

<h4 class="Heading">12.2.9.4·莱多伊特-沃尔夫线性收缩</h4>
<p class="Para" id="Par112">本节遵循 Ledoit &amp; Wolf (2004)的观点，他们为协方差矩阵提出了比样本协方差更好的估计量。许多现实生活(非教科书)问题需要估计协方差矩阵和/或其逆矩阵，其中矩阵维数<em class="EmphasisTypeItalic "> p </em>比样本大小<em class="EmphasisTypeItalic "> n </em>大。示例包括从大量股票中选择均值-方差有效的投资组合，在大截面上运行广义最小二乘(GLS)回归，以及在矩限制数量较大的一般矩方法中选择最佳加权矩阵。在这种情况下，通常的估计量，即样本协方差矩阵，已知表现不佳。当矩阵维数<em class="EmphasisTypeItalic "> p </em>大于可用观测值的数量<em class="EmphasisTypeItalic "> n </em>时，样本协方差矩阵甚至不可逆。这种情况经常发生在估计协方差矩阵时，比如说，3000 只股票，而我们没有足够的数据来进行估计。十年的数据只有 2500 个交易日，或者更糟，只有 120 个月。估计的每日或每月协方差矩阵是不可逆的。所有需要计算逆矩阵的投资组合优化算法都会失败。</p>
<p class="Para" id="Par113">当比率<img alt="$$ \frac{p}{n}&amp;lt;1 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq15.png" style="width:2.64em"/>不可忽略时，样本协方差矩阵是可逆的，但可能在数值上是病态的。(如果一个矩阵的条件数非常大，则称它是病态的。实际上，这样的矩阵几乎是奇异的，并且它的逆的计算，或者线性方程系统的解容易产生大的数值误差。不可逆矩阵的条件数等于无穷大。)这意味着反转它会显著放大估计误差。对于大的<em class="EmphasisTypeItalic "> p </em>，很难找到足够多的观测值，大的<em class="EmphasisTypeItalic "> n </em>，使<img alt="$$ \frac{p}{n} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq16.png" style="width:0.82em"/>接近于 0，因此开发一个适用于高维协方差矩阵的条件良好的估计器是很重要的。</p>
<p class="Para" id="Par114">如果我们不惜任何代价想要一个条件良好的估计量，我们总是可以在协方差矩阵上强加一些特定的结构来迫使它是条件良好的，例如对角性、稀疏性、图模型或因子模型。但是，在没有关于矩阵的真实结构的先验信息的情况下，这种特别的结构通常会被错误地指定，并且所得到的估计器可能是如此有偏差，以至于它与真实的协方差矩阵几乎没有相似之处。以前没有比样本协方差矩阵条件更好、更准确的估计量(Ledoit &amp; Wolf，2004)。</p>
<p class="Para" id="Par115">2003 年，Ledoit &amp;Wolf (2003，2004)提出了一种渐近地同时具有这两种性质的估计量。获得条件良好的结构化估计量的一种方法是施加这样的条件，即所有方差都相同，所有协方差都为零。他们推荐的估计量是这个结构化估计量和样本协方差矩阵的加权平均值。该估计器确保样本协方差矩阵和结构化估计器的加权平均值比它们中的任何一个都更准确。这种新的估计方法倾向于将最极端的系数拉向更中心的值(因此称为收缩)，从而系统地减少最重要的估计误差。</p>
<p>广泛的研究表明:( I)新的估计量比样本协方差矩阵更精确，即使对于非常少量的观察值和变量也是如此，而且通常精确很多；(ii)只要有至少 10 个变量和观测值，它基本上与有限样本决策理论中提出的一些估计量一样准确或更准确；(iii)它比真正的协方差矩阵条件化得更好；以及(iv)当存在至少 20 个观察值和变量时，一般渐近性是有限样本行为的良好近似。图<a href="#Fig10"> 12-10 </a>比较了条件数(关于数据的微小变化，矩阵有多不稳定；越小越好)<em class="EmphasisTypeItalic ">S</em><sup>∑</sup>线性收缩协方差矩阵对σ样本协方差矩阵。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig10_HTML.jpg" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig10_HTML.jpg" style="width:29.58em"/></p>
<p>图 12-10</p><p class="SimplePara">比较 Ledoit-Wolf 2004 给出的矩阵条件数和样本协方差矩阵(credit Ledoit &amp; Wolf，2004)</p>


<p>在 NM Dev 中，类<code>LedoitWolf2004</code>计算这个线性收缩协方差矩阵估计器。这里有一个例子:</p>
<pre>/*
 * These are the stock returns for MSFT, YHOO, GOOG, AAPL, MS, XOM from
 * Aug 20, 2012 to Jan 15, 2013 (i.e., returns for 100 days).
 */
Matrix X = new DenseMatrix(new double[][]{
    {0.001968, 0.000668, -0.008926, -0.013668, 0.004057, -0.005492},
    {-0.008511, -0.003340, 0.011456, 0.019523, -0.002020, 0.002991},
    {-0.009244, -0.003351, -0.000561, -0.009327, -0.024291, -0.004703},
    {0.009997, 0.003362, 0.002704, 0.000879, 0.004149, 0.008413},
    {0.004289, -0.004692, -0.013866, 0.018797, -0.002066, -0.003543},
    {-0.001971, -0.008754, 0.011999, -0.001308, 0.004831, 0.004129},
    {0.000658, 0.008152, 0.015888, -0.001965, 0.014423, -0.002284},
    {-0.010855, -0.011456, -0.009200, -0.014260, 0.006093, -0.007899},
    {0.016628, -0.001363, 0.005002, 0.002073, 0.006729, 0.001154},
    {-0.014066, 0.016382, -0.005912, 0.014617, 0.033422, -0.002075},
    {0.000000, 0.013432, -0.000470, -0.007025, 0.010996, 0.002426},
    {0.031520, 0.001325, 0.027442, 0.009023, 0.036468, 0.019011},
    {-0.012544, 0.007280, 0.009651, 0.006165, 0.051235, 0.010403},
    {-0.007492, -0.007227, -0.007619, -0.026013, -0.027598, -0.004924},
    {0.002297, 0.003309, -0.012244, -0.003244, 0.038647, 0.001574},
    {-0.000327, 0.015831, -0.001893, 0.013914, 0.009884, -0.000786},
    {0.005241, 0.012987, 0.021943, 0.019693, 0.027634, 0.018766},
    {0.008798, 0.010897, 0.005156, 0.012164, 0.019048, 0.011802},
    {0.000000, -0.005707, 0.000423, 0.012294, -0.024189, -0.004252},
    {-0.000969, 0.014668, 0.011690, 0.003043, -0.009577, -0.002847},
    {-0.004203, -0.003143, 0.012836, 0.000272, -0.003413, -0.011748},
    {0.012662, -0.004414, 0.000852, -0.004850, -0.020548, 0.010443},
    {-0.008015, -0.003167, 0.008062, 0.001999, -0.007576, 0.004398},
    {-0.013251, 0.016518, 0.020968, -0.013287, -0.002349, -0.000438},
    {-0.012774, -0.020000, -0.000294, -0.024969, -0.025898, -0.001533},
    {-0.007299, -0.004464, 0.005740, -0.012409, -0.010272, -0.005594},
    {-0.000334, 0.027546, 0.004035, 0.024254, 0.025031, 0.006287},
    {-0.013039, -0.003741, -0.002644, -0.020863, -0.005956, -0.003836},
    {-0.009146, -0.009387, 0.009649, -0.011565, 0.002996, 0.003851},
    {0.005812, 0.006949, -0.006288, 0.002910, 0.007168, -0.000877},
    {0.006798, 0.016939, 0.007279, 0.015343, 0.007117, -0.000219},
    {0.005739, 0.003701, 0.007279, -0.006927, 0.025913, 0.005706},
    {-0.006042, -0.011063, -0.000521, -0.021318, 0.001722, 0.003492},
    {-0.002364, -0.003729, -0.012779, -0.022090, -0.002865, 0.001414},
    {-0.016926, -0.011229, -0.018144, -0.003636, -0.005747, -0.005863},
    {-0.010331, -0.001262, 0.000632, 0.007963, 0.002890, -0.012014},
    {-0.001044, 0.005685, 0.009294, -0.020000, 0.026513, 0.001548},
    {0.008708, -0.002513, -0.008956, 0.002575, -0.030882, -0.001545},
    {0.010704, -0.012594, -0.005062, 0.008008, 0.025492, 0.005306},
    {-0.000683, 0.015306, 0.005020, 0.023692, 0.006780, 0.009567},
    {0.003419, 0.010678, 0.014489, -0.007977, 0.034792, 0.010892},
    {-0.003066, -0.005594, -0.080067, -0.018576, -0.037961, 0.000970},
    {-0.029050, -0.010000, -0.019007, -0.036030, -0.014656, -0.014209},
    {-0.022527, -0.004419, -0.004576, 0.039666, -0.004577, 0.000437},
    {0.001801, 0.057070, 0.002475, -0.032607, -0.019540, -0.021829},
    {-0.005392, -0.007199, -0.004483, 0.005667, 0.004103, -0.003347},
    {-0.000723, 0.003625, 0.000679, -0.011824, -0.004670, 0.006158},
    {0.011935, 0.010837, -0.003851, -0.009097, -0.003519, 0.002114},
    {0.011794, 0.002978, 0.007628, -0.014370, 0.022955, 0.005996},
    {0.034264, 0.006532, 0.010716, 0.002059, 0.013234, 0.004746},
    {-0.000683, 0.009440, 0.000480, -0.033090, 0.009654, -0.014501},
    {0.004443, 0.015196, -0.007210, 0.013550, -0.001687, 0.004013},
    {0.007826, 0.005181, -0.001816, -0.003024, 0.024789, 0.010769},
    {-0.026334, -0.004009, -0.021416, -0.038263, -0.085761, -0.031415},
    {-0.009015, -0.008626, -0.022230, -0.036290, -0.006615, -0.012588},
    {0.000700, 0.001160, 0.016465, 0.017313, 0.005448, 0.001608},
    {-0.021329, 0.014484, 0.004329, -0.007732, 0.009633, 0.001261},
    {-0.032154, 0.019417, -0.010287, 0.000129, -0.014908, -0.009734},
    {-0.009228, -0.001120, -0.009863, -0.011089, -0.026029, -0.004626},
    {-0.006706, 0.003365, -0.008107, -0.020973, 0.010566, 0.000813},
    {-0.005251, -0.001677, -0.000124, 0.003919, -0.004920, 0.003599},
    {0.007919, 0.027996, 0.032495, 0.072108, 0.021014, 0.014112},
    {-0.000748, -0.006536, 0.002634, -0.008520, -0.010291, -0.001939},
    {0.008985, 0.008772, -0.006120, 0.001408, -0.006116, 0.005829},
    {0.027829, 0.009239, 0.003154, 0.017447, 0.011077, 0.012271},
    {-0.011191, 0.010232, -0.010210, 0.031549, 0.010956, -0.005276},
    {-0.011318, 0.009062, 0.014460, -0.008057, 0.001204, -0.014331},
    {0.010340, -0.001057, 0.019323, -0.003146, 0.015033, 0.008586},
    {-0.014985, -0.002115, 0.012023, 0.011013, -0.001185, 0.000227},
    {-0.012245, -0.005299, 0.009366, -0.006923, 0.000593, 0.000227},
    {-0.007137, -0.011721, -0.004468, 0.001555, -0.023711, -0.006013},
    {-0.002270, 0.020485, -0.006070, -0.017639, 0.008500, -0.004794},
    {0.011377, -0.002113, -0.004645, -0.064357, 0.022276, 0.006193},
    {0.002250, 0.016411, 0.004812, 0.015683, -0.014134, 0.003078},
    {-0.010101, 0.000000, -0.010013, -0.025565, 0.013740, 0.006818},
    {0.018141, 0.011979, 0.001768, -0.006432, 0.002357, -0.002144},
    {0.014105, 0.004632, 0.016720, 0.021838, 0.043504, 0.006560},
    {-0.002928, -0.007172, 0.000976, -0.004415, -0.002817, 0.005169},
    {-0.004772, -0.001548, 0.007369, -0.017273, 0.005650, -0.009726},
    {-0.011066, 0.014987, -0.001053, -0.037569, 0.014045, -0.005645},
    {0.010817, 0.002546, 0.026811, 0.017733, 0.026593, 0.008969},
    {0.016974, -0.003555, 0.000402, 0.029046, 0.031840, 0.007764},
    {-0.009071, -0.001019, -0.001331, -0.014216, -0.001569, -0.012506},
    {0.013548, 0.004592, 0.003125, -0.008702, 0.009429, 0.005088},
    {-0.008309, -0.017268, -0.009317, -0.004600, -0.018163, -0.018675},
    {-0.014208, 0.015504, -0.008566, 0.001617, 0.001586, -0.003554},
    {-0.007391, -0.004071, -0.000888, -0.013784, -0.003694, 0.001726},
    {0.003723, 0.001533, -0.003640, 0.004016, -0.005826, -0.002412},
    {-0.015208, -0.005102, -0.008892, -0.010620, -0.007991, -0.020262},
    {0.006026, 0.020513, 0.010528, 0.044310, 0.026853, 0.017039},
    {0.034070, 0.009045, 0.022435, 0.031682, 0.026151, 0.024957},
    {-0.013396, -0.014940, 0.000581, -0.012622, -0.002039, -0.001804},
    {-0.018716, 0.004044, 0.019760, -0.027855, 0.031154, 0.004630},
    {-0.001870, -0.023162, -0.004363, -0.005882, -0.019316, -0.011578},
    {-0.005245, 0.013402, -0.001973, 0.002691, -0.007576, 0.006255},
    {0.005650, -0.017294, 0.006573, -0.015629, -0.001527, -0.003843},
    {-0.008989, -0.017081, 0.004552, 0.012396, 0.036697, 0.010892},
    {0.013983, 0.015798, -0.002009, -0.006132, -0.008358, 0.005724},
    {0.002236, 0.007258, -0.022622, -0.035653, -0.004958, -0.000335},
    {0.011900, 0.004632, 0.002323, -0.031550, 0.017937, -0.000558}
});
/*
 * From Wolf's implementation (http://www.econ.uzh.ch/faculty/wolf/publications.html#9):
 * phi = 4.11918014563813e-06
 * rho = 2.59272437810913e-06
 * gamma = 1.64807384775746e-08
 * kappa = 9.26205927972248e+01
 * shrinkage = 9.26205927972248e-01
 * sigma =
 * 1e-4 *
 * 1.515632920116000 0.485389976957753 0.569819071905581 0.832527350192132 0.847148840587289
 * 0.397609074332363
 * 0.485389976957753 1.385321425539000 0.536232629487419 0.789078831932216 0.788206205379818
 * 0.348026133393798
 * 0.569819071905581 0.536232629487419 1.821791453675000 0.934388133855881 0.952823814063320
 * 0.422051935833047
 * 0.832527350192132 0.789078831932216 0.934388133855881 3.948763689179000 1.349588317003072
 * 0.628591706535889
 * 0.847148840587289 0.788206205379818 0.952823814063320 1.349588317003072 3.907173836600000
 * 0.644231481562656
 * 0.397609074332363 0.348026133393798 0.422051935833047 0.628591706535889 0.644231481562656
 * 0.792958306075000
 */
LedoitWolf2004.Result result
        = new LedoitWolf2004(false).compute(X); // use biased sample (as Wolf's code)
// the Ledoi-Wolf linearly-shrunk covariance matrix
Matrix S_lshrunk = result.getCovarianceMatrix();
System.out.println("Ledoit-Wolf-2004 shrunk covariance matrix is:");
System.out.println(S_lshrunk);

// the same covariance matrix
Matrix S = new SampleCovariance(X);
System.out.println("sample covariance =");
System.out.println(S);

</pre>
<p>输出如下所示:</p>
<pre>Ledoit-Wolf-2004 shrunk covariance matrix is:
6x6
         [,1] [,2] [,3] [,4] [,5] [,6]
[1,] 0.000152, 0.000049, 0.000057, 0.000083, 0.000085, 0.000040,
[2,] 0.000049, 0.000139, 0.000054, 0.000079, 0.000079, 0.000035,
[3,] 0.000057, 0.000054, 0.000182, 0.000093, 0.000095, 0.000042,
[4,] 0.000083, 0.000079, 0.000093, 0.000395, 0.000135, 0.000063,
[5,] 0.000085, 0.000079, 0.000095, 0.000135, 0.000391, 0.000064,
[6,] 0.000040, 0.000035, 0.000042, 0.000063, 0.000064, 0.000079,
sample covariance =
6x6
         [,1] [,2] [,3] [,4] [,5] [,6]
[1,] 0.000153, 0.000028, 0.000050, 0.000065, 0.000091, 0.000063,
[2,] 0.000028, 0.000140, 0.000036, 0.000053, 0.000057, 0.000016,
[3,] 0.000050, 0.000036, 0.000184, 0.000101, 0.000132, 0.000050,
[4,] 0.000065, 0.000053, 0.000101, 0.000399, 0.000122, 0.000083,
[5,] 0.000091, 0.000057, 0.000132, 0.000122, 0.000395, 0.000109,
[6,] 0.000063, 0.000016, 0.000050, 0.000083, 0.000109, 0.000080,

</pre>
<p class="Para" id="Par119">我们可以看到，Ledoit-Wolf 线性收缩协方差矩阵与样本协方差矩阵非常不同。</p>

<h4 class="Heading">12.2.9.5·莱多伊特-沃尔夫非线性收缩</h4>
<p class="Para" id="Par120">本节遵循 Ledoit &amp; Wolf (2012 年)的观点。在缺乏关于真实协方差矩阵结构的进一步知识的情况下，可以说迄今为止最成功的方法是收缩估计。通过对两者进行加权平均，将样本协方差矩阵收缩到单位矩阵的倍数，结果相当于将样本特征值线性收缩到它们的组均值，同时保留样本特征向量。这种方法是可行的，因为样本协方差矩阵中的样本特征值使得最大样本特征值系统地向上偏移，而最小样本特征值向下偏移。线性收缩方法通过向所有样本特征值的组均值下拉最大特征值并上推最小特征值来纠正这种偏差。换句话说，它对所有样本特征值应用相同的收缩强度，而不管它们的位置。例如，如果线性收缩强度是 0.5，那么每个样本特征值向所有样本特征值的组均值移动一半。</p>
<p class="Para" id="Par121">根据手头的情况，对样本协方差矩阵的改进可能是巨大的，也可能是微小的。当<img alt="$$ \frac{p}{n} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq17.png" style="width:0.82em"/>很大和/或群体特征值彼此接近时，线性收缩捕获了对样本协方差矩阵的大部分潜在改进。在相反的情况下，即当<img alt="$$ \frac{p}{n} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq18.png" style="width:0.82em"/>小和/或群体特征值分散时，线性收缩在整个样本协方差矩阵上几乎没有改善。</p>
<p>Ledoit &amp; Wolf (2016，2015，2012)的直觉是，当高阶效应过于明显时，一阶近似并不能带来足够的改善。改进是升级到协方差矩阵的非线性收缩估计。不是给所有样本特征值相同的收缩强度，而是给每个样本特征值个性化的收缩强度。这种估计量有可能至少渐近地匹配 Ledoit &amp; Wolf (2004)的线性收缩估计量，并且通常做得更好，特别是当线性收缩不能提供对样本协方差矩阵的足够改进时。事实上，就有限样本性能而言，线性收缩估计量很少比非线性收缩估计量表现得更好。只有当线性收缩估计量已经(接近)最优时，才会发生这种情况。然而，如模拟所示，在这种情况下，优于非线性收缩估计器的性能非常小。大多数情况下，线性收缩估计远远不是最佳的，而非线性收缩则提供了大量的有限样本改进，即使对于低至<em class="EmphasisTypeItalic "> p </em> = 30 的矩阵维数也是如此。由于高阶效应的大小取决于不可观测的总体协方差矩阵，因此默认使用非线性收缩总是更安全的先验方法。见图<a href="#Fig11"> 12-11 </a>。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig11_HTML.png" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig11_HTML.png" style="width:29.55em"/></p>
<p>图 12-11</p><p class="SimplePara">协方差矩阵的非线性和线性收缩估计的比较</p>


<p class="Para" id="Par123">图<a href="#Fig11"> 12-11 </a>根据平均损失(PRIAL)的相对改善百分比，比较协方差矩阵的非线性和线性收缩估计的性能。非线性收缩估计量不仅比线性收缩估计量和样本协方差矩阵有显著改进，而且非线性收缩估计量与 oracle 估计量(只有当我们拥有关于真实总体的所有信息时才能观察到的估计量)渐近等价。</p>
<p>在 NM Dev 中，类<code>LedoitWolf2016</code>计算这个非线性收缩协方差矩阵估计器。这里有一个例子:</p>
<pre>/*
* These are the stock returns for MSFT, YHOO, GOOG, AAPL, MS, XOM from
* Aug 20, 2012 to Jan 15, 2013 (i.e., returns for 100 days).
*
* Case1 n&gt;&gt;p
* n=100,p=6
*/
Matrix X = new DenseMatrix(new double[][]{
    {0.001968, 0.000668, -0.008926, -0.013668, 0.004057, -0.005492},
    {-0.008511, -0.003340, 0.011456, 0.019523, -0.002020, 0.002991},
    {-0.009244, -0.003351, -0.000561, -0.009327, -0.024291, -0.004703},
    {0.009997, 0.003362, 0.002704, 0.000879, 0.004149, 0.008413},
    {0.004289, -0.004692, -0.013866, 0.018797, -0.002066, -0.003543},
    {-0.001971, -0.008754, 0.011999, -0.001308, 0.004831, 0.004129},
    {0.000658, 0.008152, 0.015888, -0.001965, 0.014423, -0.002284},
    {-0.010855, -0.011456, -0.009200, -0.014260, 0.006093, -0.007899},
    {0.016628, -0.001363, 0.005002, 0.002073, 0.006729, 0.001154},
    {-0.014066, 0.016382, -0.005912, 0.014617, 0.033422, -0.002075},
    {0.000000, 0.013432, -0.000470, -0.007025, 0.010996, 0.002426},
    {0.031520, 0.001325, 0.027442, 0.009023, 0.036468, 0.019011},
    {-0.012544, 0.007280, 0.009651, 0.006165, 0.051235, 0.010403},
    {-0.007492, -0.007227, -0.007619, -0.026013, -0.027598, -0.004924},
    {0.002297, 0.003309, -0.012244, -0.003244, 0.038647, 0.001574},
    {-0.000327, 0.015831, -0.001893, 0.013914, 0.009884, -0.000786},
    {0.005241, 0.012987, 0.021943, 0.019693, 0.027634, 0.018766},
    {0.008798, 0.010897, 0.005156, 0.012164, 0.019048, 0.011802},
    {0.000000, -0.005707, 0.000423, 0.012294, -0.024189, -0.004252},
    {-0.000969, 0.014668, 0.011690, 0.003043, -0.009577, -0.002847},
    {-0.004203, -0.003143, 0.012836, 0.000272, -0.003413, -0.011748},
    {0.012662, -0.004414, 0.000852, -0.004850, -0.020548, 0.010443},
    {-0.008015, -0.003167, 0.008062, 0.001999, -0.007576, 0.004398},
    {-0.013251, 0.016518, 0.020968, -0.013287, -0.002349, -0.000438},
    {-0.012774, -0.020000, -0.000294, -0.024969, -0.025898, -0.001533},
    {-0.007299, -0.004464, 0.005740, -0.012409, -0.010272, -0.005594},
    {-0.000334, 0.027546, 0.004035, 0.024254, 0.025031, 0.006287},
    {-0.013039, -0.003741, -0.002644, -0.020863, -0.005956, -0.003836},
    {-0.009146, -0.009387, 0.009649, -0.011565, 0.002996, 0.003851},
    {0.005812, 0.006949, -0.006288, 0.002910, 0.007168, -0.000877},
    {0.006798, 0.016939, 0.007279, 0.015343, 0.007117, -0.000219},
    {0.005739, 0.003701, 0.007279, -0.006927, 0.025913, 0.005706},
    {-0.006042, -0.011063, -0.000521, -0.021318, 0.001722, 0.003492},
    {-0.002364, -0.003729, -0.012779, -0.022090, -0.002865, 0.001414},
    {-0.016926, -0.011229, -0.018144, -0.003636, -0.005747, -0.005863},
    {-0.010331, -0.001262, 0.000632, 0.007963, 0.002890, -0.012014},
    {-0.001044, 0.005685, 0.009294, -0.020000, 0.026513, 0.001548},
    {0.008708, -0.002513, -0.008956, 0.002575, -0.030882, -0.001545},
    {0.010704, -0.012594, -0.005062, 0.008008, 0.025492, 0.005306},
    {-0.000683, 0.015306, 0.005020, 0.023692, 0.006780, 0.009567},
    {0.003419, 0.010678, 0.014489, -0.007977, 0.034792, 0.010892},
    {-0.003066, -0.005594, -0.080067, -0.018576, -0.037961, 0.000970},
    {-0.029050, -0.010000, -0.019007, -0.036030, -0.014656, -0.014209},
    {-0.022527, -0.004419, -0.004576, 0.039666, -0.004577, 0.000437},
    {0.001801, 0.057070, 0.002475, -0.032607, -0.019540, -0.021829},
    {-0.005392, -0.007199, -0.004483, 0.005667, 0.004103, -0.003347},
    {-0.000723, 0.003625, 0.000679, -0.011824, -0.004670, 0.006158},
    {0.011935, 0.010837, -0.003851, -0.009097, -0.003519, 0.002114},
    {0.011794, 0.002978, 0.007628, -0.014370, 0.022955, 0.005996},
    {0.034264, 0.006532, 0.010716, 0.002059, 0.013234, 0.004746},
    {-0.000683, 0.009440, 0.000480, -0.033090, 0.009654, -0.014501},
    {0.004443, 0.015196, -0.007210, 0.013550, -0.001687, 0.004013},
    {0.007826, 0.005181, -0.001816, -0.003024, 0.024789, 0.010769},
    {-0.026334, -0.004009, -0.021416, -0.038263, -0.085761, -0.031415},
    {-0.009015, -0.008626, -0.022230, -0.036290, -0.006615, -0.012588},
    {0.000700, 0.001160, 0.016465, 0.017313, 0.005448, 0.001608},
    {-0.021329, 0.014484, 0.004329, -0.007732, 0.009633, 0.001261},
    {-0.032154, 0.019417, -0.010287, 0.000129, -0.014908, -0.009734},
    {-0.009228, -0.001120, -0.009863, -0.011089, -0.026029, -0.004626},
    {-0.006706, 0.003365, -0.008107, -0.020973, 0.010566, 0.000813},
    {-0.005251, -0.001677, -0.000124, 0.003919, -0.004920, 0.003599},
    {0.007919, 0.027996, 0.032495, 0.072108, 0.021014, 0.014112},
    {-0.000748, -0.006536, 0.002634, -0.008520, -0.010291, -0.001939},
    {0.008985, 0.008772, -0.006120, 0.001408, -0.006116, 0.005829},
    {0.027829, 0.009239, 0.003154, 0.017447, 0.011077, 0.012271},
    {-0.011191, 0.010232, -0.010210, 0.031549, 0.010956, -0.005276},
    {-0.011318, 0.009062, 0.014460, -0.008057, 0.001204, -0.014331},
    {0.010340, -0.001057, 0.019323, -0.003146, 0.015033, 0.008586},
    {-0.014985, -0.002115, 0.012023, 0.011013, -0.001185, 0.000227},
    {-0.012245, -0.005299, 0.009366, -0.006923, 0.000593, 0.000227},
    {-0.007137, -0.011721, -0.004468, 0.001555, -0.023711, -0.006013},
    {-0.002270, 0.020485, -0.006070, -0.017639, 0.008500, -0.004794},
    {0.011377, -0.002113, -0.004645, -0.064357, 0.022276, 0.006193},
    {0.002250, 0.016411, 0.004812, 0.015683, -0.014134, 0.003078},
    {-0.010101, 0.000000, -0.010013, -0.025565, 0.013740, 0.006818},
    {0.018141, 0.011979, 0.001768, -0.006432, 0.002357, -0.002144},
    {0.014105, 0.004632, 0.016720, 0.021838, 0.043504, 0.006560},
    {-0.002928, -0.007172, 0.000976, -0.004415, -0.002817, 0.005169},
    {-0.004772, -0.001548, 0.007369, -0.017273, 0.005650, -0.009726},
    {-0.011066, 0.014987, -0.001053, -0.037569, 0.014045, -0.005645},
    {0.010817, 0.002546, 0.026811, 0.017733, 0.026593, 0.008969},
    {0.016974, -0.003555, 0.000402, 0.029046, 0.031840, 0.007764},
    {-0.009071, -0.001019, -0.001331, -0.014216, -0.001569, -0.012506},
    {0.013548, 0.004592, 0.003125, -0.008702, 0.009429, 0.005088},
    {-0.008309, -0.017268, -0.009317, -0.004600, -0.018163, -0.018675},
    {-0.014208, 0.015504, -0.008566, 0.001617, 0.001586, -0.003554},
    {-0.007391, -0.004071, -0.000888, -0.013784, -0.003694, 0.001726},
    {0.003723, 0.001533, -0.003640, 0.004016, -0.005826, -0.002412},
    {-0.015208, -0.005102, -0.008892, -0.010620, -0.007991, -0.020262},
    {0.006026, 0.020513, 0.010528, 0.044310, 0.026853, 0.017039},
    {0.034070, 0.009045, 0.022435, 0.031682, 0.026151, 0.024957},
    {-0.013396, -0.014940, 0.000581, -0.012622, -0.002039, -0.001804},
    {-0.018716, 0.004044, 0.019760, -0.027855, 0.031154, 0.004630},
    {-0.001870, -0.023162, -0.004363, -0.005882, -0.019316, -0.011578},
    {-0.005245, 0.013402, -0.001973, 0.002691, -0.007576, 0.006255},
    {0.005650, -0.017294, 0.006573, -0.015629, -0.001527, -0.003843},
    {-0.008989, -0.017081, 0.004552, 0.012396, 0.036697, 0.010892},
    {0.013983, 0.015798, -0.002009, -0.006132, -0.008358, 0.005724},
    {0.002236, 0.007258, -0.022622, -0.035653, -0.004958, -0.000335},
    {0.011900, 0.004632, 0.002323, -0.031550, 0.017937, -0.000558}
});

LedoitWolf2016.Result result1
        = new LedoitWolf2016().estimate(X);
// the Ledoi-Wolf nonlinearly-shrunk covariance matrix
Matrix S_nlShrunk = result1.getShrunkCovarianceMatrix();
System.out.println("Ledoit-Wolf-2016 non-linearly shrunk covariance matrix is:");
System.out.println(S_nlShrunk);

LedoitWolf2004.Result result2
        = new LedoitWolf2004(false).compute(X); // use biased sample (as Wolf's code)
// the Ledoi-Wolf linearly-shrunk covariance matrix
Matrix S_lshrunk = result2.getCovarianceMatrix();
System.out.println("Ledoit-Wolf-2004 linearly shrunk covariance matrix is:");
System.out.println(S_lshrunk);

// the same covariance matrix
Matrix S = new SampleCovariance(X);
System.out.println("sample covariance =");
System.out.println(S);
}

public void LedoitWolf2004() {
/*
 * These are the stock returns for MSFT, YHOO, GOOG, AAPL, MS, XOM from
 * Aug 20, 2012 to Jan 15, 2013 (i.e., returns for 100 days).
 */
Matrix X = new DenseMatrix(new double[][]{
    {0.001968, 0.000668, -0.008926, -0.013668, 0.004057, -0.005492},
    {-0.008511, -0.003340, 0.011456, 0.019523, -0.002020, 0.002991},
    {-0.009244, -0.003351, -0.000561, -0.009327, -0.024291, -0.004703},
    {0.009997, 0.003362, 0.002704, 0.000879, 0.004149, 0.008413},
    {0.004289, -0.004692, -0.013866, 0.018797, -0.002066, -0.003543},
    {-0.001971, -0.008754, 0.011999, -0.001308, 0.004831, 0.004129},
    {0.000658, 0.008152, 0.015888, -0.001965, 0.014423, -0.002284},
    {-0.010855, -0.011456, -0.009200, -0.014260, 0.006093, -0.007899},
    {0.016628, -0.001363, 0.005002, 0.002073, 0.006729, 0.001154},
    {-0.014066, 0.016382, -0.005912, 0.014617, 0.033422, -0.002075},
    {0.000000, 0.013432, -0.000470, -0.007025, 0.010996, 0.002426},
    {0.031520, 0.001325, 0.027442, 0.009023, 0.036468, 0.019011},
    {-0.012544, 0.007280, 0.009651, 0.006165, 0.051235, 0.010403},
    {-0.007492, -0.007227, -0.007619, -0.026013, -0.027598, -0.004924},
    {0.002297, 0.003309, -0.012244, -0.003244, 0.038647, 0.001574},
    {-0.000327, 0.015831, -0.001893, 0.013914, 0.009884, -0.000786},
    {0.005241, 0.012987, 0.021943, 0.019693, 0.027634, 0.018766},
    {0.008798, 0.010897, 0.005156, 0.012164, 0.019048, 0.011802},
    {0.000000, -0.005707, 0.000423, 0.012294, -0.024189, -0.004252},
    {-0.000969, 0.014668, 0.011690, 0.003043, -0.009577, -0.002847},
    {-0.004203, -0.003143, 0.012836, 0.000272, -0.003413, -0.011748},
    {0.012662, -0.004414, 0.000852, -0.004850, -0.020548, 0.010443},
    {-0.008015, -0.003167, 0.008062, 0.001999, -0.007576, 0.004398},
    {-0.013251, 0.016518, 0.020968, -0.013287, -0.002349, -0.000438},
    {-0.012774, -0.020000, -0.000294, -0.024969, -0.025898, -0.001533},
    {-0.007299, -0.004464, 0.005740, -0.012409, -0.010272, -0.005594},
    {-0.000334, 0.027546, 0.004035, 0.024254, 0.025031, 0.006287},
    {-0.013039, -0.003741, -0.002644, -0.020863, -0.005956, -0.003836},
    {-0.009146, -0.009387, 0.009649, -0.011565, 0.002996, 0.003851},
    {0.005812, 0.006949, -0.006288, 0.002910, 0.007168, -0.000877},
    {0.006798, 0.016939, 0.007279, 0.015343, 0.007117, -0.000219},
    {0.005739, 0.003701, 0.007279, -0.006927, 0.025913, 0.005706},
    {-0.006042, -0.011063, -0.000521, -0.021318, 0.001722, 0.003492},
    {-0.002364, -0.003729, -0.012779, -0.022090, -0.002865, 0.001414},
    {-0.016926, -0.011229, -0.018144, -0.003636, -0.005747, -0.005863},
    {-0.010331, -0.001262, 0.000632, 0.007963, 0.002890, -0.012014},
    {-0.001044, 0.005685, 0.009294, -0.020000, 0.026513, 0.001548},
    {0.008708, -0.002513, -0.008956, 0.002575, -0.030882, -0.001545},
    {0.010704, -0.012594, -0.005062, 0.008008, 0.025492, 0.005306},
    {-0.000683, 0.015306, 0.005020, 0.023692, 0.006780, 0.009567},
    {0.003419, 0.010678, 0.014489, -0.007977, 0.034792, 0.010892},
    {-0.003066, -0.005594, -0.080067, -0.018576, -0.037961, 0.000970},
    {-0.029050, -0.010000, -0.019007, -0.036030, -0.014656, -0.014209},
    {-0.022527, -0.004419, -0.004576, 0.039666, -0.004577, 0.000437},
    {0.001801, 0.057070, 0.002475, -0.032607, -0.019540, -0.021829},
    {-0.005392, -0.007199, -0.004483, 0.005667, 0.004103, -0.003347},
    {-0.000723, 0.003625, 0.000679, -0.011824, -0.004670, 0.006158},
    {0.011935, 0.010837, -0.003851, -0.009097, -0.003519, 0.002114},
    {0.011794, 0.002978, 0.007628, -0.014370, 0.022955, 0.005996},
    {0.034264, 0.006532, 0.010716, 0.002059, 0.013234, 0.004746},
    {-0.000683, 0.009440, 0.000480, -0.033090, 0.009654, -0.014501},
    {0.004443, 0.015196, -0.007210, 0.013550, -0.001687, 0.004013},
    {0.007826, 0.005181, -0.001816, -0.003024, 0.024789, 0.010769},
    {-0.026334, -0.004009, -0.021416, -0.038263, -0.085761, -0.031415},
    {-0.009015, -0.008626, -0.022230, -0.036290, -0.006615, -0.012588},
    {0.000700, 0.001160, 0.016465, 0.017313, 0.005448, 0.001608},
    {-0.021329, 0.014484, 0.004329, -0.007732, 0.009633, 0.001261},
    {-0.032154, 0.019417, -0.010287, 0.000129, -0.014908, -0.009734},
    {-0.009228, -0.001120, -0.009863, -0.011089, -0.026029, -0.004626},
    {-0.006706, 0.003365, -0.008107, -0.020973, 0.010566, 0.000813},
    {-0.005251, -0.001677, -0.000124, 0.003919, -0.004920, 0.003599},
    {0.007919, 0.027996, 0.032495, 0.072108, 0.021014, 0.014112},
    {-0.000748, -0.006536, 0.002634, -0.008520, -0.010291, -0.001939},
    {0.008985, 0.008772, -0.006120, 0.001408, -0.006116, 0.005829},
    {0.027829, 0.009239, 0.003154, 0.017447, 0.011077, 0.012271},
    {-0.011191, 0.010232, -0.010210, 0.031549, 0.010956, -0.005276},
    {-0.011318, 0.009062, 0.014460, -0.008057, 0.001204, -0.014331},
    {0.010340, -0.001057, 0.019323, -0.003146, 0.015033, 0.008586},
    {-0.014985, -0.002115, 0.012023, 0.011013, -0.001185, 0.000227},
    {-0.012245, -0.005299, 0.009366, -0.006923, 0.000593, 0.000227},
    {-0.007137, -0.011721, -0.004468, 0.001555, -0.023711, -0.006013},
    {-0.002270, 0.020485, -0.006070, -0.017639, 0.008500, -0.004794},
    {0.011377, -0.002113, -0.004645, -0.064357, 0.022276, 0.006193},
    {0.002250, 0.016411, 0.004812, 0.015683, -0.014134, 0.003078},
    {-0.010101, 0.000000, -0.010013, -0.025565, 0.013740, 0.006818},
    {0.018141, 0.011979, 0.001768, -0.006432, 0.002357, -0.002144},
    {0.014105, 0.004632, 0.016720, 0.021838, 0.043504, 0.006560},
    {-0.002928, -0.007172, 0.000976, -0.004415, -0.002817, 0.005169},
    {-0.004772, -0.001548, 0.007369, -0.017273, 0.005650, -0.009726},
    {-0.011066, 0.014987, -0.001053, -0.037569, 0.014045, -0.005645},
    {0.010817, 0.002546, 0.026811, 0.017733, 0.026593, 0.008969},
    {0.016974, -0.003555, 0.000402, 0.029046, 0.031840, 0.007764},
    {-0.009071, -0.001019, -0.001331, -0.014216, -0.001569, -0.012506},
    {0.013548, 0.004592, 0.003125, -0.008702, 0.009429, 0.005088},
    {-0.008309, -0.017268, -0.009317, -0.004600, -0.018163, -0.018675},
    {-0.014208, 0.015504, -0.008566, 0.001617, 0.001586, -0.003554},
    {-0.007391, -0.004071, -0.000888, -0.013784, -0.003694, 0.001726},
    {0.003723, 0.001533, -0.003640, 0.004016, -0.005826, -0.002412},
    {-0.015208, -0.005102, -0.008892, -0.010620, -0.007991, -0.020262},
    {0.006026, 0.020513, 0.010528, 0.044310, 0.026853, 0.017039},
    {0.034070, 0.009045, 0.022435, 0.031682, 0.026151, 0.024957},
    {-0.013396, -0.014940, 0.000581, -0.012622, -0.002039, -0.001804},
    {-0.018716, 0.004044, 0.019760, -0.027855, 0.031154, 0.004630},
    {-0.001870, -0.023162, -0.004363, -0.005882, -0.019316, -0.011578},
    {-0.005245, 0.013402, -0.001973, 0.002691, -0.007576, 0.006255},
    {0.005650, -0.017294, 0.006573, -0.015629, -0.001527, -0.003843},
    {-0.008989, -0.017081, 0.004552, 0.012396, 0.036697, 0.010892},
    {0.013983, 0.015798, -0.002009, -0.006132, -0.008358, 0.005724},
    {0.002236, 0.007258, -0.022622, -0.035653, -0.004958, -0.000335},
    {0.011900, 0.004632, 0.002323, -0.031550, 0.017937, -0.000558}
});
/*
 * From Wolf's implementation (http://www.econ.uzh.ch/faculty/wolf/publications.html#9):
 * phi = 4.11918014563813e-06
 * rho = 2.59272437810913e-06
 * gamma = 1.64807384775746e-08
 * kappa = 9.26205927972248e+01
 * shrinkage = 9.26205927972248e-01
 * sigma =
 * 1e-4 *
 * 1.515632920116000 0.485389976957753 0.569819071905581 0.832527350192132 0.847148840587289
 * 0.397609074332363
 * 0.485389976957753 1.385321425539000 0.536232629487419 0.789078831932216 0.788206205379818
 * 0.348026133393798
 * 0.569819071905581 0.536232629487419 1.821791453675000 0.934388133855881 0.952823814063320
 * 0.422051935833047
 * 0.832527350192132 0.789078831932216 0.934388133855881 3.948763689179000 1.349588317003072
 * 0.628591706535889
 * 0.847148840587289 0.788206205379818 0.952823814063320 1.349588317003072 3.907173836600000
 * 0.644231481562656
 * 0.397609074332363 0.348026133393798 0.422051935833047 0.628591706535889 0.644231481562656
 * 0.792958306075000
 */
LedoitWolf2004.Result result
        = new LedoitWolf2004(false).compute(X); // use biased sample (as Wolf's code)
// the Ledoi-Wolf linearly-shrunk covariance matrix
Matrix S_lshrunk = result.getCovarianceMatrix();
System.out.println("Ledoit-Wolf-2004 linearly shrunk covariance matrix is:");
System.out.println(S_lshrunk);

// the same covariance matrix
Matrix S = new SampleCovariance(X);
System.out.println("sample covariance =");
System.out.println(S);

</pre>
<p>输出如下所示:</p>
<pre>Ledoit-Wolf-2016 non-linearly shrunk covariance matrix is:
6x6
         [,1] [,2] [,3] [,4] [,5] [,6]
[1,] 0.000153, 0.000025, 0.000048, 0.000063, 0.000088, 0.000061,
[2,] 0.000025, 0.000141, 0.000031, 0.000052, 0.000057, 0.000015,
[3,] 0.000048, 0.000031, 0.000192, 0.000096, 0.000125, 0.000048,
[4,] 0.000063, 0.000052, 0.000096, 0.000390, 0.000118, 0.000080,
[5,] 0.000088, 0.000057, 0.000125, 0.000118, 0.000386, 0.000105,
[6,] 0.000061, 0.000015, 0.000048, 0.000080, 0.000105, 0.000083,
Ledoit-Wolf-2004 linearly shrunk covariance matrix is:
6x6
         [,1] [,2] [,3] [,4] [,5] [,6]
[1,] 0.000152, 0.000049, 0.000057, 0.000083, 0.000085, 0.000040,
[2,] 0.000049, 0.000139, 0.000054, 0.000079, 0.000079, 0.000035,
[3,] 0.000057, 0.000054, 0.000182, 0.000093, 0.000095, 0.000042,
[4,] 0.000083, 0.000079, 0.000093, 0.000395, 0.000135, 0.000063,
[5,] 0.000085, 0.000079, 0.000095, 0.000135, 0.000391, 0.000064,
[6,] 0.000040, 0.000035, 0.000042, 0.000063, 0.000064, 0.000079,
sample covariance =
6x6
         [,1] [,2] [,3] [,4] [,5] [,6]
[1,] 0.000153, 0.000028, 0.000050, 0.000065, 0.000091, 0.000063,
[2,] 0.000028, 0.000140, 0.000036, 0.000053, 0.000057, 0.000016,
[3,] 0.000050, 0.000036, 0.000184, 0.000101, 0.000132, 0.000050,
[4,] 0.000065, 0.000053, 0.000101, 0.000399, 0.000122, 0.000083,
[5,] 0.000091, 0.000057, 0.000132, 0.000122, 0.000395, 0.000109,
[6,] 0.000063, 0.000016, 0.000050, 0.000083, 0.000109, 0.000080,

</pre>



<h2 class="Heading">12.3 概率分布</h2>
<p>概率分布是一种数学函数，它给出了实验中不同可能结果出现的概率。例如，投掷一枚公平硬币的概率分布将 0.5(50%)分配给正面，0.5(50%)分配给反面。概率分布是由累积分布函数正式定义的。在<em class="EmphasisTypeItalic "> x </em>处评估的实值随机变量<em class="EmphasisTypeItalic "> X </em>的累积分布函数(CDF)是<em class="EmphasisTypeItalic "> X </em>取值小于或等于<em class="EmphasisTypeItalic "> x </em>的概率。数学上，是:<p> <img alt="$$ {F}_X(x)=P\left(X\le x\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equam.png" style="width:8.16em"/> </p></p>
<p>抛一枚公平硬币的 CDF，正面为 0，反面为 1，是一个阶跃函数，如下:<p> <img alt="$$ {F}_X(x)=\left\{\begin{array}{c}0.5,x=0\\ {}1,x=1\end{array}\right. $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equan.png" style="width:9.48em"/> </p></p>
<p>参见图<a href="#Fig12"> 12-12 </a>。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig12_HTML.jpg" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig12_HTML.jpg" style="width:29.78em"/></p>
<p>图 12-12</p><p class="SimplePara">公平抛硬币的累积分布函数</p>


<p>随机变量可以是连续的，取实线上一个区间或区间集合中的任何数值(有不可数的范围)。图<a href="#Fig13"> 12-13 </a>显示了一些正态分布的 CDF。我们看到对于<em class="EmphasisTypeItalic "> μ </em> = 0(均值为 0)的正态分布，从概率分布中得到一个值小于(或大于)0 的样本的几率为 0.5。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig13_HTML.jpg" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig13_HTML.jpg" style="width:29.52em"/></p>
<p>图 12-13</p><p class="SimplePara">正态分布的累积分布函数</p>


<p>对于一个连续的随机变量，用概率密度函数(PDF)来描述往往更直观。<p><img alt="$$ {f}_X(x)=\frac{d}{dx}{F}_X(x) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equao.png" style="width:7.53em"/>T2】</p></p>
<p><em class="EmphasisTypeItalic ">f</em><sub><em class="EmphasisTypeItalic ">X</em></sub>(<em class="EmphasisTypeItalic ">X</em>)是随机变量等于一个样本值<em class="EmphasisTypeItalic "> x </em>的相对可能性。相对可能性越大，我们就越有可能看到这个样本超过另一个样本。对于连续的随机变量，绝对似然总是 0。图<a href="#Fig14"> 12-14 </a>显示了图<a href="#Fig13"> 12-13 </a>中累积分布函数的概率密度函数。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig14_HTML.jpg" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig14_HTML.jpg" style="width:27.15em"/></p>
<p>图 12-14</p><p class="SimplePara">正态分布的概率密度函数</p>


<p>随机变量的值落在某个区域内的概率就是该区域在 PDF 下的面积，即 PDF 在该区域内的积分。数学上，是:<p> <img alt="$$ \mathrm{P}\left(a\le X\le b\right)={\int}_a^bf(x) dx $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equap.png" style="width:11.94em"/> </p></p>
<p>具体来说，我们有这个(见图<a href="#Fig15"> 12-15 </a> ): <p> <img alt="$$ {F}_X(x)=\mathrm{P}\left(-\infty &amp;lt;X\le b\right)={\int}_{-\infty}^bf(x) dx $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equaq.png" style="width:17.52em"/> </p></p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig15_HTML.jpg" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig15_HTML.jpg" style="width:42.78em"/></p>
<p>图 12-15</p><p class="SimplePara">概率密度曲线下的区域(左)是累积分布函数的值(右)</p>


<p>随机变量的概率分布的分位数函数指定随机变量的值，使得变量小于或等于该值的概率等于给定的概率。它也被称为逆累积分布函数。数学上，分位数函数<em class="EmphasisTypeItalic "> Q </em>返回值<em class="EmphasisTypeItalic "> x </em>，使得:<p> <img alt="$$ {F}_X(x)=\mathrm{P}\left(X\le x\right)=u $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equar.png" style="width:9.88em"/> </p></p>
<p>或者等价地，<p> <img alt="$$ Q(p)=\operatorname{inf}\left\{x\in \mathbb{R}\ |\ u\le F(x)\right\} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equas.png" style="width:12.8em"/> </p></p>
<p class="Para" id="Par136">inf 是给出集合中小于或等于集合中所有元素的最大元素的下确界运算符，也称为最大下界。</p>
<p>一般来说，几乎可以肯定，我们有这样的:<p> <img alt="$$ Q\left(F(X)\right)=X $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equat.png" style="width:6.15em"/> </p></p>
<p class="Para" id="Par138">因此，我们有逆累积分布函数。这里我们捕捉到了这样一个事实，即分位数函数从所有 CDF 值超过<em class="EmphasisTypeItalic "> u </em>的值中返回<em class="EmphasisTypeItalic "> x </em>的最小值(对于连续分布)。</p>
<p>在 NM Dev 中，单变量概率函数的实现继承自<code>ProbabilityDistribution</code>接口。这种实现不仅指定了 CDF 和 PDF，还指定了描述性统计，例如分布的平均值和方差，以及其他信息。签名如下:</p>
<pre>public interface ProbabilityDistribution {

    /**
     * Gets the mean of this distribution.
     *
     * @return the mean
     * @see &lt;a href="http://en.wikipedia.org/wiki/Expected_value"&gt;Wikipedia:
     * Expected value&lt;/a&gt;
     */
    public double mean();

    /**
     * Gets the median of this distribution.
     *
     * @return the media
     * @see &lt;a href="http://en.wikipedia.org/wiki/Median"&gt;Wikipedia: Median&lt;/a&gt;
     */
    public double median();

    /**
     * Gets the variance of this distribution.
     *
     * @return the variance
     * @see &lt;a href="http://en.wikipedia.org/wiki/Variance"&gt;Wikipedia:
     * Variance&lt;/a&gt;
     */
    public double variance();

    /**
     * Gets the skewness of this distribution.
     *
     * @return the skewness
     * @see &lt;a href="http://en.wikipedia.org/wiki/Skewness"&gt;Wikipedia:
     * Skewness&lt;/a&gt;
     */
    public double skew();

    /**
     * Gets the excess kurtosis of this distribution.
     *
     * @return the excess kurtosis
     * @see &lt;a href="http://en.wikipedia.org/wiki/Kurtosis"&gt;Wikipedia:
     * Kurtosis&lt;/a&gt;
     */
    public double kurtosis();

    /**
     * Gets the entropy of this distribution.
     *
     * @return the entropy
     * @see
     * &lt;a href="http://en.wikipedia.org/wiki/Information_entropy"&gt;Wikipedia:
     * Entropy
     * (information theory)&lt;/a&gt;
     */
    public double entropy();

    /**
     * Gets the cumulative probability &lt;i&gt;F(x) = Pr(X &amp;le; x)&lt;/i&gt;.
     *
     * @param x &lt;i&gt;x&lt;/i&gt;
     * @return &lt;i&gt;F(x) = Pr(X &amp;le; x)&lt;/i&gt;
     * @see
     * &lt;a href="http://en.wikipedia.org/wiki/Cumulative_distribution_function"&gt;Wikipedia:
     * Cumulative distribution function&lt;/a&gt;
     */
    public double cdf(double x);

    /**
     * Gets the quantile, the inverse of the cumulative distribution function.
     * It is the value below which random draws from the distribution would fall
     * &lt;i&gt;u&amp;times;100&lt;/i&gt; percent of the time.
     * &lt;blockquote&gt;&lt;pre&gt;&lt;i&gt;
     * F&lt;sup&gt;-1&lt;/sup&gt;(u) = x, such that
     * Pr(X &amp;le; x) = u
     * &lt;/i&gt;&lt;/pre&gt;&lt;/blockquote&gt;
     * &lt;em&gt;This may not always exist.&lt;/em&gt;
     *
     * @param u {@code u}, a quantile
     * @return &lt;i&gt;F&lt;sup&gt;-1&lt;/sup&gt;(u)&lt;/i&gt;
     * @see &lt;a href="http://en.wikipedia.org/wiki/Quantile_function"&gt;Wikipedia:
     * Quantile function&lt;/a&gt;
     */
    public double quantile(double u);

    /**
     * The density function, which, if exists, is the derivative of &lt;i&gt;F&lt;/i&gt;.
     * It describes the density of probability at each point in the sample
     * space.
     * &lt;blockquote&gt;&lt;i&gt;
     * f(x) = dF(X) / dx
     * &lt;/i&gt;&lt;/blockquote&gt;
     * &lt;em&gt;This may not always exist.&lt;/em&gt;
     * &lt;p/&gt;
     * For the discrete cases, this is the probability mass function. It gives
     * the probability that a discrete random variable is exactly equal to some
     * value.
     *
     * @param x &lt;i&gt;x&lt;/i&gt;
     * @return &lt;i&gt;f(x)&lt;/i&gt;
     * @see
     * &lt;ul&gt;
     * &lt;li&gt;&lt;a href="http://en.wikipedia.org/wiki/Probability_density_function"&gt;Wikipedia:
     * Probability density function&lt;/a&gt;&lt;/li&gt;
     * &lt;li&gt;&lt;a href="http://en.wikipedia.org/wiki/Probability_mass_function"&gt;Wikipedia:
     * Probability
     * mass function&lt;/a&gt;&lt;/li&gt;
     * &lt;/ul&gt;
     */
    public double density(double x);

    /**
     * The moment generating function is the expected value of
     * &lt;i&gt;e&lt;sup&gt;tX&lt;/sup&gt;&lt;/i&gt;. That is,
     * &lt;blockquote&gt;&lt;i&gt;
     * E(e&lt;sup&gt;tX&lt;/sup&gt;)
     * &lt;/i&gt;&lt;/blockquote&gt;
     * &lt;em&gt;This may not always exist.&lt;/em&gt;
     *
     * @param t &lt;i&gt;t&lt;/i&gt;
     * @return &lt;i&gt;E(exp(tX))&lt;/i&gt;
     * @see
     * &lt;a href="http://en.wikipedia.org/wiki/Moment_generating_function"&gt;Wikipedia:
     * Moment-generating function&lt;/a&gt;
     */
    public double moment(double t);
}

</pre>
<h3 class="Heading">12.3.1 时刻</h3>
<p>随机变量<em class="EmphasisTypeItalic "> X </em>的概率分布的均值或期望值，记为 E( <em class="EmphasisTypeItalic "> X </em>，是加权样本均值或加权平均值的推广。对于离散概率分布，它是权重等于值的概率质量的加权平均值。<p> <img alt="$$ \mathrm{E}(X)=\sum \limits_{-\infty}^{\infty }x\mathrm{P}(x) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equau.png" style="width:7.62em"/> </p></p>
<p>直观上就是<em class="EmphasisTypeItalic "> X </em>的大量独立实现的算术平均值。具有 PDF <em class="EmphasisTypeItalic "> f </em> ( <em class="EmphasisTypeItalic "> x </em>)的连续概率分布的平均值定义如下:<p> <img alt="$$ \mathrm{E}(X)=\mu ={\int}_{-\infty}^{\infty } xf(x) dx $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equav.png" style="width:11.31em"/> </p></p>
<p class="Para" id="Par142">均值可能不存在或有限。对于某些概率分布，均值是无穷大(∞或∞),而对于其他概率分布，均值是不确定的。</p>
<p>概率分布的方差定义如下:<p> <img alt="$$ Var(X)={\sigma}^2={\int}_{-\infty}^{\infty }{\left(x-\mu \right)}^2f(x) dx $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equaw.png" style="width:15.79em"/> </p> <p> <img alt="$$ ={\int}_{-\infty}^{\infty }{x}^2f(x) dx-{\mu}^2 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equax.png" style="width:9.58em"/> </p></p>
<p>一般来说，概率分布的标准化矩是归一化的矩(通常是高阶中心矩)。归一化通常是除以标准偏差的表达式，这使得矩标度不变。这具有这样的优点，即这种归一化的矩仅在除可变性之外的其他属性上不同，使得不同概率分布的形状的比较变得容易。数学上，标准化的度矩<em class="EmphasisTypeItalic "> k </em>定义如下:<p> <img alt="$$ {\overset{\sim }{\mu}}_k=\frac{\mu_k}{\sigma^k} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equay.png" style="width:3.74em"/> </p></p>
<p>其中<p> <img alt="$$ {\mu}_k=\mathrm{E}\left[{\left(X-\mu \right)}^k\right]={\int}_{-\infty}^{\infty }{\left(x-\mu \right)}^kf(x) dx $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equaz.png" style="width:17.54em"/> </p></p>
<p>还有<p> <img alt="$$ {\sigma}^k={\left(\sqrt{\mathrm{E}\left[{\left(X-\mu \right)}^2\right]}\right)}^k $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equba.png" style="width:10.04em"/> </p></p>
<p class="Para" id="Par147">标准化矩是无量纲的数字。第一个标准化矩是零，因为关于均值的第一个矩总是零。第二个标准化矩是 1，因为关于均值的二阶矩等于方差<em class="EmphasisTypeItalic ">σ</em>T2】2。</p>
<p class="Para" id="Par148">概率分布的偏斜度<img alt="$$ \gamma ={\overset{\sim }{\mu}}_3 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq19.png" style="width:3.08em"/>，是第三个标准化矩。这是分布不平衡的一种度量。任何对称分布都有第三个中心矩，如果定义的话，为零。向左侧偏斜的分布(分布的尾部在左侧较长)将具有负偏斜度。向右偏斜的分布(分布的尾部在右边较长)将具有正偏斜度。</p>
<p class="Para" id="Par149">概率分布的峰度<img alt="$$ \kappa ={\overset{\sim }{\mu}}_4 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq20.png" style="width:2.98em"/>，是第四个标准化矩。与相同方差的正态分布相比，它是对分布尾部权重的一种度量。因为它是对四次方的期望，第四中心矩，如果定义的话，总是非负的；而且除了一个点分布，它总是严格正的，可以是无界的。如果一个分布有重尾，峰度会很高(称为细峰)；相反，细尾分布(例如，均匀分布等有界分布)的峰度较低(称为平峰度)。</p>
<p>实值随机变量的矩母函数是其概率分布的另一种说明。像概率密度函数或累积分布函数一样，如果存在矩母函数，它也唯一地定义了概率分布。顾名思义，矩母函数可用于计算分布的矩:约为 0 的第<em class="EmphasisTypeItalic "> n </em>阶矩是矩母函数的第<em class="EmphasisTypeItalic "> n </em>阶导数，其值为 0。数学上，随机变量<em class="EmphasisTypeItalic "> X </em>的矩母函数定义如下:<p> <img alt="$$ {M}_x(t)=\mathrm{E}\left[{e}^{tX}\right] $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equbb.png" style="width:6.72em"/> </p></p>
<p class="Para" id="Par151">即函数是随机变量<em class="EmphasisTypeItalic "> e </em> <sup> <em class="EmphasisTypeItalic "> tX </em> </sup>对<em class="EmphasisTypeItalic "> t </em> ∈ <em class="EmphasisTypeItalic "> ℝ </em>的一个期望。如果积分不收敛，矩母函数就不存在。</p>
<p>矩母函数如此命名是因为它可以用来计算分布的矩。泰勒展开的<em class="EmphasisTypeItalic ">e</em><sup>T3】tXT5】给出了如下:<p> <img alt="$$ {e}^{tX}=1+ tX+\frac{t^2{X}^2}{2!}+\frac{t^3{X}^3}{3!}+\cdots ++\frac{t^n{X}^n}{n!}+\cdots $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equbc.png" style="width:20.55em"/> </p></sup></p>
<p>所以，我们有了这个:<p><img alt="$$ {M}_x(t)=\mathrm{E}\left[{e}^{tX}\right] $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equbd.png" style="width:6.72em"/></p><p><img alt="$$ =1+t\mathrm{E}(X)+\frac{t^2\mathrm{E}\left({X}^2\right)}{2!}+\frac{t^3\mathrm{E}\left({X}^3\right)}{3!}+\cdots ++\frac{t^n\mathrm{E}\left({X}^n\right)}{n!}+\cdots $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Eqube.png" style="width:25.14em"/></p><p><img alt="$$ =1+t{m}_1+\frac{t^2{m}_2}{2!}+\frac{t^3{m}_3}{3!}+\cdots $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equbf.png" style="width:13.36em"/></p></p>
<p class="Para" id="Par154">其中<em class="EmphasisTypeItalic ">m</em><sub>T3】nT5 是第<em class="EmphasisTypeItalic "> n </em>个时刻。微分<em class="EmphasisTypeItalic ">M</em><sub><em class="EmphasisTypeItalic ">x</em></sub>(<em class="EmphasisTypeItalic ">t</em>)<em class="EmphasisTypeItalic ">I</em>次相对于<em class="EmphasisTypeItalic "> t </em>和设置<em class="EmphasisTypeItalic "> t </em> = 0 给出了关于原点的<em class="EmphasisTypeItalic ">I</em>-次矩<em class="EmphasisTypeItalic "> m </em> <sub> <em class="EmphasisTypeItalic "> i </em> </sub>。</sub></p>
<p>由随机变量的线性变换定义的分布的矩母函数有特别简单的结果，如果它们存在的话。具体来说，如果一个随机变量<em class="EmphasisTypeItalic "> X </em>有一个矩生成函数<em class="EmphasisTypeItalic ">M</em><sub>T5】X</sub>(<em class="EmphasisTypeItalic ">t</em>，那么<em class="EmphasisTypeItalic "> αX </em> + <em class="EmphasisTypeItalic "> β </em>有如下的矩生成函数:<p> <img alt="$$ {M}_{\alpha X+\beta }(t)=\mathrm{E}\left[{e}^{t\left( aX+\beta \right)}\right]={e}^{\beta t}{M}_X\left(\alpha t\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equbg.png" style="width:15.62em"/> </p></p>
<p>而且，如果<em class="EmphasisTypeItalic "> S </em> <sub> <em class="EmphasisTypeItalic "> n </em> </sub>是随机变量的线性组合{ <em class="EmphasisTypeItalic "> X </em> <sub> <em class="EmphasisTypeItalic "> i </em> </sub> }按{<em class="EmphasisTypeItalic "/><sub><em class="EmphasisTypeItalic ">I</em></sub>}加权，如下图所示:<p> <img alt="$$ {S}_n=\sum \limits_{i=1}^n{a}_i{X}_i $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equbh.png" style="width:5.92em"/> </p></p>
<p>那么<em class="EmphasisTypeItalic ">S</em><sub>T3】nT5】的力矩生成函数如下:<p> <img alt="$$ {M}_{S_n}(t)={M}_{X_1}\left({a}_1t\right){M}_{X_2}\left({a}_2t\right)\cdots {M}_{X_n}\left({a}_nt\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equbi.png" style="width:17.94em"/> </p></sub></p>

<h3 class="Heading">正态分布</h3>
<p class="Para" id="Par158">最重要的分布(可能)是正态分布或高斯分布。许多自然过程如热扩散是正态分布的。而且，中心极限定理说，一个均值和方差有限的随机变量的许多样本(观测值)的平均值本身就是一个随机变量，随着样本数的增加，其分布收敛于正态分布。因此，作为许多独立测量值之和的物理量，例如测量误差，通常具有接近正态的分布。</p>
<p>数学上，假设{ <em class="EmphasisTypeItalic "> X </em> <sub> 1 </sub>，<em class="EmphasisTypeItalic "> X </em> <sub> <em class="EmphasisTypeItalic "> n </em> </sub> }是一个独立同分布(i.i.d .)的随机变量序列，e(<em class="EmphasisTypeItalic ">x</em><sub><em class="EmphasisTypeItalic ">I</em>【t15)=<em class="EmphasisTypeItalic ">μ</em>，var(<em class="EmphasisTypeItalic ">x</em><sub><em class="EmphasisTypeItalic ">I</em></sub>)=【t24 然后随着<em class="EmphasisTypeItalic "> n </em>趋于无穷大，随机变量<img alt="$$ \sqrt{n}\left({\overline{X}}_n-\mu \right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq21.png" style="width:5.54em"/>分布收敛到均值为 0，方差为<em class="EmphasisTypeItalic ">σ</em>T33】2 的正态分布，即<em class="EmphasisTypeItalic "> N </em> (0，<em class="EmphasisTypeItalic ">σ</em>T39】2)。<p> <img alt="$$ \sqrt{n}\left({\overline{X}}_n-\mu \right)\to N\left(0,{\sigma}^2\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equbj.png" style="width:11.04em"/> </p></sub></p>
<p>一个正态分布均值<em class="EmphasisTypeItalic "> μ </em>和方差<em class="EmphasisTypeItalic "> σ </em> <sup> 2 </sup>，记为<em class="EmphasisTypeItalic "> N </em> ( <em class="EmphasisTypeItalic "> μ </em>，<em class="EmphasisTypeItalic "> σ </em> <sup> 2 </sup>)，具有如下 PDF:<p><img alt="$$ f(x)=\frac{1}{\sigma \sqrt{2\pi }}\exp \left(-\frac{1}{2}{\left(\frac{x-\mu }{\sigma}\right)}^2\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equbk.png" style="width:14.02em"/></p></p>
<p>图<a href="#Fig16"> 12-16 </a>显示了一个例子。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig16_HTML.jpg" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig16_HTML.jpg" style="width:29.52em"/></p>
<p>图 12-16</p><p class="SimplePara">正态分布的概率密度函数</p>


<p>CDF 如下:<p> <img alt="$$ F(x)=\frac{1}{2}\left[1+\operatorname{erf}\left(\frac{x-\mu }{\sigma \sqrt{2}}\right)\right] $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equbl.png" style="width:11.54em"/> </p></p>
<p>图<a href="#Fig17"> 12-17 </a>显示了一个例子。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig17_HTML.jpg" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig17_HTML.jpg" style="width:29.52em"/></p>
<p>图 12-17</p><p class="SimplePara">正态分布的累积分布函数</p>


<p>分位数函数如下:<p> <img alt="$$ Q(q)=\mu +\sigma \sqrt{2}{\operatorname{erf}}^{-1}\left(2q-1\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equbm.png" style="width:13.32em"/> </p></p>
<p>意思如下:<p> <img alt="$$ \mathrm{E}(X)=\mu $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equbn.png" style="width:4.2em"/> </p></p>
<p>方差如下:<p> <img alt="$$ Var(X)=\mu $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equbo.png" style="width:5.26em"/> </p></p>
<p>偏斜度如下:<p> <img alt="$$ \gamma =0 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equbp.png" style="width:2.62em"/> </p></p>
<p>超额峰度如下:<p> <img alt="$$ \kappa =0 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equbq.png" style="width:2.54em"/> </p></p>
<p>力矩生成函数如下:<p> <img alt="$$ {M}_X(t)=\exp \left(\mu t+\frac{\sigma^2{t}^2}{2}\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equbr.png" style="width:10.65em"/> </p></p>
<p>NM Dev 类<code>NormalDistribution</code>实现正态分布。这里有一个例子:</p>
<pre>NormalDistribution dist = new NormalDistribution(
        0., // mean
        1. // variance
);

System.out.println("mean = " + dist.mean());
System.out.println("median = " + dist.median());
System.out.println("variance = " + dist.variance());
System.out.println("skew = " + dist.skew());
System.out.println("kurtosis = " + dist.kurtosis());
System.out.println("entropy = " + dist.entropy()); // Math.log(2 * Math.PI * Math.E)

double[] xs = new double[]{
    -1000000, -10000, -1000, -100, -10, -1, -0.1, -0.01, -0.001, -0.0001,
    0, 0.0001, 0.001, 0.01, 0.1, 1, 2, 3, 10, 100, 1000};
for (double x : xs) {
    System.out.println(String.format("F(%f) = %f", x, dist.cdf(x)));
}
for (double x : xs) {
    System.out.println(String.format("f(%f) = %f", x, dist.density(x)));
}

boolean allEquals = true;
for (double u = 0.000001; u &lt; 1d; u += 0.000001) {
    double x = dist.quantile(u);
    double y = dist.cdf(x);
    if (abs(u - y) &gt; 1e-9) {
        allEquals = false;
    }
}
System.out.println("F(Q(u)) = u for all u = " + allEquals);

</pre>
<p>输出如下所示:</p>
<pre>mean = 0.0
median = 0.0
variance = 1.0
skew = 0.0
kurtosis = 0.0
entropy = 2.8378770664093453
F(-1000000.000000) = 0.000000
F(-10000.000000) = 0.000000
F(-1000.000000) = 0.000000
F(-100.000000) = 0.000000
F(-10.000000) = 0.000000
F(-1.000000) = 0.158655
F(-0.100000) = 0.460172
F(-0.010000) = 0.496011
F(-0.001000) = 0.499601
F(-0.000100) = 0.499960
F(0.000000) = 0.500000
F(0.000100) = 0.500040
F(0.001000) = 0.500399
F(0.010000) = 0.503989
F(0.100000) = 0.539828
F(1.000000) = 0.841345
F(2.000000) = 0.977250
F(3.000000) = 0.998650
F(10.000000) = 1.000000
F(100.000000) = 1.000000
F(1000.000000) = 1.000000
f(-1000000.000000) = 0.000000
f(-10000.000000) = 0.000000
f(-1000.000000) = 0.000000
f(-100.000000) = 0.000000
f(-10.000000) = 0.000000
f(-1.000000) = 0.241971
f(-0.100000) = 0.396953
f(-0.010000) = 0.398922
f(-0.001000) = 0.398942
f(-0.000100) = 0.398942
f(0.000000) = 0.398942
f(0.000100) = 0.398942
f(0.001000) = 0.398942
f(0.010000) = 0.398922
f(0.100000) = 0.396953
f(1.000000) = 0.241971
f(2.000000) = 0.053991
f(3.000000) = 0.004432
f(10.000000) = 0.000000
f(100.000000) = 0.000000
f(1000.000000) = 0.000000
F(Q(u)) = u for all u = true

</pre>

<h3 class="Heading">对数正态分布</h3>
<p class="Para" id="Par172">对数正态分布是对数呈正态分布的随机变量的连续概率分布。因此，如果随机变量<em class="EmphasisTypeItalic "> X </em>是对数正态分布，那么<em class="EmphasisTypeItalic "> Y </em> = ln <em class="EmphasisTypeItalic "> X </em>具有正态分布。等价地，如果<em class="EmphasisTypeItalic "> Y </em>具有正态分布，那么<em class="EmphasisTypeItalic "> Y </em>，<em class="EmphasisTypeItalic "> X </em> = exp ( <em class="EmphasisTypeItalic "> Y </em>)的指数函数具有对数正态分布。对数正态分布的随机变量只取正的实数值。对于精确科学和工程科学，以及医学、经济学和金融学的测量，这是一个方便而有用的模型。著名的 Black-Scholes 模型假设股票收益服从对数正态分布。</p>
<p class="Para" id="Par173">数学上，一个正随机变量<em class="EmphasisTypeItalic "> X </em>是对数正态分布的<em class="EmphasisTypeItalic "> X </em> ~Lognormal( <em class="EmphasisTypeItalic "> μ </em>，<em class="EmphasisTypeItalic "> σ </em> <sup> 2 </sup>)，如果 ln<em class="EmphasisTypeItalic ">X</em>~<em class="EmphasisTypeItalic ">N</em>(<em class="EmphasisTypeItalic ">μ</em>，<em class="EmphasisTypeItalic "> σ </em> <sup> 2 </sup>)。</p>
<p>设<em class="EmphasisTypeItalic "> φ </em> ( <em class="EmphasisTypeItalic "> x </em>)和φ(<em class="EmphasisTypeItalic ">x</em>)为标准正态分布<em class="EmphasisTypeItalic "> N </em> (0，1)的概率密度函数和累积概率分布函数。那么<em class="EmphasisTypeItalic "> X </em> ~Lognormal( <em class="EmphasisTypeItalic "> μ </em>，<em class="EmphasisTypeItalic "> σ </em> <sup> 2 </sup>)的 PDF 如下:<p><img alt="$$ {f}_X(x)=\frac{d}{dx}\Pr \left(X\le x\right)=\frac{d}{dx}\Pr \left(\ln X\le \ln x\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equbs.png" style="width:18.75em"/></p><p><img alt="$$ =\frac{d}{dx}\Phi \left(\frac{\ln x-\mu }{\sigma}\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equbt.png" style="width:7.7em"/></p><p><img alt="$$ =\frac{1}{x\sigma \sqrt{2\pi }}\exp \left(-\frac{{\left(\ln x-\mu \right)}^2}{2{\sigma}^2}\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equbu.png" style="width:12.64em"/></p></p>
<p>图<a href="#Fig18"> 12-18 </a>显示了一个例子。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig18_HTML.jpg" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig18_HTML.jpg" style="width:20.65em"/></p>
<p>图 12-18</p><p class="SimplePara">对数正态分布的概率密度函数:相同的<em> <strong class="EmphasisTypeBoldItalic "> μ </strong> </em>不同的<em> <strong class="EmphasisTypeBoldItalic "> σ </strong> </em></p>


<p>CDF 如下:<p> <img alt="$$ {F}_X(x)=\Phi \left(\frac{\ln x-\mu }{\sigma}\right)=\frac{1}{2}\operatorname{erfc}\left(-\frac{\ln x-\mu }{\sigma \sqrt{2}}\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equbv.png" style="width:18.2em"/> </p></p>
<p class="Para" id="Par177">erfc 是一种称为互补误差函数的特殊函数。</p>
<p>图<a href="#Fig19"> 12-19 </a>显示了一个例子。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig19_HTML.jpg" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig19_HTML.jpg" style="width:20.88em"/></p>
<p>图 12-19</p><p class="SimplePara">对数正态分布的累积分布函数；相同的<em> <strong class="EmphasisTypeBoldItalic "> μ </strong> </em>不同的<em> <strong class="EmphasisTypeBoldItalic "> σ </strong> </em></p>


<p>分位数函数如下:<p> <img alt="$$ Q(q)=\exp \left(q+\sigma {Q}_{\Phi}(q)\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equbw.png" style="width:11.08em"/> </p></p>
<p class="Para" id="Par180"><em class="EmphasisTypeItalic ">Q</em><sub>φ</sub>(<em class="EmphasisTypeItalic ">Q</em>)是标准正态分布的分位数函数。</p>
<p>意思如下:<p> <img alt="$$ \mathrm{E}(X)=\exp \left(\mu +\frac{\sigma^2}{2}\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equbx.png" style="width:9.2em"/> </p></p>
<p>方差如下:<p> <img alt="$$ Var(X)=\left[\exp \left({\sigma}^2\right)-1\right]\exp \left(2\mu +{\sigma}^2\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equby.png" style="width:16.83em"/> </p></p>
<p>偏斜度如下:<p> <img alt="$$ \gamma =\left[\exp \left({\sigma}^2\right)+2\right]\sqrt{\exp \left({\sigma}^2\right)-1} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equbz.png" style="width:14.68em"/> </p></p>
<p>超额峰度如下:<p> <img alt="$$ \kappa =\exp \left(4{\sigma}^2\right)+2\exp \left(3{\sigma}^2\right)+3\exp \left(2{\sigma}^2\right)-6 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equca.png" style="width:19.94em"/> </p></p>
<p>力矩生成函数如下:<p> <img alt="$$ {M}_X(t)=\exp \left(\mu t+\frac{\sigma^2{t}^2}{2}\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equcb.png" style="width:10.65em"/> </p></p>
<p>NM Dev 类<code>LogNormalDistribution</code>实现对数正态分布。这里有一个例子:</p>
<pre>LogNormalDistribution dist = new LogNormalDistribution(
        1., // mean
        2. // variance
);

System.out.println("mean = " + dist.mean());
System.out.println("median = " + dist.median());
System.out.println("variance = " + dist.variance());
System.out.println("skew = " + dist.skew());
System.out.println("kurtosis = " + dist.kurtosis());
System.out.println("entropy = " + dist.entropy());

double[] xs = new double[]{
    -1000000, -10000, -1000, -100, -10, -1, -0.1, -0.01, -0.001, -0.0001,
    0, 0.0001, 0.001, 0.01, 0.1, 1, 2, 3, 10, 100, 1000};
for (double x : xs) {
    System.out.println(String.format("F(%f) = %f", x, dist.cdf(x)));
}
for (double x : xs) {
    System.out.println(String.format("f(%f) = %f", x, dist.density(x)));
}

boolean allEquals = true;
for (double u = 0.000001; u &lt; 1d; u += 0.000001) {
    double x = dist.quantile(u);
    double y = dist.cdf(x);
    if (abs(u - y) &gt; 1e-9) {
        allEquals = false;
    }
}
System.out.println("F(Q(u)) = u for all u = " + allEquals);

</pre>
<p>输出如下所示:</p>
<pre>mean = 20.085536923187668
median = 2.718281828459045
variance = 21623.03700131398
skew = 414.359343300147
kurtosis = 9220556.977307005
entropy = 3.112085713764618
F(-1000000.000000) = 0.000000
F(-10000.000000) = 0.000000
F(-1000.000000) = 0.000000
F(-100.000000) = 0.000000
F(-10.000000) = 0.000000
F(-1.000000) = 0.000000
F(-0.100000) = 0.000000
F(-0.010000) = 0.000000
F(-0.001000) = 0.000000
F(-0.000100) = 0.000000
F(0.000000) = 0.000000
F(0.000100) = 0.000000
F(0.001000) = 0.000038
F(0.010000) = 0.002535
F(0.100000) = 0.049339
F(1.000000) = 0.308538
F(2.000000) = 0.439031
F(3.000000) = 0.519662
F(10.000000) = 0.742571
F(100.000000) = 0.964273
F(1000.000000) = 0.998431
f(-1000000.000000) = 0.000000
f(-10000.000000) = 0.000000
f(-1000.000000) = 0.000000
f(-100.000000) = 0.000000
f(-10.000000) = 0.000000
f(-1.000000) = 0.000000
f(-0.100000) = 0.000000
f(-0.010000) = 0.000000
f(-0.001000) = 0.000000
f(-0.000100) = 0.000000
f(0.000000) = 0.000000
f(0.000100) = 0.004369
f(0.001000) = 0.080387
f(0.010000) = 0.392917
f(0.100000) = 0.510235
f(1.000000) = 0.176033
f(2.000000) = 0.098569
f(3.000000) = 0.066410
f(10.000000) = 0.016135
f(100.000000) = 0.000393
f(1000.000000) = 0.000003
F(Q(u)) = u for all u = true

</pre>

<h3 class="Heading">指数分布</h3>
<p class="Para" id="Par188">泊松过程是一系列离散事件的模型，其中事件发生的概率在任何时间或任何等长的时间间隔内都是相同的，但事件的确切时间是随机的。事件的到达以及事件发生前的等待时间与之前的所有事件和信息无关。因此这个过程被称为是无记忆的。例如，从历史数据中我们知道，新客户的到来平均为<em class="EmphasisTypeItalic "> λ </em> =每小时 10 人，但是下一个客户的时间选择完全是随机的，并且独立于任何之前的客户。客户到达过程可以建模为泊松过程。</p>
<p>更抽象地说，在图<a href="#Fig20"> 12-20 </a>中，一个从状态 0 开始的进程可以在任意时间跳转到下一个增量状态。我们不知道具体什么时候会发生，因为这是随机的。但我们知道，它随时可能以相等的概率发生。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig20_HTML.png" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig20_HTML.png" style="width:20.9em"/></p>
<p>图 12-20</p><p class="SimplePara">从 0 开始的泊松点过程，其中增量以速率<em> <strong class="EmphasisTypeBoldItalic "> λ </strong> </em>连续且独立地发生</p>


<p>泊松过程被定义为一个随机过程，满足以下条件:</p>
<ol><li class="ListItem"><p class="Para" id="Par191"><em class="EmphasisTypeItalic "> N </em> (0) = 0。</p>
 </li>
<li class="ListItem"><p class="Para" id="Par192">增量{<em class="EmphasisTypeItalic ">N</em>(<em class="EmphasisTypeItalic ">t</em><sub><em class="EmphasisTypeItalic ">N</em>+1</sub>)—<em class="EmphasisTypeItalic ">N</em>(<em class="EmphasisTypeItalic ">t</em><sub><em class="EmphasisTypeItalic ">N</em></sub>)}为独立随机变量。</p>
 </li>
<li class="ListItem"><p class="Para" id="Par193">i.i.d .随机增量的平均值为 E(<em class="EmphasisTypeItalic ">N</em>(<em class="EmphasisTypeItalic ">t</em><sub><em class="EmphasisTypeItalic ">N</em>+1</sub>-<em class="EmphasisTypeItalic ">N</em>(<em class="EmphasisTypeItalic ">t</em><sub><em class="EmphasisTypeItalic ">N</em></sub>)=<em class="EmphasisTypeItalic ">λ</em>(<em class="EmphasisTypeItalic ">t</em><sub><em class="EmphasisTypeItalic ">N</em>+1</sub>-<em class="EmphasisTypeItalic ">t</em></p>
 </li>
</ol>

<p class="Para" id="Par194"><em class="EmphasisTypeItalic "> λ </em>称为强度，是单位时间内发生的预期到达次数。</p>
<p class="Para" id="Par195">事件之间的随机时间或下一次跳转之前的随机时间称为等待时间。其分布受速率参数为<em class="EmphasisTypeItalic "> λ </em>的指数分布控制。</p>
<p>数学上，一个非负随机变量<em class="EmphasisTypeItalic "> X </em>具有指数分布<em class="EmphasisTypeItalic "> X </em> ~Exp( <em class="EmphasisTypeItalic "> λ </em>)当且仅当它具有如下 PDF: <p> <img alt="$$ f\left(x\ |\ \lambda \right)=\left\{\begin{array}{c}\lambda {e}^{-\lambda x},x\ge 0\\ {}0,\kern0.5em x&amp;lt;0\end{array}\right. $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equcc.png" style="width:11.32em"/> </p></p>
<p>图<a href="#Fig21"> 12-21 </a>显示了一个例子。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig21_HTML.jpg" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig21_HTML.jpg" style="width:19.15em"/></p>
<p>图 12-21</p><p class="SimplePara">指数分布的概率密度函数</p>


<p>CDF 如下:<p> <img alt="$$ F\left(x\ |\ \lambda \right)=\left\{\begin{array}{c}1-{e}^{-\lambda x},x\ge 0\\ {}0,\kern0.5em x&amp;lt;0\end{array}\right. $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equcd.png" style="width:12.58em"/> </p></p>
<p>图<a href="#Fig22"> 12-22 </a>显示了一个例子。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig22_HTML.jpg" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig22_HTML.jpg" style="width:19.22em"/></p>
<p>图 12-22</p><p class="SimplePara">指数分布的累积分布函数</p>


<p>我们可以从 CDF 导出指数分布的一个重要性质，称为无记忆性质。具体来说，这里有一个例子:<p><img alt="$$ \Pr \left(T&amp;gt;s+t\ |\ T&amp;gt;s\right)=\frac{\Pr \left(T&amp;gt;s+t\cap T&amp;gt;s\right)}{\Pr \left(T&amp;gt;s\right)} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equce.png" style="width:20.19em"/></p><p><img alt="$$ =\frac{\Pr \left(T&amp;gt;s+t\ \right)}{\Pr \left(T&amp;gt;s\right)} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equcf.png" style="width:7.46em"/></p><p><img alt="$$ =\frac{e^{-\lambda \left(s+t\right)}}{e^{-\lambda s}}={e}^{-\lambda t} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equcg.png" style="width:7.16em"/></p><p><img alt="$$ =\Pr \left(T&amp;gt;t\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equch.png" style="width:5.4em"/></p></p>
<p class="Para" id="Par201"><em class="EmphasisTypeItalic "> s </em>无关紧要。当<em class="EmphasisTypeItalic "> T </em>被解释为相对于某个初始时间某个事件发生的等待时间时，这种关系意味着如果<em class="EmphasisTypeItalic "> T </em>的条件是在某个初始时间段<em class="EmphasisTypeItalic "> s </em>内没有观察到该事件，则剩余等待时间的分布与原始的无条件分布相同。例如，如果一个事件在 30 秒后还没有发生，则发生至少需要 10 秒的条件概率等于在初始时间后观察到该事件超过 10 秒的无条件概率。</p>
<p>分位数函数如下:<p> <img alt="$$ Q(q)=-\frac{\ln \left(1-q\right)}{\lambda } $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equci.png" style="width:8.38em"/> </p></p>
<p>意思如下:<p> <img alt="$$ \mathrm{E}(X)=\frac{1}{\lambda } $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equcj.png" style="width:4.35em"/> </p></p>
<p>方差如下:<p> <img alt="$$ Var(X)=\frac{1}{\lambda^2} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equck.png" style="width:5.82em"/> </p></p>
<p>偏斜度如下:<p> <img alt="$$ \gamma =2 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equcl.png" style="width:2.62em"/> </p></p>
<p>超额峰度如下:<p> <img alt="$$ \kappa =6 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equcm.png" style="width:2.54em"/> </p></p>
<p>力矩生成函数如下:<p> <img alt="$$ {M}_X(t)=\frac{\lambda }{\lambda -t},t&amp;lt;\lambda $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equcn.png" style="width:8.86em"/> </p></p>
<p>NM Dev 类<code>ExponentialDistribution</code>实现了指数分布。这里有一个例子:</p>
<pre>ExponentialDistribution dist = new ExponentialDistribution(
        1.0 // lambda = 1.
);

System.out.println("mean = " + dist.mean());
System.out.println("median = " + dist.median());
System.out.println("variance = " + dist.variance());
System.out.println("skew = " + dist.skew());
System.out.println("kurtosis = " + dist.kurtosis());
System.out.println("entropy = " + dist.entropy());

double[] xs = new double[]{
    -1000000, -10000, -1000, -100, -10, -1, -0.1, -0.01, -0.001, -0.0001,
    0, 0.0001, 0.001, 0.01, 0.1, 1, 2, 3, 10, 100, 1000};
for (double x : xs) {
    System.out.println(String.format("F(%f) = %f", x, dist.cdf(x)));
}
for (double x : xs) {
    System.out.println(String.format("f(%f) = %f", x, dist.density(x)));
}

boolean allEquals = true;
for (double u = 0.000001; u &lt; 1d; u += 0.000001) {
    double x = dist.quantile(u);
    double y = dist.cdf(x);
    if (abs(u - y) &gt; 1e-9) {
        allEquals = false;
    }
}
System.out.println("F(Q(u)) = u for all u = " + allEquals);

</pre>
<p>输出如下所示:</p>
<pre>mean = 1.0
median = 0.6931471805599453
variance = 1.0
skew = 2.0
kurtosis = 6.0
entropy = 1.0
F(-1000000.000000) = 0.000000
F(-10000.000000) = 0.000000
F(-1000.000000) = 0.000000
F(-100.000000) = 0.000000
F(-10.000000) = 0.000000
F(-1.000000) = 0.000000
F(-0.100000) = 0.000000
F(-0.010000) = 0.000000
F(-0.001000) = 0.000000
F(-0.000100) = 0.000000
F(0.000000) = 0.000000
F(0.000100) = 0.000100
F(0.001000) = 0.001000
F(0.010000) = 0.009950
F(0.100000) = 0.095163
F(1.000000) = 0.632121
F(2.000000) = 0.864665
F(3.000000) = 0.950213
F(10.000000) = 0.999955
F(100.000000) = 1.000000
F(1000.000000) = 1.000000
f(-1000000.000000) = 0.000000
f(-10000.000000) = 0.000000
f(-1000.000000) = 0.000000
f(-100.000000) = 0.000000
f(-10.000000) = 0.000000
f(-1.000000) = 0.000000
f(-0.100000) = 0.000000
f(-0.010000) = 0.000000
f(-0.001000) = 0.000000
f(-0.000100) = 0.000000
f(0.000000) = 1.000000
f(0.000100) = 0.999900
f(0.001000) = 0.999000
f(0.010000) = 0.990050
f(0.100000) = 0.904837
f(1.000000) = 0.367879
f(2.000000) = 0.135335
f(3.000000) = 0.049787
f(10.000000) = 0.000045
f(100.000000) = 0.000000
f(1000.000000) = 0.000000
F(Q(u)) = u for all u = true




</pre>

<h3 class="Heading">泊松分布</h3>
<p class="Para" id="Par210">泊松过程的事件之间的等待时间由指数分布决定，而事件的数量由泊松分布决定。换句话说，泊松分布是一个离散的概率分布，它表示在一个固定的时间间隔内发生的给定数量的事件的概率，如果这些事件以一个已知的恒定平均速率发生，并且独立于自上次事件以来的时间。请注意，与我们到目前为止讨论的其他连续概率分布不同，泊松分布是一种离散概率分布。它“计算”事件发生的次数。</p>
<p class="Para" id="Par211">例如，呼叫中心平均每小时接收 180 个电话，一天 24 小时。这些调用是独立的；接收一个不会改变下一个到达的概率。任何一分钟内收到的呼叫数都呈泊松分布:最有可能的数字是 2 和 3，但也有可能是 1 和 4，极有可能低至零，极有可能是 10。另一个例子是在给定的观察期内放射源发生衰变的次数。</p>
<p>一个离散的随机变量<em class="EmphasisTypeItalic "> X </em>被称为具有泊松分布，参数<em class="EmphasisTypeItalic ">λ</em>T7】0，如果它具有一个概率质量函数(PMF)由下式给出:<p> <img alt="$$ f\left(k\ |\ \lambda \right)=\Pr \left(X=k\right)=\frac{\lambda^k{e}^{-\lambda }}{k!} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equco.png" style="width:12.98em"/> </p></p>
<p class="Para" id="Par213">其中<em class="EmphasisTypeItalic "> k </em> = 0，1，2，…是出现的次数。</p>
<p>对于图<a href="#Fig23"> 12-23 </a>中的例子，<em class="EmphasisTypeItalic "> k </em>是出现的次数。<em class="EmphasisTypeItalic "> λ </em>是预期发生率。纵轴是给定<em class="EmphasisTypeItalic "> λ </em>的情况下<em class="EmphasisTypeItalic "> k </em>发生的概率。该函数仅在<em class="EmphasisTypeItalic "> k </em>的整数值上定义；连接线只是眼睛的引导线。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig23_HTML.jpg" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig23_HTML.jpg" style="width:19.22em"/></p>
<p>图 12-23</p><p class="SimplePara">泊松分布的概率质量函数</p>


<p>CDF 如下:<p> <img alt="$$ F(k)={e}^{-\lambda}\sum \limits_{i=0}^{\underset{\_}{k}}\frac{\lambda^i}{i!} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equcp.png" style="width:7.6em"/> </p></p>
<p class="Para" id="Par216"><img alt="$$ \underset{\_}{k} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq22.png" style="width:0.74em"/>是地板函数，小于等于<em class="EmphasisTypeItalic "> k </em>的最小整数。</p>
<p>对于图<a href="#Fig23"> 12-23 </a>中的例子，横轴是指标<em class="EmphasisTypeItalic "> k </em>，是出现的次数。CDF 在整数<em class="EmphasisTypeItalic "> k </em>处是不连续的，在其他地方是平坦的，因为泊松分布的变量只取整数值。见图<a href="#Fig24"> 12-24 </a>。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig24_HTML.jpg" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig24_HTML.jpg" style="width:19.2em"/></p>
<p>图 12-24</p><p class="SimplePara">泊松分布的累积概率函数</p>


<p class="Para" id="Par218">分位数函数没有封闭的形式，但是它可以通过使用 CDF 搜索最大的<em class="EmphasisTypeItalic "> k </em>来计算，使得<em class="EmphasisTypeItalic ">F</em>(<em class="EmphasisTypeItalic ">k</em>)&lt;<em class="EmphasisTypeItalic ">q</em>。</p>
<p>意思如下:<p> <img alt="$$ \mathrm{E}(X)=\lambda $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equcq.png" style="width:4.2em"/> </p></p>
<p>方差如下:<p> <img alt="$$ Var(X)=\lambda $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equcr.png" style="width:5.26em"/> </p></p>
<p>偏斜度如下:<p> <img alt="$$ \gamma ={\lambda}^{-\frac{1}{2}} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equcs.png" style="width:3.63em"/> </p></p>
<p>超额峰度如下:<p> <img alt="$$ \kappa ={\lambda}^{-1} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equct.png" style="width:3.45em"/> </p></p>
<p>力矩生成函数如下:<p> <img alt="$$ {M}_X(t)=\exp \left[\lambda \left({e}^t-1\right)\right] $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equcu.png" style="width:10.46em"/> </p></p>
<p>NM Dev 类<code>PoissonDistribution</code>实现了泊松分布。这里有一个例子:</p>
<pre>PoissonDistribution dist = new PoissonDistribution(
        2. // lambda = 2.
);

System.out.println("mean = " + dist.mean());
System.out.println("median = " + dist.median());
System.out.println("variance = " + dist.variance());
System.out.println("skew = " + dist.skew());
System.out.println("kurtosis = " + dist.kurtosis());
System.out.println("entropy = " + dist.entropy());

double[] ks = new double[]{
    0, 1, 2, 3, 4, 5};
for (double k : ks) {
    System.out.println(String.format("F(%f) = %f", k, dist.cdf(k)));
}
for (double k : ks) {
    System.out.println(String.format("f(%f) = %f", k, dist.density(k)));
}

for (double u = 0.1; u &lt; 1d; u += 0.1) {
    double x = dist.quantile(u);
    System.out.println(String.format("Q(%f) = %f", u, x));
}

</pre>
<p>输出如下所示:</p>
<pre>mean = 2.0
median = 2.0
variance = 2.0
skew = 0.7071067811865475
kurtosis = 0.5
entropy = 1.7048826437056113
F(0.000000) = 0.135335
F(1.000000) = 0.406006
F(2.000000) = 0.676676
F(3.000000) = 0.857123
F(4.000000) = 0.947347
F(5.000000) = 0.983436
f(0.000000) = 0.135335
f(1.000000) = 0.270671
f(2.000000) = 0.270671
f(3.000000) = 0.180447
f(4.000000) = 0.090224
f(5.000000) = 0.036089
Q(0.100000) = 0.000000
Q(0.200000) = 1.000000
Q(0.300000) = 1.000000
Q(0.400000) = 1.000000
Q(0.500000) = 2.000000
Q(0.600000) = 2.000000
Q(0.700000) = 3.000000
Q(0.800000) = 3.000000
Q(0.900000) = 4.000000
Q(1.000000) = 22.000000




</pre>

<h3 class="Heading">二项式分布</h3>
<p class="Para" id="Par226">参数为<em class="EmphasisTypeItalic "> n </em>和<em class="EmphasisTypeItalic "> p </em>的二项分布是一系列<em class="EmphasisTypeItalic "> n </em>个独立实验中成功次数的离散概率分布，每个实验都有自己的是或否结果:是/成功(概率为<em class="EmphasisTypeItalic "> p </em>)或否/失败(概率为<em class="EmphasisTypeItalic ">q</em>= 1<em class="EmphasisTypeItalic ">p</em>)。单个成功/失败实验也称为伯努利试验或伯努利实验，一系列布尔结果称为伯努利过程。对于单次试验，即<em class="EmphasisTypeItalic "> n </em> = 1，二项分布是伯努利分布。对于一次公平的掷硬币，n = 1，p = 0.5。</p>
<p class="Para" id="Par227">二项式分布通常用于模拟从数量为<em class="EmphasisTypeItalic "> N </em>的总体中抽取的数量为<em class="EmphasisTypeItalic "> n </em>的样本的成功数量。如果抽样是在没有替换的情况下进行的，则抽取不是独立的，因此得到的分布是超几何分布，而不是二项式分布。然而，对于比<em class="EmphasisTypeItalic "> n </em>大得多的<em class="EmphasisTypeItalic "> N </em>，二项式分布仍然是一个很好的近似，并且被广泛使用。</p>
<p class="Para" id="Par228">二项式分布和泊松分布在某种意义上是相似的，因为它们都测量特定框架内特定随机事件(或“成功”)的数量。然而，它们是不同的，因为二项式分布计算离散试验中的离散事件，而泊松分布计算连续域中的离散事件。也就是说，使用二项分布，你有一定数量的<em class="EmphasisTypeItalic "> n </em>“尝试”，每一次都有成功的概率<em class="EmphasisTypeItalic "> p </em>。在泊松分布中，你有无数次尝试，成功的机会微乎其微。也就是说，给定一个参数为<em class="EmphasisTypeItalic "> n </em>和<em class="EmphasisTypeItalic "> p </em>的二项式分布，如果你让<em class="EmphasisTypeItalic "> n </em> → ∞和<em class="EmphasisTypeItalic "> p </em> → 0 使得<em class="EmphasisTypeItalic "> np </em> → <em class="EmphasisTypeItalic "> λ </em>，那么这个分布就接近一个参数为<em class="EmphasisTypeItalic "> λ </em>的泊松分布。因此，泊松分布可以作为二项式分布的极限来推导。</p>
<p class="Para" id="Par229">由于这种限制行为，泊松分布被用于模拟可能发生很多次但发生概率很小的罕见事件。也就是说，它们被用于更适合用具有非常大的<em class="EmphasisTypeItalic "> n </em>和小的<em class="EmphasisTypeItalic "> p </em>的二项式分布来表示的情况，尤其是当<em class="EmphasisTypeItalic "> n </em>和<em class="EmphasisTypeItalic "> p </em>的确切值未知时，例如，百年一遇的洪水。</p>
<p class="Para" id="Par230">总之，如果给定一个事件在单位时间内发生的平均概率，并要求您计算在给定时间内发生<em class="EmphasisTypeItalic "> n </em>个事件的概率，则使用泊松分布。另一方面，如果给定一个事件发生的确切概率，并要求你计算这个事件发生的概率<em class="EmphasisTypeItalic "> k </em>乘以<em class="EmphasisTypeItalic "> n </em>，那么应该使用二项分布。</p>
<p class="Para" id="Par231">而且，如果<em class="EmphasisTypeItalic "> n </em>足够大，那么二项随机变量<em class="EmphasisTypeItalic "> X </em>可以很好地近似为正态分布。即<em class="EmphasisTypeItalic "> X </em> ~ <em class="EmphasisTypeItalic "> N </em> ( <em class="EmphasisTypeItalic "> np </em>，<em class="EmphasisTypeItalic ">NP</em>(1<em class="EmphasisTypeItalic ">p</em>))。等价地，归一化随机变量<img alt="$$ z=\frac{x-\mu }{\sigma } $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq23.png" style="width:3.33em"/>具有标准正态分布<em class="EmphasisTypeItalic "> N </em> (0，1)。</p>
<p>如果随机变量<em class="EmphasisTypeItalic "> X </em>服从参数为<em class="EmphasisTypeItalic "> n </em> ∈ <em class="EmphasisTypeItalic "> ℕ </em>和<em class="EmphasisTypeItalic ">p</em>∈【0，1】的二项分布，我们写<em class="EmphasisTypeItalic ">x</em>~<em class="EmphasisTypeItalic ">b</em>(<em class="EmphasisTypeItalic ">n</em>，<em class="EmphasisTypeItalic "> p </em>)。在<em class="EmphasisTypeItalic "> n </em>次独立伯努利试验中准确获得<em class="EmphasisTypeItalic "> k </em>次成功的概率由 PMF 给出:<p> <img alt="$$ f\left(k\ |\ n,p\right)=\Pr \left(k\ |\ n,p\right)=\Pr \left(X=k\right)=\left(\begin{array}{c}n\\ {}k\end{array}\right){p}^k{\left(1-p\right)}^{n-k} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equcv.png" style="width:24.94em"/> </p></p>
<p class="Para" id="Par233">对于<em class="EmphasisTypeItalic "> k </em> = 0，1，2，…，<em class="EmphasisTypeItalic "> n </em>。</p>
<p class="Para" id="Par234"><img alt="$$ \left(\begin{array}{c}n\\ {}k\end{array}\right)=\frac{n!}{k!\left(n-k\right)!} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq24.png" style="width:6.18em"/>是二项式系数，这是分布得名的原因。公式可以这样理解:<em class="EmphasisTypeItalic "> k </em>成功发生概率<em class="EmphasisTypeItalic "> p </em> <sup> <em class="EmphasisTypeItalic "> k </em> </sup>，<em class="EmphasisTypeItalic ">n</em>—<em class="EmphasisTypeItalic ">k</em>失败发生概率(1—<em class="EmphasisTypeItalic ">p</em>)<sup><em class="EmphasisTypeItalic ">n</em>—<em class="EmphasisTypeItalic ">k</em></sup>。然而，<em class="EmphasisTypeItalic "> k </em>成功可以发生在<em class="EmphasisTypeItalic "> n </em>试验中的任何地方，并且在一系列<em class="EmphasisTypeItalic "> k </em>试验中有<img alt="$$ \left(\begin{array}{c}n\\ {}k\end{array}\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq25.png" style="width:2.22em"/>种不同的分配<em class="EmphasisTypeItalic "> k </em>成功的方式。</p>
<p>图<a href="#Fig25"> 12-25 </a>显示了一个例子。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig25_HTML.jpg" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig25_HTML.jpg" style="width:26.55em"/></p>
<p>图 12-25</p><p class="SimplePara">二项式分布的概率质量函数</p>


<p>CDF 如下:<p> <img alt="$$ F\left(k\ |\ n,p\right)=\Pr \left(X\le k\right)=\sum \limits_{i=0}^{\underset{\_}{k}}\left(\begin{array}{c}n\\ {}i\end{array}\right){p}^i{\left(1-p\right)}^{n-i} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equcw.png" style="width:20.42em"/> </p></p>
<p>图<a href="#Fig26"> 12-26 </a>显示了一个例子。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig26_HTML.jpg" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig26_HTML.jpg" style="width:26.8em"/></p>
<p>图 12-26</p><p class="SimplePara">二项分布的累积概率函数</p>


<p class="Para" id="Par238">分位数函数没有封闭的形式，但是它可以通过使用 CDF 搜索最大的<em class="EmphasisTypeItalic "> k </em>来计算，使得<em class="EmphasisTypeItalic ">F</em>(<em class="EmphasisTypeItalic ">k</em>)&lt;<em class="EmphasisTypeItalic ">q</em>。</p>
<p>意思如下:<p> <img alt="$$ \mathrm{E}(X)= np $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equcx.png" style="width:4.78em"/> </p></p>
<p>方差如下:<p> <img alt="$$ Var(X)= npq $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equcy.png" style="width:6.39em"/> </p></p>
<p>偏斜度如下:<p> <img alt="$$ \gamma =\frac{q-p}{\sqrt{npq}} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equcz.png" style="width:4.88em"/> </p></p>
<p>超额峰度如下:<p> <img alt="$$ \kappa =\frac{1-6 pq}{npq} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equda.png" style="width:5.55em"/> </p></p>
<p>力矩生成函数如下:<p> <img alt="$$ {M}_X(t)={\left(q+p{e}^t\right)}^n $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equdb.png" style="width:8.26em"/> </p></p>
<p>NM Dev 类<code>BinomialDistribution</code>实现了二项式分布。这里有一个例子:</p>
<pre>BinomialDistribution dist = new BinomialDistribution(
        20, // n
        0.7 // p
);

System.out.println("mean = " + dist.mean());
System.out.println("median = " + dist.median());
System.out.println("variance = " + dist.variance());
System.out.println("skew = " + dist.skew());
System.out.println("kurtosis = " + dist.kurtosis());
System.out.println("entropy = " + dist.entropy());

double[] ks = DoubleUtils.seq(0., 20., 1.); // a sequence of numbers from 0 to 20
for (double k : ks) {
    System.out.println(String.format("F(%f) = %f", k, dist.cdf(k)));
}
for (double k : ks) {
    System.out.println(String.format("f(%f) = %f", k, dist.density(k)));
}

for (double u = 0.1; u &lt; 1d; u += 0.1) {
    double x = dist.quantile(u);
    System.out.println(String.format("Q(%f) = %f", u, x));
}

</pre>
<p>输出如下所示:</p>
<pre>mean = 14.0
median = 14.0
variance = 4.200000000000001
skew = -0.19518001458970657
kurtosis = -0.06190476190476189
entropy = 3.0822902491263404

F(0.000000) = 0.000000
F(1.000000) = 0.000000
F(2.000000) = 0.000000
F(3.000000) = 0.000001
F(4.000000) = 0.000006
F(5.000000) = 0.000043
F(6.000000) = 0.000261
F(7.000000) = 0.001279
F(8.000000) = 0.005138
F(9.000000) = 0.017145
F(10.000000) = 0.047962
F(11.000000) = 0.113331
F(12.000000) = 0.227728
F(13.000000) = 0.391990
F(14.000000) = 0.583629
F(15.000000) = 0.762492
F(16.000000) = 0.892913
F(17.000000) = 0.964517
F(18.000000) = 0.992363
F(19.000000) = 0.999202
F(20.000000) = 1.000000
f(0.000000) = 0.000000
f(1.000000) = 0.000000
f(2.000000) = 0.000000
f(3.000000) = 0.000001
f(4.000000) = 0.000005
f(5.000000) = 0.000037
f(6.000000) = 0.000218
f(7.000000) = 0.001018
f(8.000000) = 0.003859
f(9.000000) = 0.012007
f(10.000000) = 0.030817
f(11.000000) = 0.065370
f(12.000000) = 0.114397



f(13.000000) = 0.164262
f(14.000000) = 0.191639
f(15.000000) = 0.178863
f(16.000000) = 0.130421
f(17.000000) = 0.071604
f(18.000000) = 0.027846
f(19.000000) = 0.006839
f(20.000000) = 0.000798
Q(0.100000) = 11.000000
Q(0.200000) = 12.000000
Q(0.300000) = 13.000000
Q(0.400000) = 14.000000
Q(0.500000) = 14.000000
Q(0.600000) = 15.000000
Q(0.700000) = 15.000000
Q(0.800000) = 16.000000
Q(0.900000) = 17.000000
Q(1.000000) = 20.000000




</pre>

<h3 class="Heading">T 形分布</h3>
<p>学生的 t-分布(或简称为 t-分布)是样本均值相对于独立同分布正态分布总体样本真实均值的概率分布，此时样本规模较小，总体的标准差未知。具体来说，假设集合{ <em class="EmphasisTypeItalic "> x </em> <sub> 1 </sub>，…，<em class="EmphasisTypeItalic "> x </em> <sub> <em class="EmphasisTypeItalic "> n </em> </sub> }取自均值已知<em class="EmphasisTypeItalic "> μ </em>方差未知的正态分布；那么这种样本的标准化值 t 值定义如下:<p> <img alt="$$ t=\frac{\overline{x}-\mu }{s/\sqrt{n}} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equdc.png" style="width:4.41em"/> </p></p>
<p class="Para" id="Par247">其中<img alt="$$ \overline{x} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq26.png" style="width:0.78em"/>是样本均值，而<em class="EmphasisTypeItalic "> s </em>是无偏样本标准差(分母为<em class="EmphasisTypeItalic ">n</em>1)代替真实总体标准差<em class="EmphasisTypeItalic "> σ </em>。<em class="EmphasisTypeItalic "> t </em>是随机的，因为<img alt="$$ \overline{x} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq27.png" style="width:0.78em"/>和<em class="EmphasisTypeItalic "> s </em>是随机的。随机变量<em class="EmphasisTypeItalic "> t </em>具有带<em class="EmphasisTypeItalic ">υ</em>=<em class="EmphasisTypeItalic ">n</em>1 自由度的 t 分布。</p>
<p class="Para" id="Par248">t 分布在许多广泛使用的统计分析中起着重要作用，包括用于评估两个样本均值之间差异的统计显著性(两个均值在统计上是否显著不同)的学生 t 检验，用于构建两个总体均值之间差异的置信区间，以及用于线性回归分析。学生的 t 分布也出现在对正常家庭数据的贝叶斯分析中。</p>
<p>数学上，一个随机变量<em class="EmphasisTypeItalic "> X </em>具有 t 分布当且仅当它具有如下所示的 PDF:<p><img alt="$$ f(t)=\frac{\Gamma \left(\frac{\upsilon +1}{2}\right)}{\sqrt{\upsilon \pi}\Gamma \left(\frac{\upsilon }{2}\right)}{\left(1+\frac{t^2}{\upsilon}\right)}^{-\frac{\upsilon +1}{2}} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equdd.png" style="width:12.56em"/></p></p>
<p class="Para" id="Par250">其中<em class="EmphasisTypeItalic "> υ </em>是自由度的数量，γ是伽马函数。</p>
<p>图<a href="#Fig27"> 12-27 </a>显示了一个例子。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig27_HTML.jpg" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig27_HTML.jpg" style="width:43.05em"/></p>
<p>图 12-27</p><p class="SimplePara">t 分布(红色)与正态分布(蓝色)</p>


<p>t 分布是对称的钟形，像正态分布一样。然而，t 分布具有较重的尾部，这意味着它更容易产生远离平均值的值。当自由度趋于无穷大时，t 分布收敛于正态分布。也就是<p> <img alt="$$ \underset{\upsilon \to \infty }{\lim }t=\frac{\overline{x}-\mu }{\sigma /\sqrt{n}} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equde.png" style="width:6.42em"/> </p></p>
<p class="Para" id="Par253">这是一个均值为 0、方差为 1 的标准正态分布。</p>
<p>CDF 如下:<p> <img alt="$$ F(t)=1-\frac{1}{2}{I}_{x(t)}\left(\frac{\nu }{2},\frac{1}{2}\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equdf.png" style="width:10.02em"/> </p></p>
<p>其中<em class="EmphasisTypeItalic "> I </em>是正则化的不完全 beta 函数，<em class="EmphasisTypeItalic ">t</em>T7】0，我们有这个:<p> <img alt="$$ x(t)=\frac{\nu }{t^2+\nu } $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equdg.png" style="width:5.62em"/> </p></p>
<p>图<a href="#Fig28"> 12-28 </a>显示了一个例子。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig28_HTML.jpg" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig28_HTML.jpg" style="width:19.18em"/></p>
<p>图 12-28</p><p class="SimplePara">t 分布的累积概率函数</p>


<p>当自由度<em class="EmphasisTypeItalic "> υ </em> = 1，2，4 时，t 分布的分位数函数具有简单的公式。它们分别是:<p><img alt="$$ \upsilon =1, $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equdh.png" style="width:2.9em"/></p><p><img alt="$$ Q(q)=\tan \left(\pi \left(q-\frac{1}{2}\right)\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equdi.png" style="width:9.86em"/></p><p><img alt="$$ \upsilon =2, $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equdj.png" style="width:2.9em"/></p><p><img alt="$$ Q(q)=2\left(q-\frac{1}{2}\right)\sqrt{\frac{2}{\alpha }} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equdk.png" style="width:9.67em"/></p><p><img alt="$$ \alpha =4q\left(1-q\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equdl.png" style="width:6.38em"/></p><p><img alt="$$ \upsilon =4, $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equdm.png" style="width:2.9em"/></p><p><img alt="$$ Q(q)=\operatorname{sign}\left(q-\frac{1}{2}\right)2\sqrt{u-1} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equdn.png" style="width:12.66em"/></p><p><img alt="$$ u=\frac{\cos \left(\frac{1}{3}{\cos}^{-1}\sqrt{\alpha}\right)}{\sqrt{\alpha }} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equdo.png" style="width:9em"/></p></p>
<p class="Para" id="Par258">sign 函数返回 1 表示正数，-1 表示负数，否则返回 0。</p>
<p>一般来说，分位数函数如下:<p> <img alt="$$ Q(q)=\operatorname{sign}\left({I}^{-1}-\frac{1}{2}\right)\frac{1}{\sqrt{\frac{1}{4\nu {\left({I}^{-1}-\frac{1}{2}\right)}^2}-\frac{1}{\nu }}} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equdp.png" style="width:16.48em"/> </p></p>
<p class="Para" id="Par260"><img alt="$$ {I}^{-1}={I}_{\left(\frac{\nu }{2},\frac{\nu }{2}\right)}^{-1}(q) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq28.png" style="width:6.34em"/>是两个形状参数都为<img alt="$$ \frac{\nu }{2} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq29.png" style="width:0.76em"/>的正则化不完全贝塔函数的逆。</p>
<p>意思如下:<p> <img alt="$$ \mathrm{E}(X)=0 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equdq.png" style="width:4.17em"/> </p></p>
<p class="Para" id="Par262">差异如下:</p>
<p class="Para" id="Par263"><img alt="$$ Var(X)=\left\{\begin{array}{c}\infty, 1&amp;lt;\nu \le 2\\ {}\frac{\nu }{\nu -2},\nu &amp;gt;2\kern0.5em \end{array}\right. $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq30.png" style="width:11.49em"/>，否则未定义</p>
<p class="Para" id="Par264">偏斜度如下:</p>
<p class="Para" id="Par265"><em class="EmphasisTypeItalic "> γ </em> = 0，<em class="EmphasisTypeItalic "> ν </em> &gt; 3，否则未定义</p>
<p class="Para" id="Par266">超额峰度如下:</p>
<p class="Para" id="Par267"><img alt="$$ \kappa =\left\{\begin{array}{c}\infty, 2&amp;lt;\nu \le 4\\ {}\frac{6}{\nu -4},\nu &amp;gt;4\end{array}\right. $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq31.png" style="width:8.8em"/>，否则未定义</p>
<p class="Para" id="Par268">力矩生成函数是未定义的。</p>
<p>NM Dev 类<code>TDistribution</code>实现了 t 分布。这里有一个例子:</p>
<pre>TDistribution dist = new TDistribution(4.5); // degree of freedom = 4.5

System.out.println("mean = " + dist.mean());
System.out.println("median = " + dist.median());
System.out.println("variance = " + dist.variance());
System.out.println("skew = " + dist.skew());
System.out.println("kurtosis = " + dist.kurtosis());
System.out.println("entropy = " + dist.entropy());

double[] ks = DoubleUtils.seq(0., 20., 1.); // a sequence of numbers from 0 to 20
for (double k : ks) {
    System.out.println(String.format("F(%f) = %f", k, dist.cdf(k)));
}
for (double k : ks) {
    System.out.println(String.format("f(%f) = %f", k, dist.density(k)));
}

boolean allEquals = true;
for (double u = 0.1; u &lt; 1d; u += 0.1) {
    double x = dist.quantile(u);
    double y = dist.cdf(x);
    if (abs(u - y) &gt; 1e-9) {
        allEquals = false;
    }
}
System.out.println("F(Q(u)) = u for all u = " + allEquals);

</pre>
<p>输出如下所示:</p>
<pre>mean = 0.0
median = 0.0
variance = 1.8
skew = 0.0
kurtosis = 12.0
entropy = 1.6515357247574647
F(0.000000) = 0.500000
F(1.000000) = 0.815997
F(2.000000) = 0.945871
F(3.000000) = 0.982810
F(4.000000) = 0.993618
F(5.000000) = 0.997262
F(6.000000) = 0.998679
F(7.000000) = 0.999301
F(8.000000) = 0.999602
F(9.000000) = 0.999759
F(10.000000) = 0.999847
F(11.000000) = 0.999899
F(12.000000) = 0.999931
F(13.000000) = 0.999952
F(14.000000) = 0.999965
F(15.000000) = 0.999974
F(16.000000) = 0.999981
F(17.000000) = 0.999985
F(18.000000) = 0.999989
F(19.000000) = 0.999991
F(20.000000) = 0.999993
f(0.000000) = 0.000000
f(1.000000) = 0.217424
f(2.000000) = 0.065675
f(3.000000) = 0.018403
f(4.000000) = 0.005834
f(5.000000) = 0.002144
f(6.000000) = 0.000897
f(7.000000) = 0.000417
f(8.000000) = 0.000211
f(9.000000) = 0.000115
f(10.000000) = 0.000066
f(11.000000) = 0.000040
f(12.000000) = 0.000025
f(13.000000) = 0.000016
f(14.000000) = 0.000011
f(15.000000) = 0.000008
f(16.000000) = 0.000005
f(17.000000) = 0.000004
f(18.000000) = 0.000003
f(19.000000) = 0.000002
f(20.000000) = 0.000002
F(Q(u)) = u for all u = true




</pre>

<h3 class="Heading">卡方分布</h3>
<p class="Para" id="Par271">当缩放样本均值，k 个独立正态随机变量的和<em class="EmphasisTypeItalic "/>遵循 t 分布时，k 个独立标准正态随机变量的平方和<em class="EmphasisTypeItalic "/>遵循卡方分布(也称为χ <sup> 2 </sup>分布)。这种分布有时被称为中心卡方分布，是更一般的非中心卡方分布的特例。卡方分布是推断统计学中最广泛使用的概率分布之一，特别是在假设检验和置信区间的构造中。它也用于观察分布与理论分布的拟合优度的常见卡方检验。参见第 12.4 节。</p>
<p>数学上，如果{ <em class="EmphasisTypeItalic "> Z </em> <sub> 1 </sub>，…，<em class="EmphasisTypeItalic "> Z </em> <sub> <em class="EmphasisTypeItalic "> k </em> </sub> }中的每个变量都是独立的、标准的正态随机变量，那么它们的平方和，如下所示:<p> <img alt="$$ Q=\sum \limits_{i=1}^k{Z}_i^2 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equdr.png" style="width:4.98em"/> </p></p>
<p class="Para" id="Par273">具有卡方分布<em class="EmphasisTypeItalic "> k </em>自由度。这通常表示为<em class="EmphasisTypeItalic ">Q</em>~<em class="EmphasisTypeItalic ">χ</em><sup>2</sup>(<em class="EmphasisTypeItalic ">k</em>)或<img alt="$$ Q\sim {\chi}_k^2 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq32.png" style="width:3.33em"/>。卡方分布有一个参数:一个正整数<em class="EmphasisTypeItalic "> k </em>指定自由度(被求和的随机变量的数量，<em class="EmphasisTypeItalic ">Z</em><sub><em class="EmphasisTypeItalic ">I</em></sub>s)。</p>
<p>此外，样本方差<em class="EmphasisTypeItalic "> S </em> <sup> 2 </sup>具有标度卡方分布。<img alt="$$ {S}^2=\frac{1}{n-1}\sum \limits_{i=1}^n{\left({x}_i-\overline{x}\right)}^2 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equds.png" style="width:10.4em"/>  <p> <img alt="$$ {S}^2\sim \frac{\sigma^2}{n-1}{\chi}_{n-1}^2 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equdt.png" style="width:6.87em"/> </p></p>
<p>等价地，我们有这样的:<p> <img alt="$$ \frac{S^2}{\sigma^2}\sim \frac{\chi_{n-1}^2}{n-1} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equdu.png" style="width:5.19em"/> </p></p>
<p>卡方分布的 PDF 如下:<p> <img alt="$$ f\left(x\ |\ k\right)=\frac{x^{\frac{k}{2}-1}{e}^{-\frac{x}{2}}}{2^{\frac{k}{2}}\Gamma \left(\frac{k}{2}\right)},x&amp;gt;0 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equdv.png" style="width:11.1em"/> </p></p>
<p class="Para" id="Par277">其中<img alt="$$ \Gamma \left(\frac{k}{2}\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq33.png" style="width:2.31em"/>是伽马函数。</p>
<p>图<a href="#Fig29"> 12-29 </a>显示了一个例子。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig29_HTML.png" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig29_HTML.png" style="width:19.2em"/></p>
<p>图 12-29</p><p class="SimplePara">卡方分布的概率密度函数</p>


<p>CDF 如下:<p> <img alt="$$ F\left(x\ |\ k\right)=\frac{\gamma \left(\frac{k}{2},\frac{x}{2}\right)}{\Gamma \left(\frac{k}{2}\right)}=P\left(\frac{k}{2},\frac{x}{2}\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equdw.png" style="width:12.9em"/> </p></p>
<p class="Para" id="Par280">其中<em class="EmphasisTypeItalic "> γ </em> ( <em class="EmphasisTypeItalic "> s </em>，<em class="EmphasisTypeItalic "> t </em>)为下不完全伽马函数，<em class="EmphasisTypeItalic "> P </em> ( <em class="EmphasisTypeItalic "> s </em>，<em class="EmphasisTypeItalic "> t </em>)为正则化不完全伽马函数。</p>
<p>图<a href="#Fig30"> 12-30 </a>显示了一个例子。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig30_HTML.png" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig30_HTML.png" style="width:19.2em"/></p>
<p>图 12-30</p><p class="SimplePara">卡方分布的累积分布函数</p>


<p>分位数函数是正则化不完全伽马函数的逆函数。<p><img alt="$$ Q(q)={P}^{-1}\left(\frac{k}{2},\frac{q}{2}\right)=2{P}^{-1}\left(\frac{k}{2},q\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equdx.png" style="width:14.02em"/>T2】</p></p>
<p>意思如下:<p> <img alt="$$ \mathrm{E}(X)=k $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equdy.png" style="width:4.12em"/> </p></p>
<p>方差如下:<p> <img alt="$$ Var(X)=2k $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equdz.png" style="width:5.73em"/> </p></p>
<p>偏斜度如下:<p> <img alt="$$ \gamma =\sqrt{\frac{8}{k}} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equea.png" style="width:3.97em"/> </p></p>
<p>超额峰度如下:<p> <img alt="$$ \kappa =\frac{12}{k} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equeb.png" style="width:3.22em"/> </p></p>
<p>力矩生成函数如下:<p> <img alt="$$ {M}_X(t)={\left(1-2t\right)}^{-\frac{k}{2}},t&amp;lt;\frac{1}{2} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equec.png" style="width:11.02em"/> </p></p>
<p>NM Dev 类<code>ChiSquareDistribution</code>实现了卡方分布。这里有一个例子:</p>
<pre>ChiSquareDistribution dist = new ChiSquareDistribution(
        1.5 // degree of freedom
);

System.out.println("mean = " + dist.mean());
System.out.println("median = " + dist.median());
System.out.println("variance = " + dist.variance());
System.out.println("skew = " + dist.skew());
System.out.println("kurtosis = " + dist.kurtosis());
System.out.println("entropy = " + dist.entropy());

double[] xs = new double[]{
    0, 0.0001, 0.001, 0.01, 0.1, 1, 2, 3, 10, 100, 1000};
for (double x : xs) {
    System.out.println(String.format("F(%f) = %f", x, dist.cdf(x)));
}
for (double x : xs) {
    System.out.println(String.format("f(%f) = %f", x, dist.density(x)));
}

boolean allEquals = true;
for (double u = 0.1; u &lt; 1d; u += 0.1) {
    double x = dist.quantile(u);
    double y = dist.cdf(x);
    if (abs(u - y) &gt; 1e-9) {
        allEquals = false;
    }
}
System.out.println("F(Q(u)) = u for all u = " + allEquals);

</pre>
<p>输出如下所示:</p>
<pre>mean = 1.5
median = 1.5
variance = 3.0
skew = 2.309401076758503
kurtosis = 8.0
entropy = 1.3749629120446232
F(0.000000) = 0.000000
F(0.000100) = 0.000647
F(0.001000) = 0.003637
F(0.010000) = 0.020415
F(0.100000) = 0.112622
F(1.000000) = 0.527937
F(2.000000) = 0.739980
F(3.000000) = 0.852400
F(10.000000) = 0.996474
F(100.000000) = 1.000000
F(1000.000000) = 1.000000
f(0.000000) = Infinity
f(0.000100) = 4.852013
f(0.001000) = 2.727260
f(0.010000) = 1.526765
f(0.100000) = 0.820784
f(1.000000) = 0.294304
f(2.000000) = 0.150104
f(3.000000) = 0.082266
f(10.000000) = 0.001839
f(100.000000) = 0.000000
f(1000.000000) = 0.000000
F(Q(u)) = u for all u = true

</pre>

<h3 class="Heading">F 分布</h3>
<p>缩放样本均值(即 t 值)具有 t 分布，而缩放样本方差的比率具有 f 分布。事实上，一个具有自由度为<em class="EmphasisTypeItalic "> d </em> <sub> 1 </sub>的卡方分布的随机变量与另一个具有自由度为<em class="EmphasisTypeItalic "> d </em> <sub> 2 </sub>的卡方分布的随机变量之比遵循自由度为(<em class="EmphasisTypeItalic "> d </em> <sub> 1 </sub>，<em class="EmphasisTypeItalic "> d </em> <sub> 2 </sub>，<em class="EmphasisTypeItalic "> F </em> ( <em class="EmphasisTypeItalic "> d 也就是<p> <img alt="$$ \frac{\chi_{d_1}^2}{\chi_{d_2}^2}\sim F\left({d}_1,{d}_2\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equed.png" style="width:6.99em"/> </p></em></p>
<p>而且，样本方差<em class="EmphasisTypeItalic "> S </em> <sup> 2 </sup>具有卡方分布。<p> <img alt="$$ {S}^2=\frac{1}{n-1}\sum \limits_{i=1}^n{\left({x}_i-\overline{x}\right)}^2\sim \frac{\sigma^2}{n-1}{\chi}_{n-1}^2 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equee.png" style="width:15.92em"/> </p></p>
<p class="Para" id="Par292">那么两个样本的样本方差比<img alt="$$ \frac{S_1^2}{S_2^2} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq34.png" style="width:1.23em"/>和缩放样本方差比<img alt="$$ \frac{S_1^2/{\sigma}_1^2}{S_2^2/{\sigma}_2^2} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq35.png" style="width:2.4em"/>遵循 f 分布。而且对于自由度为<em class="EmphasisTypeItalic "> ν </em>，<em class="EmphasisTypeItalic ">t</em>T8】2 的随机变量<em class="EmphasisTypeItalic "> t </em>具有 f 分布<em class="EmphasisTypeItalic "> F </em> (1，<em class="EmphasisTypeItalic "> ν </em>)。</p>
<p>如果一个随机变量<em class="EmphasisTypeItalic "> X </em>有一个参数为<em class="EmphasisTypeItalic "> d </em> <sub> 1 </sub> &gt; 0 和<em class="EmphasisTypeItalic "> d </em> <sub> 2 </sub> &gt; 0 的 f 分布，我们写<em class="EmphasisTypeItalic ">X</em>~<em class="EmphasisTypeItalic ">F</em>(<em class="EmphasisTypeItalic ">d</em><sub>1</sub>，<em class="EmphasisTypeItalic "> d </em> <sub> 2 </sub>)。PDF 如下:<p><img alt="$$ f\left(x\ |\ {d}_1,{d}_2\right)=\frac{\sqrt{\frac{{\left({d}_1x\right)}^{d_1}{d_2}^{d_2}}{{\left({d}_1x+{d}_2\right)}^{d_1+{d}_2}}}}{xB\left(\frac{d_1}{2},\frac{d_2}{2}\right)} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equef.png" style="width:12.66em"/>T24】</p></p>
<p class="Para" id="Par294"><em class="EmphasisTypeItalic "> B </em>是贝塔函数。</p>
<p>图<a href="#Fig31"> 12-31 </a>显示了一个例子。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig31_HTML.png" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig31_HTML.png" style="width:19.45em"/></p>
<p>图 12-31</p><p class="SimplePara">f 分布的概率密度函数</p>


<p>CDF 如下:<p> <img alt="$$ F\left(x\ |\ {d}_1,{d}_2\right)={I}_{\frac{d_1x}{d_1x+{d}_2}}\left(\frac{d_1}{2},\frac{d_2}{2}\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equeg.png" style="width:13em"/> </p></p>
<p class="Para" id="Par297"><em class="EmphasisTypeItalic "> I </em>是正则化的不完全 beta 函数。</p>
<p>图<a href="#Fig32"> 12-32 </a>显示了一个例子。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig32_HTML.png" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig32_HTML.png" style="width:19.42em"/></p>
<p>图 12-32</p><p class="SimplePara">f 分布的累积分布函数</p>


<p>分位数函数如下:<p> <img alt="$$ Q(q)=\frac{d_2{I}^{-1}}{d_1-{d}_1{I}^{-1}} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equeh.png" style="width:8.1em"/> </p></p>
<p class="Para" id="Par300"><img alt="$$ {I}^{-1}={I}_{\left(\frac{d_1}{2},\frac{d_2}{2}\right)}^{-1}(q) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq36.png" style="width:6.86em"/>是具有形状参数<img alt="$$ \frac{d_1}{2} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq37.png" style="width:1.11em"/>和<img alt="$$ \frac{d_2}{2} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq38.png" style="width:1.11em"/>的正则化不完全贝塔函数的逆。</p>
<p>意思如下:<p> <img alt="$$ \mathrm{E}(X)=\frac{d_2}{d_2-2},{d}_2&amp;gt;2 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equei.png" style="width:9.63em"/> </p></p>
<p>方差如下:<p> <img alt="$$ Var(X)=\frac{2{d}_2^2\left({d}_1+{d}_2-2\right)}{d_1{\left({d}_2-2\right)}^2\left({d}_2-4\right)},{d}_2&amp;gt;4 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equej.png" style="width:16.3em"/> </p></p>
<p>偏斜度如下:<p> <img alt="$$ \gamma =\frac{\left(2{d}_1+{d}_2-2\right)\sqrt{8\left({d}_2-4\right)}}{\left({d}_2-6\right)\sqrt{d_1\left({d}_1+{d}_2-2\right)}},{d}_2&amp;gt;6 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equek.png" style="width:16.65em"/> </p></p>
<p>超额峰度如下:<p> <img alt="$$ \kappa =12\frac{d_1\left(5{d}_2-22\right)\left({d}_1+{d}_2-2\right)+\left({d}_2-4\right){\left({d}_2-2\right)}^2}{d_1\left({d}_2-6\right)\left({d}_2-8\right)\left({d}_1+{d}_2-2\right)} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equel.png" style="width:22.89em"/> </p></p>
<p class="Para" id="Par305">f 分布的矩母函数不存在。</p>
<p>NM Dev 类<code>FDistribution</code>实现了 F 分布。这里有一个例子:</p>
<pre>FDistribution dist = new FDistribution(100.5, 10); // degrees of freedom = {100.5, 10}

System.out.println("mean = " + dist.mean());
System.out.println("variance = " + dist.variance());
System.out.println("skew = " + dist.skew());
System.out.println("kurtosis = " + dist.kurtosis());

double[] ks = DoubleUtils.seq(0., 20., 1.); // a sequence of numbers from 0 to 20
for (double k : ks) {
    System.out.println(String.format("F(%f) = %f", k, dist.cdf(k)));
}
for (double k : ks) {
    System.out.println(String.format("f(%f) = %f", k, dist.density(k)));
}

boolean allEquals = true;
for (double u = 0.1; u &lt; 1d; u += 0.1) {
    double x = dist.quantile(u);
    double y = dist.cdf(x);
    if (abs(u - y) &gt; 1e-9) {
        allEquals = false;
    }
}
System.out.println("F(Q(u)) = u for all u = " + allEquals);

</pre>
<p>输出如下所示:</p>
<pre>mean = 1.25
variance = 0.5622927031509121
skew = 3.4666421524967395
kurtosis = 39.05282344040168
F(0.000000) = 0.000000
F(1.000000) = 0.448778
F(2.000000) = 0.886374
F(3.000000) = 0.970125
F(4.000000) = 0.989870
F(5.000000) = 0.995874
F(6.000000) = 0.998080
F(7.000000) = 0.999013
F(8.000000) = 0.999452
F(9.000000) = 0.999676
F(10.000000) = 0.999799
F(11.000000) = 0.999870
F(12.000000) = 0.999913
F(13.000000) = 0.999940
F(14.000000) = 0.999958
F(15.000000) = 0.999969
F(16.000000) = 0.999977
F(17.000000) = 0.999983
F(18.000000) = 0.999987
F(19.000000) = 0.999990
F(20.000000) = 0.999992
f(0.000000) = 0.000000
f(1.000000) = 0.836572
f(2.000000) = 0.168807
f(3.000000) = 0.035722
f(4.000000) = 0.009923
f(5.000000) = 0.003404
f(6.000000) = 0.001365
f(7.000000) = 0.000616
f(8.000000) = 0.000304
f(9.000000) = 0.000162



f(10.000000) = 0.000091
f(11.000000) = 0.000054
f(12.000000) = 0.000034
f(13.000000) = 0.000021
f(14.000000) = 0.000014
f(15.000000) = 0.000010
f(16.000000) = 0.000007
f(17.000000) = 0.000005
f(18.000000) = 0.000003
f(19.000000) = 0.000003
f(20.000000) = 0.000002
F(Q(u)) = u for all u = true

</pre>

<h3 class="Heading">瑞利分布</h3>
<p class="Para" id="Par308">瑞利分布是非负值随机变量的连续概率分布。它本质上是具有两个自由度的卡方分布。例如，<img alt="$$ X=\sqrt{X_1^2+{X}_2^2} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq39.png" style="width:6.75em"/>遵循瑞利分布，其中<em class="EmphasisTypeItalic ">X</em>T3】1 和<em class="EmphasisTypeItalic ">X</em>T7】2 是两个正态分布，<img alt="$$ {X}_1^2 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq40.png" style="width:1.38em"/>和<img alt="$$ {X}_2^2 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq41.png" style="width:1.38em"/>是两个卡方分布。</p>
<p class="Para" id="Par309">当矢量的总幅度与其方向分量相关时，通常会观察到瑞利分布。瑞利分布自然出现的一个例子是在二维中分析风速。假设每个分量不相关，正态分布，方差相等，均值为零，那么总风速(矢量幅度)将由瑞利分布表征。分布的第二个例子出现在随机复数的情况下，其实部和虚部独立且相同地正态分布，具有相等的方差和零均值。在这种情况下，复数的绝对值是瑞利分布的。</p>
<p class="Para" id="Par310">另一种可能是<img alt="$$ X=\sigma \sqrt{-2\ln U} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq42.png" style="width:7.19em"/>，其中<em class="EmphasisTypeItalic "> U </em>是均匀分布的随机变量，具有参数<em class="EmphasisTypeItalic "> σ </em>的瑞利分布。</p>
<p>PDF 如下:<p> <img alt="$$ f\left(x\ |\ \sigma \right)=\frac{x}{\sigma^2}\exp \left(-\frac{x^2}{2{\sigma}^2}\right),x\ge 0 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equem.png" style="width:14.55em"/> </p></p>
<p class="Para" id="Par312">其中<em class="EmphasisTypeItalic "> σ </em>是分布的比例参数。</p>
<p>图<a href="#Fig33"> 12-33 </a>显示了一个例子。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig33_HTML.jpg" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig33_HTML.jpg" style="width:26.25em"/></p>
<p>图 12-33</p><p class="SimplePara">瑞利分布的概率密度函数</p>


<p>CDF 如下:<p> <img alt="$$ F\left(x\ |\ \sigma \right)=1-\exp \left(-\frac{x^2}{2{\sigma}^2}\right),x\ge 0 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equen.png" style="width:14.91em"/> </p></p>
<p>图<a href="#Fig34"> 12-34 </a>显示了一个例子。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig34_HTML.jpg" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig34_HTML.jpg" style="width:26.85em"/></p>
<p>图 12-34</p><p class="SimplePara">瑞利分布的累积分布函数</p>


<p>分位数函数如下:<p> <img alt="$$ Q(q)=\sigma \sqrt{-2\ln \left(1-q\right)} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equeo.png" style="width:10.65em"/> </p></p>
<p>意思如下:<p> <img alt="$$ \mathrm{E}(X)=\sigma \sqrt{\frac{\pi }{2}} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equep.png" style="width:6.27em"/> </p></p>
<p>方差如下:<p> <img alt="$$ Var(X)=\frac{4-\pi }{2}{\sigma}^2 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equeq.png" style="width:8.24em"/> </p></p>
<p>偏斜度如下:<p> <img alt="$$ \gamma =\frac{2\sqrt{\pi}\left(\pi -3\right)}{{\left(4-\pi \right)}^{\frac{3}{2}}} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equer.png" style="width:7.44em"/> </p></p>
<p>超额峰度如下:<p> <img alt="$$ \kappa =-\frac{6{\pi}^2-24\pi +16}{{\left(4-\pi \right)}^2} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Eques.png" style="width:9.39em"/> </p></p>
<p>力矩生成函数如下:<p> <img alt="$$ {M}_X(t)=1+\sigma t\exp \left(\frac{\sigma^2{t}^2}{2}\right)\sqrt{\frac{\pi }{2}}\left(\operatorname{erf}\left(\frac{\sigma t}{\sqrt{2}}\right)+1\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equet.png" style="width:20.19em"/> </p></p>
<p>NM Dev 类<code>RayleighDistribution</code>实现了瑞利分布。这里有一个例子:</p>
<pre>RayleighDistribution dist = new RayleighDistribution(
        2 // sigma = 2
);

System.out.println("mean = " + dist.mean());
System.out.println("median = " + dist.median());
System.out.println("variance = " + dist.variance());
System.out.println("skew = " + dist.skew());
System.out.println("kurtosis = " + dist.kurtosis());
System.out.println("entropy = " + dist.entropy());

double[] xs = new double[]{
    0, 0.0001, 0.001, 0.01, 0.1, 1, 2, 3, 10, 100, 1000};
for (double x : xs) {
    System.out.println(String.format("F(%f) = %f", x, dist.cdf(x)));
}
for (double x : xs) {
    System.out.println(String.format("f(%f) = %f", x, dist.density(x)));
}

boolean allEquals = true;
for (double u = 0.000001; u &lt; 1d; u += 0.000001) {
    double x = dist.quantile(u);
    double y = dist.cdf(x);
    if (abs(u - y) &gt; 1e-9) {
        allEquals = false;
    }
}
System.out.println("F(Q(u)) = u for all u = " + allEquals);

</pre>
<p>输出如下所示:</p>
<pre>mean = 2.5066282746310002
median = 2.3548200450309493
variance = 1.7168146928204138
skew = 0.6311106578189364
kurtosis = 0.2450893006876391
entropy = 1.635181422730739
F(0.000000) = 0.000000
F(0.000100) = 0.000000
F(0.001000) = 0.000000
F(0.010000) = 0.000012
F(0.100000) = 0.001249
F(1.000000) = 0.117503
F(2.000000) = 0.393469
F(3.000000) = 0.675348
F(10.000000) = 0.999996
F(100.000000) = 1.000000
F(1000.000000) = 1.000000
f(0.000000) = 0.000000
f(0.000100) = 0.000025
f(0.001000) = 0.000250
f(0.010000) = 0.002500
f(0.100000) = 0.024969
f(1.000000) = 0.220624
f(2.000000) = 0.303265
f(3.000000) = 0.243489
f(10.000000) = 0.000009
f(100.000000) = 0.000000
f(1000.000000) = 0.000000
F(Q(u)) = u for all u = true

</pre>

<h3 class="Heading">伽马分布</h3>
<p>伽玛分布是一个双参数连续概率分布族。指数分布和卡方分布是伽玛分布的特例。通常使用两种不同的参数化:</p>
<ul class="UnorderedListMarkBullet"><li><p class="Para" id="Par325">具有形状参数<em class="EmphasisTypeItalic "> k </em> &gt; 0 和比例参数<em class="EmphasisTypeItalic "> θ </em> &gt; 0</p></li>
<li><p class="Para" id="Par326">具有形状参数<em class="EmphasisTypeItalic ">α</em>=<em class="EmphasisTypeItalic ">k</em>T5】0 和称为速率参数的逆比例参数<img alt="$$ \beta =\frac{1}{\theta }&amp;gt;0 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq43.png" style="width:4.41em"/></p></li>
</ul>

<p class="Para" id="Par327">使用<em class="EmphasisTypeItalic "> k </em>和<em class="EmphasisTypeItalic "> θ </em>的参数化似乎在计量经济学和某些其他应用领域更为常见，例如在这些领域，伽马分布经常被用来模拟等待时间。例如，故障前的等待时间是一个随机变量，经常用γ分布建模。NM Dev 使用此参数化与<em class="EmphasisTypeItalic "> k </em>和<em class="EmphasisTypeItalic "> θ </em>。</p>
<p class="Para" id="Par328">使用<em class="EmphasisTypeItalic "> α </em>和<em class="EmphasisTypeItalic "> β </em>的参数化在贝叶斯统计中更常见，其中伽马分布被用作各种类型的逆比例(速率)参数的共轭先验分布，例如指数分布或泊松分布的<em class="EmphasisTypeItalic "> λ </em>，或者就此而言，伽马分布本身的<em class="EmphasisTypeItalic "> β </em>。</p>
<p>随机变量<em class="EmphasisTypeItalic "> X </em>具有形状为<em class="EmphasisTypeItalic "> k </em>的伽玛分布，标度<em class="EmphasisTypeItalic "> θ </em>表示如下:<p> <img alt="$$ X\sim \Gamma \left(k,\theta \right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equeu.png" style="width:5.18em"/> </p></p>
<p>PDF 如下:<p> <img alt="$$ f\left(x\ |\ k,\theta \right)=\frac{x^{k-1}\exp \left(-\frac{x}{\theta}\right)}{\theta^k\Gamma (k)} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equev.png" style="width:11.54em"/> </p></p>
<p class="Para" id="Par331">其中γ(<em class="EmphasisTypeItalic ">k</em>)是在<em class="EmphasisTypeItalic "> k </em>处计算的伽马函数。</p>
<p>图<a href="#Fig35"> 12-35 </a>显示了一个例子。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig35_HTML.png" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig35_HTML.png" style="width:19.18em"/></p>
<p>图 12-35</p><p class="SimplePara">伽玛分布的概率密度函数</p>


<p>CDF 如下:<p> <img alt="$$ f\left(x\ |\ k,\theta \right)=\frac{\gamma \left(k,\frac{x}{\theta}\right)}{\Gamma (k)} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equew.png" style="width:8.88em"/> </p></p>
<p>图<a href="#Fig36"> 12-36 </a>显示了一个例子。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig36_HTML.png" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig36_HTML.png" style="width:19.18em"/></p>
<p>图 12-36</p><p class="SimplePara">伽玛分布的累积分布函数</p>


<p>分位数函数如下:<p> <img alt="$$ Q(q)=\theta {P}^{-1}\left(k,q\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equex.png" style="width:8.01em"/> </p></p>
<p class="Para" id="Par336">其中<em class="EmphasisTypeItalic ">P</em>T2 1 是正则化不完全伽马函数的逆。</p>
<p>意思如下:<p> <img alt="$$ \mathrm{E}(X)= k\theta $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equey.png" style="width:4.6em"/> </p></p>
<p>方差如下:<p> <img alt="$$ Var(X)=k{\theta}^2 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equez.png" style="width:6.08em"/> </p></p>
<p>偏斜度如下:<p> <img alt="$$ \gamma =\frac{2}{k} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equfa.png" style="width:2.78em"/> </p></p>
<p>超额峰度如下:<p> <img alt="$$ \kappa =\frac{6}{k} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equfb.png" style="width:2.68em"/> </p></p>
<p>力矩生成函数如下:<p> <img alt="$$ {M}_X(t)={\left(1-\theta t\right)}^{-k},t&amp;lt;\frac{1}{\theta } $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equfc.png" style="width:10.86em"/> </p></p>
<p>NM Dev 类<code>GammaDistribution</code>实现伽马分布。这里有一个例子:</p>
<pre>GammaDistribution dist = new GammaDistribution(
        1., // k = 1
        2. // theta = 2
);

System.out.println("mean = " + dist.mean());
System.out.println("variance = " + dist.variance());
System.out.println("skew = " + dist.skew());
System.out.println("kurtosis = " + dist.kurtosis());

double[] xs = new double[]{
    0, 0.0001, 0.001, 0.01, 0.1, 1, 2, 3, 10, 100, 1000};
for (double x : xs) {
    System.out.println(String.format("F(%f) = %f", x, dist.cdf(x)));
}
for (double x : xs) {
    System.out.println(String.format("f(%f) = %f", x, dist.density(x)));
}

boolean allEquals = true;
for (double u = 0.001; u &lt; 1d; u += 0.001) {
    double x = dist.quantile(u);
    double y = dist.cdf(x);
    if (abs(u - y) &gt; 1e-9) {
        allEquals = false;
    }
}
System.out.println("F(Q(u)) = u for all u = " + allEquals);

</pre>
<p>输出如下所示:</p>
<pre>mean = 2.0
variance = 4.0
skew = 2.0
kurtosis = 6.0
F(0.000000) = 0.000000
F(0.000100) = 0.000050
F(0.001000) = 0.000500
F(0.010000) = 0.004988
F(0.100000) = 0.048771
F(1.000000) = 0.393469
F(2.000000) = 0.632121
F(3.000000) = 0.776870
F(10.000000) = 0.993262
F(100.000000) = 1.000000
F(1000.000000) = 1.000000
f(0.000000) = 0.500000
f(0.000100) = 0.499975
f(0.001000) = 0.499750
f(0.010000) = 0.497506
f(0.100000) = 0.475615
f(1.000000) = 0.303265
f(2.000000) = 0.183940
f(3.000000) = 0.111565
f(10.000000) = 0.003369
f(100.000000) = 0.000000
f(1000.000000) = 0.000000
F(Q(u)) = u for all u = true




</pre>

<h3 class="Heading">测试版发行</h3>
<p class="Para" id="Par344">贝塔分布是在单位区间[0，1]上定义的连续概率分布族，单位区间[0，1]由两个正形状参数<em class="EmphasisTypeItalic "> α </em>和<em class="EmphasisTypeItalic "> β </em>参数化，它们作为随机变量的指数出现并控制分布的形状。贝塔分布已被广泛应用于各种学科中，用来模拟限于有限长度区间的随机变量的行为。在贝叶斯推断中，贝塔分布是伯努利、二项式、负二项式和几何分布的共轭先验概率分布。贝塔分布是百分比和比例随机行为的合适模型。</p>
<p>具有带参数<em class="EmphasisTypeItalic "> α </em>和<em class="EmphasisTypeItalic "> β </em>的贝塔分布的随机变量<em class="EmphasisTypeItalic "> X </em>表示如下:<p> <img alt="$$ X\sim \mathrm{Beta}\left(\alpha, \beta \right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equfd.png" style="width:6.75em"/> </p></p>
<p>PDF 如下:<p> <img alt="$$ f\left(x\ |\ \alpha, \beta \right)=\frac{1}{\mathrm{B}\left(\alpha, \beta \right)}{x}^{\alpha -1}{\left(1-x\right)}^{\beta -1} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equfe.png" style="width:15.42em"/> </p></p>
<p class="Para" id="Par347">其中 B( <em class="EmphasisTypeItalic "> α </em>，<em class="EmphasisTypeItalic "> β </em>)为贝塔函数。</p>
<p>图<a href="#Fig37"> 12-37 </a>显示了一个例子。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig37_HTML.jpg" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig37_HTML.jpg" style="width:22.12em"/></p>
<p>图 12-37</p><p class="SimplePara">贝塔分布的概率密度函数</p>


<p>CDF 如下:<p> <img alt="$$ f\left(x\ |\ \alpha, \beta \right)=\frac{\mathrm{B}\left(x\ |\ \alpha, \beta \right)}{\mathrm{B}\left(\alpha, \beta \right)}={I}_x\left(\alpha, \beta \right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equff.png" style="width:15.24em"/> </p></p>
<p class="Para" id="Par350">其中 B( <em class="EmphasisTypeItalic "> x </em> | <em class="EmphasisTypeItalic "> α </em>，<em class="EmphasisTypeItalic "> β </em>)为不完全 beta 函数，<em class="EmphasisTypeItalic ">I</em><sub><em class="EmphasisTypeItalic ">x</em></sub>(<em class="EmphasisTypeItalic ">α</em>，<em class="EmphasisTypeItalic "> β </em>)为正则化不完全 beta 函数。</p>
<p>图<a href="#Fig38"> 12-38 </a>显示了一个例子。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig38_HTML.jpg" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig38_HTML.jpg" style="width:22.12em"/></p>
<p>图 12-38</p><p class="SimplePara">贝塔分布的累积分布函数</p>


<p>分位数函数是正则化不完全 beta 函数的逆。<p><img alt="$$ Q(q)={I}_q^{-1}\left(\alpha, \beta \right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equfg.png" style="width:7.42em"/>T2】</p></p>
<p>意思如下:<p> <img alt="$$ \mathrm{E}(X)=\frac{\alpha }{\alpha +\beta } $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equfh.png" style="width:6.12em"/> </p></p>
<p>方差如下:<p> <img alt="$$ Var(X)=\frac{\alpha \beta}{{\left(\alpha +\beta \right)}^2\left(\alpha +\beta +1\right)} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equfi.png" style="width:13.26em"/> </p></p>
<p>偏斜度如下:<p> <img alt="$$ \gamma =\frac{2\left(\beta -\alpha \right)\sqrt{\alpha +\beta +1}}{\left(\alpha +\beta +2\right)\sqrt{\alpha \beta}} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equfj.png" style="width:11.22em"/> </p></p>
<p>超额峰度如下:<p> <img alt="$$ \kappa =\frac{6\left[{\left(\alpha -\beta \right)}^2\left(\alpha +\beta +1\right)-\alpha \beta \left(\alpha +\beta +2\right)\right]}{\alpha \beta \left(\alpha +\beta +1\right)\left(\alpha +\beta +3\right)} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equfk.png" style="width:19.3em"/> </p></p>
<p>力矩生成函数如下:<p> <img alt="$$ {M}_X(t)=1+\sum \limits_{k=1}^{\infty}\left(\prod \limits_{r=0}^{k-1}\frac{\alpha +r}{a+\beta +r}\right)\frac{t^k}{k!} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equfl.png" style="width:15.03em"/> </p></p>
<p>NM Dev 类<code>BetaDistribution</code>实现了 Beta 版。这里有一个例子:</p>
<pre>BetaDistribution dist = new BetaDistribution(
        0.5, // alpha = 0.5
        1.5 // beta = 1.5
);

System.out.println("mean = " + dist.mean());
System.out.println("variance = " + dist.variance());
System.out.println("skew = " + dist.skew());
System.out.println("kurtosis = " + dist.kurtosis());

double[] xs = new double[]{
    0, 0.0001, 0.001, 0.01, 0.1, 1, 2, 3};
for (double x : xs) {
    System.out.println(String.format("F(%f) = %f", x, dist.cdf(x)));
}
for (double x : xs) {
    System.out.println(String.format("f(%f) = %f", x, dist.density(x)));
}

boolean allEquals = true;
for (double u = 0.001; u &lt; 1d; u += 0.001) {
    double x = dist.quantile(u);
    double y = dist.cdf(x);
    if (abs(u - y) &gt; 1e-9) {
        allEquals = false;
    }
}
System.out.println("F(Q(u)) = u for all u = " + allEquals);

</pre>
<p>输出如下所示:</p>
<pre>mean = 0.25
variance = 0.0625
skew = 1.0
kurtosis = 0.0
F(0.000000) = 0.000000
F(0.000100) = 0.012732
F(0.001000) = 0.040257
F(0.010000) = 0.127111
F(0.100000) = 0.395819
F(1.000000) = 1.000000
F(2.000000) = NaN
F(3.000000) = NaN
f(0.000000) = Infinity
f(0.000100) = 63.658794
f(0.001000) = 20.121616
f(0.010000) = 6.334287
f(0.100000) = 1.909859
f(1.000000) = 0.000000
f(2.000000) = NaN
f(3.000000) = NaN
F(Q(u)) = u for all u = true




</pre>
<p class="Para" id="Par360">注意，该分布没有被定义在单位区间[0，1]之外，并且概率密度在<em class="EmphasisTypeItalic "> x </em> = 0 时趋于无穷大。</p>

<h3 class="Heading">威布尔分布</h3>
<p>非负随机变量具有形状参数为<em class="EmphasisTypeItalic ">λ</em>T7】0 和<em class="EmphasisTypeItalic ">k</em>T8】0 的威布尔分布，如果它具有以下 PDF: <p> <img alt="$$ f\left(x\ |\ \lambda, k\right)=\frac{k}{\lambda }{\left(\frac{x}{\lambda}\right)}^{k-1}\exp \left(-{\left(\frac{x}{\lambda}\right)}^k\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equfm.png" style="width:14.59em"/> </p></p>
<p>图<a href="#Fig39"> 12-39 </a>显示了一个例子。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig39_HTML.jpg" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig39_HTML.jpg" style="width:22.38em"/></p>
<p>图 12-39</p><p class="SimplePara">威布尔分布的概率密度函数</p>


<p>CDF 如下:<p> <img alt="$$ F\left(x\ |\ \lambda, k\right)=1-\exp \left(-{\left(\frac{x}{\lambda}\right)}^k\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equfn.png" style="width:12.78em"/> </p></p>
<p>图<a href="#Fig40"> 12-40 </a>显示了一个例子。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig40_HTML.jpg" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig40_HTML.jpg" style="width:22.38em"/></p>
<p>图 12-40</p><p class="SimplePara">威布尔分布的累积分布函数</p>


<p>分位数函数如下:<p> <img alt="$$ Q(q)=\lambda {\left(-\ln \left(1-q\right)\right)}^{\frac{1}{k}} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equfo.png" style="width:10.2em"/> </p></p>
<p>意思如下:<p> <img alt="$$ \mathrm{E}(X)=\lambda \Gamma \left(1+\frac{1}{k}\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equfp.png" style="width:8.19em"/> </p></p>
<p class="Para" id="Par367">γ是伽玛函数。</p>
<p>方差如下:<p> <img alt="$$ Var(X)={\lambda}^2\left[\Gamma \left(1+\frac{1}{2}\right)-{\left(\Gamma \left(1+\frac{1}{k}\right)\right)}^2\right] $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equfq.png" style="width:17em"/> </p></p>
<p>偏斜度如下:<p> <img alt="$$ \gamma =\frac{\lambda^3\Gamma \left(1+\frac{3}{k}\right)-3\mu {\sigma}^2-{\mu}^3}{\sigma^3} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equfr.png" style="width:12.54em"/> </p></p>
<p>超额峰度如下:<p> <img alt="$$ \kappa =\frac{\lambda^4\Gamma \left(1+\frac{4}{k}\right)-4\gamma {\sigma}^3\mu -6{\mu}^2{\sigma}^2-{\mu}^4}{\sigma^4}-3 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equfs.png" style="width:18.54em"/> </p></p>
<p>力矩生成函数如下:<p> <img alt="$$ {M}_X(t)=\sum \limits_{n=0}^{\infty}\frac{t^n{\lambda}^n}{n!}\Gamma \left(1+\frac{n}{k}\right),k\ge 1 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equft.png" style="width:14.4em"/> </p></p>
<p>NM Dev 类<code>WeibullDistribution</code>实现了威布尔分布。这里有一个例子:</p>
<pre>WeibullDistribution dist = new WeibullDistribution(
        1, // lambda, the scale parameter = 1
        1 // the shape parameter = 1
);

System.out.println("mean = " + dist.mean());
System.out.println("variance = " + dist.variance());
System.out.println("skew = " + dist.skew());
System.out.println("kurtosis = " + dist.kurtosis());
System.out.println("entropy = " + dist.entropy());

double[] xs = new double[]{
    0, 0.0001, 0.001, 0.01, 0.1, 1, 2, 3};
for (double x : xs) {
    System.out.println(String.format("F(%f) = %f", x, dist.cdf(x)));
}
for (double x : xs) {
    System.out.println(String.format("f(%f) = %f", x, dist.density(x)));
}

boolean allEquals = true;
for (double u = 0.001; u &lt; 1d; u += 0.001) {
    double x = dist.quantile(u);
    double y = dist.cdf(x);
    if (abs(u - y) &gt; 1e-9) {
        allEquals = false;
    }
}
System.out.println("F(Q(u)) = u for all u = " + allEquals);

</pre>
<p>输出如下所示:</p>
<pre>mean = 1.0
variance = 1.0
skew = 1.9999999999999973
kurtosis = 6.0000000000000036
entropy = 1.0
F(0.000000) = 0.000000
F(0.000100) = 0.000100
F(0.001000) = 0.001000
F(0.010000) = 0.009950
F(0.100000) = 0.095163
F(1.000000) = 0.632121
F(2.000000) = 0.864665
F(3.000000) = 0.950213
f(0.000000) = 1.000000
f(0.000100) = 0.999900
f(0.001000) = 0.999000
f(0.010000) = 0.990050
f(0.100000) = 0.904837
f(1.000000) = 0.367879
f(2.000000) = 0.135335
f(3.000000) = 0.049787
F(Q(u)) = u for all u = true

</pre>

<h3 class="Heading">经验分布</h3>
<p class="Para" id="Par374">到目前为止，我们讨论的概率分布都是基于模型的参数分布。这些分布的形状由几个(形状)参数决定。基于模型或参数的分布需要对数据集或生成过程的基本统计性质有所了解或假设。例如，我们可以假设原子衰变率遵循指数分布，股票价格遵循对数正态分布。然而，有时很难证明这种假设，甚至很难找到一个参数分布来描述数据。</p>
<p class="Para" id="Par375">另一方面，经验分布不需要事先知道数据集的统计性质。它的形状完全由数据集本身决定。当我们不能证明或拟合一个足够精确的参数分布时，它们是有用的。当没有足够的样本或缺乏数据的理论基础时，可能会出现这种情况。</p>
<p class="Para" id="Par376">具体来说，经验累积分布函数是在每个<em class="EmphasisTypeItalic "> n </em>数据点上跳跃<img alt="$$ \frac{1}{n} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq44.png" style="width:0.76em"/>的阶跃函数。它在随机变量的任何指定值处的值是小于或等于指定值的变量观察值的分数。经验分布函数是对产生样本点的累积分布函数的估计。根据 Glivenko-Cantelli 定理，它以概率 1 收敛于该基本分布。</p>
<p>数学上，设{<em class="EmphasisTypeItalic ">X</em>T2】1，...、<em class="EmphasisTypeItalic "> X </em> <sub> <em class="EmphasisTypeItalic "> n </em> </sub> }为独立同分布的实随机变量，具有相同的累积分布函数<em class="EmphasisTypeItalic "> F </em> ( <em class="EmphasisTypeItalic "> x </em>)。那么经验累积分布函数定义如下:<p> <img alt="$$ {\hat{F}}_n(x)=\frac{1}{n}\sum \limits_{i=1}^n{\mathbf{1}}_{X_i\le x} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equfu.png" style="width:8.46em"/> </p></p>
<p class="Para" id="Par378">其中<strong class="EmphasisTypeBold ">1</strong><sub>T3A</sub>是事件<em class="EmphasisTypeItalic "> A </em>的指示器。当条件或事件满足时，它等于 1。这种情况下，条件是<em class="EmphasisTypeItalic ">X</em><sub><em class="EmphasisTypeItalic ">I</em></sub>≤<em class="EmphasisTypeItalic ">X</em>。<img alt="$$ {\hat{F}}_n(x) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq45.png" style="width:2.61em"/>是<em class="EmphasisTypeItalic "> F </em> ( <em class="EmphasisTypeItalic "> x </em>)的无偏估计量。</p>
<p>例如，在图<a href="#Fig41"> 12-41 </a>中，平滑曲线渐进地接近高度 0 和 1，但没有达到它们，这是标准正态分布的真实累积分布函数。底部的散列标记表示从该分布中抽取的特定样本中的观察值。阶跃函数的水平阶跃(包括每个阶跃中最左边的点，但不包括最右边的点)形成该样本的经验分布函数。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig41_HTML.jpg" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig41_HTML.jpg" style="width:19.12em"/></p>
<p>图 12-41</p><p class="SimplePara">经验分布与正态分布</p>


<p>样本量<em class="EmphasisTypeItalic "> n </em>的经验分布的分位数函数是这样的，如果<em class="EmphasisTypeItalic "> nq </em>不是整数，那么第<em class="EmphasisTypeItalic "> q </em>个分位数是唯一的，并且等于第<img alt="$$ \overline{nq} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq46.png" style="width:1.32em"/>个样本，其中<img alt="$$ \overline{nq} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq47.png" style="width:1.32em"/>是小于或等于<em class="EmphasisTypeItalic "> nq </em>的最大整数。<p> <img alt="$$ Q(q)={x}_{\overline{nq}} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equfv.png" style="width:4.89em"/> </p></p>
<p>如果<em class="EmphasisTypeItalic "> nq </em>是整数，那么<em class="EmphasisTypeItalic "> q </em>的分位数不是唯一的，而是任意实数<em class="EmphasisTypeItalic "> x </em>，使得:<p> <img alt="$$ {x}_{nq}&amp;lt;x&amp;lt;{x}_{nq+1} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equfw.png" style="width:6.81em"/> </p></p>
<p>均值是总体分布均值的无偏估计量:<p> <img alt="$$ {\mathrm{E}}_n(X)=\overline{x}=\frac{1}{n}\left(\sum \limits_{i=1}^n{x}_i\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equfx.png" style="width:9.94em"/> </p></p>
<p>方差如下:<p> <img alt="$$ Var(X)=\frac{1}{n}\left(\sum \limits_{i=1}^n{\left({x}_i-\overline{x}\right)}^2\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equfy.png" style="width:11.61em"/> </p></p>
<p class="Para" id="Par385">偏度就是样本偏度。</p>
<p class="Para" id="Par386">超额峰度是样本超额峰度。</p>
<p>NM Dev 类<code>EmpiricalDistribution</code>计算数据集的经验分布。这里有一个例子:</p>
<pre>// the data set
double[] X = new double[]{0, 1, 2, 3, 4, 5, 6, 7, 8, 99};
// construct the empirical distribution from the data set
EmpiricalDistribution dist = new EmpiricalDistribution(X);

System.out.println("mean = " + dist.mean());
System.out.println("variance = " + dist.variance());
System.out.println("skew = " + dist.skew());
System.out.println("kurtosis = " + dist.kurtosis());

double[] xs = new double[]{
    0, 0.0001, 0.001, 0.01, 0.1, 1, 2, 3};
for (double x : xs) {
    System.out.println(String.format("F(%f) = %f", x, dist.cdf(x)));
}
for (double x : xs) {
    System.out.println(String.format("f(%f) = %f", x, dist.density(x)));
}

boolean allEquals = true;
for (double u = 0.1; u &lt; 1d; u += 0.1) {
    double x = dist.quantile(u);
    double y = dist.cdf(x);
    if (abs(u - y) &gt; 1e-9) {
        allEquals = false;
    }
}
System.out.println("F(Q(u)) = u for all u = " + allEquals);

</pre>
<p>输出如下所示:</p>
<pre>mean = 13.5
variance = 909.1666666666666
skew = 2.2456049365721427
kurtosis = 3.478017579042259
F(0.000000) = 0.100000
F(0.000100) = 0.100000
F(0.001000) = 0.100000
F(0.010000) = 0.100000
F(0.100000) = 0.100000
F(1.000000) = 0.200000
F(2.000000) = 0.300000
F(3.000000) = 0.400000
f(0.000000) = 0.100000
f(0.000100) = 0.000000
f(0.001000) = 0.000000
f(0.010000) = 0.000000
f(0.100000) = 0.000000
f(1.000000) = 0.100000
f(2.000000) = 0.100000
f(3.000000) = 0.100000
F(Q(u)) = u for all u = true

</pre>


<h2 class="Heading">12.4 多元概率分布</h2>
<p class="Para" id="Par389">给定定义在概率空间上的多个随机变量{ <em class="EmphasisTypeItalic "> X </em> <sub> 1 </sub>、<em class="EmphasisTypeItalic "> X </em> <sub> <em class="EmphasisTypeItalic "> n </em> </sub> }，它们的联合概率分布是给出每个<em class="EmphasisTypeItalic "> X </em> <sub> <em class="EmphasisTypeItalic "> i </em> </sub>落在为该变量指定的任何特定范围或离散值集中的概率的概率分布， p(<em class="EmphasisTypeItalic ">x</em><sub>1</sub>∈<em class="EmphasisTypeItalic ">x</em><sub>1</sub>、⋯、<em class="EmphasisTypeItalic ">x</em><sub><em class="EmphasisTypeItalic ">n</em></sub>∈<em class="EmphasisTypeItalic ">x</em><sub>n</sub>)。 在只有两个离散随机变量<em class="EmphasisTypeItalic "> X </em>和<em class="EmphasisTypeItalic "> Y </em>的情况下，是<em class="EmphasisTypeItalic ">X</em>=<em class="EmphasisTypeItalic ">X</em><sub>1</sub>取某一值和<em class="EmphasisTypeItalic ">Y</em>=<em class="EmphasisTypeItalic ">Y</em><sub>1</sub>同时取某一值的概率。这被称为二元分布，但是这个概念可以推广到任意数量的随机变量和连续变量，给出多元概率分布。</p>
<p class="Para" id="Par390">联合概率分布可以用联合累积分布函数或联合概率密度函数(对于连续变量)或联合概率质量函数(对于离散变量，见第 12.3.3.4 节)来表示。</p>
<p class="Para" id="Par391">这些反过来可以用来寻找其他两种类型的分布。边际分布给出了特定范围内任何一个变量的概率，而其他变量可以取任何值。条件概率分布给出了变量的任何子集的概率，条件是其他变量取特定值。</p>
<p>例如，假设两个瓮中的红色球是蓝色球的两倍。还假设从每个瓮中随机选择一个球，两次抽奖相互独立。设<em class="EmphasisTypeItalic "> A </em>和<em class="EmphasisTypeItalic "> B </em>分别是与从第一瓮和第二瓮中抽取的结果相关联的离散随机变量。从任何一个骨灰盒中抽出红球的概率是 2/3，抽出蓝球的概率是 1/3。联合概率分布如下表所示:</p>
<table style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; border-left: 0.5pt solid ; border-right: 0.5pt solid ; "><colgroup><col class="tcol1 align-left"/>
<col class="tcol2 align-left"/>
<col class="tcol3 align-left"/>
<col class="tcol4 align-left"/>
</colgroup>
<thead><tr><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; text-align: left;"> </th>
<th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">A =红色</p>
</th>
<th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">A =蓝色</p>
</th>
<th style="border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">边际利润</p>
</th>
</tr>
</thead>
<tbody><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">B =红色</p>
</td>
<td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">(2/3) (2/3)=4/9</p>
</td>
<td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">(1/3) (2/3)=2/9</p>
</td>
<td style="border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">4/9+2/9=2/3</p>
</td>
</tr>
<tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">B =蓝色</p>
</td>
<td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">(2/3) (1/3)=2/9</p>
</td>
<td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">(1/3) (1/3)=1/9</p>
</td>
<td style="border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">2/9+1/9=1/3</p>
</td>
</tr>
<tr><td style="border-right: 0.5pt solid ; text-align: left;"><p class="SimplePara">边际利润</p>
</td>
<td style="border-right: 0.5pt solid ; text-align: left;"><p class="SimplePara">4/9+2/9=2/3</p>
</td>
<td style="border-right: 0.5pt solid ; text-align: left;"><p class="SimplePara">2/9+1/9=1/3</p>
</td>
<td style="text-align: left;"> </td>
</tr>
</tbody>
</table>

<p class="Para" id="Par393">四个内部单元格中的每一个都显示了两次抽奖结果的特定组合的概率。联合概率分布由这些概率组成。在任何一个单元格中，特定组合发生的概率是(因为抽奖是独立的)A<em class="EmphasisTypeItalic ">的指定结果的概率和 B<em class="EmphasisTypeItalic ">的指定结果的概率的乘积。这四个单元格中的概率总和为 1，因为概率分布总是如此。</em></em></p>
<p class="Para" id="Par394">此外，最后一行和最后一列分别给出了<em class="EmphasisTypeItalic "> A </em>的边际概率分布和<em class="EmphasisTypeItalic "> B </em>的边际概率分布。例如，对于<em class="EmphasisTypeItalic "> A </em>，这些单元格中的第一个给出了<em class="EmphasisTypeItalic "> A </em>为红色的概率之和，而不管<em class="EmphasisTypeItalic "> B </em>取什么值，为 2/3。因此，<em class="EmphasisTypeItalic "> A </em>的边际概率分布在表格的边缘给出了<em class="EmphasisTypeItalic "> A </em>在<em class="EmphasisTypeItalic "> B </em>上的无条件概率。同样，B<em class="EmphasisTypeItalic ">为蓝色的边际概率分布在 a 的所有值上是 1/3。</em></p>
<p>数学上，对于<em class="EmphasisTypeItalic "> n </em>随机变量{<em class="EmphasisTypeItalic ">x</em>T4】1、<em class="EmphasisTypeItalic "> X </em> <sub> <em class="EmphasisTypeItalic "> n </em> </sub> }作为随机向量<em><strong class="EmphasisTypeBoldItalic ">×t15】=(<em class="EmphasisTypeItalic ">x</em><sub>1</sub>、<em class="EmphasisTypeItalic ">x</em><sub><em class="EmphasisTypeItalic ">n</em></sub>)<sup><em class="EmphasisTypeItalic ">t</em></sup></strong></em></p>
<p>在两个随机变量<em class="EmphasisTypeItalic "> X </em>和<em class="EmphasisTypeItalic "> Y </em>的情况下，联合 CDF 简化为:<p> <img alt="$$ {F}_{X,Y}\left(x,y\right)=\mathrm{P}\left(X\le x,Y\le y\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equga.png" style="width:12.68em"/> </p></p>
<p class="Para" id="Par397">右边表示随机变量<em class="EmphasisTypeItalic "> X </em>取值小于或等于<em class="EmphasisTypeItalic "> x </em>以及<em class="EmphasisTypeItalic "> Y </em>取值小于或等于<em class="EmphasisTypeItalic "> y </em>的概率。</p>
<p>连续随机变量的联合概率密度函数定义为联合 CDF 对所有变量各一次的偏导数，如下:<p> <img alt="$$ {f}_{\boldsymbol{X}}\left(\boldsymbol{x}\right)=\frac{\partial^n{F}_{\boldsymbol{X}}\left(\boldsymbol{x}\right)}{\partial {x}_1\dots \partial {x}_n} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equgb.png" style="width:8.7em"/> </p></p>
<p>在两个随机变量<em class="EmphasisTypeItalic "> X </em>和<em class="EmphasisTypeItalic "> Y </em>的情况下，联合 PDF 简化为:<p> <img alt="$$ {f}_{X,Y}\left(x,y\right)=\frac{\partial^2{F}_{X,Y}\left(x,y\right)}{\partial x\partial y} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equgc.png" style="width:10.83em"/> </p></p>
<p>这等于下面:<p> <img alt="$$ {f}_{X,Y}\left(x,y\right)={f}_{Y\mid X}\left(y\ |\ x\right){f}_X(x)={f}_{X\mid Y}\left(x\ |\ y\right){f}_Y(y) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equgd.png" style="width:20.12em"/> </p></p>
<p class="Para" id="Par401"><em class="EmphasisTypeItalic ">f</em><sub><em class="EmphasisTypeItalic ">y</em>∣<em class="EmphasisTypeItalic ">x</em></sub>(<em class="EmphasisTypeItalic ">y</em>|<em class="EmphasisTypeItalic ">x</em>)是<em class="EmphasisTypeItalic "> Y </em>给定<em class="EmphasisTypeItalic "> X </em>的条件 PDF。<em class="EmphasisTypeItalic ">f</em><sub><em class="EmphasisTypeItalic ">X</em></sub>(<em class="EmphasisTypeItalic ">X</em>)是<em class="EmphasisTypeItalic "> X </em>的边际 PDF。<em class="EmphasisTypeItalic ">f</em><sub><em class="EmphasisTypeItalic ">x</em>∣<em class="EmphasisTypeItalic ">y</em></sub>(<em class="EmphasisTypeItalic ">x</em>|<em class="EmphasisTypeItalic ">y</em>)是<em class="EmphasisTypeItalic "> X </em>给定<em class="EmphasisTypeItalic "> Y </em>的条件 PDF。<em class="EmphasisTypeItalic ">f</em><sub><em class="EmphasisTypeItalic ">Y</em></sub>(<em class="EmphasisTypeItalic ">Y</em>)是<em class="EmphasisTypeItalic "> Y </em>的边际 PDF。</p>
<p>区分<em class="EmphasisTypeItalic "> X </em>和<em class="EmphasisTypeItalic "> Y </em>的联合概率分布(多元分布)和每个变量单独的概率分布(单变量分布)是很重要的。随机变量的个体概率分布称为其边际概率分布。一般情况下，<em class="EmphasisTypeItalic "> X </em>的边际概率分布可以由<em class="EmphasisTypeItalic "> X </em>等随机变量的联合概率分布来确定。例如，如果随机变量<em class="EmphasisTypeItalic "> X </em>和<em class="EmphasisTypeItalic "> Y </em>的联合概率密度函数为<em class="EmphasisTypeItalic "> f </em> <sub> <em class="EmphasisTypeItalic "> X </em>，<em class="EmphasisTypeItalic "> Y </em> </sub> ( <em class="EmphasisTypeItalic "> x </em>，<em class="EmphasisTypeItalic "> y </em>)，定义边际分布的<em class="EmphasisTypeItalic "> X </em>和<em class="EmphasisTypeItalic "> Y </em>的边际概率密度函数由下式给出:【T28</p>
<p class="Para" id="Par403">第一次积分是对特定的<em class="EmphasisTypeItalic "> X </em> = <em class="EmphasisTypeItalic "> x </em>范围(<em class="EmphasisTypeItalic "> X </em>，<em class="EmphasisTypeItalic "> Y </em>)内的所有点的积分，对所有的<em class="EmphasisTypeItalic "> y </em>求和。第二次积分是对(<em class="EmphasisTypeItalic "> X </em>，<em class="EmphasisTypeItalic "> Y </em>)范围内所有点的积分，其中<em class="EmphasisTypeItalic "> Y </em> = <em class="EmphasisTypeItalic "> y </em>对所有<em class="EmphasisTypeItalic "> x </em>求和。</p>
<p>例如，图<a href="#Fig42"> 12-42 </a>显示了从二元正态分布中抽取的随机样本(黑点)。边缘概率密度函数也被显示。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig42_HTML.png" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig42_HTML.png" style="width:17.72em"/></p>
<p>图 12-42</p><p class="SimplePara">二元正态分布的随机样本</p>


<p>在 NM Dev 中，单变量概率函数的实现继承自<code>MultivariateProbabilityDistribution</code>接口。这种实现不仅指定了 CDF 和 PDF，还指定了描述性统计，例如分布的平均值和方差，以及其他信息。签名如下:</p>
<pre>public interface MultivariateProbabilityDistribution {

    /**
     * Gets the cumulative probability &lt;i&gt;F(x) = Pr(X &amp;le; x)&lt;/i&gt;.
     *
     * @param x &lt;i&gt;x&lt;/i&gt;
     * @return &lt;i&gt;F(x) = Pr(X &amp;le; x)&lt;/i&gt;
     */
    public double cdf(Vector x);

    /**
     * The density function, which, if exists, is the derivative of &lt;i&gt;F&lt;/i&gt;. It
     * describes the density of probability at each point in the sample space.
     * &lt;blockquote&gt;&lt;i&gt;
     * f(x) = dF(X) / dx
     * &lt;/i&gt;&lt;/blockquote&gt;
     * &lt;em&gt;This may not always exist.&lt;/em&gt;
     * &lt;p/&gt;
     * For the discrete cases, this is the probability mass function. It gives
     * the probability that a discrete random variable is exactly equal to some
     * value.
     *
     * @param x &lt;i&gt;x&lt;/i&gt;
     * @return &lt;i&gt;f(x)&lt;/i&gt;
     */
    public double density(Vector x);

    /**
     * Gets the mean of this distribution.
     *
     * @return the mean
     */
    public Vector mean();

    /**
     * Gets the mode of this distribution.
     *
     * @return the mean
     */
    public Vector mode();

    /**
     * Gets the covariance matrix of this distribution.
     *
     * @return the covariance
     */
    public Matrix covariance();

    /**
     * Gets the entropy of this distribution.
     *
     * @return the entropy
     * @see
     * &lt;a href="http://en.wikipedia.org/wiki/Information_entropy"&gt;Wikipedia:
     * Entropy
     * (information theory)&lt;/a&gt;
     */
    public double entropy();

    /**
     * The moment generating function is the expected value of
     * &lt;i&gt;e&lt;sup&gt;tX&lt;/sup&gt;&lt;/i&gt;. That is,
     * &lt;blockquote&gt;&lt;i&gt;
     * E(e&lt;sup&gt;tX&lt;/sup&gt;)
     * &lt;/i&gt;&lt;/blockquote&gt;
     * &lt;em&gt;This may not always exist.&lt;/em&gt;
     *
     * @param t &lt;i&gt;t&lt;/i&gt;
     * @return &lt;i&gt;E(exp(tX))&lt;/i&gt;
     * @see
     * &lt;a href="http://en.wikipedia.org/wiki/Moment_generating_function"&gt;Wikipedia:
     * Moment-generating function&lt;/a&gt;
     */
    public double moment(Vector t);
}

</pre>
<p class="Para" id="Par406">请注意，对于多元分布，可能不支持某些成员函数。</p>
<h3 class="Heading">多元正态分布</h3>
<p class="Para" id="Par407">多元正态分布、多元高斯分布或联合正态分布是一维(单变量)正态分布向更高维度的推广。它通常用于描述(至少是近似地)任何一组(可能)相关的实值随机变量，每个变量都聚集在一个平均值周围。</p>
<p class="Para" id="Par408">一个<em class="EmphasisTypeItalic ">k</em>-维随机向量<em><strong class="EmphasisTypeBoldItalic ">x</strong></em>=(<em class="EmphasisTypeItalic ">x</em><sub>1</sub>，⋯，<em class="EmphasisTypeItalic ">x</em><sub><em class="EmphasisTypeItalic ">k</em></sub>)<sup><em class="EmphasisTypeItalic ">t</em></sup>称为标准正态随机向量，如果它的所有分量都是均值和单位方差为零的独立标准正态。即<em class="EmphasisTypeItalic ">X</em><sub><em class="EmphasisTypeItalic ">I</em></sub>~<em class="EmphasisTypeItalic ">N</em>(0，1)为所有<em class="EmphasisTypeItalic "> i </em>。</p>
<p>a<em class="EmphasisTypeItalic ">k</em>-维随机向量<em><strong class="EmphasisTypeBoldItalic ">x</strong></em>=(<em class="EmphasisTypeItalic ">x</em><sub>1</sub>，<em class="EmphasisTypeItalic ">x</em><sub><em class="EmphasisTypeItalic ">k</em></sub>)<sup><em class="EmphasisTypeItalic ">t</em></sup>具有多元正态分布，记为<em><strong class="EmphasisTypeBoldItalic ">x</strong></em>~<em class="EmphasisTypeItalic ">n</em>(<em><strong class="EmphasisTypeBoldItalic ">μ<strong class="EmphasisTypeBoldItalic "> 当且仅当存在一个标准正态随机向量<em><strong class="EmphasisTypeBoldItalic ">z∈</strong></em><em class="EmphasisTypeItalic ">ℝ</em><sup><em class="EmphasisTypeItalic ">l</em></sup>一个向量<em><strong class="EmphasisTypeBoldItalic ">μ∈</strong></em><em class="EmphasisTypeItalic ">ℝ</em><sup><em class="EmphasisTypeItalic ">k</em></sup>和一个矩阵<strong class="EmphasisTypeBoldItalic ">a</strong></strong></strong></em>∈<em class="EmphasisTypeItalic ">ℝ<em class="EmphasisTypeItalic "/></em></p>
<p class="Para" id="Par410">矩阵<strong class="EmphasisTypeBold ">σ=</strong><em><strong class="EmphasisTypeBoldItalic ">AA</strong></em><sup><em class="EmphasisTypeItalic ">T</em></sup>是随机变量{<em class="EmphasisTypeItalic ">X</em><sub><em class="EmphasisTypeItalic ">I</em></sub>}的协方差矩阵。</p>
<p class="Para" id="Par411">可以证明，如果<em><strong class="EmphasisTypeBoldItalic ">X</strong></em>~<em class="EmphasisTypeItalic ">N</em>(<em><strong class="EmphasisTypeBoldItalic ">μ</strong></em>，<strong class="EmphasisTypeBold ">σ</strong>)，那么其分量的每一个线性组合，<em class="EmphasisTypeItalic ">Y</em>=<em class="EmphasisTypeItalic ">a</em><sub>1</sub><em class="EmphasisTypeItalic ">X</em><sub>1</sub>+…+<em class="EmphasisTypeItalic ">a</em><sub><em class="EmphasisTypeItalic ">k</em></sub>即对于任意常数向量<em><strong class="EmphasisTypeBoldItalic ">a∈</strong></em><em class="EmphasisTypeItalic ">ℝ</em><sup><em class="EmphasisTypeItalic ">k</em></sup>随机变量<em class="EmphasisTypeItalic ">y</em>=<em><strong class="EmphasisTypeBoldItalic ">a</strong></em><sup><em class="EmphasisTypeItalic ">t</em></sup><em>x</em>具有一元正态分布。</p>
<p>给定均值<em><strong class="EmphasisTypeBoldItalic "/></em>和正定协方差矩阵<strong class="EmphasisTypeBold ">【σ】</strong>，多元正态分布的概率密度函数如下:<p> <img alt="$$ {f}_{\boldsymbol{X}}\left(\boldsymbol{x}\right)=\frac{1}{\sqrt{{\left(2\pi \right)}^k\left|\boldsymbol{\Sigma} \right|}}\exp \left(-\frac{1}{2}{\left(\boldsymbol{x}-\boldsymbol{\mu} \right)}^T{\boldsymbol{\Sigma}}^{-1}\left(\boldsymbol{x}-\boldsymbol{\mu} \right)\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equgh.png" style="width:21.24em"/> </p></p>
<p class="Para" id="Par413">如果<strong class="EmphasisTypeBold ">σ</strong>是 1 × 1 矩阵(即单个实数)，则之前的等式简化为单变量正态分布的等式。</p>
<p>在两个随机变量<em class="EmphasisTypeItalic "> X </em>和<em class="EmphasisTypeItalic "> Y </em>的情况下，一个向量[<em class="EmphasisTypeItalic ">XY</em><sup><em class="EmphasisTypeItalic ">T</em></sup>的联合 PDF 如下:<p> <img alt="$$ f\left(x,y\right)=\frac{1}{2\pi {\sigma}_X{\sigma}_Y\sqrt{1-{\rho}^2}}\exp \left(-\frac{1}{2\left(1-{\rho}^2\right)}\left[{\left(\frac{x-{\mu}_X}{\sigma_X}\right)}^2-2\rho \left(\frac{x-{\mu}_X}{\sigma_X}\right)\left(\frac{y-{\mu}_Y}{\sigma_Y}\right)+{\left(\frac{y-{\mu}_Y}{\sigma_Y}\right)}^2\right]\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equgi.png" style="width:40.05em"/> </p></p>
<p class="Para" id="Par415">其中<em class="EmphasisTypeItalic "> ρ </em>为<em class="EmphasisTypeItalic "> X </em>与<em class="EmphasisTypeItalic "> Y </em>的相关性，其中<em class="EmphasisTypeItalic ">σ</em><sub><em class="EmphasisTypeItalic ">X</em></sub>&gt;0 与<em class="EmphasisTypeItalic ">σ</em><sub><em class="EmphasisTypeItalic ">Y</em></sub>&gt;0。就更一般的多元正态 PDF 而言，我们有:</p>
<p class="Para" id="Par416"><img alt="$$ \boldsymbol{\mu} =\left(\begin{array}{c}{\mu}_X\\ {}{\mu}_Y\end{array}\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq48.png" style="width:4.69em"/>和<img alt="$$ \boldsymbol{\Sigma} =\left(\begin{array}{cc}{\sigma}_X^2&amp;amp; \rho {\sigma}_X{\sigma}_Y\\ {}\rho {\sigma}_X{\sigma}_Y&amp;amp; {\sigma}_Y^2\end{array}\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq49.png" style="width:10.4em"/></p>
<p>例如，图<a href="#Fig43"> 12-43 </a>显示了二元正态分布的样本点，如下所示:</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig43_HTML.png" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig43_HTML.png" style="width:22.35em"/></p>
<p>图 12-43</p><p class="SimplePara">二元正态分布</p>


<p class="Para" id="Par418"><img alt="$$ \boldsymbol{\mu} =\left(\begin{array}{c}0\\ {}0\end{array}\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq50.png" style="width:4.11em"/>和<img alt="$$ \boldsymbol{\Sigma} =\left(\begin{array}{cc}1&amp;amp; 0.6\\ {}0.6&amp;amp; 1\end{array}\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq51.png" style="width:6.99em"/></p>
<p class="Para" id="Par419">还显示了两个边际分布、一维直方图和三西格马椭圆。</p>
<p>意思如下:<p> <img alt="$$ \mathrm{E}\left(\boldsymbol{X}\right)=\boldsymbol{\mu} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equgj.png" style="width:4.48em"/> </p></p>
<p>方差如下:<p> <img alt="$$ Var\left(\boldsymbol{X}\right)=\boldsymbol{\Sigma} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equgk.png" style="width:5.64em"/> </p></p>
<p>力矩生成函数如下:<p> <img alt="$$ {M}_X(t)=\exp \left({\boldsymbol{\mu}}^T\boldsymbol{t}+\frac{1}{2}{\boldsymbol{t}}^T\boldsymbol{\Sigma} \mathbf{t}\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equgl.png" style="width:12.06em"/> </p></p>
<p>NM Dev 类<code>MultivariateNormalDistribution</code>实现多元正态分布。这里有一个例子:</p>
<pre>System.out.println("construct a 3-dimensional multivariate standard normal distribution");
MultivariateProbabilityDistribution mvnorm1
        = new MultivariateNormalDistribution(
                3 // dimension
        );
System.out.println("mean = " + mvnorm1.mean());
System.out.println("variance = " + mvnorm1.covariance());

Vector x1 = new DenseVector(0.0, 0.0, 0.0);
System.out.println(String.format("f(%s) = %f", x1, mvnorm1.density(x1)));
x1 = new DenseVector(1.0, 0.0, 0.0);
System.out.println(String.format("f(%s) = %f", x1, mvnorm1.density(x1)));
x1 = new DenseVector(0.0, 0.5, 0.0);
System.out.println(String.format("f(%s) = %f", x1, mvnorm1.density(x1)));
x1 = new DenseVector(0.0, 0.0, 0.3);
System.out.println(String.format("f(%s) = %f", x1, mvnorm1.density(x1)));
x1 = new DenseVector(1.0, 0.5, 0.0);
System.out.println(String.format("f(%s) = %f", x1, mvnorm1.density(x1)));
x1 = new DenseVector(0.0, 0.5, 0.3);
System.out.println(String.format("f(%s) = %f", x1, mvnorm1.density(x1)));
x1 = new DenseVector(1.0, 0.0, 0.3);
System.out.println(String.format("f(%s) = %f", x1, mvnorm1.density(x1)));
x1 = new DenseVector(1.0, 0.5, 0.3);
System.out.println(String.format("f(%s) = %f", x1, mvnorm1.density(x1)));

System.out.println("construct a 2-dimensional multivariate normal distribution");
DenseVector mu = new DenseVector(1.0, 2.0);
DenseMatrix sigma = new DenseMatrix(new double[][]{{4.0, 2.0}, {2.0, 3.0}});
MultivariateProbabilityDistribution mvnorm2
        = new MultivariateNormalDistribution(mu, sigma);
System.out.println("mean = " + mvnorm2.mean()); // same as mu
System.out.println("variance = " + mvnorm2.covariance()); // same as sigma
Vector x2 = new DenseVector(0.3, 0.4);
System.out.println(String.format("f(%s) = %f", x2, mvnorm2.density(x2)));
x2 = new DenseVector(0.4, 0.3);
System.out.println(String.format("f(%s) = %f", x2, mvnorm2.density(x2)));

</pre>
<p>输出如下所示:</p>
<pre>mean = [0.000000, 0.000000, 0.000000]
variance = 3x3
        [,1] [,2] [,3]
[1,] 1.000000, 0.000000, 0.000000,
[2,] 0.000000, 1.000000, 0.000000,
[3,] 0.000000, 0.000000, 1.000000,
f([0.000000, 0.000000, 0.000000] ) = 0.063494
f([1.000000, 0.000000, 0.000000] ) = 0.038511
f([0.000000, 0.500000, 0.000000] ) = 0.056033
f([0.000000, 0.000000, 0.300000] ) = 0.060700
f([1.000000, 0.500000, 0.000000] ) = 0.033986
f([0.000000, 0.500000, 0.300000] ) = 0.053567
f([1.000000, 0.000000, 0.300000] ) = 0.036816
f([1.000000, 0.500000, 0.300000] ) = 0.032490
construct a 2-dimensional multivariate normal distribution
mean = [1.000000, 2.000000]
variance = 2x2
         [,1] [,2]
[1,] 4.000000, 2.000000,
[2,] 2.000000, 3.000000,
f([0.300000, 0.400000] ) = 0.035812
f([0.400000, 0.300000] ) = 0.032955

</pre>

<h3 class="Heading">多元 t 分布</h3>
<p class="Para" id="Par425">多元 t 分布是一维(单变量)t 分布向更高维度的推广。对于一个<em class="EmphasisTypeItalic "> p </em>维 t 分布，假设<em><strong class="EmphasisTypeBoldItalic ">y</strong></em>~<em class="EmphasisTypeItalic ">N</em>(<strong class="EmphasisTypeBold ">0</strong>，<strong class="EmphasisTypeBold ">σ</strong>)是多元正态，<img alt="$$ u\sim {\chi}_{\upsilon}^2 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq52.png" style="width:3.08em"/>是<em class="EmphasisTypeItalic "> υ </em>自由度的卡方，我们有一个<em class="EmphasisTypeItalic "> p </em> × <em class="EmphasisTypeItalic "> p </em>正定标度矩阵<strong class="EmphasisTypeBold ">σ</strong>这样【T21</p>
<p>PDF 如下:<p> <img alt="$$ f\left(\boldsymbol{x}\ |\ \upsilon, \boldsymbol{\mu}, \boldsymbol{\Sigma} \right)=\frac{\Gamma \left(\frac{\upsilon +p}{2}\right)}{\Gamma \left(\frac{\upsilon }{2}\right){\upsilon}^{\frac{p}{2}}{\pi}^{\frac{p}{2}}{\left|\boldsymbol{\Sigma} \right|}^{\frac{1}{2}}}{\left[1+\frac{1}{\upsilon }{\left(\boldsymbol{x}-\boldsymbol{\mu} \right)}^T{\boldsymbol{\Sigma}}^{-1}\left(\boldsymbol{x}-\boldsymbol{\mu} \right)\right]}^{-\frac{\upsilon +p}{2}} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equgm.png" style="width:26.8em"/> </p></p>
<p class="Para" id="Par427">其含义如下:</p>
<p class="Para" id="Par428">e(<em><strong class="EmphasisTypeBoldItalic "/></em>)=<em><strong class="EmphasisTypeBoldItalic "/></em>，<em class="EmphasisTypeItalic "/>&gt;1；else undefined</p>
<p class="Para" id="Par429">差异如下:</p>
<p class="Para" id="Par430"><em class="EmphasisTypeItalic ">、<em class="EmphasisTypeItalic "/>&gt;2；else undefined</em></p>
<p class="Para" id="Par431">偏斜度为 0。</p>
<p>NM Dev 类<code>MultivariateTDistribution</code>实现多元 t 分布。这里有一个例子:</p>
<pre>int p = 2; // dimension
Vector mu = new DenseVector(1., 2.); // mean
Matrix Sigma = new DenseMatrix(p, p).ONE(); // scale matrix

int v = 1; // degree of freedom
MultivariateTDistribution t
        = new MultivariateTDistribution(v, mu, Sigma);
Vector x = new DenseVector(1.23, 4.56);
System.out.println(String.format("f(%s) = %f", x, t.density(x)));

v = 2;
t = new MultivariateTDistribution(v, mu, Sigma);
x = new DenseVector(1.23, 4.56);
System.out.println(String.format("f(%s) = %f", x, t.density(x)));

v = 3;
t = new MultivariateTDistribution(v, mu, Sigma);
x = new DenseVector(1.23, 4.56);
System.out.println(String.format("f(%s) = %f", x, t.density(x)));

v = 4;
t = new MultivariateTDistribution(v, mu, Sigma);
x = new DenseVector(1.23, 4.56);
System.out.println(String.format("f(%s) = %f", x, t.density(x)));

v = 5;
t = new MultivariateTDistribution(v, mu, Sigma);
x = new DenseVector(1.23, 4.56);
System.out.println(String.format("f(%s) = %f", x, t.density(x)));

v = 6;
t = new MultivariateTDistribution(v, mu, Sigma);
x = new DenseVector(1.23, 4.56);
System.out.println(String.format("f(%s) = %f", x, t.density(x)));

</pre>
<p>输出如下所示:</p>
<pre>f([1.230000, 4.560000] ) = 0.007587
f([1.230000, 4.560000] ) = 0.008595
f([1.230000, 4.560000] ) = 0.008674
f([1.230000, 4.560000] ) = 0.008537
f([1.230000, 4.560000] ) = 0.008351
f([1.230000, 4.560000] ) = 0.008167

</pre>

<h3 class="Heading">多元贝塔分布</h3>
<p class="Para" id="Par434">多元贝塔分布，通常称为狄利克雷分布，是一维(单变量)贝塔分布向更高维度的推广。它的概率密度函数返回这样的信念:假定每个事件已经被观察了<em class="EmphasisTypeItalic "> a </em> <sub> <em class="EmphasisTypeItalic "> i </em> </sub>次，则<em class="EmphasisTypeItalic "> K </em>个竞争事件的概率是<em class="EmphasisTypeItalic ">x</em><sub>T5】I</sub>。</p>
<p>参数为<em class="EmphasisTypeItalic ">a</em>T4】1，…，<em class="EmphasisTypeItalic "> a </em> <sub> <em class="EmphasisTypeItalic "> K </em> </sub>的阶数为<em class="EmphasisTypeItalic "> K </em> ≥ 2 的狄利克雷分布有一个概率密度函数，如下图:<p> <img alt="$$ f\left({x}_1,\dots |{x}_K,\ {a}_1,\dots, {a}_K\right)=\frac{1}{B\left(\boldsymbol{a}\right)}\prod \limits_{i=1}^K{x_i}^{a_i-1} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equgn.png" style="width:18.5em"/> </p></p>
<p class="Para" id="Par436">其中<img alt="$$ \sum \limits_{i=1}^K{x}_i=1 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq55.png" style="width:4.06em"/>和<em class="EmphasisTypeItalic "> x </em> <sub> <em class="EmphasisTypeItalic "> i </em> </sub> ≥ 0 为所有<em class="EmphasisTypeItalic "> i </em>。</p>
<p>归一化常数是多元 beta 函数，可以用 gamma 函数来表示，如下:<p> <img alt="$$ B\left(\boldsymbol{a}\right)=\frac{\prod \limits_{i=1}^K\Gamma \left({a}_i\right)}{\Gamma \left(\sum \limits_{i=1}^K{a}_i\right)} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equgo.png" style="width:7.46em"/> </p></p>
<p>图<a href="#Fig44"> 12-44 </a>显示了一个例子。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig44_HTML.jpg" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig44_HTML.jpg" style="width:42.82em"/></p>
<p>图 12-44</p><p class="SimplePara">狄利克雷分布的概率密度函数</p>


<p>NM Dev 类<code>DirichletDistribution</code>实现了 Dirichlet 分布。这里有一个例子:</p>
<pre>// the parameters
double[] a = new double[]{1, 2, 3, 4, 5};
DirichletDistribution dist = new DirichletDistribution(a);
Vector x = new DenseVector(0.1, 0.2, 0.3, 0.2, 0.2);
System.out.println(String.format("f(%s) = %f", x, dist.density(x)));

</pre>
<p>输出如下所示:</p>
<pre>f([0.100000, 0.200000, 0.300000, 0.200000, 0.200000] ) = 69.742633

</pre>

<h3 class="Heading">多项式分布</h3>
<p class="Para" id="Par441">多项式分布是二项式分布向更高维度的推广。二项式分布给出了一系列二元结果实验中成功(和失败)次数的概率，而多项式分布给出了每一次<em class="EmphasisTypeItalic "> k </em>面骰子滚动<em class="EmphasisTypeItalic "> n </em>次的计数概率。换句话说，对于<em class="EmphasisTypeItalic "> n </em>个独立试验，其中每个试验导致<em class="EmphasisTypeItalic "> k </em>个类别中恰好一个类别的成功，每个类别具有给定的固定成功概率，多项式分布给出了各种类别的成功数量的任何特定组合的概率。当<em class="EmphasisTypeItalic "> k </em>为 2 而<em class="EmphasisTypeItalic "> n </em>为 1 时，多项式分布就是伯努利分布。当<em class="EmphasisTypeItalic "> k </em>为 2 而<em class="EmphasisTypeItalic "> n </em>大于 1 时，为二项分布。当<em class="EmphasisTypeItalic "> k </em>大于 2 且<em class="EmphasisTypeItalic "> n </em>为 1 时，为分类分布。</p>
<p class="Para" id="Par442">数学上，我们有<em class="EmphasisTypeItalic "> k </em>个可能互斥的结果，对应概率<em class="EmphasisTypeItalic "> p </em> <sub> 1 </sub>，…，<em class="EmphasisTypeItalic "> p </em> <sub> <em class="EmphasisTypeItalic "> k </em> </sub>和<em class="EmphasisTypeItalic "> n </em>个独立试验。由于<em class="EmphasisTypeItalic "> k </em>的结果是互斥的，并且其中一个必须发生，所以对于<em class="EmphasisTypeItalic "> i </em> = 1，…，<em class="EmphasisTypeItalic "> k </em>和<img alt="$$ \sum \limits_{i=1}^k{p}_i=1 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq56.png" style="width:4.16em"/>，我们有<em class="EmphasisTypeItalic ">p</em><sub><em class="EmphasisTypeItalic ">I</em></sub>≥0。</p>
<p class="Para" id="Par443">如果随机变量{ <em class="EmphasisTypeItalic "> X </em> <sub> <em class="EmphasisTypeItalic "> i </em> </sub> }表示在<em class="EmphasisTypeItalic "> n </em>次试验中观察到第<em class="EmphasisTypeItalic "> i </em>次结果的次数，则随机向量<em class="EmphasisTypeItalic ">X</em>=(<em class="EmphasisTypeItalic ">X</em><sub>1</sub>，…，<em class="EmphasisTypeItalic ">X</em><sub><em class="EmphasisTypeItalic ">k</em></sub>)<sup><em class="EmphasisTypeItalic ">T</em>虽然试验是独立的，但是它们的结果<em class="EmphasisTypeItalic "> X </em>是相关的，因为它们必须被加起来<em class="EmphasisTypeItalic "> n </em>，<img alt="$$ \sum \limits_{i=1}^k{x}_i=n $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq57.png" style="width:4.06em"/>。</sup></p>
<p>多项式分布是一种离散的概率分布。概率质量函数描述了同时发生的<em class="EmphasisTypeItalic "> k </em>个事件的联合概率。【T2<img alt="$$ {p}_{X_1,\dots, {X}_k}\left({x}_1,\dots, {x}_k\right)=\mathrm{P}\left({X}_1={x}_1\wedge \dots \wedge {X}_k={x}_k\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equgp.png" style="width:21.29em"/></p>
<p>所有结果的总和等于 1。<p><img alt="$$ \sum \limits_i\sum \limits_j\dots \sum \limits_n\mathrm{P}\left({X}_1={x}_{1i},\dots, {X}_k={x}_{kn}\right)=1 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equgq.png" style="width:19.08em"/>T2】</p></p>
<p>这种多项分布的概率质量函数给出了从一个袋子中挑选<em class="EmphasisTypeItalic "> k </em>种不同颜色的<em class="EmphasisTypeItalic "> n </em>个球的概率，在每次抽取后替换被抽取的球。相同颜色的球是等价的。<img alt="$$ f\left({x}_1,\dots |{x}_k,\ n,{p}_1,\dots, {p}_k\right)=\mathrm{P}\left({X}_1={x}_1,\dots, {X}_k={x}_k\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equgr.png" style="width:23.14em"/>  <p> <img alt="$$ =\frac{n!}{x_1!\dots {x}_k!}{p}_1^{x_1}\times \dots \times {p}_k^{x_k} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equgs.png" style="width:11.64em"/> </p></p>
<p>意思如下:<p> <img alt="$$ \mathrm{E}\left({X}_i\right)=n{p}_i $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equgt.png" style="width:5.4em"/> </p></p>
<p>方差和协方差如下:<p> <img alt="$$ Var\left({X}_i\right)=n{p}_i\left(1-{p}_i\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equgu.png" style="width:9.92em"/> </p> <p> <img alt="$$ Cov\left({X}_i,{X}_j\right)=-n{p}_i{p}_j,i\ne j $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equgv.png" style="width:12.16em"/> </p></p>
<p>力矩生成函数如下:<p> <img alt="$$ {M}_X(t)={\left(\sum \limits_{i=1}^k{p}_i{e}^{t_i}\right)}^n $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equgw.png" style="width:8.7em"/> </p></p>
<p>假设我们将 100 个球扔进 3 个箱子，每个箱子的成功概率分别为 0.1、0.2 和 0.7。每个箱中有 10、20 和 70 的概率是 0.013279。见图<a href="#Fig45"> 12-45 </a>。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig45_HTML.png" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig45_HTML.png" style="width:43.02em"/></p>
<p>图 12-45</p><p class="SimplePara">多项式分布，<em> <strong class="EmphasisTypeBoldItalic "> k </strong> </em> = <strong class="EmphasisTypeBold "> 3 </strong>，<em> <strong class="EmphasisTypeBoldItalic "> n </strong> </em> = <strong class="EmphasisTypeBold "> 100 </strong></p>


<p>NM Dev 类<code>MultinomialDistribution</code>实现了多项式分布。下面的代码实现了前面的示例:</p>
<pre>// k = 3, each of the 3 probabilities of success
double[] prob = new double[]{0.1, 0.2, 0.7};
int n = 100;
MultinomialDistribution dist
        = new MultinomialDistribution(n, prob);

// an outcome of the n trials
Vector x = new DenseVector(new double[]{10, 20, 70});
System.out.println(String.format("f(%s) = %f", x, dist.density(x)));

</pre>
<p>输出如下所示:</p>
<pre>f([10.000000, 20.000000, 70.000000] ) = 0.013279

</pre>


<h2 class="Heading">12.5 假设检验</h2>
<p>统计假设检验是一种统计推断方法。假设检验用于评估样本数据是否支持我们称之为假设的数据解释。一个假设是布尔型的，要么是，要么不是。例如，我们可能要测试以下内容:</p>
<ul class="UnorderedListMarkBullet"><li><p class="Para" id="Par454">数据呈正态分布。</p></li>
<li><p class="Para" id="Par455">关于总体参数的假设是正确的。</p></li>
<li><p class="Para" id="Par456">两个样本取自相同的潜在人口分布。</p></li>
</ul>

<p class="Para" id="Par457">假设检验背后的想法是评估，假设(零)假设是真的，我们观察数据的可能性有多大。如果这种可能性很低，我们说结果在统计学上足够显著，足以“拒绝零假设”否则，我们“无法拒绝零假设。”统计推断提供了另一种“证明”某事的方法。我们可能无法用演绎逻辑从一组公理一步步证明上帝的存在，直到得出结论。我们可以从统计学上证明上帝的存在。至少，我们不能拒绝上帝存在的虚假假设。</p>
<p class="Para" id="Par458">通过假设检验并不意味着零假设为真。这只意味着没有足够的证据表明它可能是错误的。这些结果在统计学上并不显著。事实上，有两种类型的推断错误，我们可以使用假设检验。第一类错误是当零假设确实是真的，但我们拒绝了它。这也被称为假阳性。如果我们的观察是极端的(不太可能，但还是发生了)，那就是这种情况。第二类错误是当零假设是错误的，但我们无法拒绝它。这也被称为假阴性。比如一种药是无效的，但是我们根据数据认为是可以的。</p>
<p>再举一个例子，假设我们怀疑一个硬币是有偏向的，在旋转的时候，正面着地的机会少于 50%。为了验证这个猜想，我们做了一个实验，将硬币旋转 100 次，得到 37 个正面和 63 个反面。观察到的人头比例为<img alt="$$ \frac{37}{100}=37\ \mathrm{percent} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq58.png" style="width:7.3em"/>。我们对这些数据有两种可能的解释。</p>
<ul class="UnorderedListMarkBullet"><li><p class="Para" id="Par460">零假设(<em class="EmphasisTypeItalic "> H </em> <sub> 0 </sub>):数据仅仅是随机变化的反映。旋转硬币时正面朝上的概率真的是<em class="EmphasisTypeItalic "> p </em> = 0.5。</p></li>
<li><p class="Para" id="Par461">备选假设(<em class="EmphasisTypeItalic "> H </em> <sub> 1 </sub>)如下:硬币旋转时正面朝上的概率真的是<em class="EmphasisTypeItalic "> p </em> &lt; 0.5。</p></li>
</ul>

<p class="Para" id="Par462">注意，零假设和备择假设必须是互斥的。如果我们不能拒绝零假设，我们将接受替代解释数据。</p>
<p>让我们来回答这个问题“零假设是否支持对数据的合理解释？”首先，我们需要设计一个测试统计量来衡量假设零假设为真时数据和预期值之间的差异。在我们的例子中，如果零假设为真，人头的数量(以及人头的比例)具有二项式分布，其中<em class="EmphasisTypeItalic "> p </em> = 0.5 和<em class="EmphasisTypeItalic "> υ </em> = 100。这个分布的标准差等于 0.05。可以使用以下代码来计算:</p>
<pre>int n = 100;
BinomialDistribution dist2 = new BinomialDistribution(
        n,
        0.5 // p
);
double stdev = sqrt(dist2.variance()) / n;
System.out.println("standard deviation = " + stdev);

</pre>
<p>输出如下所示:</p>
<pre>standard deviation = 0.05

</pre>
<p>因此，观察比例(37%)和真实比例(50%)之间差异的标准化 z 值如下:<p> <img alt="$$ z=\frac{0.37-0.5}{0.05}=-2.6 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equgx.png" style="width:9.8em"/> </p></p>
<p>我们可以看到，如果零假设为真，那么这个 z 值异常地为负，位于正态分布的极端一侧。读取标准正常 CDF，z 得分为 2.6 的概率为 0.004661188023718749 (p 值)，发生概率小于 0.5%。此代码计算 z 得分和 p 值。</p>
<pre>double z_score = (0.37 - 0.5) / stdev;
System.out.println("z-score = " + z_score);
double p_value = new NormalDistribution() // default ctor for standard normal distribution
        .cdf(z_score);
System.out.println("p-value = " + p_value);

</pre>
<p>输出如下所示:</p>
<pre>z-score = -2.6
p-value = 0.004661188023718749

</pre>
<p>换句话说，如果零假设是真的，我们观察到数据的概率(37%的头部)不太可能发生。零假设不能很好地解释我们的数据。因此，我们拒绝零假设，接受替代假设。实际情况可能是，这枚硬币是一枚有偏向的硬币，旋转时正面朝上的几率不到 50%。见图<a href="#Fig46"> 12-46 </a>。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig46_HTML.jpg" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig46_HTML.jpg" style="width:22.4em"/></p>
<p>图 12-46</p><p class="SimplePara">假设检验拒绝区域</p>


<p>这个例子说明了进行假设检验的一般程序。这六个步骤如下:</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig47_HTML.png" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig47_HTML.png" style="width:8.98em"/></p>
<p>图 12-47</p><p class="SimplePara">假设检验步骤</p>


<ol><li class="ListItem"><p class="Para" id="Par470">收集数据和/或进行实验。</p>
 </li>
<li class="ListItem"><p class="Para" id="Par471">陈述原假设(<em class="EmphasisTypeItalic "> H </em> <sub> 0 </sub>)和备选假设(<em class="EmphasisTypeItalic "> H </em> <sub> 1 </sub>)。零假设本身不涉及数据。它是关于总体的参数或数字特征的陈述。我们测试该参数的有效性。替代假设是零假设的互斥否定版本。</p>
 </li>
<li class="ListItem"><p class="Para" id="Par472">设计适当的测试和测试统计量<em class="EmphasisTypeItalic "> T </em>。在零假设和假设下推导检验统计量的分布。常用的有正态分布和 t 分布。</p>
 </li>
<li class="ListItem"><p class="Para" id="Par473">选择一个显著性水平<em class="EmphasisTypeItalic "> α </em>，这是一个概率阈值，低于该阈值无效假设将被拒绝。通常的值是 5%(统计显著)和 1%(统计非常显著)。</p>
 </li>
<li class="ListItem"><p class="Para" id="Par474">根据观察值计算检验统计量<em class="EmphasisTypeItalic "> T </em>的观察值<img alt="$$ \hat{t} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq59.png" style="width:0.58em"/>。计算 p 值。这是在零假设下，抽样检验统计量至少与观察到的一样极端的概率(该事件的最大概率)。</p>
 </li>
<li class="ListItem"><p class="Para" id="Par475">当且仅当 p 值小于(或等于)显著性水平阈值<em class="EmphasisTypeItalic "> α </em>时，拒绝零假设，支持替代假设。见图<a href="#Fig47"> 12-47 </a>。</p>
 </li>
</ol>

<p>NM Dev 提供了广泛的假设检验，用于检验人口分布、检验人口参数和比较潜在的人口分布。所有假设检验实现都扩展了这个抽象类<code>HypothesisTest</code>。签名如下:</p>
<pre>public abstract class HypothesisTest {

    /**
     * Get the test statistics.
     *
     * @return the test statistics
     * @see &lt;a href="http://en.wikipedia.org/wiki/Test_statistic"&gt;Wikipedia:
     * Test statistic&lt;/a&gt;
     */
    public abstract double statistics();

    /**
     * Get the p-value for the test statistics.
     *
     * @return the p-value
     * @see &lt;a href="http://en.wikipedia.org/wiki/P-value"&gt;Wikipedia:
     * P-value&lt;/a&gt;
     */
    public abstract double pValue();

    /**
     * Get a description of the null hypothesis.
     *
     * @see &lt;a href="http://en.wikipedia.org/wiki/Null_hypothesis"&gt;Wikipedia:
     * Null hypothesis&lt;/a&gt;
     *
     * @return the null hypothesis description
     */
    public abstract String getNullHypothesis();

    /**
     * Get the description of the alternative hypothesis.
     *
     * @return the alternative hypothesis description
     * @see
     * &lt;a href="http://en.wikipedia.org/wiki/Alternative_hypothesis"&gt;Wikipedia:
     * Alternative hypothesis&lt;/a&gt;
     */
    public abstract String getAlternativeHypothesis();

    /**
     * Get the number of groups of observations.
     *
     * @return the number of groups of observations
     */
    public int nGroups() {
        return k;
    }

    /**
     * Get the total number of observations.
     *
     * @return the total number of observations
     */
    public int nObs() {
        return N;
    }




    /**
     * Use the p-value to check whether the null hypothesis can be rejected for
     * a given significance level. That is, the probability of making the
     * observations under the null is small.
     *
     * @param alpha a significance level of test
     * @return {@code true} if the hypothesis is rejected due to &lt;i&gt;p-value &lt;
     *         &amp;alpha;&lt;/i&gt;
     */
    public boolean isNullRejected(double alpha) {
        return pValue() &lt; alpha;
    }

    /**
     * The one-sided p-value is the probability of observing a test statistic
     * &lt;em&gt;at least&lt;/em&gt; as extreme as the one observed. For a continuous
     * distribution, it is given by the complementary cumulative distribution
     * function (survival function). For a discrete distribution, we need to add
     * also the probability of observing the critical value.
     *
     * @param F a univariate distribution
     * @param x the critical value
     * @return the p-value for the critical value
     */
    public static double oneSidedPvalue(ProbabilityDistribution F, double x) {
        if (F instanceof EmpiricalDistribution) {
            return 1.0 - F.cdf(x) + F.density(x);
        }

        return 1.0 - F.cdf(x);
    }
}




</pre>
<h3 class="Heading">12.5.1 分布测试</h3>
<p class="Para" id="Par477">NM Dev 支持大范围的假设检验，以评估数据样本是否来自特定的分布，例如正态分布，或者两个样本是否具有相同的基本总体分布。</p>
<h4 class="Heading">12.5.1.1 正态性检验</h4>
<p class="Para" id="Par478">有许多假设检验来评估样本是否具有正态分布。他们有不同的权力和限制，如上限样本大小。</p>
<h5 class="Heading">夏皮罗-维尔克试验</h5>
<p>正态性的最佳检验是夏皮罗-维尔克检验，其样本量最多为 5000 个数据点，并且不具有太多相同的值。夏皮罗-维尔克检验检验零假设，即样本{ <em class="EmphasisTypeItalic "> x </em> <sub> 1 </sub>，…，<em class="EmphasisTypeItalic "> x </em> <sub> <em class="EmphasisTypeItalic "> n </em> </sub> }来自正态分布总体。测试统计如下:<p> <img alt="$$ W=\frac{{\left(\sum \limits_{i=i}^n{a}_i{x}_{(i)}\right)}^2}{\sum \limits_{i=1}^n{\left({x}_i-\overline{x}\right)}^2} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equgy.png" style="width:7.47em"/> </p></p>
<p class="Para" id="Par480">其中<em class="EmphasisTypeItalic "> x </em> <sub> ( <em class="EmphasisTypeItalic "> i </em> ) </sub>(用括号括起下标索引<em class="EmphasisTypeItalic ">I</em>；不要和<em class="EmphasisTypeItalic "> x </em> <sub> <em class="EmphasisTypeItalic "> i </em> </sub>混淆)是第<em class="EmphasisTypeItalic "> i </em>阶统计量。为了找到订单统计数据，我们需要对样本进行排序，并找到样本中第<em class="EmphasisTypeItalic "> i </em>个最小的数字。<img alt="$$ \overline{x} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq60.png" style="width:0.78em"/>是样本均值。</p>
<p>系数<em class="EmphasisTypeItalic "> a </em> <sub> <em class="EmphasisTypeItalic "> i </em> </sub>给出如下:<p> <img alt="$$ \left({a}_1,\dots, {a}_n\right)=\frac{m^T{V}^{-1}}{C} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equgz.png" style="width:9.45em"/> </p></p>
<p>其中<em class="EmphasisTypeItalic "> C </em>为向量范数，如下图:<p> <img alt="$$ C=\left\Vert {V}^{-1}m\right\Vert ={\left({m}^T{V}^{-1}{V}^{-1}m\right)}^{\frac{1}{2}} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equha.png" style="width:13.47em"/> </p></p>
<p class="Para" id="Par483">向量<em class="EmphasisTypeItalic "> m </em>由从标准正态分布采样的独立同分布随机变量的顺序统计量的期望值组成。<em class="EmphasisTypeItalic "> V </em>是那些正态顺序统计量的协方差矩阵。</p>
<p class="Para" id="Par484">W 遵循算法 R94(匿名)中实现的夏皮罗-维尔克分布。, 1995).</p>
<p>NM Dev 类<code>ShapiroWilk</code>实现了夏皮罗-维尔克测试。这里有一个例子:</p>
<pre>double[] sample = new double[]{-1.7, -1, -1, -.73, -.61, -.5, -.24, .45, .62, .81, 1, 5};
ShapiroWilk test = new ShapiroWilk(sample);
System.out.println("H0: " + test.getNullHypothesis());
System.out.println("H1: " + test.getAlternativeHypothesis());
System.out.println("test statistics = " + test.statistics());
System.out.println("p-value = " + test.pValue());
System.out.println("is null rejected at 5% = " + test.isNullRejected(0.05));

</pre>
<p>输出如下所示:</p>
<pre>H0: the samples come from a normally distributed population
H1: the samples do not come from a normally distributed population
test statistics = 0.7818521311977514
p-value = 0.005868730248429044
is null rejected at 5% = true

</pre>
<p class="Para" id="Par487">对于这个样本，零假设被拒绝了 5%。取而代之的是接受样本不具有正态分布的替代假设。</p>

<h5 class="Heading">Jarque-Bera 测试</h5>
<p class="Para" id="Par488">Jarque-Bera 检验是一种拟合优度检验，用于检验样本数据的偏斜度和峰度是否符合正态分布。正态分布的偏度和过度峰度都等于零。如果其中任何一个远离零，则表明数据不具有正态分布。</p>
<p>测试统计量<em class="EmphasisTypeItalic "> JB </em>定义如下:<p> <img alt="$$ JB=\frac{n}{6}\left({S}^2+\frac{1}{4}{\left(K-3\right)}^2\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equhb.png" style="width:11.07em"/> </p></p>
<p class="Para" id="Par490">其中<em class="EmphasisTypeItalic "> n </em>是观测值的个数(或一般的自由度)，<em class="EmphasisTypeItalic "> S </em>是样本偏度，<em class="EmphasisTypeItalic "> K </em>是样本峰度。</p>
<p class="Para" id="Par491">如果数据来自正态分布，<em class="EmphasisTypeItalic "> JB </em>统计量渐近地具有两个自由度的卡方分布，因此该统计量可用于测试数据来自正态分布的假设。零假设是偏度为零的联合假设，超额峰度为零。正如<em class="EmphasisTypeItalic "> JB </em>的定义所示，任何偏离都会增加 JB 统计量。</p>
<p class="Para" id="Par492">对于小样本，卡方近似过于敏感，当零假设为真时，通常会拒绝零假设。此外，p 值的分布偏离均匀分布，成为右偏单峰分布，尤其是对于小 p 值。这导致了大的 I 型错误率。常态有更强有力的测试。</p>
<p>NM Dev 类<code>JarqueBera</code>实现 Jarque-Bera 测试。这里有一个例子:</p>
<pre>double[] samples = new double[]{
    39, 35, 33, 33, 32, 30, 30, 30, 28, 28,
    27, 27, 27, 27, 27, 26, 26, 26, 26, 26,
    26, 25, 25, 25, 25, 25, 25, 24, 24, 24,
    24, 24, 23, 23, 23, 23, 23, 23, 23, 23,
    23, 23, 23, 23, 23, 22, 22, 22, 22, 21,
    21, 21, 21, 21, 21, 21, 20, 20, 19, 19,
    18, 16
};
JarqueBera test = new JarqueBera(
        samples,
        false // not using the exact Jarque-Bera distribution
);
System.out.println("H0: " + test.getNullHypothesis());
System.out.println("H1: " + test.getAlternativeHypothesis());
System.out.println("test statistics = " + test.statistics());
System.out.println("p-value = " + test.pValue());
System.out.println("is null rejected at 5% = " + test.isNullRejected(0.05));

</pre>
<p>输出如下所示:</p>
<pre>H0: both the skewness and the excess kurtosis are 0
H1: either the skewness or the excess kurtosis is non-zero
test statistics = 18.957211215941424
p-value = 7.647049269299266E-5
is null rejected at 5% = true






</pre>

<h5 class="Heading">奥古斯丁的测验</h5>
<p class="Para" id="Par495">在检验正态性方面，达戈斯蒂诺检验比 Jarque-Bera 检验更有效。这也是偏离常态的拟合优度度量。该测试基于样本峰度和偏斜度的变换。它结合了偏度测试和峰度测试。偏斜度测试确定数据的偏斜度在统计上是否不同于零。测试统计是<img alt="$$ {z}_s^2 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq61.png" style="width:1.06em"/>。同样，峰度测试确定数据的过度峰度在统计上是否不为零。测试统计是<img alt="$$ {z}_k^2 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq62.png" style="width:1.06em"/>。达戈斯蒂诺检验是基于这样一个事实:当数据呈正态分布时，检验统计量<img alt="$$ T={z}_s^2+{z}_k^2 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq63.png" style="width:5.06em"/>具有两个自由度的卡方分布。这个测试通常不应该用于少于 20 个元素的数据集。零假设如下:偏度和超额峰度都是 0。另一个假设如下:偏度或过度峰度不为零。</p>
<p>NM Dev 类<code>DAgostino</code>实现了 D'Agostino 测试。这里有一个例子:</p>
<pre>double[] samples = new double[]{
    39, 35, 33, 33, 32, 30, 30, 30, 28, 28,
    27, 27, 27, 27, 27, 26, 26, 26, 26, 26,
    26, 25, 25, 25, 25, 25, 25, 24, 24, 24,
    24, 24, 23, 23, 23, 23, 23, 23, 23, 23,
    23, 23, 23, 23, 23, 22, 22, 22, 22, 21,
    21, 21, 21, 21, 21, 21, 20, 20, 19, 19,
    18, 16
};
DAgostino test = new DAgostino(samples);
System.out.println("H0: " + test.getNullHypothesis());
System.out.println("H1: " + test.getAlternativeHypothesis());
System.out.println("skewness test statistics " + test.Z1());
System.out.println("p-value for skewness test = " + test.pvalueZ1());
System.out.println("kurtosis test statistics " + test.Z2());
System.out.println("test statistics = " + test.statistics());
System.out.println("p-value = " + test.pValue());
System.out.println("is null rejected at 5% = " + test.isNullRejected(0.05));

</pre>
<p>输出如下所示:</p>
<pre>H0: both the skewness and the excess kurtosis are 0
H1: either the skewness or the excess kurtosis is non-zero
skewness test statistics 3.1816798934083783
p-value for skewness test = 0.001464235568704897
kurtosis test statistics 2.328055257751046
test statistics = 15.542928227261438
p-value = 4.2159555092358136E-4
is null rejected at 5% = true






</pre>

<h5 class="Heading">小弗的测试</h5>
<p class="Para" id="Par498">Lilliefors 测试检验零假设，即数据来自具有估计样本均值和方差的正态分布总体。检验统计量是经验分布和假设正态分布之间的最大绝对差值。由于假设的 CDF 使用的是基于数据的均值和方差估计，因此检验统计量的“零分布”，即假设零假设为真时的概率分布，在随机性上小于零假设仅选择一个正态分布时的概率分布(Lilliefors 分布的原因)。</p>
<p>测试过程如下:</p>
<ol><li class="ListItem"><p class="Para" id="Par500">首先，根据数据估计总体均值和总体方差。</p>
 </li>
<li class="ListItem"><p class="Para" id="Par501">然后，用估计的均值和估计的方差求正态分布的经验分布函数和累积分布函数的最大差异。</p>
 </li>
<li class="ListItem"><p class="Para" id="Par502">最后，评估最大差异是否大到足以具有统计学意义，从而拒绝零假设。我们对截止区域使用 Lilliefors 分布。</p>
 </li>
</ol>

<p>NM Dev 类<code>Lilliefors</code>实现 Lilliefors 测试。在这个实现中，我们首先使用 Dallal &amp; Wilkinson (1986)中的公式计算 p 值，该公式仅在 p 值小于 0.1 时才被认为是可靠的。当 p 值大于 0.1 时，我们使用修正统计量的分布再次计算 p 值(Stephens，1974)。这里有一个例子:</p>
<pre>double[] sample = new double[]{-1.7, -1, -1, -.73, -.61, -.5, -.24, .45, .62, .81, 1, 5};
Lilliefors test = new Lilliefors(sample);
System.out.println("H0: " + test.getNullHypothesis());
System.out.println("H1: " + test.getAlternativeHypothesis());
System.out.println("test statistics = " + test.statistics());
System.out.println("p-value = " + test.pValue());
System.out.println("is null rejected at 5% = " + test.isNullRejected(0.05));

</pre>
<p>输出如下所示:</p>
<pre>H0: the samples come from a normally distributed population
H1: the samples do not come from a normally distributed population
test statistics = 0.23353570622938402
p-value = 0.0696831488554199
is null rejected at 5% = false






</pre>


<h4 class="Heading">12.5.1.2·科尔莫戈罗夫试验</h4>
<p>Kolmogorov-Smirnov 检验有两个版本(K-S 检验或 KS 检验)。单样本 KS 检验比较样本的经验分布函数和参考分布的累积分布函数之间的距离(如 Lilliefors 检验)。双样本 KS 检验比较两个样本的经验分布函数之间的距离。此统计的零分布是在零假设下计算的，假设样本取自参考分布(在单样本情况下)或样本取自同一分布(在双样本情况下)。见图<a href="#Fig48"> 12-48 </a>。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig48_HTML.jpg" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig48_HTML.jpg" style="width:19.18em"/></p>
<p>图 12-48</p><p class="SimplePara">单样本 Kolmogorov-Smirnov 统计的图示。平滑线是参考 CDF，阶梯线是经验 CDF，黑色箭头是 K-S 统计量。</p>


<p>单样本 Kolmogorov-Smirnov 统计量如下:<p> <img alt="$$ {D}_n=\underset{x}{\sup}\left|{F}_n(x)-F(x)\right| $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equhc.png" style="width:10.36em"/> </p></p>
<p class="Para" id="Par507">其中<img alt="$$ \underset{x}{\sup } $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq64.png" style="width:1.74em"/>是经验分布函数<em class="EmphasisTypeItalic ">F</em><sub><em class="EmphasisTypeItalic ">n</em></sub>(<em class="EmphasisTypeItalic ">x</em>)与累积分布函数<em class="EmphasisTypeItalic "> F </em> ( <em class="EmphasisTypeItalic "> x </em>)之间的距离集合的上确界。直观地说，统计采用所有<em class="EmphasisTypeItalic "> x </em>值中两个分布函数之间的最大绝对差值。根据格利文科-坎特利定理，如果样本来自分布<em class="EmphasisTypeItalic "> F </em> ( <em class="EmphasisTypeItalic "> x </em>，那么<em class="EmphasisTypeItalic "> D </em> <sub> <em class="EmphasisTypeItalic "> n </em> </sub>在<em class="EmphasisTypeItalic "> n </em>趋于无穷大的极限内几乎必然收敛于 0。实际上，该统计需要相对大量的数据点(与其他拟合优度标准如 Anderson-Darling 检验统计相比),以正确拒绝零假设。如果<em class="EmphasisTypeItalic "> F </em> ( <em class="EmphasisTypeItalic "> x </em>)的参数是根据数据确定的，例如 Lilliefors 测试中的样本均值和样本方差，则使用 Kolmogorov-Smirnov 分布确定的临界值无效。</p>
<p>双样本 Kolmogorov-Smirnov 检验评估两个基本的一维概率分布是否不同。两样本 KS 统计如下:<p> <img alt="$$ {D}_{n,m}=\underset{x}{\sup}\left|{F}_{1,n}(x)-{F}_{2,m}(x)\right| $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equhd.png" style="width:12.81em"/> </p></p>
<p class="Para" id="Par509">其中<em class="EmphasisTypeItalic "> F </em> <sub> 1，<em class="EmphasisTypeItalic ">n</em>T5】(<em class="EmphasisTypeItalic ">x</em>)和<em class="EmphasisTypeItalic "> F </em> <sub> 2，<em class="EmphasisTypeItalic "> m </em> </sub> ( <em class="EmphasisTypeItalic "> x </em>)分别为第一个和第二个样本的经验分布函数，<img alt="$$ \underset{x}{\sup } $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq65.png" style="width:1.74em"/>为上确界函数。</sub></p>
<p>双样本 KS 检验是比较两个样本的最有用和最通用的非参数方法之一，因为它对两个样本的经验累积分布函数的位置和形状的差异都很敏感。参见图<a href="#Fig49"> 12-49 </a>。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig49_HTML.png" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig49_HTML.png" style="width:19.2em"/></p>
<p>图 12-49</p><p class="SimplePara">双样本 Kolmogorov-Smirnov 统计的图示。平滑线和阶梯线各对应一个经验分布函数，黑色箭头是双样本 KS 统计量</p>


<p class="Para" id="Par511">Kolmogorov-Smirnov 检验可以被修改以用作拟合优度检验。在检验分布正态性的特殊情况下，样本被标准化并与标准正态分布进行比较。这相当于将参考分布的均值和方差设置为样本估计值，众所周知，使用这些来定义特定的参考分布会改变检验统计量的零分布(参见 Lilliefors 检验)。各种研究发现，即使在这种修正形式下，该检验的正态性也不如夏皮罗-维尔克检验或安德森-达林检验。然而，这些其他的测试有它们自己的缺点。例如，众所周知，夏皮罗-维尔克检验不适用于大样本或有许多相同值的样本。</p>
<p>NM Dev 类<code>KolmogorovSmirnov1Sample</code>和<code>KolmogorovSmirnov2Samples</code>实现单样本和双样本 Kolmogorov-Smirnov 测试。这里有一个例子:</p>
<pre>// one-sample KS test
KolmogorovSmirnov1Sample test1 = new KolmogorovSmirnov1Sample(
        new double[]{ // with duplicates
            1.2142038235675114, 0.8271665834857130, -2.2786245743283295, 0.8414895245471727,
            -1.4327682855296735, -0.2501807766164897, -1.9512765152306415, 0.6963626117638846,
            0.4741320101265005, 1.2142038235675114
        },
        new NormalDistribution(),
        KolmogorovSmirnov.Side.TWO_SIDED // options are: TWO_SIDED, GREATER, LESS
);
System.out.println("H0: " + test1.getNullHypothesis());
System.out.println("test statistics = " + test1.statistics());
System.out.println("p-value = " + test1.pValue());
System.out.println("is null rejected at 5% = " + test1.isNullRejected(0.05));

// two-sample KS test
KolmogorovSmirnov2Samples test2 = new KolmogorovSmirnov2Samples(
        new double[]{ // x = rnorm(10)
            1.2142038235675114, 0.8271665834857130, -2.2786245743283295, 0.8414895245471727,
            -1.4327682855296735, -0.2501807766164897, -1.9512765152306415, 0.6963626117638846,
            0.4741320101265005, -1.2340784297133520
        },
        new double[]{ // x = rnorm(15)
            1.7996197748754565, -1.1371109188816089, 0.8179707525071304, 0.3809791236763478,
            0.1644848304811257, 0.3397412780581336, -2.2571685407244795, 0.4137315314876659,
            0.7318687611171864, 0.9905218801425318, -0.4748590846019594, 0.8882674167954235,
            1.0534065683777052, 0.2553123235884622, -2.3172807717538038},
        KolmogorovSmirnov.Side.GREATER // options are: TWO_SIDED, GREATER, LESS
);
System.out.println("H0: " + test2.getNullHypothesis());
System.out.println("test statistics = " + test2.statistics());
System.out.println("p-value = " + test2.pValue());
System.out.println("is null rejected at 5% = " + test2.isNullRejected(0.05));

</pre>
<p>输出如下所示:</p>
<pre>H0: the true distribution function of sample is equal to the hypothesized distribution function
test statistics = 0.2822971133259847
p-value = 0.4028859117233684
is null rejected at 5% = false
H0: the true distribution function of sample is greater than the distribution function of the other sample
test statistics = 0.2666666666666667
p-value = 0.4259925874001307
is null rejected at 5% = false

</pre>

<h4 class="Heading">12.5.1.3·安德森-达林试验</h4>
<p class="Para" id="Par514">Anderson-Darling K 样本检验检验 K 个样本是否来自同一个分布，不需要指定。测试产生两个统计值和两个 p 值。<em class="EmphasisTypeItalic "> T </em> <sub> <em class="EmphasisTypeItalic "> kN </em> </sub>和<em class="EmphasisTypeItalic "> p </em> <sub> <em class="EmphasisTypeItalic "> kN </em> </sub>是没有并列观测值时的统计量和 p 值。<em class="EmphasisTypeItalic ">T</em><sub><em class="EmphasisTypeItalic ">akN</em></sub>和<em class="EmphasisTypeItalic ">p</em><sub><em class="EmphasisTypeItalic ">akN</em></sub>是分布离散或连续数据分组时的替代统计量和 p 值。在这两种情况下，可能会有相同的观察结果。</p>
<p>NM Dev 类<code>AndersonDarling</code>实现了 Anderson-Darling K-sample 测试。这里有一个例子:</p>
<pre>// the samples
double[] x1 = new double[]{38.7, 41.5, 43.8, 44.5, 45.5, 46.0, 47.7, 58.0};
double[] x2 = new double[]{39.2, 39.3, 39.7, 41.4, 41.8, 42.9, 43.3, 45.8};
double[] x3 = new double[]{34.0, 35.0, 39.0, 40.0, 43.0, 43.0, 44.0, 45.0};
double[] x4 = new double[]{34.0, 34.8, 34.8, 35.4, 37.2, 37.8, 41.2, 42.8};

AndersonDarling test = new AndersonDarling(x1, x2, x3, x4);
System.out.println("H0: " + test.getNullHypothesis());
System.out.println("H1: " + test.getAlternativeHypothesis());
System.out.println("test statistics = " + test.statistics());
System.out.println("p-value = " + test.pValue());
System.out.println("alternative test statistics = " + test.statisticsAlternative());
System.out.println("alternative p-value = " + test.pValueAlternative());
System.out.println("is null rejected at 5% = " + test.isNullRejected(0.05));

</pre>
<p>输出如下所示:</p>
<pre>H0: all samples come from a common distribution
H1: not all samples come from a common distribution
test statistics = 4.449262232403152
p-value = 0.0023633128630889486
alternative test statistics = 4.479780627135353
alternative p-value = 0.0022781660876509324
is null rejected at 5% = true

</pre>

<h4 class="Heading">12 . 5 . 1 . 4 mises 等效应力分析</h4>
<p class="Para" id="Par517">双样本 Cramer Von Mises 检验是另一种比较两个样本以评估它们是否来自相同的基础总体分布的检验。</p>
<p>NM Dev 类<code>CramerVonMises2Samples</code>实现了双样本 Cramer Von Mises 测试。这里有一个例子:</p>
<pre>// the samples
double[] x1 = new double[]{-0.54289848, 0.08999578, -1.77719573, -0.67991860, -0.65741590, -0.25776164, 1.02024626, 1.26434300, 0.51068476, -0.23998229};
double[] x2 = new double[]{1.7053818, 1.0260726, 1.7695157, 1.5650577, 1.4945107, 1.8593791, 2.1760302, -0.9728721, 1.4208313, 1.5892663};
CramerVonMises2Samples test = new CramerVonMises2Samples(x1, x2);
System.out.println("H0: " + test.getNullHypothesis());
System.out.println("H1: " + test.getAlternativeHypothesis());
System.out.println("test statistics = " + test.statistics());
System.out.println("p-value = " + test.pValue());
System.out.println("is null rejected at 5% = " + test.isNullRejected(0.05));

</pre>
<p>输出如下所示:</p>
<pre>H0: the two samples are drawn from the same distribution
H1: the two samples are not drawn from the same distribution
test statistics = 1.1450000000000002
p-value = 0.0010713596423332916
is null rejected at 5% = true






</pre>

<h4 class="Heading">12.5.1.5·皮尔逊卡方检验</h4>
<p class="Para" id="Par520">Pearson 的独立性卡方检验评估在列联表(矩阵)中表示的两个变量的成对观察值是否相互独立。无效假设是这两个变量在统计上相互独立。</p>
<p>例如，假设我们想知道上课是否有助于通过考试，就像澳大利亚机遇班的考试一样。我们将在如下的应急表中记录出勤/缺勤与通过/失败的关系:</p>
<table style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; border-left: 0.5pt solid ; border-right: 0.5pt solid ; "><colgroup><col class="tcol1 align-left"/>
<col class="tcol2 align-left"/>
<col class="tcol3 align-left"/>
<col class="tcol4 align-left"/>
</colgroup>
<thead><tr><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; text-align: left;"> </th>
<th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">及格</p>
</th>
<th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">失败</p>
</th>
<th style="border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">总数</p>
</th>
</tr>
</thead>
<tbody><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">出席</p>
</td>
<td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">Twenty-five</p>
</td>
<td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">six</p>
</td>
<td style="border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">Thirty-one</p>
</td>
</tr>
<tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">缺席的</p>
</td>
<td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">eight</p>
</td>
<td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">Fifteen</p>
</td>
<td style="border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">Twenty-three</p>
</td>
</tr>
<tr><td style="border-right: 0.5pt solid ; text-align: left;"><p class="SimplePara">总数</p>
</td>
<td style="border-right: 0.5pt solid ; text-align: left;"><p class="SimplePara">Thirty-three</p>
</td>
<td style="border-right: 0.5pt solid ; text-align: left;"><p class="SimplePara">Twenty-one</p>
</td>
<td style="text-align: left;"><p class="SimplePara">Fifty-four</p>
</td>
</tr>
</tbody>
</table>

<p>如果变量是真正独立的，我们会期望一个公平的结果，如下所示:</p>
<table style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; border-left: 0.5pt solid ; border-right: 0.5pt solid ; "><colgroup><col class="tcol1 align-left"/>
<col class="tcol2 align-left"/>
<col class="tcol3 align-left"/>
<col class="tcol4 align-left"/>
</colgroup>
<thead><tr><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; text-align: left;"> </th>
<th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">及格</p>
</th>
<th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">失败</p>
</th>
<th style="border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">总数</p>
</th>
</tr>
</thead>
<tbody><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">出席</p>
</td>
<td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">31*33/54 = 18.94</p>
</td>
<td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">31*21/54 = 12.06</p>
</td>
<td style="border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">Thirty-one</p>
</td>
</tr>
<tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">缺席的</p>
</td>
<td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">23*33/54 = 14.06</p>
</td>
<td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">23*21/54 = 8.94</p>
</td>
<td style="border-bottom: 0.5pt solid ; text-align: left;"><p class="SimplePara">Twenty-three</p>
</td>
</tr>
<tr><td style="border-right: 0.5pt solid ; text-align: left;"><p class="SimplePara">总数</p>
</td>
<td style="border-right: 0.5pt solid ; text-align: left;"><p class="SimplePara">Thirty-three</p>
</td>
<td style="border-right: 0.5pt solid ; text-align: left;"><p class="SimplePara">Twenty-one</p>
</td>
<td style="text-align: left;"><p class="SimplePara">Fifty-four</p>
</td>
</tr>
</tbody>
</table>

<p>测试统计如下:<p> <img alt="$$ {\chi}^2=\sum \limits_{i=1}^r\sum \limits_{j=1}^c\frac{{\left({O}_{ij}-{E}_{ij}\right)}^2}{E_{ij}} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equhe.png" style="width:10.82em"/> </p></p>
<p class="Para" id="Par524">其中<em class="EmphasisTypeItalic "> O </em> <sub> <em class="EmphasisTypeItalic "> ij </em> </sub>是小区中的观测频率，<em class="EmphasisTypeItalic "> E </em> <sub> <em class="EmphasisTypeItalic "> ij </em> </sub>是假设独立性的零假设的期望频率。测试统计对所有行(<em class="EmphasisTypeItalic "> r </em>)和列(<em class="EmphasisTypeItalic "> c </em>)求和。它基本上是由预期频率缩放的偏差平方和，以标准化所有单元中的大计数和小计数。注意<em class="EmphasisTypeItalic "> χ </em> <sup> 2 </sup> = 0 当且仅当<em class="EmphasisTypeItalic ">O</em><sub><em class="EmphasisTypeItalic ">ij</em></sub>=<em class="EmphasisTypeItalic ">E</em><sub><em class="EmphasisTypeItalic ">ij</em></sub>为所有单元格。</p>
<p class="Para" id="Par525">当样本量较小且列联表不平衡时，<em class="EmphasisTypeItalic "> χ </em> <sup> 2 </sup>具有费雪精确分布。否则，当样本量较大，列联表平衡时，我们使用卡方分布，这是费雪精确分布的渐近分布。</p>
<p>NM Dev 类<code>ChiSquareIndependenceTest</code>实现了 Pearson 的独立性卡方测试。以下代码为前面的示例计算:</p>
<pre>// the attendance/absence vs. pass/fail counts
Matrix counts = new DenseMatrix(new double[][]{
    {25, 6},
    {8, 15}
});
ChiSquareIndependenceTest test1
        = new ChiSquareIndependenceTest(
                counts,
                0,
                // the asymptotic distribution is the Chi-square distribution
                ChiSquareIndependenceTest.Type.ASYMPTOTIC
        );

Matrix expected = ChiSquareIndependenceTest.getExpectedContingencyTable(
        new int[]{31, 23}, // row sums
        new int[]{33, 21} // column sums
);
System.out.println("the expected frequencies:");
System.out.println(expected);

System.out.println("H0: " + test1.getNullHypothesis());
System.out.println("H1: " + test1.getAlternativeHypothesis());
System.out.println("test statistics = " + test1.statistics());
System.out.println("p-value = " + test1.pValue());
System.out.println("is null rejected at 5% = " + test1.isNullRejected(0.05));

ChiSquareIndependenceTest test2
        = new ChiSquareIndependenceTest(
                counts,
                100000,// number of simulation to compute the Fisher exact distribution
                ChiSquareIndependenceTest.Type.EXACT // use the Fisher exact distribution
        );
System.out.println("p-value = " + test2.pValue());
System.out.println("is null rejected at 5% = " + test2.isNullRejected(0.05));

</pre>
<p>输出如下所示:</p>
<pre>the expected frequencies:
2x2
         [,1] [,2]
[1,] 18.944444, 12.055556,
[2,] 14.055556, 8.944444,
H0: the two random variables in the contingency table are independent
H1: the two random variables in the contingency table are not independent
test statistics = 9.835886413726527
p-value = 0.0017113979062570728
is null rejected at 5% = true
p-value = 6.500000000000436E-4
is null rejected at 5% = true

</pre>
<p class="Para" id="Par528">使用卡方分布作为渐近分布，我们得到 p 值为 0.0017。使用 Fisher 精确分布，我们得到 p 值为 0.0006。在任何情况下，零假设在 5%被安全地拒绝。我们的结论是，上课对通过考试没有影响是不太可能的。或者换句话说，上课和通过考试可能是相关的。所以，不要逃课！</p>


<h3 class="Heading">等级测试</h3>
<p class="Para" id="Par529">NM Dev 支持一套假设检验，用于评估两个样本是否具有相同的总体均值、中位数和变异性。</p>
<h4 class="Heading">12.5.2.1 T 检验</h4>
<p class="Para" id="Par530">t 检验为方差未知但相等的两个同分布正态总体的均值相等提供了精确的检验。Welch 的 t 检验是一种近乎精确的检验，适用于数据为正态但方差可能不同的情况。当用于一个样本时，测试可用于比较样本平均值和假设平均值。对于中等规模的样本和单尾检验，t 检验对于中等程度违反正态性假设是相对稳健的。在足够大的样本中，t 检验渐近地接近 z 检验，并且变得稳健，即使偏离正态性很大。然而，如果数据实质上是非正态的，并且样本量很小，t 检验会给出误导性的结果。</p>
<p>NM Dev 类<code>T</code>实现了相等方差的 t 检验和可能不相等方差的 Welch t 检验。这里有一个例子:</p>
<pre>// the t-test
T test1 = new T(
        new double[]{1, 3, 5, 2, 3, 5},
        new double[]{2, 5, 6, 4, 9, 8},
        true, // assume variances are equal
        4 // the hypothetical mean-difference = 4 in the null hypothesis
);
System.out.println("H0: " + test1.getNullHypothesis());
System.out.println("H1: " + test1.getAlternativeHypothesis());
System.out.println("test statistics = " + test1.statistics());
System.out.println("1st mean = " + test1.mean1());
System.out.println("2nd mean = " + test1.mean2());
System.out.println("p-value = " + test1.pValue());
System.out.println("p-value, right sided = " + test1.rightOneSidedPvalue());
System.out.println("p-value, left sided = " + test1.leftOneSidedPvalue());
System.out.println(String.format("95%% confidence interval = (%f, %f)", test1.leftConfidenceInterval(0.95), test1.rightConfidenceInterval(0.95)));
System.out.println("97.5%% confidence interval = " + Arrays.toString(test1.confidenceInterval(0.975)));
System.out.println("is null rejected at 5% = " + test1.isNullRejected(0.05));

// Welch's t-test
T test2 = new T(
        new double[]{1, 3, 5, 2, 3, 5},
        new double[]{2, 5, 6, 4, 9, 8},
        false, // assume variances are different
        4 // the hypothetical mean-difference = 4 in the null hypothesis
);
System.out.println("test statistics = " + test2.statistics());
System.out.println("p-value = " + test2.pValue());
System.out.println("p-value, right sided = " + test2.rightOneSidedPvalue());
System.out.println("p-value, left sided = " + test2.leftOneSidedPvalue());
System.out.println(String.format("95%% confidence interval = (%f, %f)", test2.leftConfidenceInterval(0.95), test2.rightConfidenceInterval(0.95)));
System.out.println("97.5%% confidence interval = " + Arrays.toString(test2.confidenceInterval(0.975)));
System.out.println("is null rejected at 5% = " + test2.isNullRejected(0.05));

</pre>
<p>输出如下所示:</p>
<pre>H0: the means are equal
H1: the means are different
test statistics = -5.239739845279477
1st mean = 3.1666666666666665
2nd mean = 5.666666666666667
p-value = 3.7894052596908147E-4
p-value, right sided = 0.9998105297370155
p-value, left sided = 1.8947026298454073E-4
95% confidence interval = (-0.251606, -4.748394)
97.5%% confidence interval = [-5.26404992720365, 0.26404992720364895]
is null rejected at 5% = true
test statistics = -5.239739845279477
p-value = 6.816159267755681E-4
p-value, right sided = 0.9996591920366122
p-value, left sided = 3.4080796338778404E-4
95% confidence interval = (-0.205769, -4.794231)
97.5%% confidence interval = [-5.339736444764696, 0.33973644476469556]
is null rejected at 5% = true

</pre>
<p class="Para" id="Par533">第一组的平均值为 3.17，第二组的平均值为 5.67。假设方差相等，t 检验在 5%的显著性水平上拒绝了均值差为 4 的零假设。韦尔奇的 t 检验，假设方差不相等，也拒绝零假设。</p>

<h4 class="Heading">12.5.2.2 单向方差分析检验</h4>
<p class="Para" id="Par534">单向 ANOVA 检验测试几组平均值的相等性。ANOVAs 是有帮助的，因为它们比双样本 t 检验更有优势。进行多次双样本 t 检验会增加犯 I 型错误的几率。由于这个原因，ANOVAs 在比较三个或更多的平均值时是有用的。</p>
<p>NM Dev 类<code>OneWayANOVA</code>实现单向 ANOVA 测试。这里有一个例子:</p>
<pre>double[][] samples = new double[4][];
samples[0] = new double[]{1.3, 5.4, 7.6, 7.2, 3.5};
samples[1] = new double[]{2.7, 5.21, 6.3, 4.4, 9.8, 10.24};
samples[2] = new double[]{-2.3, -5.3, -4.33, -5.4};
samples[3] = new double[]{0.21, 0.34, 0.27, 0.86, 0.902, 0.663};

OneWayANOVA test = new OneWayANOVA(samples);
System.out.println("H0: " + test.getNullHypothesis());
System.out.println("H1: " + test.getAlternativeHypothesis());
System.out.println("test statistics = " + test.statistics());
System.out.println("p-value = " + test.pValue());
System.out.println("is null rejected at 5% = " + test.isNullRejected(0.05));

</pre>
<p>输出如下所示:</p>
<pre>H0: all k population means are equal
H1: at least two means are different
test statistics = 23.708487028327358
p-value = 2.629604777371064E-6
is null rejected at 5% = true

</pre>

<h4 class="Heading">12.5.2.3 Kruskal-Wallis 测试</h4>
<p class="Para" id="Par537">Kruskal-Wallis 检验是一种非参数方法，用于检验群体中值的相等性。它等同于单向方差分析，其中数据由它们的等级代替。由于它是非参数方法，Kruskal-Wallis 检验不像类似的单向方差分析那样假设正态总体。然而，除了中位数的任何差异之外，该检验确实假设每组具有相同形状和比例的分布。</p>
<p>NM Dev 类<code>KruskalWallis</code>实现了 Kruskal-Wallis 测试。这里有一个例子:</p>
<pre>double[][] samples = new double[4][];
samples[0] = new double[]{1, 1, 7.6, 7.2, 3.5};
samples[1] = new double[]{2, 2, 6.3, 4.4, 9.8, 10.24};
samples[2] = new double[]{-9, -9, -4.33, -5.4};
samples[3] = new double[]{0.21, 0.21, 0.21, 0.86, 0.902, 0.663};

KruskalWallis test = new KruskalWallis(samples);
System.out.println("H0: " + test.getNullHypothesis());
System.out.println("H1: " + test.getAlternativeHypothesis());
System.out.println("test statistics = " + test.statistics());
System.out.println("p-value = " + test.pValue());
System.out.println("is null rejected at 5% = " + test.isNullRejected(0.05));

</pre>
<p>输出如下所示:</p>
<pre>H0: all population medians are equal
H1: at least two medians are different
test statistics = 16.873233311589477
p-value = 7.504596408127728E-4
is null rejected at 5% = true






</pre>

<h4 class="Heading">12.5.2.4·威尔科克森符号秩检验</h4>
<p class="Para" id="Par540">Wilcoxon 带符号秩检验测试单样本情况下的分布中值与假设中值的对比，以及双样本情况下各组中值的相等性。与 t 检验不同，Wilcoxon 符号秩检验不假设任何总体分布。Wilcoxon 秩和统计量是所有对{( <em class="EmphasisTypeItalic "> x </em>，<em class="EmphasisTypeItalic "> y </em> ) | <em class="EmphasisTypeItalic "> y </em> ≤ <em class="EmphasisTypeItalic "> x </em> }的个数，其中<em class="EmphasisTypeItalic "> y </em>不大于<em class="EmphasisTypeItalic "> x </em>。该统计采用 0 和<em class="EmphasisTypeItalic "> MN </em>之间的值，其中<em class="EmphasisTypeItalic "> M </em>是组 1 中的观察数，而<em class="EmphasisTypeItalic "> N </em>是组 2 中的观察数。测试统计具有 Wilcoxon 秩和分布，参见<code>WilcoxonRankSumDistribution</code>类。</p>
<p>NM Dev 类<code>WilcoxonSignedRank</code>实现了 Wilcoxon 符号秩测试。这里有一个例子:</p>
<pre>double[] sample1 = new double[]{1.3, 5.4, 7.6, 7.2, 3.5};
double[] sample2 = new double[]{2.7, 5.2, 6.3, 4.4, 9.8};

WilcoxonSignedRank test = new WilcoxonSignedRank(
        sample1, sample2,
        2, // the hypothetical median that the distribution is symmetric about true
           // use the exact Wilcoxon rank sum distribution rather than normal distribution
);
System.out.println("H0: " + test.getNullHypothesis());
System.out.println("H1: " + test.getAlternativeHypothesis());
System.out.println("test statistics = " + test.statistics());
System.out.println("p-value = " + test.pValue());
System.out.println("p-value, right sided = " + test.rightOneSidedPvalue());
System.out.println("p-value, left sided = " + test.leftOneSidedPvalue());
System.out.println("is null rejected at 5% = " + test.isNullRejected(0.05));

</pre>
<p>输出如下所示:</p>
<pre>H0: the medians are equal (by offset mu)
H1: the medians are different (not by mu)
test statistics = 2.0
p-value = 0.1875
p-value, right sided = 0.9375
p-value, left sided = 0.09375
is null rejected at 5% = false






</pre>

<h4 class="Heading">12.5.2.5 密封件-Tukey 试验</h4>
<p class="Para" id="Par543">Siegel-Tukey 检验测试两组数据中的一组是否比另一组具有更大的分散值。换句话说，该测试确定两组中的一组是否倾向于移动，有时向右，有时向左，但远离(序数标度的)中心。零假设是两组有相同的方差和中位数。另一个假设是一组比另一组有更大的方差。</p>
<p class="Para" id="Par544">假设有两组 A 和 B，第一组有<em class="EmphasisTypeItalic "> n </em>个观测值，第二组有<em class="EmphasisTypeItalic "> m </em>个观测值(因此有<em class="EmphasisTypeItalic "> N </em> = <em class="EmphasisTypeItalic "> n </em> + <em class="EmphasisTypeItalic "> m </em>个总观测值)。如果所有的<em class="EmphasisTypeItalic "> N </em>个观察值都按升序排列，那么可以预计，如果两组之间没有差异(遵循零假设 H <sub> 0 </sub>)，那么两组的值将会混合或随机排序。这意味着，在极端(高和低)分数的等级中，A 组和 b 组会有相似的值。如果 A 组更倾向于极端值(替代假设 H <sub> 1 </sub>)，那么 A 组会有更高比例的观察值具有低或高值，而中间值的比例会降低。测试统计具有 Wilcoxon 秩和分布，参见<code>WilcoxonRankSumDistribution</code>类。</p>
<p>NM Dev 类<code>SiegelTukey</code>实现了 Siegel-Tukey 测试。这里有一个例子:</p>
<pre>double[] sample1 = new double[]{4, 16, 48, 51, 66, 98};
double[] sample2 = new double[]{33, 62, 84, 85, 88, 93, 97};

SiegelTukey test = new SiegelTukey(
        sample1,
        sample2,
        0, // the hypothetical mean difference true
         // use the exact Wilcoxon Rank Sum distribution rather than normal distribution
);
System.out.println("H0: " + test.getNullHypothesis());
System.out.println("H1: " + test.getAlternativeHypothesis());
System.out.println("test statistics = " + test.statistics());
System.out.println("p-value = " + test.pValue());
System.out.println("p-value, right sided = " + test.rightOneSidedPvalue());
System.out.println("p-value, left sided = " + test.leftOneSidedPvalue());
System.out.println("is null rejected at 5% = " + test.isNullRejected(0.05));

</pre>
<p>输出如下所示:</p>
<pre>H0: the two samples have the same variability and median
H1: the two samples have different variabilities
test statistics = 16.0
p-value = 0.5337995337995338
p-value, right sided = 0.7773892773892773
p-value, left sided = 0.2668997668997669
is null rejected at 5% = false






</pre>

<h4 class="Heading">12.5.2.6 瓦耳尔试验</h4>
<p class="Para" id="Par547">范德华检验将等级从标准的 Kruskal-Wallis 单向方差分析转换为标准正态分布的分位数。这些被称为正常分数，测验是根据这些正常分数计算出来的。单因素模型最常见的非参数检验是 Kruskal-Wallis 检验。克鲁斯卡尔-沃利斯检验是基于数据的等级。范德华检验的优势在于，当正态性假设事实上得到满足时，它提供了标准方差分析的高效率，但当正态性假设未得到满足时，它也提供了克鲁斯卡尔-沃利斯检验的稳健性。</p>
<p>NM Dev 类<code>VanDerWaerden</code>实现了范德瓦尔登测试。这里有一个例子:</p>
<pre>double[][] samples = new double[3][];
samples[0] = new double[]{8, 10, 9, 10, 9};
samples[1] = new double[]{7, 8, 5, 8, 5};
samples[2] = new double[]{4, 8, 7, 5, 7};

VanDerWaerden test = new VanDerWaerden(samples);
System.out.println("H0: " + test.getNullHypothesis());
System.out.println("H1: " + test.getAlternativeHypothesis());
System.out.println("test statistics = " + test.statistics());
System.out.println("p-value = " + test.pValue());
System.out.println("is null rejected at 5% = " + test.isNullRejected(0.05));

</pre>
<p>输出如下所示:</p>
<pre>H0: all population distribution functions are identical
H1: at least two samples do not come from the same distribution
test statistics = 8.512005836094222
p-value = 0.014178863374360917
is null rejected at 5% = true






</pre>



<h2 class="Heading">12.6 马尔可夫模型</h2>
<p class="Para" id="Par550">马尔可夫模型是描述一系列可能状态的随机模型，其中下一个状态的概率仅取决于当前状态，而不取决于历史，因此是无记忆的(不记得过去的任何事情)。在贝叶斯统计、热力学、统计力学、物理学、化学、经济学、金融学、信号处理、信息论和语音处理中有广泛的应用。马尔可夫过程是称为马尔可夫链蒙特卡罗(MCMC)的一般随机模拟方法的基础，该方法用于模拟复杂概率分布的抽样。</p>
<h3 class="Heading">12.6.1 离散时间马尔可夫链</h3>
<p>最简单的马尔可夫模型是离散时间马尔可夫链(DTMC)。它以离散的时间步长移动状态，状态的数量是有限的或可计数的。下一个状态的概率只取决于当前状态，而不取决于过去的任何信息。数学上，假设一个随机变量序列<em class="EmphasisTypeItalic "> X </em> <sub> 0 </sub>，<em class="EmphasisTypeItalic "> X </em> <sub> 1 </sub>，<em class="EmphasisTypeItalic "> X </em> <sub> 2 </sub>，…具有马尔可夫性质，那么我们就有了这个(见图<a href="#Fig50"> 12-50 </a> ): <p> <img alt="$$ \Pr \left({X}_{n+1}=x\ |\ {X}_1={x}_1,{X}_2={x}_2,\dots, {X}_n={x}_n\right)=\Pr \left({X}_{n+1}=x\ |\ {X}_n={x}_n\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equhf.png" style="width:30.16em"/> </p></p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig50_HTML.png" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig50_HTML.png" style="width:32.5em"/></p>
<p>图 12-50</p><p class="SimplePara">具有三个状态的离散时间马尔可夫链</p>


<p>例如，在图<a href="#Fig50"> 12-50 </a>中，我们可以将股票市场分为三种不同的状态:低波动、中波动和高波动。明天市场可能停留在相同的(低波动性)状态(40%的可能性)，但它也可能进入另一个状态，如中等波动性状态(20%的可能性)或高波动性状态(40%的可能性)。转移概率(用箭头和数字表示)是过程从一个状态到另一个状态的概率。请注意，离开一个状态并停留在同一状态(指向自身的箭头)的转移概率之和必须为 1。转移概率通常由随机矩阵来描述，随机矩阵列出了从任何单个状态(行)移动到每个状态(列)的概率。图<a href="#Fig50"> 12-50 </a>中 DTMC 的随机矩阵如下:<p> <img alt="$$ A=\left[\begin{array}{ccc}0.4&amp;amp; 0.2&amp;amp; 0.4\\ {}0.3&amp;amp; 0.2&amp;amp; 0.5\\ {}0.25&amp;amp; 0.25&amp;amp; 0.5\end{array}\right] $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equhg.png" style="width:9.96em"/> </p></p>
<p>从这个矩阵和初始状态的初始概率一起，完全表征了一个时间均匀的 DTMC。可以计算出系统在未来<em class="EmphasisTypeItalic "> n </em>步处于特定状态的概率。比如我们可以计算观察到这个状态序列的概率<em class="EmphasisTypeItalic "> Q </em> = { <em class="EmphasisTypeItalic "> s </em> <sub> 3 </sub>，<em class="EmphasisTypeItalic "> s </em> <sub> 1 </sub>，<em class="EmphasisTypeItalic "> s </em> <sub> 1 </sub>，<em class="EmphasisTypeItalic "> s </em> <sub> 1 </sub> }。系统在状态<em class="EmphasisTypeItalic ">s</em>T22】3 启动(概率为 1)。<p><img alt="$$ \Pr \left(Q\ |\ A\right)=\mathrm{P}\left({s}_1,{s}_1|{s}_1|{s}_3\ |\ A\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equhh.png" style="width:12.94em"/></p><p><img alt="$$ =\Pr \left({s}_3\ |\ A\right)\times \Pr \left({s}_1\ |{s}_3,A\right)\times \Pr \left({s}_1\ |{s}_1,{s}_3,A\right)\times \Pr \left({s}_1\ |{s}_1,{s}_1,{s}_3,A\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equhi.png" style="width:28.53em"/></p><p><img alt="$$ =\Pr \left({s}_3\ |\ A\right)\times \Pr \left({s}_1\ |{s}_3,A\right)\times \Pr \left({s}_1\ |{s}_1,A\right)\times \Pr \left({s}_1\ |{s}_1,A\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equhj.png" style="width:24.56em"/></p><p><img alt="$$ =1\times 0.25\times 0.4\times 0.4=0.04 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equhk.png" style="width:12.99em"/></p></p>
<p>我们在步骤 3 中使用了马尔可夫属性来简化条件概率。具体地说，马尔科夫属性表示如下:<p> <img alt="$$ \Pr \left({q}_t|{q}_{t-1},\cdots, {q}_1\right)=\Pr \left({q}_t|{q}_{t-1}\ \right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equhl.png" style="width:14.16em"/> </p></p>
<p class="Para" id="Par555">在数量金融学中，马尔可夫性质与有效市场假说的弱形式一致，即市场的未来价格不依赖于任何历史价格。他们不预测未来。</p>
<p class="Para" id="Par556">DTMC 可以永远从一个州搬到另一个州。它生成的状态序列是一个随机数(整数)序列。一个具有随机矩阵的 DTMC，<em class="EmphasisTypeItalic "> A </em>，具有平稳分布，<em class="EmphasisTypeItalic "> π </em>，当且仅当<em class="EmphasisTypeItalic "> πA </em> = <em class="EmphasisTypeItalic "> π </em>。平稳分布是当时间趋于无穷大时，我们发现系统在每个状态下的概率。</p>
<p>NM Dev 类<code>SimpleMC</code>实现了一个时间均匀的 DTMC。例如，以下代码实现了前面的三态马尔可夫链:</p>
<pre>// the stochastic matrix of transition probabilities
Matrix A = new DenseMatrix(new double[][]{
    {0.4, 0.2, 0.4},
    {0.3, 0.2, 0.5},
    {0.25, 0.25, 0.5}
});
// start in state 3
Vector I = new DenseVector(0., 0., 1.);

SimpleMC MC = new SimpleMC(I, A);
Vector PI = SimpleMC.getStationaryProbabilities(A);
System.out.println("the stationary distribution = " + PI);

// simulate the next 9 steps
System.out.println("time 0 = " + 3);
for (int i = 1; i &lt; 10; ++i) {
    int state = MC.nextState();
    System.out.println(String.format("time %d = %d", i, state));
}

</pre>
<p>输出如下所示:</p>
<pre>the stationary distribution = [0.307263, 0.223464, 0.469274]
time 0 = 3
time 1 = 3
time 2 = 3
time 3 = 3
time 4 = 3
time 5 = 3
time 6 = 1
time 7 = 2
time 8 = 2
time 9 = 1

</pre>
<p class="Para" id="Par559">当时间趋向于无穷大时，稳态分布就是我们将找到的系统的状态。在这种情况下，我们会发现系统有 47%的时间处于这个马尔可夫链的状态 3。</p>

<h3 class="Heading">隐马尔可夫模型</h3>
<p>隐马尔可夫模型(HMM)是一种随机过程，其基础过程是状态的马尔可夫链，但是您看不到系统处于哪个状态，因此它是隐藏的。你所看到的是观察。存在与每个隐藏状态相关联的观察值的(不同的)概率分布。见图<a href="#Fig51"> 12-51 </a>。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig51_HTML.png" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig51_HTML.png" style="width:35.52em"/></p>
<p>图 12-51</p><p class="SimplePara">股票市场的隐马尔可夫模型</p>


<p class="Para" id="Par561">例如，扩展图<a href="#Fig51"> 12-51 </a>中的例子，市场可以处于三种状态:低、中和高波动性。股票在每个状态下的日收益率正态分布为零均值但波动率不同，<img alt="$$ {\sigma}_1^2\le {\sigma}_2^2\le {\sigma}_3^2 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq66.png" style="width:6.21em"/>。请注意，每种状态都会产生相同的收益集(∞，+∞),但概率不同。我们不知道也无法准确判断市场在任何时间点都处于哪种状态。我们不仅不知道(隐藏的)状态，我们也不知道模型的参数，<em class="EmphasisTypeItalic "> λ </em>，比如转移概率和<img alt="$$ \left\{{\sigma}_i^2\right\} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq67.png" style="width:2.11em"/>。我们观察到的所有信息都是历史回报、观察序列ω(和 HMM 结构)。</p>
<p class="Para" id="Par562">关于 HMM，我们可能会问三个问题。首先，可能性问题。给定参数<em class="EmphasisTypeItalic "> λ </em>和一个观测序列ω，我们能否计算出观测到这个特定序列 Pr(ω|<em class="EmphasisTypeItalic ">λ</em>)的可能性？第二，解码问题。给定参数<em class="EmphasisTypeItalic "> λ </em>和观察序列ω，我们能否确定最可能隐藏的状态序列<em class="EmphasisTypeItalic "> Q </em>？第三，学习问题。给定一个观察序列，ω，和 HMM 结构，我们能学习<em class="EmphasisTypeItalic "> λ </em>吗？</p>
<h4 class="Heading">12.6.2.1 可能性问题</h4>
<p>给定模型<em class="EmphasisTypeItalic "> λ </em>的参数，我们想要计算特定观察或输出序列ω的概率。概念上最简单的方法是对所有可能的状态序列中观察到ω的概率求和。也就是<p> <img alt="$$ \Pr \left(\Omega |\lambda\ \right)={\sum}_{{\left\{q\right\}}^{\prime }s}\Pr \left(\Omega, Q|\lambda \right)={\sum}_{{\left\{q\right\}}^{\prime }s}\Pr \left(\Omega |Q,\lambda \right)\times \Pr \left(Q|\lambda \right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equhm.png" style="width:26.65em"/> </p></p>
<p>第一项是给定隐藏的状态序列<em class="EmphasisTypeItalic "> Q </em>时观察到ω的概率；第二项是给定 HMM 参数<em class="EmphasisTypeItalic "> λ </em>的隐藏状态序列的概率。对于第一个学期，我们有这样的:<p> <img alt="$$ \Pr \left(\Omega |Q,\lambda \right)={\prod}_{t=1}^T\Pr \left({\omega}_t|{q}_t,\lambda\ \right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equhn.png" style="width:14.1em"/> </p></p>
<p class="Para" id="Par565">pr(<em class="EmphasisTypeItalic ">ω</em><sub><em class="EmphasisTypeItalic ">t</em></sub>|<em class="EmphasisTypeItalic ">q</em><sub><em class="EmphasisTypeItalic ">t</em></sub>，<em class="EmphasisTypeItalic "> λ </em>)是在状态<em class="EmphasisTypeItalic ">q</em><sub><em class="EmphasisTypeItalic ">t</em><em class="EmphasisTypeItalic ">t</em>观察到<em class="EmphasisTypeItalic "> ω </em> <sub> <em class="EmphasisTypeItalic "> t </em> </sub>的概率。这由与每个状态相关的概率分布给出。在我们图<a href="#Fig51"> 12-51 </a>的例子中，它是由状态<em class="EmphasisTypeItalic "> q </em> <sub> <em class="EmphasisTypeItalic "> t </em> </sub>(系统在时刻<em class="EmphasisTypeItalic "> t </em>所处的状态)中的正态分布给出的。</sub></p>
<p>对于第二个术语，我们有这样的:<p> <img alt="$$ \Pr \left(Q|\lambda \right)={\pi}_{q_1}\times {a}_{q_1{q}_2}\times {a}_{q_2{q}_3}\times \cdots \times {a}_{q_{T-1}{q}_T} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equho.png" style="width:19.02em"/> </p></p>
<p class="Para" id="Par567">它只是初始状态概率<img alt="$$ {\pi}_{q_1} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq68.png" style="width:1.54em"/>(从状态<em class="EmphasisTypeItalic ">q</em>T3】1 开始)和转移概率的乘积。</p>
<p class="Para" id="Par568">然而，这种天真的方法在计算上是不可行的，因为路径的数量呈指数增长。我们需要一种更有效的方法。</p>
<p>将前向概率<em class="EmphasisTypeItalic ">α</em><sub><em class="EmphasisTypeItalic ">t</em></sub>(<em class="EmphasisTypeItalic ">I</em>)定义为部分观测序列直到时间<em class="EmphasisTypeItalic "> t </em>且系统在时间<em class="EmphasisTypeItalic "> t </em>处于状态<em class="EmphasisTypeItalic "> s </em> <sub> <em class="EmphasisTypeItalic "> i </em> </sub>的概率。也就是<p> <img alt="$$ {\alpha}_t(i)=\Pr \left({\omega}_1,{\omega}_2|\cdots |{\omega}_t|{q}_t={s}_i|\lambda \right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equhp.png" style="width:14.76em"/> </p></p>
<p>这可以使用正向归纳来计算。初始化第一步，如下图:<p> <img alt="$$ {\alpha}_1(i)={\pi}_i{b}_i\left({\omega}_1\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equhq.png" style="width:7.2em"/> </p></p>
<p>其中<em class="EmphasisTypeItalic ">b</em><sub><em class="EmphasisTypeItalic ">I</em></sub>(<em class="EmphasisTypeItalic ">ω</em><sub>1</sub>)为状态<em class="EmphasisTypeItalic "> i </em>下观察到<em class="EmphasisTypeItalic "> ω </em> <sub> 1 </sub>的概率。它是由状态的概率分布给出的。在我们的例子中，它由正态分布给出。(这里使用具有概率质量函数的离散概率分布可能更容易，因为在我们的数学中<em class="EmphasisTypeItalic "> ω </em> s 是离散的。想法是一样的。)参见图<a href="#Fig52"> 12-52 </a>。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig52_HTML.png" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig52_HTML.png" style="width:11.8em"/></p>
<p>图 12-52</p><p class="SimplePara">正向算法</p>


<p>归纳步骤说<em class="EmphasisTypeItalic ">α</em><sub>T3】t+1</sub>(<em class="EmphasisTypeItalic ">I</em>)是前面所有<em class="EmphasisTypeItalic ">α</em><sub><em class="EmphasisTypeItalic ">t</em></sub>(<em class="EmphasisTypeItalic ">j</em>)的总和然后达到状态<em class="EmphasisTypeItalic "> j </em>。也就是<p> <img alt="$$ {\alpha}_{t+1}(i)=\left[\sum \limits_{j=1}^N{\alpha}_t(i){a}_{ij}\right]{b}_i\left({\omega}_{t+1}\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equhr.png" style="width:13.36em"/> </p></p>
<p class="Para" id="Par573">其中<em class="EmphasisTypeItalic "> N </em>是 HMM 中状态的数量，<em class="EmphasisTypeItalic ">a</em><sub>T5】ij</sub>是从状态<em class="EmphasisTypeItalic "> i </em>到状态<em class="EmphasisTypeItalic "> j </em>的转移概率。</p>
<p>最后，观察到ω给定<em class="EmphasisTypeItalic "> λ </em>的概率，简单来说就是跨越所有状态的所有<em class="EmphasisTypeItalic "> α </em> <sub> <em class="EmphasisTypeItalic "> T </em> </sub>之和。<p> <img alt="$$ \Pr \left(\Omega |\lambda\ \right)=\sum \limits_{j=1}^N{\alpha}_T(j) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equhs.png" style="width:9.18em"/> </p></p>
<p class="Para" id="Par575">例如，考虑一个村庄，所有村民要么健康要么发烧，只有乡村医生可以确定每个人是否发烧。医生通过询问病人的感觉来诊断发烧。村民可能只会回答觉得正常，头晕，或者冷。</p>
<p class="Para" id="Par576">医生认为他的病人的健康状况就像一个离散的马尔可夫链。有两种状态，健康和发烧，但医生无法直接观察；他们对他隐藏。每天，病人都有一定的机会告诉医生他是正常的、冷的还是头晕的，这取决于他的健康状况。</p>
<p>观察值(正常、寒冷或眩晕)以及隐藏状态(健康、发烧)形成了一个隐马尔可夫模型(HMM ),可以表示为如图<a href="#Fig53"> 12-53 </a>所示。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig53_HTML.jpg" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig53_HTML.jpg" style="width:23.88em"/></p>
<p>图 12-53</p><p class="SimplePara">村民健康的隐马尔可夫模型</p>


<p>NM Dev 类<code>DiscreteHMM</code>实现了一个离散的隐马尔可夫模型，而类<code>ForwardBackwardProcedure</code>执行向前-向后算法来计算向前和向后的概率。例如，以下代码实现了前面的双态 HMM:</p>
<pre>// the initial probabilities for 2 states
DenseVector PI = new DenseVector(
        new double[]{0.6, 0.4}
);
// the transition probabilities
DenseMatrix A = new DenseMatrix(new double[][]{
    {0.7, 0.3},
    {0.4, 0.6}
});
// the observation probabilities; 3 possible outcomes for 2 states
DenseMatrix B = new DenseMatrix(new double[][]{
    {0.5, 0.4, 0.1},
    {0.1, 0.3, 0.6}
});
// construct an HMM
DiscreteHMM hmm = new DiscreteHMM(PI, A, B);

// the realized observations
double[] observations = new double[]{1, 2, 3};

// run the forward-backward algorithm
ForwardBackwardProcedure fb = new ForwardBackwardProcedure(hmm, observations);
for (int t = 1; t &lt;= observations.length; ++t) {
    System.out.println(String.format(
            "the *scaled* forward probability, alpha, in each state at time %d: %s",
            t,
            fb.scaledAlpha(t)
    ));
}

</pre>
<p>输出如下所示:</p>
<pre>the *scaled* forward probability, alpha, in each state at time 1: [0.882353, 0.117647]
the *scaled* forward probability, alpha, in each state at time 2: [0.725522, 0.274478]
the *scaled* forward probability, alpha, in each state at time 3: [0.212128, 0.787872]

</pre>

<h4 class="Heading">12.6.2.2 解码问题</h4>
<p class="Para" id="Par580">给定模型参数<em class="EmphasisTypeItalic "> λ </em>和一个观测值序列ω，滤波问题就是计算系统处于序列末端状态的概率，即 Pr(<em class="EmphasisTypeItalic ">q</em><sub>T5】T</sub>=<em class="EmphasisTypeItalic ">s</em><sub><em class="EmphasisTypeItalic ">I</em></sub>|<em class="EmphasisTypeItalic ">λ</em>，ω)。使用前面所示的正向算法可以有效地解决这个问题。</p>
<p class="Para" id="Par581">平滑问题类似于滤波问题，但它计算的是系统处于一个序列中间状态的概率，换句话说，Pr(<em class="EmphasisTypeItalic ">q</em><sub><em class="EmphasisTypeItalic ">t</em></sub>=<em class="EmphasisTypeItalic ">s</em><sub><em class="EmphasisTypeItalic ">I</em></sub>|<em class="EmphasisTypeItalic ">λ</em>，ω)。</p>
<p>将后向概率<em class="EmphasisTypeItalic ">β</em><sub>T3】tT5】(<em class="EmphasisTypeItalic ">I</em>)定义为系统在时间<em class="EmphasisTypeItalic "> t </em>处于状态<em class="EmphasisTypeItalic "> s </em> <sub> <em class="EmphasisTypeItalic "> i </em> </sub>的概率，以及从那时起直到时间<em class="EmphasisTypeItalic "> t </em>的部分观测值。也就是<p> <img alt="$$ {\beta}_t(i)=\Pr \left({\omega}_{t+1},{\omega}_{t+2}|\cdots, {\omega}_T,\lambda, {q}_t={s}_i\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equht.png" style="width:17.22em"/> </p></sub></p>
<p>这可以使用逆向归纳法来计算。初始化最后一步，如图<a href="#Fig54"> 12-54 </a>所示。【T2<img alt="$$ {\beta}_T(i)=1 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equhu.png" style="width:4.16em"/></p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig54_HTML.png" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig54_HTML.png" style="width:11.8em"/></p>
<p>图 12-54</p><p class="SimplePara">反向算法</p>


<p>归纳步骤说<em class="EmphasisTypeItalic ">β</em><sub><em class="EmphasisTypeItalic ">t</em></sub>(<em class="EmphasisTypeItalic ">I</em>)是从状态<em class="EmphasisTypeItalic "> i </em>到下一时间步<em class="EmphasisTypeItalic ">β</em><sub><em class="EmphasisTypeItalic ">t</em>+1</sub>(<em class="EmphasisTypeItalic ">j</em>)的所有可能路径的总和，并对所有路径进行观察<em class="EmphasisTypeItalic ">ω</em><sub><em class="EmphasisTypeItalic ">t</em>+1</sub>。也就是<p> <img alt="$$ {\beta}_t(i)=\sum \limits_{j=1}^N{a}_{ij}{b}_j\left({\omega}_{t+1}\right){\beta}_{t+1}(j) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equhv.png" style="width:12.68em"/> </p></p>
<p>最后，给定观测值ω和参数<em class="EmphasisTypeItalic "> λ </em>，系统在时刻<em class="EmphasisTypeItalic "> t </em>处于状态<em class="EmphasisTypeItalic "> i </em>的概率如下:<p><img alt="$$ {\gamma}_t(i)=\Pr \left({q}_t={s}_i\ |\ \Omega, \lambda \right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equhw.png" style="width:10.56em"/></p><p><img alt="$$ =\frac{\Pr \left({q}_t={s}_i,\Omega |\lambda \right)}{\Pr \left(\Omega |\lambda \right)} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equhx.png" style="width:8.04em"/></p><p><img alt="$$ =\frac{\alpha_t(i){\beta}_t(i)}{\Pr \left(\Omega |\lambda \right)} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equhy.png" style="width:5.1em"/></p><p><img alt="$$ =\frac{\alpha_t(i){\beta}_t(i)}{\sum \limits_{j=1}^N{\alpha}_t(j){\beta}_t(j)} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equhz.png" style="width:6.77em"/></p></p>
<p>在不考虑状态序列出现概率的情况下，每一瞬间最可能的状态<em class="EmphasisTypeItalic "> t </em>如下:<p> <img alt="$$ {q}_t=\underset{1\le i\le N}{\mathrm{argmax}}\left[{\gamma}_t(i)\right] $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equia.png" style="width:8.24em"/> </p></p>
<p>最可能的隐藏状态序列，即在所有可能的状态序列中找到最大值，可以使用维特比算法来求解。定义系统行进这些状态的最大概率，在时间<em class="EmphasisTypeItalic "> t </em>时着陆状态<em class="EmphasisTypeItalic "> s </em> <sub> <em class="EmphasisTypeItalic "> i </em> </sub>，并生成观测值:<p> <img alt="$$ {\delta}_t(i)=\max \left[\Pr \left({q}_1,{q}_2|\cdots |{q}_t={s}_i|{\omega}_0|\cdots |{\omega}_t|\lambda \right)\right] $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equib.png" style="width:20.07em"/> </p></p>
<p>初始化:<p><img alt="$$ {\delta}_1(i)={\pi}_i{b}_i\left({\omega}_1\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equic.png" style="width:7.06em"/></p>T3】<img alt="$$ {\psi}_1=0 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equid.png" style="width:3.14em"/>T5】</p>
<p><p> <img alt="$$ {\delta}_t(j)=\underset{i}{\max}\left[{\delta}_{t-1}(i){a}_{ij}{b}_j\left({\omega}_t\right)\right] $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equie.png" style="width:12.72em"/> </p>递归</p>
<p>这里的<em class="EmphasisTypeItalic ">δ</em><sub><em class="EmphasisTypeItalic ">t</em></sub>(<em class="EmphasisTypeItalic ">I</em>)是最可能状态序列的概率<em class="EmphasisTypeItalic "> q </em> <sub> 1 </sub>，<em class="EmphasisTypeItalic "> q </em> <sub> 2 </sub>，<em class="EmphasisTypeItalic "> q </em> <sub> <em class="EmphasisTypeItalic "> t </em> </sub>负责第一个<em class="EmphasisTypeItalic "> t </em>的观测，以<em class="EmphasisTypeItalic "> j </em>为其最终状态<p> <img alt="$$ {\psi}_t=\underset{i}{\mathrm{argmax}}\left[{\delta}_{t-1}(i){a}_{ij}\right] $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equif.png" style="width:10.27em"/> </p></p>
<p class="Para" id="Par591">其中<em class="EmphasisTypeItalic ">ψ</em><sub>T3】tT5 是在时间<em class="EmphasisTypeItalic "> t </em>选择的状态，以最大化<em class="EmphasisTypeItalic ">δ</em><sub><em class="EmphasisTypeItalic ">t</em></sub>(<em class="EmphasisTypeItalic ">j</em>)。</sub></p>
<p>终止:<p> <img alt="$$ {\delta_T}^{\ast }=\underset{i}{\max }{\delta}_T(i) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equig.png" style="width:6.84em"/> </p> <p> <img alt="$$ {q}_T=\underset{i}{\mathrm{argmax}}{\delta}_T $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equih.png" style="width:6.84em"/> </p></p>
<p>NM Dev 类<code>Viterbi</code>实现维特比算法。以下代码延续了图<a href="#Fig54"> 12-54 </a>中的示例:</p>
<pre>// the initial probabilities for 2 states
DenseVector PI = new DenseVector(
        new double[]{0.6, 0.4}
);
// the transition probabilities
DenseMatrix A = new DenseMatrix(new double[][]{
    {0.7, 0.3},
    {0.4, 0.6}
});
// the observation probabilities; 3 possible outcomes for 2 states
DenseMatrix B = new DenseMatrix(new double[][]{
    {0.5, 0.4, 0.1},
    {0.1, 0.3, 0.6}
});
// construct an HMM
DiscreteHMM hmm = new DiscreteHMM(PI, A, B);

// the realized observations
double[] observations = new double[]{1, 2, 3};

// run the Viterbi algorithm to find the most likely sequence of hidden states
Viterbi viterbi = new Viterbi(hmm);
int[] viterbi_states = viterbi.getViterbiStates(observations);
System.out.println("the Viterbi states: " + Arrays.toString(viterbi_states));

</pre>
<p>输出如下所示:</p>
<pre>the Viterbi states: [1, 1, 2]

</pre>

<h4 class="Heading">12.6.2.3 的学习问题</h4>
<p>HMM 中的参数学习任务是在给定输出序列ω的情况下，找到状态转移概率<em class="EmphasisTypeItalic "> A </em>和概率分布参数<em class="EmphasisTypeItalic "> λ </em>的最佳集合。任务通常是在给定输出序列集的情况下，导出 HMM 参数的最大似然估计。也就是说，我们的目标是找到最大化 Pr(ω|<em class="EmphasisTypeItalic ">λ</em>)的<em class="EmphasisTypeItalic "> λ </em>。对于任意<em class="EmphasisTypeItalic "> λ </em>，我们可以计算 Pr(ω|<em class="EmphasisTypeItalic ">λ</em>)。这个问题变成了一个多元无约束优化问题。任何优化算法，如 Nelder-Mead，原则上都可以解决它。然而，在实践中，存在收敛和效率问题。还没有精确解决这个问题的易处理算法，但是使用 Baum-Welch 算法可以有效地导出局部最大似然。Baum-Welch 算法是期望最大化算法(EM 算法)的特例。它利用向前向后算法来计算期望步骤中的统计量。见图<a href="#Fig55"> 12-55 </a>。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig55_HTML.jpg" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig55_HTML.jpg" style="width:23.62em"/></p>
<p>图 12-55</p><p class="SimplePara">鲍姆-韦尔奇算法，ξ <sub> t </sub> (i，j)</p>


<p>定义<em class="EmphasisTypeItalic ">ξ</em><sub><em class="EmphasisTypeItalic ">t</em></sub>(<em class="EmphasisTypeItalic ">I</em>，<em class="EmphasisTypeItalic "> j </em>)为在时刻<em class="EmphasisTypeItalic "> t </em>处于状态<em class="EmphasisTypeItalic "> s </em> <sub> <em class="EmphasisTypeItalic "> i </em> </sub>的概率，以及在时刻<em class="EmphasisTypeItalic "> t </em> + 1 处于状态<em class="EmphasisTypeItalic "> s </em> <sub> <em class="EmphasisTypeItalic "> j </em> </sub>的概率，给定模型<em class="EmphasisTypeItalic "> λ也就是<p> <img alt="$$ {\xi}_t\left(i,j\right)=\Pr \left({q}_t={s}_i,{q}_{t+1}={s}_j\ |\ \Omega, \lambda \right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equii.png" style="width:15.79em"/> </p></em></p>
<p>我们可以用向前和向后的概率来写。<p><img alt="$$ {\xi}_t\left(i,j\right)=\Pr \left({q}_t={s}_i,{q}_{t+1}={s}_j\ |\ \Omega, \lambda \right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equij.png" style="width:15.79em"/></p><p><img alt="$$ =\frac{\Pr \left({q}_t={s}_i,{q}_{t+1}={s}_j|\Omega |\lambda \right)}{\Pr \left(\Omega |\lambda \right)} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equik.png" style="width:12.06em"/></p><p><img alt="$$ =\frac{\alpha_t(i){a}_{ij}{b}_j\left({\omega}_{t+1}\right){\beta}_{t+1}(j)}{\Pr \left(\Omega |\lambda \right)} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equil.png" style="width:11.01em"/></p></p>
<p>因此，我们有了这个:<p> <img alt="$$ {\gamma}_t(i)=\Pr \left({q}_t={s}_i\ |\ \Omega, \lambda \right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equim.png" style="width:10.56em"/> </p> <p> <img alt="$$ =\sum \limits_{j=1}^N{\xi}_t\left(i,j\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equin.png" style="width:5.65em"/> </p></p>
<p class="Para" id="Par599">求和<em class="EmphasisTypeItalic ">γ</em><sub><em class="EmphasisTypeItalic ">t</em></sub>(<em class="EmphasisTypeItalic ">I</em>)随时间是状态<em class="EmphasisTypeItalic "> s </em> <sub> <em class="EmphasisTypeItalic "> i </em> </sub>被访问的次数。求和<em class="EmphasisTypeItalic ">ξ</em><sub><em class="EmphasisTypeItalic ">t</em></sub>(<em class="EmphasisTypeItalic ">I</em>，<em class="EmphasisTypeItalic "> j </em>)随时间变化是系统从状态<em class="EmphasisTypeItalic "> s </em> <sub> <em class="EmphasisTypeItalic "> i </em> </sub>到状态<em class="EmphasisTypeItalic "> s </em> <sub> <em class="EmphasisTypeItalic "> j </em> </sub>的次数。我们现在可以估计模型参数<em class="EmphasisTypeItalic "> λ </em>如下:</p>
<p class="Para" id="Par600"><img alt="$$ \hat{\pi_i}={\gamma}_1(i) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq69.png" style="width:4.3em"/>，初始状态概率</p>
<p class="Para" id="Par601"><img alt="$$ \hat{a_{ij}}=\frac{\sum \limits_{t=1}^{T-1}{\xi}_t\left(i,j\right)}{\sum \limits_{t=1}^{T-1}{\gamma}_t(i)} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq70.png" style="width:5.78em"/>，转移概率</p>
<p class="Para" id="Par602"><img alt="$$ \hat{b_{j\left({v}_k\right)}}=\frac{\sum \limits_{t=1,{\omega}_t={v}_k}^{T-1}{\gamma}_t(j)}{\sum \limits_{t=1}^{T-1}{\gamma}_t(i)} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq71.png" style="width:8.16em"/>，状态<em class="EmphasisTypeItalic "> s </em> <sub> <em class="EmphasisTypeItalic "> j </em> </sub>下观察值的条件概率，用于离散观察值</p>
<p>NM Dev 类<code>BaumWelch</code>实现了 Baum-Welch 算法。以下代码从原始 HMM 的一些随机生成的样本中学习图<a href="#Fig53"> 12-53 </a>中的 HMM:</p>
<pre>// generate a sequence of observations from a HMM
// the initial probabilities for 2 states
DenseVector PI = new DenseVector(
        new double[]{0.6, 0.4}
);
// the transition probabilities
DenseMatrix A = new DenseMatrix(new double[][]{
    {0.7, 0.3},
    {0.4, 0.6}
});
// the observation probabilities; 3 possible outcomes for 2 states
DenseMatrix B = new DenseMatrix(new double[][]{
    {0.5, 0.4, 0.1},
    {0.1, 0.3, 0.6}
});
// construct an HMM1
DiscreteHMM model = new DiscreteHMM(PI, A, B);
model.seed(1234507890L, 1234507891L);

// generate the observations
int T = 10000;
HmmInnovation[] innovations = new HmmInnovation[T];
int[] states = new int[T];
int[] observations = new int[T];
for (int t = 0; t &lt; T; ++t) {
    innovations[t] = model.next();
    states[t] = innovations[t].state();
    observations[t] = (int) innovations[t].observation();
}
System.out.println("observations: ");
for (int t = 1; t &lt;= 100; ++t) {
    System.out.print(observations[t] + ", ");
    if (t % 20 == 0) {
        System.out.println("");
    }
}
System.out.println("");

// learn the HMM from observations
DenseVector PI_0 = new DenseVector(new double[]{0.5, 0.5}); // initial guesses
DenseMatrix A_0 = new DenseMatrix(new double[][]{ // initial guesses
    {0.5, 0.5},
    {0.5, 0.5}
});
DenseMatrix B_0 = new DenseMatrix(new double[][]{ // initial guesses
    {0.60, 0.20, 0.20},
    {0.20, 0.20, 0.60}
});
DiscreteHMM model_0 = new DiscreteHMM(PI_0, A_0, B_0);  // initial guesses

// training
int nIterations = 40;
for (int i = 1; i &lt;= nIterations; ++i) {
    model_0 = BaumWelch.train(observations, model_0);
}

// training results
System.out.println("estimated transition probabilities: ");
System.out.println(model_0.A()); // should be close to A
System.out.println("(observation) conditional probabilities: ");
System.out.println(model_0.B());  // should be close to B

</pre>
<p>输出如下所示:</p>
<pre>observations:
2, 3, 3, 3, 3, 2, 1, 3, 2, 2, 2, 1, 2, 3, 3, 2, 2, 2, 2, 3,
1, 2, 3, 2, 2, 3, 2, 1, 3, 1, 1, 2, 2, 1, 2, 2, 2, 3, 1, 1,
3, 3, 1, 1, 3, 2, 3, 1, 3, 3, 2, 2, 2, 1, 3, 3, 1, 1, 2, 3,
3, 3, 3, 2, 1, 1, 1, 2, 1, 1, 3, 2, 3, 1, 1, 2, 1, 1, 3, 3,
1, 1, 1, 2, 2, 2, 1, 3, 2, 3, 2, 1, 1, 1, 3, 3, 1, 2, 2, 1,

estimated transition probabilities:
2x2
         [,1] [,2]
[1,] 0.701488, 0.298512,
[2,] 0.336808, 0.663192,
(observation) conditional probabilities:
2x3
         [,1] [,2] [,3]
[1,] 0.500569, 0.428947, 0.070485,
[2,] 0.130704, 0.271811, 0.597485,

</pre>
<p class="Para" id="Par605">经过训练的 HMM 具有接近原始 HMM 的参数，直到前两位十进制数字。</p>
<p>我们的公式到目前为止假设离散的条件概率。采用连续概率密度函数(如正态分布)的公式是相似的，但计算更复杂。这些被称为混合隐马尔可夫模型(混合 HMM)。观察值是连续的，并且遵循连续分布。NM Dev 类<code>MixtureHMM</code>实现混合 HMM。为了学习它们的参数，我们需要推导出它们各自的最大似然函数，用于 EM 算法中。在给定观察值和参数的当前估计值的情况下，E-step 计算条件期望。M 步最大化关于估计参数和数据集的对数似然函数。重复这两个步骤，直到满足某种收敛标准。然而，他们的解决方案甚至可能不是解析的，例如 t 分布。NM Dev 支持一套混合发行版，如下所示:</p>
<ul class="UnorderedListMarkBullet"><li><p class="Para ParaOneEmphasisChild" id="Par607"><code>NormalMixtureDistribution</code></p></li>
<li><p class="Para ParaOneEmphasisChild" id="Par608"><code>LogNormalMixtureDistribution</code></p></li>
<li><p class="Para ParaOneEmphasisChild" id="Par609"><code>ExponentialMixtureDistribution</code></p></li>
<li><p class="Para ParaOneEmphasisChild" id="Par610"><code>PoissonMixtureDistribution</code></p></li>
<li><p class="Para ParaOneEmphasisChild" id="Par611"><code>GammaMixtureDistribution</code></p></li>
<li><p class="Para ParaOneEmphasisChild" id="Par612"><code>BetaMixtureDistribution</code></p></li>
<li><p class="Para ParaOneEmphasisChild" id="Par613"><code>BinomialMixtureDistribution</code></p></li>
</ul>

<p>NM Dev 类<code>MixtureHMMEM</code>实现 EM 算法来学习混合 HMM。下面的代码演示了学习具有正态混合分布的 HMM，这是图<a href="#Fig50"> 12-50 </a>中三种状态下的每日股票回报模型:</p>
<pre>// the initial probabilities
Vector PI0 = new DenseVector(new double[]{0., 0., 1.});
// the transition probabilities
Matrix A0 = new DenseMatrix(new double[][]{
    {0.4, 0.2, 0.4},
    {0.3, 0.2, 0.5},
    {0.25, 0.25, 0.5}
});
// the conditional normal distributions
NormalMixtureDistribution.Lambda[] lambda0 = new NormalMixtureDistribution.Lambda[]{
    new NormalMixtureDistribution.Lambda(0., .5), // (mu, sigma)
    new NormalMixtureDistribution.Lambda(0., 1.), // medium volatility
    new NormalMixtureDistribution.Lambda(0., 2.5) // high volatility
};
// the original HMM: a model of daily stock returns in 3 regimes
MixtureHMM model0 = new MixtureHMM(PI0, A0, new NormalMixtureDistribution(lambda0));
model0.seed(1234567890L);

// generate a sequence of observations from the HMM
int T = 10000;
HmmInnovation[] innovations = new HmmInnovation[T];
double[] observations = new double[T];
for (int t = 0; t &lt; T; ++t) {
    innovations[t] = model0.next();
    observations[t] = innovations[t].observation();
}
System.out.println("observations: ");
for (int t = 1; t &lt;= 100; ++t) {
    System.out.print(observations[t] + ", ");
    if (t % 20 == 0) {
        System.out.println("");
    }
}
System.out.println("");

// learn an HMM from the observations
MixtureHMM model1
        = new MixtureHMMEM(observations, model0, 1e-5, 20); // using true parameters as initial estimates
Matrix A1 = model1.A();
NormalMixtureDistribution.Lambda[] lambda1
        = ((NormalMixtureDistribution) model1.getDistribution()).getParams();

System.out.println("original transition probabilities");
System.out.println(A0);
System.out.println("learned transition probabilities");
System.out.println(A1);

for (int i = 0; i &lt; lambda0.length; ++i) {
    System.out.println(String.format("compare mu: %f vs %f", lambda0[i].mu, lambda1[i].mu));
    System.out.println(String.format("compare sigma: %f vs %f", lambda0[i].sigma, lambda1[i].sigma));
}

</pre>
<p>输出如下所示:</p>
<pre>observations:
0.6667426768019611, -0.32352325221978717, 3.694903034165229, -1.3008707225256613, 0.07691232606090105, -1.0668653899699068, 1.2547831047356035, -0.3246773249494731, -3.1233208370458296, 0.07292920944831502, -0.11620867976390438, -0.09177918144492855, 1.061260530481548, 3.7632206619139903, 0.8109245344429039, -1.0456473967986801, 0.023362246470829524, 0.7787930654317092, -2.576397166364735, -0.0467834253483496,
3.503162408902286, 1.1028762361945696, 0.18432457538929753, -0.15602885867240143, 0.2860555006413944, 0.5199262544700902, 3.289672039992487, 0.3423964725249409, 1.4075325491240163, 4.10317186600716, 0.4828282434224251, 0.25452361143844454, 0.5712599275796462, -2.5704804292527013, 0.33450861675375654, -2.8531667206093934, -3.0936506692640764, -0.15973644756612507, -0.47277685283533033, 0.0707131186690788,
-1.7796825533737028, 0.9864117126346634, 0.2939922129246895, -2.5399726513271608, -2.6290623371098096, 0.25314785052888766, -0.18575291314328318, -0.7946029274675578, 0.23552969611536276, 2.9897693796241063, 0.5660684741804526, -0.6527078440547278, -0.5004832349155411, -0.2704637817979793, -0.6025767412479524, 0.5771268464391458, -0.24208449949682542, -0.02819954652010102, -2.486386056973469, -3.441724309397634,
-0.4133398692983409, 0.31129502315376223, -0.04193184097521976, -1.0182212276190052, -0.3671837409753249, 0.536533989621346, 3.462093125207502, -2.461234362203126, -2.3392296163644772, -0.47516934718702636, -0.11730581631252934, -0.4265784970780354, -0.8615577291928018, 6.920251345713026, 1.76323228509548, -2.6811368060909544, -1.5171036957836417, -4.899485440536609, -3.610116084182736, 0.33601950735980296,
-0.5835341423322717, 2.6648103130978678, 0.10317758590238832, 0.19254522009732306, -2.2919311524559345, -2.7407736539634344, 0.17291860725525898, 0.18227164156727216, -0.5643594075632472, -0.035583544387142646, -0.09409631532976256, -0.025219030831549336, 0.4529864965098783, -0.8837144318482597, -0.12251468831918433, -0.31744262647741256, 5.209863176061461, -2.474241618649255, 0.1755140184813729, 0.2368171868332689,

original transition probabilities
3x3
         [,1] [,2] [,3]
[1,] 0.400000, 0.200000, 0.400000,
[2,] 0.300000, 0.200000, 0.500000,
[3,] 0.250000, 0.250000, 0.500000,
learned transition probabilities
3x3
         [,1] [,2] [,3]
[1,] 0.413363, 0.192624, 0.394012,
[2,] 0.291749, 0.191727, 0.516524,
[3,] 0.262275, 0.245234, 0.492491,
compare mu: 0.000000 vs -0.006115
compare sigma: 0.500000 vs 0.509837
compare mu: 0.000000 vs 0.036859
compare sigma: 1.000000 vs 0.952345
compare mu: 0.000000 vs 0.000615
compare sigma: 2.500000 vs 2.559295

</pre>
<p class="Para" id="Par616">我们可以从输出中看到，EM 算法从每日股票回报中很好地学习了真正的 HMM，匹配了三种制度的方差。</p>



<h2 class="Heading">12.7 主成分分析</h2>
<p>考虑一个在 XY 平面上绘制(比如说，实验)数据的激励例子，如图<a href="#Fig56"> 12-56 </a>所示。我们看到两个变量<em class="EmphasisTypeItalic "> X </em>和<em class="EmphasisTypeItalic "> Y </em>非常相关。当<em class="EmphasisTypeItalic "> X </em>大时，<em class="EmphasisTypeItalic "> Y </em>趋于大。同样，当<em class="EmphasisTypeItalic "> X </em>小时，<em class="EmphasisTypeItalic "> Y </em>也趋于变小。实际上，<em class="EmphasisTypeItalic "> Y </em>可以近似为<em class="EmphasisTypeItalic "> X </em>的一个线性函数。如果我们只记录了<em class="EmphasisTypeItalic "> X </em>，我们对<em class="EmphasisTypeItalic "> Y </em>有足够好的估计。没有必要两者都记录；仅记录<em class="EmphasisTypeItalic "> X </em>就足够了。我们实质上是将二维数据“压缩”到一维空间。这是降维的基础。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig56_HTML.png" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig56_HTML.png" style="width:23.65em"/></p>
<p>图 12-56</p><p class="SimplePara">XY 平面上的数据</p>


<p>如果我们旋转 XY 平面的轴，使大多数点位于或靠近新的 x 轴，<em class="EmphasisTypeItalic ">x</em><sup>′</sup>，我们可以更好地看到尺寸的减少，如图<a href="#Fig57"> 12-57 </a>所示。我们实际上不需要记录<em class="EmphasisTypeItalic ">y</em>T8】′，因为它们在一个窄的频带内都接近 0。我们只需要记录<em class="EmphasisTypeItalic ">x</em><sup>’</sup>，因为它们可以取范围很广的许多值。数据大部分分布在<em class="EmphasisTypeItalic ">x</em>T16’上，这也是最大的差异所在。找到一个新的坐标系，使大部分方差只存在于轴的一个小的子集上，这有助于降低维数，过滤掉噪声，识别数据的重要部分，并识别模式。这正是主成分分析(PCA)的原理。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig57_HTML.png" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig57_HTML.png" style="width:23.65em"/></p>
<p>图 12-57</p><p class="SimplePara">旋转 XY 平面上的数据</p>


<p>Jon (2003)给出了另一个真实的例子来说明我们为什么以及如何进行 PCA。在实验物理学中，我们经常需要对一个现象进行多次测量。图<a href="#Fig58"> 12-58 </a>显示了我们使用三个摄像机来捕捉一个与弹簧相连的球的运动。在我们理解一个现象之前，我们不一定知道如何进行测量。我们可以简单地把摄像机放在方便和有空间的地方。每个摄像机从他们的视角记录一系列的<em class="EmphasisTypeItalic "> x </em> s 和<em class="EmphasisTypeItalic "> y </em> s。每个快照中共有六个坐标。<p> <img alt="$$ \boldsymbol{X}=\left[\begin{array}{c}{x}_A\\ {}{y}_A\\ {}{x}_B\\ {}{y}_B\\ {}{x}_C\\ {}{y}_C\end{array}\right] $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equio.png" style="width:4.8em"/> </p></p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig58_HTML.jpg" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig58_HTML.jpg" style="width:25.1em"/></p>
<p>图 12-58</p><p class="SimplePara">测量连接在弹簧上的球的运动</p>


<p>我们可以收集成千上万的坐标进行分析。然而，我们知道，事后来看，弹簧是如何工作的，这六个坐标的数据很难分析，它们隐藏了弹簧运动的全貌，弹簧实际上只朝一个方向运动。是否有可能“转换”数据，使主要组件易于可视化？从数学上来说，我们希望找到一个坐标的变化，或者说是基的变化，这样新的坐标就能反映弹簧来回弹跳的一维。即基矩阵<em> <strong class="EmphasisTypeBoldItalic "> P </strong> </em>的变化使得:<p> <img alt="$$ \boldsymbol{PX}=\boldsymbol{Y} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equip.png" style="width:3.76em"/> </p></p>
<p class="Para" id="Par621">其中<em> <strong class="EmphasisTypeBoldItalic "> X </strong> </em>为降级数据(在 PCA 中，我们总是先减去每个因子或行的平均值<em><strong class="EmphasisTypeBoldItalic ">X</strong></em><sub><em><strong class="EmphasisTypeBoldItalic ">I</strong></em></sub>)；<em> <strong class="EmphasisTypeBoldItalic "> Y </strong> </em>是新基础中的新坐标。详见第<a href="02.html"> 2 </a>章。</p>
<p>为了找到<em> <strong class="EmphasisTypeBoldItalic "> P </strong> </em>，我们需要强加一些性质来证明<em> <strong class="EmphasisTypeBoldItalic "> P </strong> </em>是基的良好变化。例如，我们希望在新的坐标系中使用<em> <strong class="EmphasisTypeBoldItalic "> Y </strong> </em>，这样</p>
<ul class="UnorderedListMarkBullet"><li><p class="Para" id="Par623">每个新轴的方差被最大化。</p></li>
<li><p class="Para" id="Par624">任何一对变量之间的协方差都是最小的，比如说，0。</p></li>
</ul>

<p>这两个性质基本上都是说<em> <strong class="EmphasisTypeBoldItalic "> Y </strong> </em>的协方差矩阵应该是对角矩阵。也就是说，对角线元素(方差)最大化，非对角线元素(协方差)为 0。数学上，我们有这样的:<p><img alt="$$ {\boldsymbol{S}}_{\boldsymbol{Y}}=\frac{1}{n-1}\boldsymbol{Y}{\boldsymbol{Y}}^T $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equiq.png" style="width:6.99em"/></p><p><img alt="$$ =\frac{1}{n-1}\left(\boldsymbol{PX}\right){\left(\boldsymbol{PX}\right)}^T $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equir.png" style="width:9.02em"/></p><p><img alt="$$ =\frac{1}{n-1}\boldsymbol{PX}{\boldsymbol{X}}^T\boldsymbol{P} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equis.png" style="width:7.23em"/></p></p>
<p>注意<em><strong class="EmphasisTypeBoldItalic ">A</strong></em>=<em><strong class="EmphasisTypeBoldItalic ">XX</strong></em><sup><em class="EmphasisTypeItalic ">T</em></sup>是<em><strong class="EmphasisTypeBoldItalic ">×15</strong></em>的协方差矩阵(去除样本均值和比例因子后)。它是对称的，因此是可对角化的。存在特征向量矩阵<em> <strong class="EmphasisTypeBoldItalic "> E </strong> </em>和对角矩阵<em> <strong class="EmphasisTypeBoldItalic "> D </strong> </em>使得:<p> <img alt="$$ \boldsymbol{A}=\boldsymbol{ED}{\boldsymbol{E}}^T $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equit.png" style="width:5.31em"/> </p></p>
<p>假设我们选择基的变化<em><strong class="EmphasisTypeBoldItalic ">P = E</strong></em><sup><em class="EmphasisTypeItalic ">T</em></sup>；我们有以下:<p> <img alt="$$ {\boldsymbol{S}}_{\boldsymbol{Y}}=\frac{1}{n-1}\boldsymbol{P}{\boldsymbol{P}}^T\boldsymbol{D}{\boldsymbol{P}}^T\boldsymbol{P} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equiu.png" style="width:9.94em"/> </p></p>
<p><img alt="$$ =\frac{1}{n-1}\boldsymbol{P}{\boldsymbol{P}}^{-1}\boldsymbol{D}{\boldsymbol{P}}^{-1}\boldsymbol{P} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq72.png" style="width:8.2em"/>，因为<em> <strong class="EmphasisTypeBoldItalic "> P </strong> </em>是正交的<p> <img alt="$$ =\frac{1}{n-1}\boldsymbol{D} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equiv.png" style="width:4.5em"/> </p></p>
<p class="Para" id="Par629">由此可见，<em><strong class="EmphasisTypeBoldItalic ">P = E</strong></em><sup>T5】T</sup>对角化<em><strong class="EmphasisTypeBoldItalic ">S</strong></em><sub><em><strong class="EmphasisTypeBoldItalic ">Y</strong></em></sub>。这就是 PCA 中的<em> <strong class="EmphasisTypeBoldItalic "> X </strong> </em>产生坐标的变化<em> <strong class="EmphasisTypeBoldItalic "> P </strong> </em>到有<em> <strong class="EmphasisTypeBoldItalic "> Y </strong> </em>。</p>
<p>我们也可以用奇异值分解进行主成分分析。对于退化数据(数据减去样本均值)<em> <strong class="EmphasisTypeBoldItalic "> X </strong> </em>，存在标准正交基<em> <strong class="EmphasisTypeBoldItalic "> U </strong> </em>和<em> <strong class="EmphasisTypeBoldItalic "> V </strong> </em>和对角矩阵<strong class="EmphasisTypeBold "/>使得:<p> <img alt="$$ \boldsymbol{X}=\boldsymbol{U}\boldsymbol{\Sigma } {\boldsymbol{V}}^T $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equiw.png" style="width:5.13em"/> </p></p>
<p>相当于，<p> <img alt="$$ {\boldsymbol{U}}^T\boldsymbol{X}=\boldsymbol{\Sigma} {\boldsymbol{V}}^T $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equix.png" style="width:5.67em"/> </p></p>
<p>在这里，我们又有了如下的变化依据:<p> <img alt="$$ \boldsymbol{P}={\boldsymbol{U}}^T $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equiy.png" style="width:3.6em"/> </p></p>
<p>而新的坐标为:<p> <img alt="$$ \boldsymbol{Y}=\boldsymbol{\Sigma} {\boldsymbol{V}}^T $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equiz.png" style="width:4.24em"/> </p></p>
<p class="Para" id="Par634"><em><strong class="EmphasisTypeBoldItalic "/></em>是跨越一个<em class="EmphasisTypeItalic "> n </em>维空间的向量的正交集合；<em> <strong class="EmphasisTypeBoldItalic "> V </strong> </em>是跨越一个<em class="EmphasisTypeItalic "> m </em>维空间的向量的正交集合。该 SVD 或 PCA 将 n<em class="EmphasisTypeItalic ">维空间投影到 m </em>维空间，从而降低维度。我们通常对<strong class="EmphasisTypeBold ">σ</strong>中的对角元素进行降序排序，以便我们可以选择截断无关紧要的奇异值。这将进一步减小投影空间的维度。回到图<a href="#Fig58"> 12-58 </a>中的弹簧示例，我们想找到旋转坐标的<em> <strong class="EmphasisTypeBoldItalic "> P </strong> </em>，以便大部分数据位于一个(新的)x 轴上。此外，我们只保留一个最重要的奇异值，并截断其他五个以消除噪声。这将数据的维数从 6 减少到 1。然后，我们可以很容易地想象和分析弹簧沿直线来回运动。</p>
<p>NM Dev 同时支持特征分解和 SVD 做 PCA。所有实现都继承自接口<code>PCA</code>。签名如下:</p>
<pre>public interface PCA {

    /**
     * Gets the number of observations in the original data; sample size.
     *
     * @return &lt;i&gt;nObs&lt;/i&gt;, the number of observations in the original data
     */
    public int nObs();

    /**
     * Gets the number of variables in the original data.
     *
     * @return &lt;i&gt;nFactors&lt;/i&gt;, the number of variables in the original data
     */
    public int nFactors();

    /**
     * Gets the sample means that were subtracted.
     *
     * @return the sample means of each variable in the original data
     */
    public Vector mean();

    /**
     * Gets the scalings applied to each variable.
     *
     * @return the scalings applied to each variable in the original data
     */
    public Vector scale();

    /**
     * Gets the (possibly centered and/or scaled) data matrix &lt;i&gt;X&lt;/i&gt; used for
     * the PCA.
     *
     * @return the (possibly centered and/or scaled) data matrix &lt;i&gt;X&lt;/i&gt;
     */
    public Matrix X();

    /**
     * Gets the standard deviations of the principal components (i.e., the
     * square roots of the eigenvalues of the correlation (or covariance)
     * matrix).
     *
     * @return the standard deviations of the principal components
     */
    public Vector sdPrincipalComponents();

    /**
     * Gets the standard deviation of the &lt;i&gt;i&lt;/i&gt;-th principal component.
     *
     * @param i an index, counting from 1
     * @return the standard deviation of the &lt;i&gt;i&lt;/i&gt;-th principal component.
     */
    public double sdPrincipalComponent(int i);

    /**
     * Gets the matrix of variable loadings.
     * The signs of the columns of the loading are arbitrary.
     *
     * @return the matrix of variable loadings
     */
    public Matrix loadings();

    /**
     * Gets the loading vector of the &lt;i&gt;i&lt;/i&gt;-th principal component.
     *
     * @param i an index, counting from 1
     * @return the loading vector of the &lt;i&gt;i&lt;/i&gt;-th principal component
     */
    public Vector loading(int i);

    /**
     * Gets the proportion of overall variance explained by each of the
     * principal components.
     *
     * @return the proportion of overall variance explained by each of the
     *         principal components
     */
    public Vector proportionVar();

    /**
     * Gets the proportion of overall variance explained by the &lt;i&gt;i&lt;/i&gt;-th
     * principal component.
     *
     * @param i an index, counting from 1
     * @return the proportion of overall variance explained by the &lt;i&gt;i&lt;/i&gt;-th
     *         principal component
     */
    public double proportionVar(int i);

    /**
     * Gets the cumulative proportion of overall variance explained by the
     * principal components
     *
     * @return the cumulative proportion of overall variance explained by the
     *         principal components
     */
    public Vector cumulativeProportionVar();

    /**
     * Gets the scores of supplied data on the principal components.
     * The signs of the columns of the scores are arbitrary.
     *
     * @return the scores of supplied data on the principal components
     */
    public Matrix scores();
}

</pre>
<p>例如，下面的代码运行 r 中美国逮捕数据的 PCA。(数据集在本书的源代码中给出。)</p>
<pre>// run PCA on the data using eigen decomposition
PCA pca = new PCAbyEigen(
        USArrests, // the data set in matrix form
        false // use covariance matrix instead of correlation matrix
);

// number of factors
int p = pca.nFactors();
// number of observations
int n = pca.nObs();

Vector mean = pca.mean();
Vector scale = pca.scale();
Vector sdev = pca.sdPrincipalComponents();
Matrix loadings = pca.loadings();
Vector proportion = pca.proportionVar();
Vector cumprop = pca.cumulativeProportionVar();
Matrix scores = pca.scores();

System.out.println("number of factors = " + p);
System.out.println("number of observations = " + n);

System.out.println("mean: " + mean);
System.out.println("scale: " + scale);
// The standard deviations differ by a factor of sqrt(50 / 49),
// since we use divisor (nObs - 1) for the sample covariance matrix
System.out.println("standard deviation: " + sdev);

// The signs of the columns of the loading are arbitrary.
System.out.println("loading: ");
System.out.println(loadings);

// the proportion of variance in each dimension
System.out.println("proportion of variance: " + proportion);
System.out.println("cumulative proportion of variance: " + cumprop);

System.out.println("score: ");
System.out.println(scores);

</pre>
<p>输出如下所示:</p>
<pre>number of factors = 4
number of observations = 50
mean: [7.788000, 170.760000, 65.540000, 21.232000]
scale: [1.000000, 1.000000, 1.000000, 1.000000]
standard deviation: [83.732400, 14.212402, 6.489426, 2.482790]
loading:
4x4
         [,1] [,2] [,3] [,4]
[1,] -0.041704, 0.044822, 0.079891, 0.994922,
[2,] -0.995221, 0.058760, -0.067570, -0.038938,
[3,] -0.046336, -0.976857, -0.200546, 0.058169,
[4,] -0.075156, -0.200718, 0.974081, -0.072325,
proportion of variance: [0.965534, 0.027817, 0.005800, 0.000849]
cumulative proportion of variance: [0.965534, 0.993352, 0.999151, 1.000000]

</pre>
<p class="Para" id="Par638">PCA 将数据的维数从 4 降低到 1 或 2。第一个主成分占数据可变性的 96.6%。前两个主成分占数据可变性的 99%。我们可以安全地截断最后两个部分。</p>
<p>下面的代码使用 SVD 解决了同样的问题:</p>
<pre>// run PCA on the data using SVD
PCA pca = new PCAbySVD(
        USArrests // the data set in matrix form
);

// number of factors
int p = pca.nFactors();
// number of observations
int n = pca.nObs();

Vector mean = pca.mean();
Vector scale = pca.scale();
Vector sdev = pca.sdPrincipalComponents();
Matrix loadings = pca.loadings();
Vector proportion = pca.proportionVar();
Vector cumprop = pca.cumulativeProportionVar();

System.out.println("number of factors = " + p);
System.out.println("number of observations = " + n);

System.out.println("mean: " + mean);
System.out.println("scale: " + scale);
// The standard deviations differ by a factor of sqrt(50 / 49),
// since we use divisor (nObs - 1) for the sample covariance matrix
System.out.println("standard deviation: " + sdev);

// The signs of the columns of the loading are arbitrary.
System.out.println("loading: ");
System.out.println(loadings);

// the proportion of variance in each dimension
System.out.println("proportion of variance: " + proportion);
System.out.println("cumulative proportion of variance: " + cumprop);

</pre>
<p>输出如下所示:</p>
<pre>number of factors = 4
number of observations = 50
mean: [7.788000, 170.760000, 65.540000, 21.232000]
scale: [4.355510, 83.337661, 14.474763, 9.366385]
standard deviation: [1.574878, 0.994869, 0.597129, 0.416449]
loading:
4x4
         [,1] [,2] [,3] [,4]
[1,] 0.535899, -0.418181, -0.341233, 0.649228,
[2,] 0.583184, -0.187986, -0.268148, -0.743407,
[3,] 0.278191, 0.872806, -0.378016, 0.133878,
[4,] 0.543432, 0.167319, 0.817778, 0.089024,
proportion of variance: [0.620060, 0.247441, 0.089141, 0.043358]
cumulative proportion of variance: [0.620060, 0.867502, 0.956642, 1.000000]

</pre>

<h2 class="Heading">12.8 因素分析</h2>
<p class="Para" id="Par641">因子分析是用来解释一组相关的变量或观察值，即数量较少的未观察到的变量，称为因子。例如，十个观察变量的变化可能主要反映了两个未观察(潜在)变量的变化。观察变量被建模为未观察因素加上“误差”项的线性组合。类似于 PCA，它有助于降低数据的维数。在处理大型数据集时，因子分析通常用于生物学、心理测量学、人格理论、市场营销、产品管理、运筹学和金融学。</p>
<p class="Para" id="Par642">这个概念最好用一个例子来说明。假设一个心理学家有这样一个假设，智力有两种，言语智力和数学智力，这两种智力都不是直接观察到的。从 1000 名学生的 10 个不同学术领域的考试成绩中寻找该假设的证据。心理学家的假设说，对于 10 个学术领域中的每一个，学生的分数是他的语言智力和数学智力的线性组合。虽然每个学生都有他们的语言智能和数学智能，但这两个因素的系数对每个人都是一样的。这些系数被称为因子载荷。因子的因子负荷量化了观察变量与给定因子相关的程度(权重)。例如，假设可以预测学生的天文学分数如下:</p>
<p class="Para" id="Par643">{10 ×学生的语言智力} + {6 ×学生的数学智力}</p>
<p class="Para" id="Par644">数字 10 和 6 是与天文学相关的因子载荷。其他学科可能有不同的因素负荷。</p>
<p class="Para" id="Par645">假设两个学生具有相同的语言和数学智能，因此预测的分数相同，但他们在天文学和其他学科的分数可能不同。预测值和实际值(观察值)之间的这种差异称为误差。</p>
<p class="Para" id="Par646">可观察的数据是 1000 名学生对总共 10000 个数字的 10 个分数。未观察到的因子值(每个学生 2 个，总共 2000 个数字)和因子负荷是使用因子分析从数据中估计的。</p>
<p>我们可以写出数学中的关系。对于一个学生<em class="EmphasisTypeItalic "> i </em>，他在 10 个科目中的标准化 z 分数(我们使用 z 分数，以便所有变量的大小是可比较的)可以建模如下:<p> <img alt="$$ {\displaystyle \begin{array}{c}{z}_{1,i}={l}_{1,1}{F}_{1,i}+{l}_{1,2}{F}_{2,i}+{\varepsilon}_{1,i}\\ {}\vdots \\ {}{z}_{10,i}={l}_{10,1}{F}_{1,i}+{l}_{10,2}{F}_{2,i}+{\varepsilon}_{10,i}\end{array}} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equja.png" style="width:14.06em"/> </p></p>
<p>或者，更简洁地说，可以这样写:<p> <img alt="$$ {z}_{a,i}=\sum \limits_{p=1}^2{l}_{a,1}{F}_{p,i}+{\varepsilon}_{a,i} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equjb.png" style="width:9.66em"/> </p></p>
<p>其中<em class="EmphasisTypeItalic "> F </em> <sub> 1，<em class="EmphasisTypeItalic ">I</em>T5】为学生<em class="EmphasisTypeItalic "> i </em>的言语智力，<em class="EmphasisTypeItalic "> F </em> <sub> 2，<em class="EmphasisTypeItalic "> i </em> </sub>为学生<em class="EmphasisTypeItalic "> i </em>的数学智力，<em class="EmphasisTypeItalic "> l </em> <sub> <em class="EmphasisTypeItalic "> a </em>，<em class="EmphasisTypeItalic "> p </em> </sub>为<em class="EmphasisTypeItalic ">a</em>-的因子载荷见图<a href="#Fig59"> 12-59 </a>。</sub></p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig59_HTML.png" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig59_HTML.png" style="width:20.9em"/></p>
<p>图 12-59</p><p class="SimplePara">因子分析的几何解释</p>


<p class="Para" id="Par650">几何上，数据(<em class="EmphasisTypeItalic "> z </em> <sub> <em class="EmphasisTypeItalic "> a </em>、<em class="EmphasisTypeItalic "> i </em> </sub>)、因子(<em class="EmphasisTypeItalic "> F </em> <sub> <em class="EmphasisTypeItalic "> p </em>、<em class="EmphasisTypeItalic "> i </em> </sub>)、误差(<em class="EmphasisTypeItalic "> ε </em> <sub> <em class="EmphasisTypeItalic "> a </em>、<em class="EmphasisTypeItalic "> i </em> </sub>)可以看作是一个<em class="EmphasisTypeItalic "> N </em>维欧几里德中的向量 <em><strong class="EmphasisTypeBoldItalic ">F</strong></em><sub><em><strong class="EmphasisTypeBoldItalic ">j</strong></em></sub>和<em><strong class="EmphasisTypeBoldItalic ">ε</strong></em><sub><em><strong class="EmphasisTypeBoldItalic ">a</strong></em></sub>分别。 由于数据是标准化的，所以数据向量是单位长度的(‖<em><strong class="EmphasisTypeBoldItalic ">z</strong></em><sub><em><strong class="EmphasisTypeBoldItalic ">a</strong></em></sub>‖<em><strong class="EmphasisTypeBoldItalic ">=</strong></em>1)。因子向量在该空间中定义了一个<em class="EmphasisTypeItalic "> k </em>维线性子空间(即超平面)，数据向量被正交投影到该子空间上。在前面的例子中，超平面是由两个因子向量定义的二维平面，如图<a href="#Fig59"> 12-59 </a>所示。因子分析的目标是找到一个在某种意义上“最适合”数据的超平面，所以定义这个超平面的因子向量如何选择并不重要，只要它们是独立的，并且位于超平面中。</p>
<p>一般来说，对于所有学生所有科目，用矩阵表示法，我们有这样的:<p> <img alt="$$ Z= LF+\varepsilon $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equjc.png" style="width:5.24em"/> </p></p>
<p>NM Dev 类<code>FactorAnalysis</code>实现因子分析过程，找到给定<em class="EmphasisTypeItalic "> Z </em>(或<em class="EmphasisTypeItalic "> X </em>)的<em class="EmphasisTypeItalic "> L </em>、<em class="EmphasisTypeItalic "> F </em>和<em class="EmphasisTypeItalic "> ε </em>。这里有一个例子:</p>
<pre>// number of hidden factors
int nFactors = 3;
FactorAnalysis factor_analysis
        = new FactorAnalysis(
                R_data,
                nFactors,
                FactorAnalysis.ScoringRule.THOMSON // specify the scoring rule
        );

System.out.println("number of observations = " + factor_analysis.nObs());
System.out.println("number of variables = " + factor_analysis.nVariables());
System.out.println("number of factors = " + factor_analysis.nFactors());

// covariance matrix


Matrix S = factor_analysis.S();
System.out.println("covariance matrix:");
System.out.println(S);

FAEstimator estimators = factor_analysis.getEstimators(700);
double fitted = estimators.logLikelihood();
System.out.println("log-likelihood of the fitting = " + fitted);

Vector uniqueness = estimators.psi();
System.out.println("uniqueness = " + uniqueness);

int dof = estimators.dof();
System.out.println("degree of freedom = " + dof);

// the factor loadings
Matrix loadings = estimators.loadings();
System.out.println("factor loadings:");
System.out.println(loadings);

double testStats = estimators.statistics();
System.out.println("test statistics = " + testStats);

double pValue = estimators.pValue();
System.out.println("p-value = " + pValue);

Matrix scores = estimators.scores();
System.out.println("scores:");
System.out.println(scores);

</pre>
<p>输出如下所示:</p>
<pre>number of observations = 18
number of variables = 6
number of factors = 3
covariance matrix:
6x6
         [,1] [,2] [,3] [,4] [,5] [,6]
[1,] 1.000000, 0.939308, 0.512887, 0.432031, 0.466495, 0.408608,
[2,] 0.939308, 1.000000, 0.412444, 0.408428, 0.436393, 0.432611,
[3,] 0.512887, 0.412444, 1.000000, 0.877075, 0.512887, 0.432031,
[4,] 0.432031, 0.408428, 0.877075, 1.000000, 0.432031, 0.432326,
[5,] 0.466495, 0.436393, 0.512887, 0.432031, 1.000000, 0.947345,
[6,] 0.408608, 0.432611, 0.432031, 0.432326, 0.947345, 1.000000,
log-likelihood of the fitting = 0.475515649954116
uniqueness = [0.005000, 0.100900, 0.005000, 0.224053, 0.084290, 0.005000]
degree of freedom = 0
factor loadings:
6x3
         [,1] [,2] [,3]
[1,] 0.943840, 0.181926, 0.266614,
[2,] 0.904720, 0.234836, 0.159479,
[3,] 0.235639, 0.209603, 0.946344,
[4,] 0.179976, 0.242255, 0.827568,
[5,] 0.242107, 0.880640, 0.285599,
[6,] 0.192766, 0.958837, 0.196209,
test statistics = 5.785440407775078
p-value = -1.0
scores:
18x3
         [,1] [,2] [,3]
[1,] -0.896511, -0.924689, 0.936376,
[2,] -0.861396, -0.926617, 0.924255,
[3,] -0.900730, -0.925772, 0.950364,
[4,] -0.993305, -0.251413, 0.808659,
[5,] -0.896511, -0.924689, 0.936376,
[6,] -0.741151, 0.720108, -0.783533,
[7,] -0.706036, 0.718180, -0.795654,
[8,] -0.745370, 0.719025, -0.769545,
[9,] -0.802830, 1.391456, -0.923371,
[10,] -0.741151, 0.720108, -0.783533,
[11,] 0.916893, -0.925056, -0.830334,
[12,] 0.952008, -0.926984, -0.842455,
[13,] 0.912674, -0.926140, -0.816346,
[14,] 0.820099, -0.251780, -0.958051,
[15,] 0.916893, -0.925056, -0.830334,
[16,] 0.426454, 2.035689, 1.282442,
[17,] 1.464788, 1.290102, 0.547953,
[18,] 1.875185, 0.313530, 1.946731,



</pre>

<h2 class="Heading">12.9 协方差选择</h2>
<p>本节遵循 d'Aspremont (2011 年)的内容。协方差矩阵是建立协变量模型和理解变量之间关系的基础。它是许多算法中的一条关键信息，例如投资组合优化(需要协方差矩阵的逆矩阵)。为了深入了解为什么估计协方差矩阵很困难，我们看一下我们想要估计 3，000 只股票(大约是纽约证券交易所上市股票的数量)的协方差矩阵的情况。协方差矩阵是一个 3000 × 3000 的矩阵。因为对称性，自由元素的个数如下:<p> <img alt="$$ \frac{3000^2+3000}{2}=4,504,500 $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equjd.png" style="width:12.21em"/> </p></p>
<p class="Para" id="Par655">换句话说，我们需要估计大约 450 万个参数！鉴于有限的数据集，这似乎远远超出了可行性。10 年的数据，只有 2500 个交易日。对于 100 年的数据(不确定我们是否真的有这么多记录)，只有 25，000 个交易日，这是(错误地)假设股票的协方差在过去 100 年中没有变化。</p>
<p class="Para" id="Par656">从真实数据估计协方差矩阵通常是困难的。这个课题已经有很多研究了。12.2.9.4 和 12.2.9.5 的收缩方法是一种方法。另一种流行的方法是对协方差矩阵施加结构，例如将协方差矩阵的逆矩阵中的元素设置为零。后一种方法称为协方差选择。</p>
<p>逆协方差矩阵中的零对应于模型中的条件独立变量，这种方法可用于同时获得协方差矩阵的稳健估计，同时，可能更重要的是，发现底层图形模型中的结构。这种权衡是在解矩阵的对数似然<em><strong class="EmphasisTypeBoldItalic ">×对数似然</strong>×对数似然</em>和其逆矩阵(即模型结构)中的零个数之间进行的，可以形式化为下面的问题:<p> <img alt="$$ \underset{\boldsymbol{X}}{\max}\left\{\log \det \left(\boldsymbol{X}\right)- Tr\left(\boldsymbol{\Sigma} \boldsymbol{X}\right)-\rho \mathrm{Card}\left(\boldsymbol{X}\right)\right\} $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equje.png" style="width:17.78em"/> </p></p>
<p class="Para" id="Par658">这里我们选择一个协方差矩阵<em> <strong class="EmphasisTypeBoldItalic "> X </strong> </em>。Card( <em> <strong class="EmphasisTypeBoldItalic "> X </strong> </em>)是<em> <strong class="EmphasisTypeBoldItalic "> X </strong> </em>的基数，即<em><strong class="EmphasisTypeBoldItalic ">X</strong></em><em class="EmphasisTypeItalic ">ρ</em>&gt;0 中非零系数的个数，是控制似然性和结构之间权衡的参数。</p>
<p>解决这个被惩罚的最大似然估计问题既通过隐含地减少参数的数量提高了这个估计过程的稳定性，又直接突出了基础模型中的结构。不幸的是，基数损失使得这个问题很难用数字来解决。d'Aspremont (2011 年)描述了一个解决方案。就是放宽卡(<em> <strong class="EmphasisTypeBoldItalic "> X </strong> </em>)罚，代之以<em> <strong class="EmphasisTypeBoldItalic "> X </strong> </em>系数的(凸)L1 范数来求解代替。<p> <img alt="$$ \underset{\boldsymbol{X}}{\max}\left(\log \det \left(\boldsymbol{X}\right)- Tr\left(\boldsymbol{\Sigma} \boldsymbol{X}\right)-\rho \sum \limits_{i,j=1}^n\left|{X}_{ij}\right|\right) $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_Equjf.png" style="width:17.8em"/> </p></p>
<p class="Para" id="Par660">涉及<em> <strong class="EmphasisTypeBoldItalic "> X </strong> </em>的条目的绝对值之和的惩罚项充当基数的代理:函数<img alt="$$ \sum \limits_{i,j=1}^n\left|{X}_{ij}\right| $$" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Chapter_TeX_IEq73.png" style="width:3.72em"/>可以被视为超立方体上用于秩最小化的 Card( <em> <strong class="EmphasisTypeBoldItalic "> X </strong> </em>)上的最大凸下界。它也常用于回归和变量选择程序，如套索。</p>
<p class="Para" id="Par661">在多元高斯分布中，逆协方差矩阵中的零指向条件独立的变量，以所有剩余变量为条件。这有一个清晰的金融解释:逆协方差矩阵反映了资产价格动态的特质成分之间的独立性关系。</p>
<p>图<a href="#Fig60"> 12-60 </a>显示了由此产生的依赖性网络，或美国互换利率的图形模型。在此图中，当且仅当变量(节点)有条件依赖时，它们才由链接连接。这是从逆样本协方差矩阵中的零模式推断出的图形模型。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig60_HTML.jpg" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig60_HTML.jpg" style="width:14.55em"/></p>
<p>图 12-60</p><p class="SimplePara">从逆样本协方差矩阵中的零点模式推断的条件依赖网络</p>


<p>图<a href="#Fig61"> 12-61 </a>显示了相同的图，这次使用了惩罚参数<em class="EmphasisTypeItalic "> ρ </em> = 0.1 的惩罚协方差估计。请注意，在补偿估计中，利率是按到期时间聚集的。该图清楚地显示，互换利率是一条曲线。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig61_HTML.jpg" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig61_HTML.jpg" style="width:14.17em"/></p>
<p>图 12-61</p><p class="SimplePara">使用惩罚协方差估计的条件依赖网络</p>


<p>NM Dev 类<code>CovarianceSelectionLASSO</code>实现了协方差选择的套索方法。这里有一个例子:</p>
<pre>// generate random samples from standard normal distribution
StandardNormalRNG rnorm = new StandardNormalRNG();
rnorm.seed(1234567890L);
int nRows = 50;
int nCols = 10;
Matrix X = new DenseMatrix(nRows, nCols);
for (int i = 1; i &lt;= nRows; ++i) {
    for (int j = 1; j &lt;= nCols; ++j) {
        X.set(i, j, rnorm.nextDouble());
    }
}

// sample covariance matrix
Matrix S = new SampleCovariance(X);
System.out.println("sample covariance:");
System.out.println(S);
Matrix S_inv = new Inverse(S);
System.out.println("inverse sample covariance:");
System.out.println(S_inv);

// the penalty parameter
double rho = 0.03;
CovarianceSelectionProblem problem
        = new CovarianceSelectionProblem(S, rho);
CovarianceSelectionLASSO lasso
        = new CovarianceSelectionLASSO(problem, 1e-5);
Matrix sigma = lasso.covariance();
System.out.println("estimated sigma:");
System.out.println(sigma);
System.out.println("inverse sigma:");
Matrix sigma_inv = lasso.inverseCovariance();
System.out.println(sigma_inv);

</pre>
<p>输出如下所示:</p>
<pre>sample covariance:
10x10
         [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
[1,] 1.257573, -0.268311, -0.004012, 0.016913, 0.165132, -0.141960, -0.120079, -0.160693, -0.004260, -0.020667,
[2,] -0.268311, 0.967782, -0.095157, 0.024637, -0.072037, 0.247739, 0.087125, 0.104371, 0.027777, -0.120613,
[3,] -0.004012, -0.095157, 1.054483, -0.265138, -0.052141, -0.060283, 0.183169, 0.019140, -0.153415, -0.249564,
[4,] 0.016913, 0.024637, -0.265138, 1.349217, 0.198557, 0.152614, -0.241012, -0.312265, 0.129352, -0.005313,
[5,] 0.165132, -0.072037, -0.052141, 0.198557, 0.757638, 0.051643, -0.104339, -0.155671, -0.057254, -0.049277,
[6,] -0.141960, 0.247739, -0.060283, 0.152614, 0.051643, 1.040272, -0.062670, -0.145262, -0.054679, -0.032205,
[7,] -0.120079, 0.087125, 0.183169, -0.241012, -0.104339, -0.062670, 1.010590, 0.215534, 0.096810, -0.236964,
[8,] -0.160693, 0.104371, 0.019140, -0.312265, -0.155671, -0.145262, 0.215534, 1.265944, 0.165415, 0.042200,
[9,] -0.004260, 0.027777, -0.153415, 0.129352, -0.057254, -0.054679, 0.096810, 0.165415, 0.819512, -0.059635,
[10,] -0.020667, -0.120613, -0.249564, -0.005313, -0.049277, -0.032205, -0.236964, 0.042200, -0.059635, 0.903708,
inverse sample covariance:
10x10
         [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
[1,] 0.889463, 0.204701, 0.024410, 0.040368, -0.159001, 0.093188, 0.082792, 0.084561, -0.031126, 0.064997,
[2,] 0.204701, 1.220477, 0.158580, -0.010523, 0.089933, -0.266324, -0.053575, -0.099297, 0.020385, 0.198650,
[3,] 0.024410, 0.158580, 1.139158, 0.169159, 0.065688, 0.019023, -0.114823, 0.004253, 0.223593, 0.326010,
[4,] 0.040368, -0.010523, 0.169159, 0.898154, -0.177519, -0.076864, 0.156986, 0.189060, -0.179432, 0.059589,
[5,] -0.159001, 0.089933, 0.065688, -0.177519, 1.459253, -0.061742, 0.069285, 0.068113, 0.121494, 0.125836,
[6,] 0.093188, -0.266324, 0.019023, -0.076864, -0.061742, 1.075471, 0.046224, 0.113329, 0.065587, 0.017503,
[7,] 0.082792, -0.053575, -0.114823, 0.156986, 0.069285, 0.046224, 1.175381, -0.123063, -0.130119, 0.274742,
[8,] 0.084561, -0.099297, 0.004253, 0.189060, 0.068113, 0.113329, -0.123063, 0.925784, -0.191756, -0.089434,
[9,] -0.031126, 0.020385, 0.223593, -0.179432, 0.121494, 0.065587, -0.130119, -0.191756, 1.366450, 0.136669,
[10,] 0.064997, 0.198650, 0.326010, 0.059589, 0.125836, 0.017503, 0.274742, -0.089434, 0.136669, 1.317651,
estimated sigma:
10x10
         [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
[1,] 1.257573, -0.003607, -0.000000, 0.000088, 0.004447, -0.000108, -0.000000, -0.000003, -0.000000, 0.000000,
[2,] -0.003607, 0.967782, -0.000000, -0.000000, -0.000013, 0.029033, 0.000000, 0.000000, 0.000000, 0.000000,
[3,] -0.000000, -0.000000, 1.054483, -0.000000, -0.000000, -0.000000, 0.000564, 0.000001, -0.021276, -0.019718,
[4,] 0.000088, -0.000000, -0.000000, 1.349217, 0.035708, -0.000000, -0.000054, -0.038336, -0.000377, 0.000001,
[5,] 0.004447, -0.000013, -0.000000, 0.035708, 0.757638, -0.000000, -0.000001, -0.001014, -0.000010, 0.000000,
[6,] -0.000108, 0.029033, -0.000000, -0.000000, -0.000000, 1.040272, -0.000000, 0.000000, -0.000000, 0.000000,
[7,] -0.000000, 0.000000, 0.000564, -0.000054, -0.000001, -0.000000, 1.010590, 0.001605, 0.000004, -0.011437,
[8,] -0.000003, 0.000000, 0.000001, -0.038336, -0.001014, 0.000000, 0.001605, 1.265944, 0.012436, -0.000018,
[9,] -0.000000, 0.000000, -0.021276, -0.000377, -0.000010, -0.000000, 0.000004, 0.012436, 0.819512, 0.000398,
[10,] 0.000000, 0.000000, -0.019718, 0.000001, 0.000000, 0.000000, -0.011437, -0.000018, 0.000398, 0.903708,
inverse sigma:
10x10
         [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
[1,] 0.795208, 0.002964, 0.000000, 0.000072, -0.004671, 0.000000, 0.000000, 0.000000, 0.000000, -0.000000,
[2,] 0.002964, 1.034168, 0.000000, -0.000000, 0.000000, -0.028863, -0.000000, -0.000000, -0.000000, -0.000000,
[3,] 0.000000, 0.000000, 0.949216, -0.000000, 0.000000, 0.000000, -0.000296, -0.000242, 0.024637, 0.020696,
[4,] 0.000072, -0.000000, -0.000000, 0.742735, -0.034976, 0.000000, 0.000004, 0.022464, -0.000000, -0.000000,
[5,] -0.004671, 0.000000, 0.000000, -0.034976, 1.321568, 0.000000, 0.000000, -0.000000, -0.000000, -0.000000,
[6,] 0.000000, -0.028863, 0.000000, 0.000000, 0.000000, 0.962092, 0.000000, -0.000000, 0.000000, -0.000000,
[7,] 0.000000, -0.000000, -0.000296, 0.000004, 0.000000, 0.000000, 0.989665, -0.001255, -0.000000, 0.012519,
[8,] 0.000000, -0.000000, -0.000242, 0.022464, -0.000000, -0.000000, -0.001255, 0.790724, -0.011995, 0.000000,
[9,] 0.000000, -0.000000, 0.024637, -0.000000, -0.000000, 0.000000, -0.000000, -0.011995, 1.221060, -0.000000,
[10,] -0.000000, -0.000000, 0.020696, -0.000000, -0.000000, -0.000000, 0.012519, 0.000000, -0.000000, 1.107162,

</pre>
<p class="Para" id="Par666">我们看到，与样本协方差矩阵(及其逆矩阵)相比，惩罚协方差矩阵(及其逆矩阵)更接近单位矩阵(因为数据是同分布标准正态，所以应该如此)，这突出了样本协方差矩阵的问题以及 LASSO 协方差选择方法的有效性。</p>
<p>Sustik &amp; Ben (2012)开发了一个比原始套索实现速度更快的实现。图<a href="#Fig62"> 12-62 </a>显示了各种 LASSO 实现之间的基准比较。</p>
<p><img alt="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig62_HTML.jpg" src="../images/500382_1_En_12_Chapter/500382_1_En_12_Fig62_HTML.jpg" style="width:26.85em"/></p>
<p>图 12-62</p><p class="SimplePara">比较 GLASSOFAST 和 GLASSO</p>


<p>NM Dev 类<code>CovarianceSelectionGLASSOFAST</code>实现了协方差选择的快速套索算法。这里有一个例子:</p>
<pre>// generate random samples from standard normal distribution
StandardNormalRNG rnorm = new StandardNormalRNG();
rnorm.seed(1234567890L);
int nRows = 50;
int nCols = 10;
Matrix X = new DenseMatrix(nRows, nCols);
for (int i = 1; i &lt;= nRows; ++i) {
    for (int j = 1; j &lt;= nCols; ++j) {
        X.set(i, j, rnorm.nextDouble());
    }
}

// sample covariance matrix
Matrix S = new SampleCovariance(X);
System.out.println("sample covariance:");
System.out.println(S);
Matrix S_inv = new Inverse(S);
System.out.println("inverse sample covariance:");
System.out.println(S_inv);

// the penalty parameter
double rho = 0.03;
CovarianceSelectionProblem problem
        = new CovarianceSelectionProblem(S, rho);

long time1 = System.currentTimeMillis();
CovarianceSelectionLASSO lasso
        = new CovarianceSelectionLASSO(problem, 1e-5);
Matrix sigma = lasso.covariance();
time1 = System.currentTimeMillis() - time1;

System.out.println("estimated sigma:");
System.out.println(sigma);
System.out.println("inverse sigma:");
Matrix sigma_inv = lasso.inverseCovariance();
System.out.println(sigma_inv);

long time2 = System.currentTimeMillis();
CovarianceSelectionGLASSOFAST lasso2 = new CovarianceSelectionGLASSOFAST(problem);
Matrix sigma2 = lasso2.covariance();
time2 = System.currentTimeMillis() - time2;

System.out.println("CovarianceSelectionLASSO took " + time1 + " millisecs");
System.out.println("CovarianceSelectionGLASSOFAST took " + time2 + " millisecs ");

</pre>
<p>输出如下所示:</p>
<pre>CovarianceSelectionLASSO took 542 millisecs
CovarianceSelectionGLASSOFAST took 9 millisecs

</pre>
<p class="Para" id="Par670">显然，GLASSOFAST 比传统的 LASSO 实现快几个数量级。</p>



</body>
</html>