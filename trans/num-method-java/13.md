# 13.随机数和模拟

随机数或随机变量是随机过程的结果，其结果是不确定的。我们只能知道后验变量的确切值，也就是事后的意思。例如，下一次掷骰子是随机的。我们只有滚过之后才知道脸。掷硬币也是随机的。我们只有在事情发生后才知道事实。看待随机变量的另一种方式是看它揭示了什么信息。例如，虽然一个班级学生的考试成绩是固定的，但它是随机的，因为在我们看到它之前，它对我们来说是未知的或不确定的。我们只有在信息可用后才知道考试分数。因此，许多应用和物理现象都是随机的，要么是因为它们的性质、不确定性，要么是因为无法获得信息。对随机数的研究是统计学的核心。

有许多方法可以产生随机数。这些方法被称为随机数生成器(RNG)。RNG 最重要的特点是它能产生独立同分布的随机数。也就是说，下一个生成的随机数与之前生成的任何数都没有关系，只是它们来自同一个概率分布。

真正的随机数是利用物理现象产生的，例如掷硬币、掷骰子、电子元件的噪声、核裂变和放射性衰变。这种 RNG 被称为物理随机数生成器。它们价格昂贵，并且难以集成到计算机中。用计算机生成真随机数，我们可以统计，比如一段时间内的计算次数，系统时间的误差，声卡的噪音。实际上，我们不使用真随机数，因为它们的生产成本很高。更重要的是，它们是不可重复的。通常，我们必须在模拟中重复相同的随机数序列，以使我们的计算和实验可重复。调试一个我们可以重现的问题也比调试一个每次都在变化的问题要容易得多。

伪随机数发生器是一种算法，旨在生成没有任何模式的伪随机数序列。重要的是要知道序列根本不是随机的，它完全是由相对较小的一组初始值决定的。了解生成算法和状态可以预测下一个值。“看似”的随机值是以确定的方式产生的。另一方面，它们具有很长的周期，这意味着它们不会重复相同的模式，直到经过很长的序列。它们具有与真实对应物相似的统计特性。一个好的伪 RNG 或简单的 RNG 实现必须很快，因为我们经常需要在应用程序中生成数百万或数十亿甚至更多的随机数。此外，我们可以通过检查 RNG 生成的随机数的一致性、随机性和独立性来评估其质量。

## 13.1 统一随机数发生器

最简单的 RNG 是一类均匀 RNG。它们根据均匀分布产生 0 和 1 之间的随机数。也就是说，0 和 1 之间的任何数字都有均等的机会被选中。它们是所有其他更复杂 RNG 的构建模块，例如从高斯、贝塔和伽马 RNG 等概率分布中采样的 RNG。更复杂的分布通常会对均匀分布进行转换。

### 13.1.1 线性同余法

用于均匀分布的经典且最著名的伪随机数发生器算法是线性同余发生器(lcg)家族。他们首先产生整数，然后将它们缩放到单位区间内。这个理论相对容易理解。它们易于实现且速度很快，特别是在通过存储位截断支持模运算的计算机硬件上。

两个整数 A 和 B 相对于模 M 全等当且仅当它们被自然数 M 整除时有相同的余数这里有个例子:

![$$ 55=7\times 7+6 $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equa.png)

![$$ 461=65\times 7+6 $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equb.png)

461 除以 7 有余数 6；55 除以 7 还有余数 6。因此，461 和 55 对于模 7 是全等的。我们写下如下内容:

461≡55 mod 7

LCG 由以下递归关系定义:

![$$ {X}_{n+1}=\left(a{X}_n+c\right)\operatorname{mod}m $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equc.png)

*X*<sub>T3】nT5】是一个随机数序列。</sub>

*m* ，0 < *m* ，这是模数。

*a* ，0 < *a* < *m* ，也就是乘数。

0 ≤ *c* < *m* ，这是增量也叫偏移量。

*X* <sub>0</sub> ，0≤*X*<sub>0</sub><*m*，这是起始值。

给定一个起始值 *X* <sub>0</sub> ，我们可以继续运行递归关系来产生一个随机数序列。假设参数选择得当，随机性的质量是好的。所有可能的整数最终都会出现。序列的最大周期为 *m* 。然而，LCG 的质量很大程度上取决于所选择的参数。它可以产生短周期甚至非随机数(高度序列相关)。我们通常不会手动选择这些参数。

Lehmer 随机数发生器是一种流行的参数选择。它将 *m* 设置为质数或质数的幂，并且 *c* = 0。例如，NM Dev 默认使用 *m* = 2147483563 和 *a* = 40014。

LCG 的一个问题是周期对于应用来说可能太小。创建更大周期的 LCG 的一种方法是将几个 lcg 组合在一起。复合 LCG 的输出相当于单个 LCG 的输出，其模数与分量发生器模数的乘积相同，其周期为分量周期的最小公倍数。

在 NM Dev 中，我们有一套随机数生成器。随机数发生器的签名如下。方法`seed`将 RNG 初始化为随机序列的开始。方法`nextDouble`基于特定 RNG 的属性产生下一个随机数。

```py
public interface Seedable {

    /**
     * Seed the random number/vector/scenario generator to produce repeatable experiments.
     *
     * @param seeds the seeds
     */
    public void seed(long... seeds);
}

public interface RandomNumberGenerator extends Seedable {

    /**
     * Get the next random {@code double}.
     *
     * @return the next random number
     */
    public double nextDouble();
}

```

下面的代码使用不同的 lcg 生成了许多随机数序列。LCG 的方法`nextLong`产生整数；方法`nextDouble`产生 0 和 1 之间的双精度值。

```py
System.out.println("generate randome numbers using an Lehmer RNG:");
RandomLongGenerator rng1 = new Lehmer();
rng1.seed(1234567890L);
generateIntAndPrint(rng1, 10);
double[] arr = generate(rng1, 10);
print(arr);

System.out.println("generate randome numbers using an LEcuyer RNG:");
RandomLongGenerator rng2 = new LEcuyer();
rng2.seed(1234567890L);
generateIntAndPrint(rng2, 10);
arr = generate(rng2, 10);
print(arr);

System.out.println("generate randome numbers using a composite LCG:");
RandomLongGenerator rng3
        = new CompositeLinearCongruentialGenerator(
                new LinearCongruentialGenerator[]{
                    (LinearCongruentialGenerator) rng1,
                    (LinearCongruentialGenerator) rng2
                }
        );
rng3.seed(1234567890L);
generateIntAndPrint(rng3, 10);
arr = generate(rng3, 10);
print(arr);

```

输出如下所示:

```py
generate randome numbers using an Lehmer RNG:
[1435150771, 264992611, 1287986023, 14695885, 1778129691, 1803529921, 261124279, 1119365911, 242889263, 1607847107]
[0.9693015489683634, 0.6321804200929291, 0.06732959846175084, 0.12655284849786763, 0.8856797936757945, 0.591264143240383, 0.8434276206844243, 0.9128140665540452, 0.34205909356243114, 0.15256980711986945]

generate randome numbers using an LEcuyer RNG:
[931800788, 1315300572, 50110053, 1984090886, 1233048435, 1852047791, 1666959172, 802962765, 288962461, 1436549801]
[0.5579439720874392, 0.8760583083499495, 0.27437038918694967, 0.8951008789684162, 0.9749086084658786, 0.5236797712387888, 0.5190309786792058, 0.07284812912011898, 0.947280622528531, 0.9903890099331686]

generate randome numbers using a composite LCG:
[1435150771, 264992611, 1287986023, 14695885, 1778129691, 1803529921, 261124279, 1119365911, 242889263, 1607847107]
[0.9693015115049681, 0.6321803956592273, 0.06732959585946947, 0.12655284360661437, 0.8856797594443706, 0.5912641203880907, 0.8434275880860421, 0.9128140312738847, 0.34205908034188587, 0.15256980122306366]

```

注意，lcg 产生整数。为了从均匀分布中取样，他们将整数调整到单位区间内。

通过使用相同的种子，在本例中为 1234567890L，代码总是产生相同的随机数序列。这对于我们想要一遍又一遍地重复相同的随机实验是很重要的，例如，调试，计算π得到相同的值。一般来说，在有多个 RNG 的应用中，它们应该共享相同的统一 RNG。换句话说，一个应用应该有且只有一个统一的 RNG，而不管它可能使用多少 RNG。这种统一的 RNG 需要一粒种子，在整个申请期内，在申请开始时只应播种一次。

一个`CompositeLinearCongruentialGenerator`的签名如下:

```py
/**
 * Constructs a linear congruential generator from some simpler and shorter
 * modulus generators.
 *
 * @param rng simpler and shorter modulus linear congruential generators
 */
public CompositeLinearCongruentialGenerator(LinearCongruentialGenerator[] rng)

```

### 梅森尼龙卷风

线性同余方法的一个问题是周期对于应用来说可能太小，例如 2 <sup>32</sup> 。即使我们使用一个复合 LCG 将它们中的一些组合在一起，它仍然很小。因此，LCG 适用于只需要几千个随机数而不是几百万个的小应用程序。相比之下，一个常用的梅森龙卷风(MT) RNG，称为 MT19937，周期为 2<sup>19937</sup>1(松本&西村，1998)。此外，MT RNG 具有良好的统计随机性。MT19937 是应用最广泛的通用 RNG。

以下代码使用 MT19937 在 114 毫秒内产生 100 万个随机数:

```py
RandomLongGenerator rng = new MersenneTwister();

long startTime = System.nanoTime();
int N = 1_000_000;
for (int i = 0; i < N; ++i) {
    rng.nextDouble();
}
long endTime = System.nanoTime();

long duration = (endTime - startTime);
double ms = (double) duration / 1_000_000.; // divide by 1000000 to get milliseconds
System.out.println(String.format("took MT19937 %f milliseconds to generate %d random numbers", ms, N));

```

输出如下所示:

```py
took MT19937 114.543900 milliseconds to generate 1000000 random numbers

```

## 13.2 从概率分布中取样

随机数生成广泛用于游戏、赌博、密码术、模拟和许多其他需要产生不可预测结果的领域。一些物理现象本质上是随机的(随机的一个奇特的词)，比如扔硬币、放射性衰变、粒子位置以及量子领域中的一切。模拟和蒙特卡罗方法已被证明可以有效地解决没有其他已知解决方案的难题。它们广泛应用于科学的各个分支，并且基于随机数生成的基础。因此，我们经常需要对过程或系统的随机性质进行建模。换句话说，我们希望生成模拟系统概率属性的随机数。比如我们想写一个程序，模拟一个投掷 100 个硬币的实验，并统计每个实验的人头数。我们需要按照 50-50 的概率分布生成很多随机数{正面= 0，反面= 1}。我们称之为从概率分布中抽取随机数。

随机变量， *X* ，是一个可以取不同值的变量。直到你看到它，你才知道它的价值。这与(确定性)变量相反，例如， *x* = 1，它总是只能取一个值。每次你“观察”一个随机变量，它都是这个随机变量的一个样本。例如，掷硬币的结果是一个随机变量。你不知道它是头还是尾，直到你扔硬币。投掷硬币 10 次，得到 10 个观察值或样本，例如{ *x* <sub>1</sub> = 1， *x* <sub>2</sub> = 1， *x* <sub>3</sub> = 0，⋯， *x* <sub>10</sub> = 0}。每个样本都来自一枚公平硬币的概率分布。

概率分布是一种数学函数，它给出了实验中不同可能结果出现的概率。例如，投掷一枚公平硬币的概率分布将 0.5(50%)分配给正面，0.5(50%)分配给反面。概率分布是由累积分布函数正式定义的。在 *x* 处评估的实值随机变量 *X* 的累积分布函数(CDF)是 *X* 取值小于或等于 *x* 的概率。数学上，我们有这个(见图 [13-1](#Fig1) ):

![$$ {F}_X(x)=P\left(X\le x\right) $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equd.png)

![img/500382_1_En_13_Chapter/500382_1_En_13_Fig1_HTML.jpg](img/500382_1_En_13_Chapter/500382_1_En_13_Fig1_HTML.jpg)

图 13-1

公平抛硬币的累积分布函数

抛一枚公平硬币，正面为 0，反面为 1 的 CDF 如下:

![$$ {F}_X(x)=\left\{\begin{array}{c}0.5,x=0\\ {}1,x=1\end{array}\right. $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Eque.png)

图 [13-2](#Fig2) 显示了一些正态分布的 CDF。我们看到对于 *μ* = 0(均值为 0)的正态分布，从概率分布中得到一个值小于(或大于)0 的样本的几率为 0.5。

![img/500382_1_En_13_Chapter/500382_1_En_13_Fig2_HTML.jpg](img/500382_1_En_13_Chapter/500382_1_En_13_Fig2_HTML.jpg)

图 13-2

正态分布的累积分布函数

对于一个连续的随机变量，用概率密度函数(PDF)来描述往往更直观。

![$$ {f}_X(x)=\frac{d}{dx}{F}_X(x) $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equf.png)T2】

*f*<sub>*X*</sub>(*X*)是随机变量等于一个样本值 *x* 的相对可能性。相对可能性越大，我们就越有可能看到这个样本超过另一个样本。对于连续的随机变量，绝对似然总是 0。随机变量的值落在某个区域内的概率就是该区域在 PDF 下的面积，即 PDF 在该区域内的积分。

我们已经在第 [13.1](#Sec1) 节讨论了均匀分布的抽样。本节讨论从任意概率分布中抽样的方法。

### 逆变换采样

逆变换采样是一种从给定累积分布函数的任何概率分布中随机生成样本的方法。它从 0 到 1 之间的均匀分布 *y* 中取一个随机数，解释为一个概率，然后从分布*F*<sub>*X*</sub>(*X*)使得*F*<sub>*X*</sub>(*X*≤*y*的定义域中返回最大的数 *x* 。换句话说，它计算图 [13-3](#Fig3) 中例子的倒数![$$ {F}_X^{-1}(y)=\operatorname{inf}\left\{x|{F}_X(x)\ge y\right\} $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_IEq1.png)，一个均匀随机数产生四个样本![$$ {U}_1,{U}_2^a,{U}_2^b,{U}_2^c $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_IEq2.png)。概率分布*F*<sub>*X*</sub>(*X*)对应的样本是![$$ {F}_X^{-1}\left({U}_1\right) $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_IEq3.png)和三个![$$ {F}_X^{-1}\left({U}_2\right) $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_IEq4.png)。

![img/500382_1_En_13_Chapter/500382_1_En_13_Fig3_HTML.jpg](img/500382_1_En_13_Chapter/500382_1_En_13_Fig3_HTML.jpg)

图 13-3

逆变换采样示意图

NM Dev 有一个做逆变换采样的类。签名如下:

```py
/**
 * Constructs a random number generator to sample from a distribution.
 *
 * @param distribution the distribution to sample from
 * @param uniform      a uniform random number generator
 */
public InverseTransformSampling(
                                ProbabilityDistribution distribution,
                                RandomLongGenerator uniform)

```

瑞利分布有如下 CDF:

![$$ F\left(x|\sigma \right)=1-\exp \left(-\frac{x^2}{2{\sigma}^2}\right),x\in \left[\left.0,\infty \right)\right. $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equg.png)

为了构造瑞利分布的 RNG，我们简单地将其概率分布传递给`InverseTransformSampling`(见图 [13-4](#Fig4) )。

![img/500382_1_En_13_Chapter/500382_1_En_13_Fig4_HTML.jpg](img/500382_1_En_13_Chapter/500382_1_En_13_Fig4_HTML.jpg)

图 13-4

瑞利分布的 CDF

```py
/**
 * Constructs a random number generator to sample from the Rayleigh
 * distribution.
 *
 * @param sigma the standard deviation
 */
public RayleighRNG(double sigma) {
    super(new dev.nm.stat.distribution.univariate.RayleighDistribution(sigma));
}

```

在计算上，该方法包括计算分布的分位数函数，即累积分布函数的倒数。这就是为什么这种方法的名称中有“逆”这个术语。不幸的是，当很难或不可能积分分布的 PDF 或计算 CDF 的逆时，这种方法对于许多分布来说计算效率低或不可行。逆变换采样对于罕见事件是低效的。对于那些概率接近 0 的事件，*P*(*X*∈*A*)≈0，将需要接近无限个均匀样本![$$ \frac{1}{P\left(X\in A\right)} $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_IEq5.png)才能得到它们。

### 接受-拒绝抽样

假设我们要从一个 PDF*f*<sub>*X*</sub>(*X*)中采样。我们在一个大的矩形板上画 PDF。我们随机而均匀地向棋盘投掷飞镖。去掉曲线下区域以外的省道。剩余的省道将均匀分布在曲线下的区域，这些省道的 *x* 位置将根据随机变量的密度分布。这是因为曲线最高的地方有最大的空间让飞镖落地，因此概率密度最大。

![img/500382_1_En_13_Chapter/500382_1_En_13_Fig5_HTML.png](img/500382_1_En_13_Chapter/500382_1_En_13_Fig5_HTML.png)

图 13-5

接受-拒绝概念图；接受曲线下方的点，拒绝曲线上方的点

这个想法可以扩展到建议分布不均匀的地方(即矩形板)，也可以扩展到我们知道如何从中抽样的任何分布。建议分布需要至少与目标分布一样高，以完全包围后者。否则，我们想要采样的弯曲区域的某些部分将永远无法到达。这种接受-拒绝算法也适用于高维 pdf。

假设我们想从一个目标 PDF *f* ( *x* )中取样。我们想要提案 a PDF *g* ( *x* )这样:

*   对于任意 *x* 、*f(**x*)<=*M*×*g*(*x*)。

*   *g* ( *x* )很容易取样。

*   *g* ( *x* )在形状上应该类似于 *f (* *x* )。

拒绝方法如下:

1.  样本从提案分布 *g* ( *x* )得到 *x* <sub>*i*</sub> ，*x*<sub>*I*</sub>~*g*(*x*)。

2.  从均匀分布的样本中得到*U*<sub>T3】IT5】~*U*(*a*， *b* )。</sub>

3.  如果![$$ {u}_i\le \frac{f\left({x}_i\right)}{M\times g\left({x}_i\right)} $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_IEq6.png)，则接受 *x* <sub>* i *</sub> 作为有效样本；否则，拒绝。

4.  重复步骤 1 到 3，直到我们对样本集满意为止。

该算法的一个缺点是，在找到一个有效样本之前，它可能会产生大量不需要的样本。这个问题在高维空间中更严重，使得它在这种情况下是低效和不切实际的。

### 13.2.3 从单变量分布中取样

逆变换采样和接受-拒绝采样是(几乎)适用于所有概率分布的通用方法，但它们速度较慢。对于一些特定的概率分布，有专门的更快速的方法从中采样。NM Dev 有一大套 RNG，它们从一些最流行的概率分布中采样:高斯/正态分布、贝塔分布、伽马分布、指数分布、泊松分布、伯努利分布、二项式分布、瑞利分布、威布尔分布等。其中一些有多种实现方式，例如正态分布。

#### 13.2.3.1 高斯或正态分布

最重要的概率分布可能是高斯分布或正态分布。有许多自然现象要么是精确的，近似的，要么被认为是正常的。经过一段时间后，扩散粒子的位置是完全正常的。在一系列抛硬币的游戏中，正面的数量大致正常。股票收益对数的变化被认为是正态的。它的应用广泛存在于金融、物理、生物、统计等领域。

从数学上讲，正态分布有许多好的性质。它们是对称的、单峰的、无限可微的、完全由前两个矩(均值和方差)表征的、最大熵的、没有暗示独立性的相关性的和可加的。也许使正态分布成为统计学核心的是中心极限定理，该定理认为样本集的平均值的分布是正态分布，样本大小趋于无穷大。换句话说，作为样本值的平均值(或总和)的一切，例如测量值和误差，都是近似正态分布的。见图 [13-6](#Fig6) 。

![img/500382_1_En_13_Chapter/500382_1_En_13_Fig6_HTML.jpg](img/500382_1_En_13_Chapter/500382_1_En_13_Fig6_HTML.jpg)

图 13-6

正态分布的概率密度函数

正态分布的概率密度函数如下:

![$$ f\left(x|\mu, \sigma \right)=\frac{1}{\sqrt{2\pi}\sigma}\mathit{\exp}\left(-\frac{1}{2}{\left(\frac{x-\mu }{\sigma}\right)}^2\right) $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equh.png)

参数 *μ* 是分布的均值或期望值，参数 *σ* 是标准差。分布的方差为*σ*T6】2。具有高斯分布的随机变量 *X* 被称为正态分布，表示为*X*~*N*(*μ*， *σ* <sup>2</sup> )。正态分布的均值 *μ* 决定其位置，标准差 *σ* 决定分布的大小。当 *μ* = 0、 *σ* = 1 时，正态分布为标准正态分布。

NM Dev 有许多生成随机正态样本的实现。分别是`Zignor2005` (Doornik，2005)`Ziggurat2000`(marsag lia&Tsang，2000)`MarsagliaBray1964`(g .&Bray)`BoxMuller`(Box&Muller，1958)。默认情况下，我们使用`Zignor2005`。

以下代码片段是生成标准正常样本和正常样本的示例:

```py
RandomLongGenerator uniform = new MersenneTwister();
uniform.seed(1234567890L);

RandomStandardNormalGenerator rng1 = new Zignor2005(uniform); // mean = 0, stdev = 1
int N = 1000;
double[] arr1 = new double[N];
for (int i = 0; i < N; ++i) {
    arr1[i] = rng1.nextDouble();
}

// check the statistics of the random samples
Variance var1 = new Variance(arr1);
System.out.println(
        String.format(
                "mean = %f, stdev = %f",
                var1.mean(),
                var1.standardDeviation()));

NormalRNG rng2 = new NormalRNG(1., 2., rng1); // mean = 1, stdev = 2
double[] arr2 = new double[N];
for (int i = 0; i < N; ++i) {
    arr2[i] = rng2.nextDouble();
}

// check the statistics of the random samples

Variance var2 = new Variance(arr2);
System.out.println(
        String.format(
                "mean = %f, stdev = %f",
                var2.mean(),
                var2.standardDeviation()));

```

输出如下所示:

```py
mean = 0.011830, stdev = 1.009379
mean = 0.940225, stdev = 2.037228

```

样本的统计数据与传递给 RNG 构造函数的分布参数相匹配。

签名如下:

```py
/**
 * Constructs an improved Ziggurat random normal generator.
 *
 * @param uniform a uniform random number generator
 */
public Zignor2005(RandomLongGenerator uniform)

/**
 * Construct a random number generator to sample from the Normal distribution.
 *
 * @param mean  the mean
 * @param sigma the standard deviation
 * @param rnorm a standard random normal number generator
 */
public NormalRNG(double mean, double sigma, RandomStandardNormalGenerator rnorm)

```

标准的正常 RNG `Zignor2005`将统一的 RNG 作为输入，在我们的例子中是`MersenneTwister`。然后，正态 RNG 将标准正态 RNG 和分布参数作为输入。请注意，我们在一个应用程序中只播种一次统一 RNG。

#### 13.2.3.2 贝塔分布

贝塔分布是在单位区间[0，1]上定义的一族连续概率分布，单位区间[0，1]由两个正的形状参数参数化，用 *α* 和 *β* 表示，它们控制分布的形状。贝塔分布已被广泛应用于各种学科中，用来模拟限于有限长度区间的随机变量的行为。贝塔分布的概率密度函数如下:

![$$ f\left(x|\alpha, \beta \right)=\frac{1}{B\left(\alpha, \beta \right)}{x}^{\alpha -1}{\left(1-x\right)}^{\beta -1} $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equi.png)

*B* ( *α* ， *β* )是贝塔函数。参数为 *α* 和 *β* 的服从贝塔分布的随机变量 *X* 写成*X*~*Be*(*α*， *β* )。

![img/500382_1_En_13_Chapter/500382_1_En_13_Fig7_HTML.jpg](img/500382_1_En_13_Chapter/500382_1_En_13_Fig7_HTML.jpg)

图 13-7

贝塔分布的概率密度函数

NM Dev 有许多实现来生成随机测试样本。他们是`Cheng1978`(程，1978)和`VanDerWaerden1969`(范德华登)。默认情况下，我们使用`Cheng1978`。类`Cheng1978`是一种新的生成 beta 变量的拒绝方法。该方法与以前发表的方法在理论上和通过计算机计时进行了比较。与以前的方法相比，该方法在速度和编程简单性方面都有优势，特别是对于参数值的“困难”组合。具体来说，如果 *X* 和 *Y* 与*X*~γ(*α*， *θ* )和*Y*~γ(*β*， *θ* )相互独立，那么![$$ \frac{X}{X+Y}\sim \mathrm{Beta}\left(\alpha, \theta \right) $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_IEq7.png)。为了从贝塔分布中取样，我们可以生成![$$ \frac{X}{X+Y} $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_IEq8.png)，其中 *X* 是带有参数γ的伽马变量( *α* ，1)，而 *Y* 是带有参数γ的独立伽马变量( *β* ，1)。

以下代码片段生成β变量，其中 *α* = 0.1， *β* = 0.2:

```py
final int size = 1_000_000;

final double alpha = 0.1;
final double beta = 0.2;

RandomBetaGenerator rng = new Cheng1978(alpha, beta, new UniformRNG());
rng.seed(1234567890L);

double[] x = new double[size];
for (int i = 0; i < size; ++i) {
    x[i] = rng.nextDouble();
}

// compute the sample statistics
Mean mean = new Mean(x);
Variance var = new Variance(x);
Skewness skew = new Skewness(x);
Kurtosis kurtosis = new Kurtosis(x);

// compute the theoretial statistics
ProbabilityDistribution dist = new BetaDistribution(alpha, beta);

// compare sample vs theoretical statistics
printStats(dist, mean, var, skew, kurtosis);

```

输出如下所示:

```py
theoretical mean = 0.333333, sample mean = 0.333402
theoretical var = 0.170940, sample var = 0.171025
theoretical skew = 0.701066, sample skew = 0.700741
theoretical kurtosis = -1.304348, sample kurtosis = -1.305287

```

我们可以看到，样本统计数据与从概率分布函数分析计算的理论值非常匹配。

构造函数签名如下:

```py
/**
 * Constructs a random number generator to sample from the beta
 * distribution.
 *
 * @param aa      the degree of freedom
 * @param bb      the degree of freedom
 * @param uniform a uniform random number generator
 */
public Cheng1978(double aa, double bb, RandomLongGenerator uniform)

```

#### 13.2.3.3 伽马分布

伽玛分布是一个双参数连续概率分布族。指数分布、Erlang 分布和卡方分布是伽玛分布的特例。这两个参数是形状参数 *k* 和比例参数 *θ* 。伽玛分布常用于模拟等待时间。例如，在寿命测试中，死亡前的等待时间是一个随机变量，通常用伽玛分布建模。伽马分布也用于模拟保险索赔和降雨量的规模。这意味着总的保险索赔和水库中累积的降雨量通过伽马过程建模。在肿瘤学中，癌症发病率的年龄分布通常遵循伽马分布，而形状和尺度参数分别预测驱动事件的数量和它们之间的时间间隔。在神经科学中，伽马分布经常被用来描述棘波间期的分布。在细菌基因表达中，组成型表达的蛋白质的拷贝数通常遵循伽马分布，其中尺度和形状参数分别是每个细胞周期的平均爆发数和单个 mRNA 在其生命周期中产生的蛋白质分子的平均数。

参数 *α* = *k* 称为形状参数，![$$ \beta =\frac{1}{\theta } $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_IEq9.png)称为逆比例参数。伽马分布的概率密度函数如下:

![$$ f\left(x|\beta, \alpha \right)=\frac{\beta^{\alpha }{x}^{\alpha -1}{e}^{-\beta x}}{\Gamma \left(\alpha \right)},x&gt;0 $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equj.png)

γ(*α*)是伽玛函数。服从带参数 *α* 和 *β* 的伽玛分布的随机变量 *X* 写成*X*~γ(*α*， *β* )。见图 [13-8](#Fig8) 。

![img/500382_1_En_13_Chapter/500382_1_En_13_Fig8_HTML.jpg](img/500382_1_En_13_Chapter/500382_1_En_13_Fig8_HTML.jpg)

图 13-8

伽玛分布的概率密度函数

NM Dev 有许多实现来生成随机伽马样本。分别是`InverseTransformSamplingGammaRNG`逆变换采样(效率较低)`MarsagliaTsang2000` (Marsaglia & Tsang，2000)`XiTanLiu2010a``XiTanLiu2010b`(、谭、&刘)`KunduGupta2007` (Kundu & Gupta，2007)。默认情况下，我们使用`KunduGupta2007`。当形状参数位于 0 和 1 之间时，它使用一种方便的方式来生成使用广义指数分布的伽马变量。

以下代码片段生成伽马变量，其中 *k* = 0.1， *θ* = 1:

```py
final int size = 1_000_000;

final double k = 0.1;
final double theta = 1;

KunduGupta2007 rng = new KunduGupta2007(k, theta, new UniformRNG());
rng.seed(1234567895L);

double[] x = new double[size];
for (int i = 0; i < size; ++i) {
    x[i] = rng.nextDouble();
}

// compute the sample statistics
Mean mean = new Mean(x);
Variance var = new Variance(x);
Skewness skew = new Skewness(x);
Kurtosis kurtosis = new Kurtosis(x);

// compute the theoretial statistics
ProbabilityDistribution dist = new GammaDistribution(k, theta);

// compute the theoretial statistics
printStats(dist, mean, var, skew, kurtosis);

```

输出如下所示:

```py
theoretical mean = 0.100000, sample mean = 0.102555
theoretical var = 0.100000, sample var = 0.102297
theoretical skew = 6.324555, sample skew = 6.303562
theoretical kurtosis = 60.000000, sample kurtosis = 60.330271

```

我们可以看到，样本统计数据与从概率分布函数分析计算的理论值非常匹配。

构造函数签名如下:

```py
/**
 * Constructs a random number generator to sample from the gamma
 * distribution.
 *
 * @param k       the shape parameter
 * @param theta   the scale parameter
 * @param uniform a uniform random number generator
 */
public KunduGupta2007(double k, double theta, RandomLongGenerator uniform)

```

#### 13.2.3.4 泊松分布

泊松过程是一系列离散事件，其中事件之间的平均时间是已知的，但是下一个事件的确切时间是随机的。一个事件的到来与之前的事件无关；即事件之间的等待时间是马尔可夫的或无记忆的。例如，呼叫中心平均每小时接收 180 个电话，一天 24 小时。这些调用是独立的；接收一个不会改变下一个到达的概率。在任何一分钟内收到的电话数量具有泊松概率分布:最可能的数字是 2 和 3，但是 1 和 4 也是可能的，并且有很小的概率是 0，极小的概率是 10。另一个例子是在给定的观察期内放射源发生衰变的次数。泊松分布概率质量函数给出了在固定时间间隔内观察到 *k* 个随机事件的概率，前提是事件的数量具有已知的每个间隔的平均值，并且与自上次事件以来的时间无关。概率质量函数有这样的形式:

![$$ P\left(X=k\right)=\frac{\lambda^k{e}^{-\lambda }}{k!},k=0,1,\dots $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equk.png)

泊松分布的参数 *λ* 是单位时间内随机事件的平均数。泊松分布的期望和方差都是 *λ* 。请注意，与我们之前看到的所有分布不同，泊松分布是一种离散分布。 *X* 取整数值。

![img/500382_1_En_13_Chapter/500382_1_En_13_Fig9_HTML.jpg](img/500382_1_En_13_Chapter/500382_1_En_13_Fig9_HTML.jpg)

图 13-9

泊松分布的概率质量函数

在 NM Dev 中，泊松 RNG 类是`Knuth1969`。以下代码片段生成泊松变量，其中 *λ* = 1:

```py
final int N = 10_000;
double lambda = 1;

RandomNumberGenerator rng = new Knuth1969(lambda);
rng.seed(123456789L);

double[] x = new double[N];
for (int i = 0; i < N; ++i) {
    x[i] = rng.nextDouble();
}

// compute the sample statistics
Mean mean = new Mean(x);
Variance var = new Variance(x);
Skewness skew = new Skewness(x);
Kurtosis kurtosis = new Kurtosis(x);

// compute the theoretial statistics
PoissonDistribution dist = new PoissonDistribution(lambda);

// compute the theoretial statistics
printStats(dist, mean, var, skew, kurtosis);

```

输出如下所示:

```py
theoretical mean = 1.000000, sample mean = 1.013300
theoretical var = 1.000000, sample var = 1.022225
theoretical skew = 1.000000, sample skew = 1.000960
theoretical kurtosis = 1.000000, sample kurtosis = 0.990813

```

我们可以看到，样本统计数据与从概率分布函数分析计算的理论值非常匹配。

构造函数签名如下:

```py
/**
 * Constructs a random number generator to sample from the Poisson
 * distribution.
 *
 * @param lambda  the shape parameter
 * @param uniform a uniform random number generator
 */
public Knuth1969(double lambda, RandomLongGenerator uniform)

```

#### 13.2.3.5 指数分布

泊松分布描述的是时间间隔内的事件数量，而指数分布描述的是泊松过程中事件之间的时间间隔。这是随机时间的分布。这是伽玛分布的一个特例。有许多指数分布的例子，例如直到放射性粒子衰变的时间，在你下一次打电话之前的时间，以及在信用风险建模中直到拖欠贷款的时间。

*λ*T15】0 称为速率参数。它是单位时间内事件发生的平均次数。随机时间范围为[0，∞)。如果一个随机变量 *X* 呈指数分布，则记为 *X* ~ *E* ( *λ* )。概率密度函数如下(图 [13-10](#Fig10) ):

![$$ f\left(x|\lambda \right)=\left\{\begin{array}{c}\lambda {e}^{-\lambda x}\kern2.25em x&gt;0\\ {}0\kern4.5em x\le 0\end{array}\right. $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equl.png)

![img/500382_1_En_13_Chapter/500382_1_En_13_Fig10_HTML.jpg](img/500382_1_En_13_Chapter/500382_1_En_13_Fig10_HTML.jpg)

图 13-10

指数分布的概率密度函数

我们可以通过使用逆变换采样来生成指数变量。NM Dev 实现了一个更有效的算法`Ziggurat2000Exp` (Marsaglia & Tsang，2000)。以下代码片段生成标准指数变量，其中 *λ* = 1。注意`Ziggurat2000Exp`使用默认的构造函数，并且不接受参数。

```py
int size = 500_000;

RandomExpGenerator rng = new Ziggurat2000Exp();
rng.seed(634641070L);

double[] x = new double[size];
for (int i = 0; i < size; ++i) {
    x[i] = rng.nextDouble();
}

// compute the sample statistics
Mean mean = new Mean(x);
Variance var = new Variance(x);
Skewness skew = new Skewness(x);
Kurtosis kurtosis = new Kurtosis(x);

// compute the theoretial statistics
ProbabilityDistribution dist = new ExponentialDistribution();

// compute the theoretial statistics
printStats(dist, mean, var, skew, kurtosis);

```

输出如下所示:

```py
theoretical mean = 1.000000, sample mean = 1.000983
theoretical var = 1.000000, sample var = 0.996058
theoretical skew = 2.000000, sample skew = 1.958222
theoretical kurtosis = 6.000000, sample kurtosis = 5.489008

```

我们可以看到，样本统计数据与从概率分布函数分析计算的理论值非常匹配。

要生成非标准指数方差，我们可以首先生成标准指数变量，然后对它们进行缩放。或者，我们可以直接使用将 *λ* 作为参数的`InverseTransformSamplingExpRNG`。签名如下:

```py
/**
 * Constructs a random number generator to sample from the exponential
 * distribution using the inverse transform sampling method.
 *
 * @param lambda the rate parameter
 */
public InverseTransformSamplingExpRNG(double lambda)

```

### 13.2.4 多元分布的取样

NM Dev 支持为一些高维的多元分布生成随机向量。每个样本都是数字的向量，而不仅仅是一个数字。它们包括但不限于以下内容，因为我们一直在扩充库:

*   高维盒域上的多元均匀分布

*   高维单位超球面上的多元均匀分布

*   多元正态分布

*   多项分布

随机向量 RNG 的签名`RandomVectorGenerator`如下:

```py
public interface RandomVectorGenerator extends Seedable {

    /**
     * Gets the next random vector.
     *
     * @return the next random vector
     */
    public double[] nextVector();
}

```

每次调用`nextVector`都会生成一个`double[]`形式的矢量样本。

#### 盒子上的 13.2.4.1 多元均匀分布

类别`UniformDistributionOverBox`是一个随机向量 RNG，它在高维超立方体或盒子上均匀地产生样本。它将一维均匀 RNG 和盒子的尺寸作为输入。签名如下:

```py
/**
 * Constructs a random vector generator to uniformly sample points over a
 * box region.
 *
 * @param uniform a uniform random number generator
 * @param bounds  the feasible box region
 */
public UniformDistributionOverBox(
        RandomLongGenerator uniform,
        RealInterval... bounds
)

```

![img/500382_1_En_13_Chapter/500382_1_En_13_Fig11_HTML.jpg](img/500382_1_En_13_Chapter/500382_1_En_13_Fig11_HTML.jpg)

图 13-11

不同维度的立方体

下面展示了如何使用随机抽样来计算圆的周长与直径之比，即 *π* 。想法是把随机飞镖扔到一个单位棋盘上，*x*∈[1，1]，*y*∈[1，1]，里面有一个圆。正方形的面积是 1，圆的面积![$$ \frac{\pi }{4} $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_IEq10.png)。即圆内飞镖的数量，*N*T9】0，相对于整板内的数量， *N* ，其比值为:

![$$ \frac{N_0}{N}=\frac{\pi }{4} $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equm.png)

我们求解 *π* 。以下代码实现了该过程:

```py
private void compute_Pi() {
    final int N = 1_000_000;

    RandomVectorGenerator rvg
            = new UniformDistributionOverBox(
                    new RealInterval(-1., 1.), // a unit square box
                    new RealInterval(-1., 1.));

    int N0 = 0;
    for (int i = 0; i < N; i++) {
        double[] xy = rvg.nextVector();
        double x = xy[0], y = xy[1];
        if (x * x + y * y <= 1.) { // check if the dot is inside a circle
            N0++;
        }
    }
    double pi = 4\. * N0 / N;
    System.out.println("pi = " + pi);
}

```

输出如下所示:

```py
pi = 3.139588

```

#### 超球面上的 13.2.4.2 多元均匀分布

类别`HypersphereRVG`是一个随机向量 RNG，它在一个高维超球面的表面上均匀地产生样本。它将球体维度和一维标准法线 RNG 作为输入。签名如下:

```py
/**
 * Constructs a hypersphere RVG to generate random uniform points.
 *
 * @param dimension the dimension of the hypersphere
 * @param rnorm     the standard Normal RNG to be used
 */
public HypersphereRVG(int dimension, RandomStandardNormalGenerator rnorm)

```

#### 13.2.4.3 多元正态分布

多元正态分布、多元高斯分布或联合正态分布是一维(单变量)正态分布向更高维度的推广。一个定义是，如果一个随机向量的 *k* 分量的每个线性组合都具有单变量正态分布，则称该随机向量为 *k* 变量正态分布。根据多维中心极限定理，多元正态分布通常用于描述(至少近似地)任何一组(可能)相关的实值随机变量，其中每个随机变量都聚集在一个平均值周围。

一个实随机向量***x***=(*x*<sub>1</sub>，*x*<sub>*k*</sub>)<sup>*t*</sup>称为一个(多元)标准正态随机向量，如果它的每个分量 *X* <sub>*i*</sub> 本身是一个单变量标准正态，并且它们是独立的。即*X*<sub>*I*</sub>~*N*(0，1)对所有 *i* 。可以证明，任何多元法线向量都可以写成一个*k*-向量 *μ* 和一个缩放后的多元标准法线之和。即***x***~*n*(***μ***，**σ**)当且仅当存在***μ***∈*ℝ*<sup>*k*</sup>和 ***A*** ∈时 ***μ*** 为*k*-维均值向量，**σ**为分量的 *k* × *k* 协方差矩阵。参见图 [13-12](#Fig12) 。

![img/500382_1_En_13_Chapter/500382_1_En_13_Fig12_HTML.jpg](img/500382_1_En_13_Chapter/500382_1_En_13_Fig12_HTML.jpg)

图 13-12

二维正态分布的概率密度函数

多元正态分布的概率密度函数如下:

![$$ {f}_X\left({x}_1,\cdots, {x}_k\right)=\frac{1}{\sqrt{{\left(2\pi \right)}^k\left|\boldsymbol{\Sigma} \right|}}\exp \left(-\frac{1}{2}{\left(\boldsymbol{x}-\boldsymbol{\mu} \right)}^T{\boldsymbol{\Sigma}}^{-1}\left(\boldsymbol{x}-\boldsymbol{\mu} \right)\right) $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equn.png)

在 NM Dev 中，类`NormalRVG`从多元正态分布中采样。以下代码片段产生相关的多元正态变量:

```py
// mean
Vector mu = new DenseVector(new double[]{-2., 2.});
// covariance matrix
Matrix sigma = new DenseMatrix(new double[][]{
    {1., 0.5},
    {0.5, 1.}
});
NormalRVG rvg = new NormalRVG(mu, sigma);
rvg.seed(1234567890L);

final int size = 10_000;
double[][] x = new double[size][];

Mean mean1 = new Mean();
Mean mean2 = new Mean();
for (int i = 0; i < size; ++i) {
    double[] v = rvg.nextVector();
    mean1.addData(v[0]);
    mean2.addData(v[1]);

    x[i] = v;
}

System.out.println(String.format("mean of X_1 = %f", mean1.value()));
System.out.println(String.format("mean of X_2 = %f", mean2.value()));

Matrix X = new DenseMatrix(x);
SampleCovariance cov = new SampleCovariance(X);
System.out.println(String.format("sample covariance = %s", cov.toString()));

```

输出如下所示:

```py
mean of X_1 = -2.007342
mean of X_2 = 1.995800
sample covariance = 2x2
        [,1] [,2]
[1,] 1.003598, 0.496158,
[2,] 0.496158, 1.012381,

```

样本均值和样本协方差矩阵与输入匹配得相当好。

`NormalRVG`构造函数签名如下:

```py
    /**
     * Constructs a multivariate normal random vector generator.
     *
     * @param mu      the mean
     * @param sigma   the covariance matrix
     * @param epsilon a precision parameter: when a number |x| &le; &epsilon;,
     *                it is considered 0
     * @param rnorm   a random standard normal number generator
     */
    public NormalRVG(
            final Vector mu,
            final Matrix sigma,
            final double epsilon,
            final RandomStandardNormalGenerator rnorm
    )

```

#### 13.2.4.4 多项式分布

多项式分布根据箱的概率将 *n* 个项目放入 *k* 个箱中。一个输出随机向量计算每个箱子中的物体数量，总共有 *n* 。当 *k* = 2、 *n* = 1(将一个物体放入两个箱柜)时，就是伯努利分布。输出为(0，1)或(1，0)。这就像抛一次硬币(不一定是公平的)，你要么得到一个头，要么得到一个尾。当 *k* = 2、 *n* > 1(将 *n* 对象放入 2 个箱)时，为二项分布。这就像把同一个硬币抛 *n* 次，然后数出正面(或反面)的数量。对于一个固定的有限的 *k* ，在 ***X*** 中的第 *i* 个分量表示在 *n* 个项目总数中的第 *i* 个项目的数量。

多项分布的概率质量函数如下:

![$$ f\left({x}_1,\cdots |{x}_k,n,{p}_1,\cdots, {p}_k\right)=\Pr \left({X}_1={x}_1,\cdots, {X}_k={x}_k\right) $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equo.png)

![$$ =\left\{\begin{array}{c}\frac{n!}{x_1!\cdots {x}_k!}{p_1}^{x_1}\times \cdots \times {p_k}^{x_k}\\ {}0,\mathrm{otherwise}\end{array}\right. $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equp.png)

在 NM Dev 中，类`MultinomialRVG`从多项分布中采样。下面的代码片段将 10，000 个项目放入两个箱子中，70%的可能性和 30%的可能性:

```py
MultinomialRVG rvg
        = new MultinomialRVG(100_000, new double[]{0.7, 0.3}); // bin0 is 70% chance, bin1 30% chance
double[] bin = rvg.nextVector();

double total = 0;
for (int i = 0; i < bin.length; ++i) {
    total += bin[i];
}

double bin0 = bin[0] / total; // bin0 percentage
double bin1 = bin[1] / total; // bin0 percentage

System.out.println(String.format("bin0 %% = %f, bin1 %% = %f", bin0, bin1));

```

输出如下所示:

```py
bin0 % = 0.702410, bin1 % = 0.297590

```

样本百分比与输入中每个条柱的个体概率相当匹配。

`MultinomialRVG`构造函数签名如下:

```py
/**
 * Constructs a multinomial random vector generator.
 *
 * @param N       an integer, say <i>N</i>, specifying the total number of
 *                objects that are put into <i>K</i> boxes in a typical multinomial
 *                experiment
 * @param prob    a numeric non-negative vector of length <i>K</i>,
 *                specifying the probability for the <i>K</i> boxes
 * @param uniform a uniform random number generator
 */
public MultinomialRVG(int N, double[] prob, RandomLongGenerator uniform)

```

### 重采样方法

下面是一种形象化经验分布方法的方法。给定一组样本，经验分布给每个样本分配 1/ *N* 的概率。然后以 1/ *N* 的概率，从集合中随机抽取一个样本作为下一个随机变量。在集合中出现得越频繁的项目越有可能被抽取，因此具有更高的概率质量。稀有物品不太可能被绘制，也不经常出现在输出中。本质上，我们从样本集中采样以生成新的样本。我们可以将这种重采样思想推广到一次绘制多个项目。与经验分布法相比，一次绘制多个项目的一个重要优点是，前者还考虑了样本之间的序列相关性，而后者假设数据集中的所有样本都是独立且同分布的。换句话说，通过重采样方法生成的变量不仅具有与真实分布相似的概率分布，而且还具有相似的序列相关性(样本之间的时间相关性)。当系统的真实概率分布未知时，重采样方法是进行统计估计和统计推断的一种常用的非参数方法。

在 NM Dev 中，一个重采样类扩展了这个接口。每次调用方法`newResample()`都会基于原始样本集生成一组新样本。

```py
public interface Resampler extends Seedable {

    /**
     * Gets a resample from the original sample.
     *
     * <em>It is very important this method is thread-safe so resampling can be
     * run in parallel.</em>
     *
     * @return a resample, e.g., a bootstrap sample
     */
    public double[] newResample();
}

```

#### 13.2.5.1 自举方法

Bootstrapping 是从给定的样本集(通常称为训练集)进行替换的统一采样。当选择一个样本块时，它是 RNG 的输出。相同的样本被“放回”训练集，并可用于重新选择。bootstrapping 的基本思想是，关于真实概率分布 *J* 的总体推断可以通过使用经验分布![$$ \hat{J} $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_IEq11.png)计算推断来近似。因为我们知道![$$ \hat{J} $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_IEq13.png)，所以可以测量使用重采样数据的关于![$$ \hat{J} $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_IEq12.png)的推断的准确性。如果![$$ \hat{J} $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_IEq14.png)是 J 的合理近似，那么可以反过来推断 J 上的推断质量。

更具体地说，假设我们想要估计全世界人的平均身高。我们无法衡量全球人口中的所有人。相反，我们只对其中的一小部分进行取样和测量。假设样本的大小为*N*；也就是说，我们测量了 N 个*个体的身高。从单个样本中，只能获得一个平均值估计。为了对总体进行推理，我们需要对我们计算出的平均值的可变性有所了解。最简单的 bootstrap 方法包括获取原始身高数据集(训练集)并从中采样以形成新样本(称为重采样或 bootstrap 样本)，其大小也为 *N* 。通过使用替换采样从原始样本中获取引导样本(例如，我们可能从[150，155，160，165，170]中“重新采样”五次，得到[155，170，165，165，150])。如果 *N* 足够大，实际上，它与训练集相同的概率几乎为零。这个过程要重复很多次(通常是 1000 或 10000 次)。对于这些 bootstrap 样本中的每一个，我们计算它的平均值(这些样本中的每一个称为 bootstrap 估计)。我们现在可以创建一个自举平均值的直方图。该直方图提供了对样本均值分布形状的估计，从中我们可以回答关于不同重采样的均值变化有多大的问题。这里描述的方法适用于平均值，几乎可以应用于任何其他统计量或估计量。*

![img/500382_1_En_13_Chapter/500382_1_En_13_Fig13_HTML.jpg](img/500382_1_En_13_Chapter/500382_1_En_13_Fig13_HTML.jpg)

图 13-13

bootstrap 均值直方图

以下代码片段实现了前面估计平均高度的示例:

```py
// sample from true population
double[] sample = new double[]{150., 155., 160., 165., 170.};
CaseResamplingReplacement boot = new CaseResamplingReplacement(sample);
boot.seed(1234567890L);

int B = 1000;
double[] means = new double[B];
for (int i = 0; i < B; ++i) {
    double[] resample = boot.newResample();
    means[i] = new Mean(resample).value();
}

// estimator of population mean
double mean = new Mean(means).value();
// variance of estimator; limited by sample size (regardless of how big B is)
double var = new Variance(means).value();

System.out.println(
        String.format("mean = %f, variance of the estimated mean = %f",
                mean,
                var));

```

或者，`BootstrapEstimator`提供了一个方便的包装器来重写这个例子，如下所示:

```py
// sample from true population
double[] sample = new double[]{150., 155., 160., 165., 170.};
CaseResamplingReplacement boot = new CaseResamplingReplacement(sample);
boot.seed(1234567890L);

int B = 1000;
BootstrapEstimator estimator
        = new BootstrapEstimator(boot, () -> new Mean(), B);

System.out.println(
        String.format("mean = %f, variance of the estimated mean = %f",
                estimator.value(),
                estimator.variance()));

```

输出如下所示:

```py
mean = 159.976000, variance of the estimated mean = 9.286711

```

人口身高的估计平均值为 159.976，精确度(根据估计平均值的方差测量)为 9.2867。注意，这个方差是估计的方差，不是种群高度的方差。

我们在这个例子中使用的引导重采样器是类`CaseResamplingReplacement`。签名如下:

```py
/**
 * Constructs a bootstrap sample generator. This is the classical bootstrap
 * with replacement.
 *
 * @param sample the original sample.
 */
public CaseResamplingReplacement(double[] sample)

```

`BootstrapEstimator`签名如下:

```py
    /**
     * Constructs a bootstrap estimator.
     *
     * @param bootstrap the bootstrap method and the sample
     * @param factory   the statistic
     * @param B         the number of bootstrap replicas
     */
    public BootstrapEstimator(
            Resampler bootstrap,
            StatisticFactory factory,
            int B
    )

```

一般来说，增加训练集的大小 *N* ，对于相同数量的自举重采样，可以提高精度。增加自举重采样的数量，即 *B* ，可以提高估计器的估计，但不能提高精度。一个样本在每次重采样中被选中的概率是![$$ \frac{1}{N} $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_IEq15.png)，那么不被选中的概率是![$$ 1-\frac{1}{N} $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_IEq16.png)。未被选择所有 *B* 次，即未出现在任何重采样集中的概率是![$$ {\left(1-\frac{1}{N}\right)}^B $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_IEq17.png)。当训练集大小和重采样次数都趋于无穷大时，该概率将接近*e*<sup>-1</sup>= 0.368。换句话说，使用带替换的简单情况重采样方法，训练集中只有大约 63.2%的原始数据集将出现在重采样中。

#### 13.2.5.2 政治-怀特-巴顿方法

NM Dev 还实现了根据自动块长度选择的自举方法，用于相关自举(Politis & White，2004)和对自动块长度选择的修正，用于相关自举(Politis，White & Patton，2009)。Politis-White-Patton bootstrap 方法生成序列的重采样，即，串行或时间相关的数据序列，其比使用替换方法的简单情况重采样更好地类似训练数据。例如，任何给定模式的出现次数都更接近于原始序列中的出现次数。下面的代码示例通过以概率 *q* 保留最后一个值，同时以概率(1*q*)更改最后一个值，来构造一个串行相关序列(由 0 和 1 组成)。然后，对于给定的模式，例如{1，0，1，0，1}，它比较训练序列中的出现次数和不同自举重采样序列中的出现次数。

```py
final int N = 10000;
final double q = 0.70; // the probability of retaining last value

UniformRNG uniformRNG = new UniformRNG();
uniformRNG.seed(1234567890L);

// generate a randome series of 0s and 1s with serial correlation
final double[] sample = new double[N];
[0] = uniformRNG.nextDouble() > 0.5 ? 1 : 0;
for (int i = 1; i < N; ++i) {
    sample[i] = uniformRNG.nextDouble() < q ? sample[i - 1] : 1 - sample[i - 1];
}

// simple case resampling with replacement method
CaseResamplingReplacement simpleBoot
        = new CaseResamplingReplacement(sample, uniformRNG);
Mean countInSimpleBootstrap = new Mean();

RandomNumberGenerator rlg = new Ziggurat2000Exp();
rlg.seed(1234567890L);

// Patton-Politis-White method using stationary blocks
PattonPolitisWhite2009 stationaryBlock
        = new PattonPolitisWhite2009(
                sample,
                PattonPolitisWhite2009ForObject.Type.STATIONARY,
                uniformRNG,
                rlg);
Mean countInStationaryBlockBootstrap = new Mean();

// Patton-Politis-White method using circular blocks
PattonPolitisWhite2009 circularBlock
        = new PattonPolitisWhite2009(
                sample,
                PattonPolitisWhite2009ForObject.Type.CIRCULAR,
                uniformRNG,
                rlg);
Mean countInCircularBlockBootstrap = new Mean();

// change this line to use a different pattern
final double[] pattern = new double[]{1, 0, 1, 0, 1};

final int B = 10000;
for (int i = 0; i < B; ++i) {
    // count the number of occurrences for the pattern in the series
    int numberOfMatches = match(simpleBoot.newResample(), pattern);
    countInSimpleBootstrap.addData(numberOfMatches);

    // count the number of occurrences for the pattern in the series
    numberOfMatches = match(stationaryBlock.newResample(), pattern);
    countInStationaryBlockBootstrap.addData(numberOfMatches);

    // count the number of occurrences for the pattern in the series
    numberOfMatches = match(circularBlock.newResample(), pattern);
    countInCircularBlockBootstrap.addData(numberOfMatches);
}

// compare the numbers of occurrences of the pattern using different bootstrap methods
int countInSample = match(sample, pattern);
System.out.println("matched patterns in sample: " + countInSample);
.out.println("matched patterns in simple bootstrap: " + countInSimpleBootstrap.value());
System.out.println("matched patterns in stationary block bootstrap: " + countInStationaryBlockBootstrap.value());
System.out.println("matched patterns in circular block bootstrap: " + countInCircularBlockBootstrap.value());

```

输出如下所示:

```py
matched patterns in sample: 39
matched patterns in simple bootstrap: 316.8101000000013
matched patterns in stationary block bootstrap: 45.09940000000004
matched patterns in circular block bootstrap: 44.1490999999999

```

在原始训练序列中，模式{1，0，1，0，1}出现了 39 次。使用替换方法的简单情况重采样的自举序列差得很远(316)。使用 Politis-White-Patton 方法得到的自举序列接近原始训练序列，分别为 45 和 44。

类`PattonPolitisWhite2009`具有以下签名:

```py
/**
 * Constructs a block bootstrap sample generator. The block length is
 * automatically selected.
 *
 * @param sample  the original sample
 * @param type    the type of block bootstrap, either
 *                {@linkplain Type#STATIONARY} or
 *                {@linkplain Type#CIRCULAR}
 * @param uniform a concurrent random long generator
 * @param rng     a concurrent random exponential generator
 */
public PattonPolitisWhite2009(
        double[] sample,
        PattonPolitisWhite2009ForObject.Type type,
        RandomLongGenerator uniform,
        RandomNumberGenerator rng
)

```

## 13.3 差异减少

假设我们想要估计随机变量 *X* 的统计量 *Z* 。我们需要生成大量的 *X* <sub>1</sub> 、 *X* <sub>*n*</sub> 然后计算每个 *X* <sub>*i*</sub> 的统计量 *Z* <sub>*i*</sub> 以得到 *Z* <sub>1</sub> 、 *Z 然后估计器如下:*

*![$$ \hat{z}=\frac{1}{n}\sum \limits_{i=1}^n{Z}_i $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equq.png)*

这种方法被称为蒙特卡罗模拟。由于这种基于随机性的计算的本质，每个随机样本都与限制结果精度的方差相关联。中心极限定理说![$$ \hat{z} $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_IEq18.png)在 *n* → ∞时收敛到真均值 *z* 和标准差![$$ \frac{\sigma }{\sqrt{n}} $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_IEq19.png)的正态分布。这意味着标准误差(反向精度)以速率![$$ \sqrt{n} $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_IEq20.png)趋向于 0。为了使估计量的准确度加倍，我们需要 4 倍的随机样本数。例如，对于 13.2.4.1 区的`compute_Pi`代码，有 1，000，000 个样本，精度为 2 个小数点。要使精度翻倍，我们需要 400 万个样本。那会产生很多分数。

方差缩减是一种在相同计算量(如使用的随机样本数)的情况下提高估计量准确性的技术。NM Dev 有一套现成的方差减少技术，我们可以用它来提高估计器的准确性。

### 常见随机数

当我们想要比较两个或多个估计量时，公共随机数(CRNs)是一种流行且有用的方差缩减技术。更具体地说，我们要估计如下:

![$$ d=\mathrm{E}(f)-\mathrm{E}(g) $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equr.png)

如果我们分别对 *f* 和 *g* 使用两个独立的码流序列，即如下所示:

![$$ \mathrm{E}(f)=\frac{1}{n}\sum \limits_{i=1}^nf\left({X}_{1,i}\right) $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equs.png)

![$$ \mathrm{E}(g)=\frac{1}{n}\sum \limits_{i=1}^nf\left({X}_{2,i}\right) $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equt.png)

然后我们有了这个:

![$$ Var\left({M}_2-{M}_1\right)= Var\left(\frac{1}{n}\sum \limits_{i=1}^nf\left({X}_{1,i}\right)-\frac{1}{n}\sum \limits_{i=1}^ng\left({X}_{2,i}\right)\right) $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equu.png)

![$$ =\frac{1}{n} Var\left(f\left({X}_1\right)\right)+\frac{1}{n} Var\left(g\left({X}_2\right)\right) $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equv.png)

假设 *X* <sub>1、*I*T5、 *X* <sub>2、 *i*</sub> 正相关；然后我们有了这个:</sub>

![$$ {M}_3= Var\left(\frac{1}{n}\sum \limits_{i=1}^nf\left({X}_{1,i}\right)-\frac{1}{n}\sum \limits_{i=1}^ng\left({X}_{2,i}\right)\right) $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equw.png)

![$$ =\frac{1}{n} Var\left(f\left({X}_1\right)\right)+\frac{1}{n} Var\left(g\left({X}_2\right)\right)- Cov\left(f\left({X}_1\right),\mathrm{g}\left({X}_2\right)\right) $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equx.png)

如果我们进一步假设 *f* 和 *g* 都是单调非减的，那么正 Cov(*X*T6】1， *X* <sub>2</sub> )隐含正 Cov(*f(**X*<sub>1</sub>)，g( *X* <sub>2 【T21))。因此，我们减少了估计量的方差。</sub>

![$$ {M}_3&lt; Var\left({M}_2-{M}_1\right) $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equy.png)

以下代码对此进行了计算:

![$$ d={\int}_0^1\left(2-\frac{\sin x}{x}\right) dx-{\int}_0^1\left({e}^{x^2}-\frac{1}{2}\right) dx $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equz.png)

```py
final UnivariateRealFunction f
        = new AbstractUnivariateRealFunction() {

    @Override
    public double evaluate(double x) {
        double fx = 2\. - Math.sin(x) / x;
        return fx;
    }
};

final UnivariateRealFunction g
        = new AbstractUnivariateRealFunction() {

    @Override
    public double evaluate(double x) {
        double gx = Math.exp(x * x) - 0.5;
        return gx;
    }
};

RandomLongGenerator X1 = new UniformRNG();
X1.seed(1234567890L);

CommonRandomNumbers crn0
        = new CommonRandomNumbers(
                f,
                g,
                X1,
                new AbstractUnivariateRealFunction() { // another independent uniform RNG
            final RandomLongGenerator X2 = new UniformRNG();

            {
                X2.seed(246890123L);
            }

            @Override
            public double evaluate(double x) {
                return X2.nextDouble();
            }
        });
Estimator estimator0 = crn0.estimate(100_000);
System.out.println(
        String.format("d = %f, variance = %f",
                estimator0.mean(),
                estimator0.variance()));

CommonRandomNumbers crn1

        = new CommonRandomNumbers(f, g, X1); // use X1 for both f and g
Estimator estimator1 = crn1.estimate(100_000);
System.out.println(
        String.format("d = %f, variance = %f",
                estimator1.mean(),
                estimator1.variance()));

```

输出如下所示:

```py
d = 0.091698, variance = 0.227836
d = 0.090606, variance = 0.182244

```

在两种 CRN 估计量中， *d* ≈ 0.091。与使用两个独立随机数流*X*T8】1 和*X*2 的第一 CRN 估计器相比，使用相关(实际上相同)随机数序列 *X* <sub>1</sub> 的第二 CRN 估计器具有更好的准确性(更小的方差)。请注意，CRN 在某些情况下可能不适用，或者如果 Cov(*f(**X*<sub>1</sub>)，g(*X*<sub>2</sub>)<0。

类`CommonRandomNumbers`的构造函数的签名如下:

```py
/**
 * Estimates \(E(f(X_1) - g(X_2))\), where <i>f</i> and <i>g</i> are
 * functions of uniform random variables. We set <i>X<sub>2</sub> =
 * X<sub>1</sub></i>.
 *
 * @param f  the first system
 * @param g  the second system
 * @param X1 a uniform random number generator
 */
public CommonRandomNumbers(
        UnivariateRealFunction f,
        UnivariateRealFunction g,
        RandomLongGenerator X1

)

```

### 对偶变量

对偶变量法是一种通过在观测值对之间引入负相关来减少方差的技术。一般来说，我们有这样的:

![$$ Var\left(X+Y\right)= Var(X)+ Var(Y)+2 Cov\left(X,Y\right) $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equaa.png)

![$$ = Var(X)+ Var(Y)+2{\rho}_{XY}{\sigma}_X{\sigma}_Y $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equab.png)

如果 *X* 和 *Y* 之间的相关性*ρ*<sub>T3】XYT5】为负，则( *X* + *Y* )的方差小于它们的方差之和，从而实现方差减小。一种方法是，对于获得的每条样本路径，{ *ε* <sub>1</sub> ，*ε*<sub>*n*</sub>}，我们使对偶路径为{-t24】ε<sub>1</sub>，-t28】ε<sub>*n*</sub>}。这有效地使样本数量加倍，并减少了样本路径的方差，从而提高了精度。</sub>

以下代码计算积分![$$ I={\int}_0^1\frac{1}{1+x} dx=\ln 2 $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_IEq21.png):

```py
UnivariateRealFunction f
        = new AbstractUnivariateRealFunction() {

    @Override
    public double evaluate(double x) {
        double fx = 1\. / (1\. + x);
        return fx;
    }
};

RandomLongGenerator uniform = new UniformRNG();
uniform.seed(1234567894L);

AntitheticVariates av
        = new AntitheticVariates(
                f,
                uniform,
                AntitheticVariates.REFLECTION);
Estimator estimator = av.estimate(1500);
System.out.println(
        String.format(
                "mean = %f, variance = %f",
                estimator.mean(),
                estimator.variance()));

```

输出如下所示:

```py
mean = 0.693158, variance = 0.000595

```

方差为 0.0006。否则，如果使用简单的方法，它将是 0.00255。

类`AntitheticVariates`的构造函数的签名如下:

```py
    /**
     * Estimates \(E(f(X_1))\), where <i>f</i> is a function of a random
     * variable.
     *
     * @param f  the random function to evaluate the expectation of
     * @param X1 a random number generator
     * @param X2 the antithetic function, given {@code X}
     */
    public AntitheticVariates(
            UnivariateRealFunction f,
            RandomNumberGenerator X1,
            UnivariateRealFunction X2
    )

```

### 控制变量

控制变量法是一种方差减少技术，它利用关于已知量的估计误差的信息来减少未知量的估计误差。更具体的说，假设我们要估计 *μ* ，统计量是 *m* ，那么 E( *m* ) = *μ* 。假设我们有另一个统计量 *t* 我们知道 E( *t* ) = *τ* 。我们可以使用 *t* 来帮助估计 *μ* 。说我们有这个:

![$$ {m}^{\ast }=m+c\left(t-\tau \right) $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equac.png)

那么*m*<sup>∫</sup>对于任意 *c* 也是 *μ* 的估计量因为 E(*m*<sup>∫</sup>)= E(*m*)=*μ*。*m*T18】∫的方差如下:

![$$ Var\left({m}^{\ast}\right)= Var(m)+{c}^2 Var(t)+2 cCov\left(m,t\right) $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equad.png)

*m*<sup>∫</sup>的方差最小化，如下图:

![$$ {c}^{\ast }=-\frac{Cov\left(m,t\right)}{Var(t)} $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equae.png)

![$$ Var\left({m}^{\ast}\right)= Var(m)-\frac{Cov{\left(m,t\right)}^2}{Var(t)} $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equaf.png)

![$$ =\left(1-{\rho}_{m,t}^2\right) Var(m) $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equag.png)

![$$ {\rho}_{m,t}^2=\mathrm{Corr}\left(m,t\right) $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_IEq22.png)，也就是 *m* 和 *t* 的相关性。![$$ {\rho}_{m,t}^2 $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_IEq23.png)的值越大，方差减少越多。

下面的代码示例再次计算上一示例中的相同积分:

![$$ f(x)=\frac{1}{1+x} $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equah.png)

它使用这个已知的积分如下所示:

![$$ \mathrm{E}\left(g(U)\right)={\int}_0^1\left(1+x\right) dx=\frac{3}{2} $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equai.png)

我们有以下:

![$$ I\approx \frac{1}{n}\sum \limits_if\left({u}_i\right)+c\left(\frac{1}{n}\sum \limits_ig\left({u}_i\right)-\frac{3}{2}\right) $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equaj.png)

*<sub>*I*</sub>是来自均匀分布的样本。*

```py
UnivariateRealFunction f
        = new AbstractUnivariateRealFunction() {

    @Override
    public double evaluate(double x) {
        double fx = 1\. / (1\. + x);
        return fx;
    }
};

UnivariateRealFunction g
        = new AbstractUnivariateRealFunction() {

    @Override
    public double evaluate(double x) {
        double gx = 1\. + x;
        return gx;
    }
};

RandomLongGenerator uniform = new UniformRNG();
uniform.seed(1234567891L);

ControlVariates cv

        = new ControlVariates(f, g, 1.5, -0.4773, uniform);
ControlVariates.Estimator estimator = cv.estimate(1500);
System.out.println(
        String.format(
                "mean = %f, variance = %f, b = %f",
                estimator.mean(),
                estimator.variance(),
                estimator.b()));

```

输出如下所示:

```py
mean = 0.692015, variance = 0.000601, b = -0.472669

```

方差为 0.0006。否则，如果使用简单的方法，它将是 0.00255。对于这个问题，使用控制变量的结果类似于使用对偶变量的结果。

类`ControlVariates`的构造函数的签名如下:

```py
/**
 * Estimates \(E(f(X_1))\), where <i>f</i> is a function of a random
 * variable.
 *
 * @param f  the random function to evaluate the expectation of
 * @param g  the random function with known value
 * @param Eg the expectation of g
 * @param c  a coefficient
 * @param X  a random number generator
 */
public ControlVariates(
        UnivariateRealFunction f,
        UnivariateRealFunction g,
        double Eg,
        double c,
        RandomNumberGenerator X
)

```

### 重要性抽样

在使用蒙特卡罗模拟来估计概率分布的属性时，重要性抽样是一种重要的策略，同时只使用从与感兴趣的分布不同的分布生成的样本。重要性抽样背后的思想是，模拟中输入随机变量的某些值对计算的积分(或平均值)的影响比其他值更大。如果通过更频繁地采样来强调这些“重要”值，那么估计量的方差就可以减小。因此，重要性抽样的基本方法是选择一个“鼓励”重要值的分布。如果直接应用于模拟，这种“有偏”分布的使用将导致有偏估计量。然而，模拟输出被加权以校正有偏分布的使用。这确保了新的重要抽样估计量是无偏的。

假设我们要计算目标分布 *P* 下函数 *f (* *x* )的期望。如果我们从 *P* 中取样，使用蒙特卡罗方法会导致以下计算:

![$$ {E}_{x\sim P}\left[f(x)\right]={\int}_x^NP(x)f(x) dx\approx \frac{1}{N}\sum \limits_{x_i\sim P,i=1}^Nf\left({x}_i\right) $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equak.png)

然而，如果我们不能容易或有效地从 *P* 采样，那么这个求和就不能执行。我们可以尝试找到另一个分布*P*<sup>’</sup>，我们知道如何从中采样来进行积分。测度或概率分布的变化公式如下:

![$$ {E}_{x\sim P}\left[f(x)\right]={\int}_x^Nf(x)P(x) dx $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equal.png)

![$$ ={\int}_x^Nf(x)\frac{P(x)}{P^{\prime }(x)}{P}^{\prime }(x) dx $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equam.png)

![$$ ={E}_{x\sim {P}^{\prime }}\left[\frac{P}{P^{\prime }}f(x)\right] $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equan.png)

![$$ \approx \frac{1}{N}\sum \limits_{x_i\sim {P}^{\prime },i=1}^N\frac{P(x)}{P^{\prime }(x)}f\left({x}_i\right) $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equao.png)

数学上说，我们现在从*P*T8】′采样*x*<sub>T3】IT5】s，并且对于每个*f(**x*<sub>*I*</sub>)，我们需要通过![$ \frac{P(x)}{P^{\prime }(x)} $](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_IEq24.png)缩放输出以校正偏差。</sub>

这里有一个简单的例子。假设我们要计算正态分布(均值= 1，标准差= 1)下的恒等函数 *f* ( *x* ) = *x* ，*N*<sub>0</sub>=*N*(0，1)的积分。我们不是从标准正态分布中取样，而是从另一个均值= 1、标准差= 0.5、*N*<sub>1</sub>=*N*(0，0.5)的正态分布中取样。对于我们从 *N* <sub>1</sub> 中抽取的每个样本 *x* <sub>*i*</sub> ，我们计算校正后的输出并取平均值。

![$$ \frac{N_0(x)}{N_1(x)}{x}_i $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equap.png)

更具体地说，假设我们从 *N* <sub>1</sub> 中抽取两次，得到 1.09 和 2.36。计算如下:

![$$ \frac{1}{2}\left(\frac{0.3973}{0.7851}1.09+\frac{0.1582}{0.0197}2.36\right)=9.7517 $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equaq.png)

我们可以进一步开发这个例子来计算标准正态函数的积分， *ϕ* ( *x* )，在 0 和 1 之间。也就是

![$$ I={\int}_0^1\phi (x) dx $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equar.png)

一种方法是从标准正态分布*N*T8】0 中抽取*x*<sup>T3】sT5】的样本，如果*x*<sup>*s*</sup>∈[0，1】则只保留这些样本，否则拒绝这些样本。这个意思如下:</sup>

![$$ {I}_0=\frac{\sum \limits_{s=1}^S{x}^s\bullet \mathbf{1}\left({x}^s\in \left[0,1\right]\right)}{\mathbf{1}\left({x}^s\in \left[0,1\right]\right)} $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equas.png)

如果我们拒绝大量的样本，即**1**(*x*T4】t5】s∈【0，1】)≪*s*，那么这种计算是低效的。

或者，我们借鉴均匀分布，设*g*(*x*)= 1 if*x*<sup>*s*</sup>∈【0，1】。权重如下:

![$$ {w}^s=\frac{\phi \left({x}^s\right)}{\int_0^1\phi (z) dz} $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equat.png)

意思如下:

![$$ {I}_1=\frac{1}{S}\sum \limits_{s=1}^S{x}^s\bullet {w}^s $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equau.png)

没有拒绝任何样品。以下代码片段解决了这个示例:

```py
UnivariateRealFunction h = new AbstractUnivariateRealFunction() {

    @Override
    public double evaluate(double x) {
        return x; // the identity function
    }
};

UnivariateRealFunction w = new AbstractUnivariateRealFunction() {
    private final Gaussian phi = new Gaussian();
    private final StandardCumulativeNormal N = new CumulativeNormalMarsaglia();
    private final double I = N.evaluate(1) - N.evaluate(0);

    @Override
    public double evaluate(double x) {
        double w = phi.evaluate(x) / I; // the weight
        return w;
    }
};

RandomNumberGenerator rng = new UniformRNG();
rng.seed(1234567892L);

ImportanceSampling is = new ImportanceSampling(h, w, rng);
Estimator estimator = is.estimate(100000);
System.out.println(
        String.format(
                "mean = %f, variance = %f",
                estimator.mean(),
                estimator.variance()));

```

输出如下所示:

```py
mean = 0.459671, variance = 0.047314

```

类`ImportanceSampling`的构造函数的签名如下:

```py
/**
 * Uses importance sample to do Monte Carlo integration.
 *
 * @param h the function to integrate
 * @param w the weight function or the change of measure
 * @param G a uniform random number generator
 */
public ImportanceSampling(
        UnivariateRealFunction h,
        UnivariateRealFunction w,
        RandomNumberGenerator G
)

```

我们给出了一个来自(scratchapixel)的例子来说明重要性抽样的有效性。如果我们能使用“匹配”分布而不是均匀分布，这将是有效的。假设我们想用蒙特卡罗模拟来计算这个积分。参见图 [13-14](#Fig14) 。【T2![$$ I={\int}_0^{\frac{\pi }{2}}\sin (x) dx $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equav.png)

![$$ ={\left[-\cos (x)\right]}_0^{\frac{\pi }{2}} $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equaw.png)

![$$ =-\cos \left(\frac{\pi }{2}\right)--\cos (0) $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equax.png)

![$$ =1 $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equay.png)

![img/500382_1_En_13_Chapter/500382_1_En_13_Fig14_HTML.jpg](img/500382_1_En_13_Chapter/500382_1_En_13_Fig14_HTML.jpg)

图 13-14

使用两种不同 pdf 的重要性抽样

我们有两种发行版可供选择。

*   我们通常使用的均匀分布:![$$ {f}_0(x)=\frac{1}{\frac{\pi }{2}}=\frac{2}{\pi } $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_IEq25.png)

*   PDF 接近被积函数的分布:![$$ {f}_1(x)=\frac{8x}{\pi^2} $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_IEq26.png)

使用均匀分布，我们首先反演 CDF。

![$$ {\xi}_0={F}_0(x)={\int}_0^x{f}_0(z) dz=\frac{2}{\pi }x $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equaz.png)

![$$ x=\frac{\pi }{2}{\xi}_0 $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equba.png)

*ξ* <sub>0</sub> 在单位区间上均匀分布。蒙特卡洛求和如下:

![$$ {\int}_0^{\frac{\pi }{2}}f(x) dx\approx \frac{1}{N}\sum \limits_{i=1}^N\frac{f\left({x}_i\right)}{f_0\left({x}_i\right)}=\frac{\pi }{2N}\sum \limits_{i=1}^N\sin {x}_i $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equbb.png)

利用第二次分配，我们再次首先投资 CDF。

![$$ {\xi}_1={F}_1(x)={\int}_0^x{f}_0(z) dz=\frac{4}{\pi^2}{x}^2 $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equbc.png)

![$$ x=\frac{\pi }{2}\sqrt{\xi_1} $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Equbd.png)

*ξ* <sub>1</sub> 在单位区间上均匀分布。蒙特卡洛求和如下:

![$$ {\int}_0^{\frac{\pi }{2}}f(x) dx\approx \frac{1}{N}\sum \limits_{i=1}^N\frac{f\left({x}_i\right)}{f_1\left({x}_i\right)}=\frac{\pi^2}{8N}\sum \limits_{i=1}^N\frac{\sin {x}_i}{x_i} $$](img/500382_1_En_13_Chapter/500382_1_En_13_Chapter_TeX_Eqube.png)

下面的代码比较这两个和:

```py
RandomNumberGenerator rng = new UniformRNG();
rng.seed(1234567892L);

int N = 16;
for (int n = 0; n < 10; ++n) {
    float sumUniform = 0, sumImportance = 0;
    for (int i = 0; i < N; ++i) {
        double r = rng.nextDouble();
        sumUniform += sin(r * PI * 0.5);
        double xi = sqrt(r) * PI * 0.5;
        sumImportance += sin(xi) / ((8 * xi) / (PI * PI));
    }
    sumUniform *= (PI * 0.5) / N;
    sumImportance *= 1.f / N;
    System.out.println(String.format("%f %f\n", sumUniform, sumImportance));
}

```

输出如下所示:

![img/500382_1_En_13_Chapter/500382_1_En_13_Figa_HTML.jpg](img/500382_1_En_13_Chapter/500382_1_En_13_Figa_HTML.jpg)

我们可以看到，对于相同数量的随机样本和相同的随机值*ξ*<sub>0</sub>=*ξ*<sub>1</sub>，重要性抽样技术显著降低了方差，收敛更快。*