# 8.使用 Scikit-Learn、PySpark 和 H2O 进行聚类分析

本章通过实现一组不同的 Python 框架(即 Scikit-Learn、PySpark 和 H2O)来解释 *k-means* 聚类方法。首先，它阐明了该方法如何将值分配给聚类。

## 探索 K 均值方法

k-means 方法是最常用的距离计算方法。它是无监督机器学习家族的一部分。它使用欧几里德距离目标函数来有效地计算值之间的距离，然后确定中心并绘制与中心相邻的值来建立聚类。

与其他聚类方法(即空间聚类方法、birch 方法和凝聚方法)相比，此方法要求您在训练之前规定 k 的数量。本章使用揭示线性变化向量波动的*肘曲线* *、*来确定 *k* 的个数。本章执行该方法，根据具体特征(即年龄、报酬和消费习惯)对客户进行分组。

清单 [8-1](#PC1) 从微软 CSV 文件中获取必要的数据。

```py
import pandas as pd
df = pd.read_csv(r"filepath\Mall_Customers.csv")

Listing 8-1Attain the Data

```

清单 [8-2](#PC2) 删除了数据中不必要的特征。

```py
drop_column_names = df.columns[[0, 1]]
initial_data = df.drop(drop_column_names, axis="columns")

Listing 8-2Drop Unnecessary Features

```

清单 [8-3](#PC3) 用标准缩放器缩放数据。

```py
from sklearn.preprocessing import StandardScaler
sk_standard_scaler = StandardScaler()
sk_standard_scaled_data = sk_standard_scaler.fit_transform(initial_data)

Listing 8-3Scale the Data

```

清单 [8-4](#PC4) 使用 Scikit-Learn 框架执行主成分方法。

```py
from sklearn.decomposition import PCA
sk_principal_component_method = PCA(n_components=3)
sk_principal_component_method.fit(sk_standard_scaled_data)
sk_principal_component_method_transformed_data = sk_principal_component_method.transform(sk_standard_scaled_data)

Listing 8-4Execute the Principal Component Method with the Scikit-Learn Framework

```

清单 [8-5](#PC5) 公开了使用弯头曲线的 *k* 的数量(见图 [8-1](#Fig1) )。

![../images/517508_1_En_8_Chapter/517508_1_En_8_Fig1_HTML.jpg](../images/517508_1_En_8_Chapter/517508_1_En_8_Fig1_HTML.jpg)

图 8-1

使用肘形曲线揭示 k 的数量

```py
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
%matplotlib inline
elbow_range = range(1, 15)
sk_kmeans_method = [KMeans(n_clusters=x) for x in elbow_range]
sk_kmeans_method_score = [sk_kmeans_method[x].fit(sk_principal_component_method_transformed_data).score(sk_principal_component_method_transformed_data) for x in range(len(sk_kmeans_method))]
plt.plot(elbow_range, sk_kmeans_method_score)
plt.xlabel("Number of k")
plt.ylabel("Eigenvalues")
plt.show()

Listing 8-5Disclose the Number of K Using an Elbow Curve

```

图 [8-1](#Fig1) 显示曲线突然扭曲，这表明 k-means 方法必须包含三个分量。

## sci kit-在行动中学习

本节使用 Scikit-Learn 框架执行 k-means 方法；参见清单 [8-6](#PC6) 。

```py
sk_kmeans_method = KMeans(n_clusters=3)
sk_kmeans_method_fitted = sk_kmeans_method.fit(sk_standard_scaled_data)

Listing 8-6Execute the K-Means Method Using the Scikit-Learn Framework

```

清单 [8-7](#PC7) 计算 Scikit-Learn k-means 方法的标签。

```py
sk_kmeans_method_labels = pd.DataFrame(sk_kmeans_method_fitted.labels_, columns = ["Labels"])

Listing 8-7Compute the Scikit-Learn K-Means Method’s Labels

```

列表 [8-8](#PC8) 计算聚类中心并确定它们的平均值和标准偏差(见表 [8-1](#Tab1) )。

表 8-1

质心统计

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"></colgroup> 
|   | 

**中心平均值**

 | 

**中心标准偏差**

 |
| --- | --- | --- |
| 第一中心 | -0.157489 | 0.942836 |
| 第二中心 | 0.129950 | 0.854012 |
| 第三中心 | 0.222984 | 0.891719 |

```py
sk_kmeans_method = KMeans(n_clusters=3)
sk_kmeans_method_centers = sk_kmeans_method_fitted.cluster_centers_
sk_kmeans_method_centers = pd.DataFrame(sk_kmeans_method_centers, columns = ("1st center","2nd center","3rd center"))
sk_kmeans_method_centers_mean = pd.DataFrame(sk_kmeans_method_centers.mean())
sk_kmeans_method_centers_std = pd.DataFrame(sk_kmeans_method_centers.std())
sk_kmeans_method_centers_mean_std = pd.concat([sk_kmeans_method_centers_mean, sk_kmeans_method_centers_std], axis=1)
sk_kmeans_method_centers_mean_std.columns =["Center mean", "Center standard deviation"]
print(sk_kmeans_method_centers_mean_std)

Listing 8-8Compute Cluster Centers and Their Mean and Standard Deviation

```

清单 [8-9](#PC9) 确定 Scikit-Learn k-means 方法计算的缩放数据和标签(见图 [8-2](#Fig2) )。

![../images/517508_1_En_8_Chapter/517508_1_En_8_Fig2_HTML.jpg](../images/517508_1_En_8_Chapter/517508_1_En_8_Fig2_HTML.jpg)

图 8-2

Scikit-Learn k-means 方法标签

```py
plt.scatter(sk_principal_component_method_transformed_data[:,0], sk_principal_component_method_transformed_data[:, 1],
            c=sk_kmeans_method_fitted.labels_,cmap="coolwarm", s=120)
plt.xlabel("y")
plt.show()

Listing 8-9Determine the PySpark K-Means Method ‘s Labels

```

### PySpark 在行动

本节使用 PySpark 框架执行和评估 k-means 方法。

清单 [8-10](#PC10) 使用`findspark`框架准备 PySpark 框架。

```py
import findspark as initiate_pyspark
initiate_pyspark.init("filepath\spark-3.0.0-bin-hadoop2.7")

Listing 8-10Prepare the PySpark Framework

```

清单 [8-11](#PC11) 使用`SparkConf()`方法规定了 PySpark 应用程序。

```py
from pyspark import SparkConf
pyspark_configuration = SparkConf().setAppName("pyspark_kmeans_method").setMaster("local")

Listing 8-11Stipulate the PySpark App

```

清单 [8-12](#PC12) 使用`SparkSession()`方法准备 PySpark 会话。

```py
from pyspark.sql import SparkSession
pyspark_session = SparkSession(pyspark_context)
from pyspark.sql import SparkSession

Listing 8-12Prepare the Spark Session

```

清单 [8-13](#PC13) 使用`createDataFrame()`方法将本章前面创建的`pandas`数据帧更改为 PySpark 数据帧。

```py
pyspark_initial_data = pyspark_session.createDataFrame(initial_data)

Listing 8-13Change the Pandas Dataframe to a PySpark Dataframe

```

清单 [8-14](#PC14) 为独立特征创建一个列表，为从属特征创建一个字符串。然后，它使用 PySpark 框架建模的`VectorAssembler()`方法转换数据。

```py
x_list = list(initial_data.iloc[::, 0:3].columns)
from pyspark.ml.feature import VectorAssembler
pyspark_data_columns = x_list
pyspark_vector_assembler = VectorAssembler(inputCols=pyspark_data_columns, outputCol="features")
pyspark_data = pyspark_vector_assembler.transform(pyspark_initial_data)

Listing 8-14Transform the Data

```

清单 [8-15](#PC15) 使用 PySpark 框架执行 k-means 方法。

```py
from pyspark.ml.clustering import KMeans
pyspark_kmeans_method = KMeans().setK(3).setSeed(1)
pyspark_kmeans_method_fitted = pyspark_kmeans_method.fit(pyspark_data)

Listing 8-15Execute the K-Means Method Using the PySpark Framework

```

清单 [8-16](#PC16) 计算 k-means 方法的标签，并将它们传递给一个`pandas`数据帧。

```py
pyspark_yhat = pyspark_kmeans_method_fitted.transform(pyspark_data)
pyspark_yhat_pandas_df = pyspark_yhat.toPandas()

Listing 8-16Compute the PySpark K-Means Method ‘s Labels

```

清单 [8-17](#PC17) 显示了 PySpark k-means 方法计算的缩放数据和标签(见图 [8-3](#Fig3) )。

![../images/517508_1_En_8_Chapter/517508_1_En_8_Fig3_HTML.jpg](../images/517508_1_En_8_Chapter/517508_1_En_8_Fig3_HTML.jpg)

图 8-3

PySpark k 均值方法标签

```py
from mpl_toolkits.mplot3d import Axes3D
figure = plt.figure(figsize=(12, 12))
ax = Axes3D(figure)
ax.scatter(pyspark_yhat_pandas_df.iloc[::, 0],
           pyspark_yhat_pandas_df.iloc[::, 1],
           pyspark_yhat_pandas_df.iloc[::, 2],
           c = pyspark_yhat_pandas_df.iloc[::, 4],
           cmap = "coolwarm",
           s = 120)
ax.set_xlabel(initial_data.columns[0])
ax.set_ylabel(initial_data.columns[1])
ax.set_zlabel(initial_data.columns[2])
figure.show()

Listing 8-17Disclose the PySpark K-Means Method’s Labels

```

清单 [8-18](#PC18) 计算 PySpark k-means 方法的中心。

```py
pyspark_kmeans_method_centers = pyspark_kmeans_method_fitted.clusterCenters()
print("K-Means method cluster centers")
for pyspark_cluster_center in pyspark_kmeans_method_centers:
    print(pyspark_cluster_center)
K-Means method cluster centers
[26.5952381  33.14285714 65.66666667]
[45.30769231 60.52991453 34.47008547]
[32.97560976 88.73170732 79.24390244]

Listing 8-18Compute the PySpark K-Means Method’s Centers

```

清单 [8-19](#PC19) 使用剪影法评估 PySpark k-means 方法。

```py
from pyspark.ml.evaluation import ClusteringEvaluator
pyspark_kmeans_method_assessment = ClusteringEvaluator()
pyspark_kmeans_method_silhoutte = pyspark_kmeans_method_assessment.evaluate(pyspark_yhat)
print("Silhouette score = " + str(pyspark_kmeans_method_silhoutte))

Silhouette score = 0.45097978411312134

Listing 8-19Assess the PySpark K-Means Method Using the Silhouette Method

```

### H2O 在行动

这部分使用 H2O 框架执行和评估 k-means 方法。

清单 [8-20](#PC20) 准备 H2O 框架。

```py
import h2o as initialize_h2o
initialize_h2o.init()

Listing 8-20Prepare the H2O Framework

```

清单 [8-21](#PC21) 将`pandas`数据帧更改为 H2O 数据帧。

```py
h2o_data = initialize_h2o.H2OFrame(initial_data)

Listing 8-21Change the Pandas Dataframe to an H2O Dataframe

```

清单 [8-22](#PC22) 概述了独立和从属特征。

```py
y = y_list
x = h2o_data.col_names
x.remove(y_list)

Listing 8-22Outline the Features

```

清单 [8-23](#PC23) 为训练和验证 H2O k 均值方法保留数据。

```py
h2o_training_data, h2o_validation_data = h2o_data.split_frame(ratios=[.8])

Listing 8-23Randomly Divide the Dataframe

```

清单 [8-24](#PC24) 执行 H2O k 均值方法。

```py
from h2o.estimators import H2OKMeansEstimator
h2o_kmeans_method = H2OKMeansEstimator(k=3)
h2o_kmeans_method.train(x = x_list, training_frame = h2o_training_data, validation_frame = h2o_validation_data)

Listing 8-24Execute the K-Means Method Using the H2O Framework

```

清单 [8-25](#PC25) 计算 H2O k 均值方法的标签。

```py
h2o_yhat = h2o_kmeans_method.predict(h2o_validation_data)

Listing 8-25Compute the H2O K-Means Method Labels

```

清单 [8-26](#PC26) 评估 H2O k 均值方法(见表 [8-2](#Tab2) )。

表 8-2

PySpark 质心统计

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"> <col class="tcol4 align-left"> <col class="tcol5 align-left"></colgroup> 
|   |   | 

图心

 | 

大小

 | 

在 _cluster_sum_of_squares 内

 |
| --- | --- | --- | --- | --- |
| Zero |   | One | Seventy-eight | 134.983658 |
| one |   | Two | Fifty-one | 69.748489 |
| Two |   | Three | Thirty-two | 33.898533 |

```py
from h2o.estimators import H2OKMeansEstimator
h2o_kmeans_method_assessment = h2o_kmeans_method.model_performance()
h2o_kmeans_method_assessment

ModelMetricsClustering: kmeans
** Reported on train data. **
MSE: NaN
RMSE: NaN
Total Within Cluster Sum of Square Error: 238.6306804611187
Total Sum of Square Error to Grand Mean: 479.99999503427534
Between Cluster Sum of Square Error: 241.36931457315666

Listing 8-26Assess the K-Means Method Executed with the H2O Framework

```

## 结论

本章执行了三个关键的机器学习框架(Scikit-Learn、PySpark 和 H2O ),以便将数据分组为三个集群。您看到了如何使用肘曲线来识别 k 的数量。为了评估这种方法，您采用了剪影法并查看了误差平方和。