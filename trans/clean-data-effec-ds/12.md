

# 关闭

# 你知道什么

这本书希望已经向你展示了你在为分析和建模准备数据时需要的一系列技术。我们处理了您在日常工作中会遇到的大多数最常见的数据格式。希望即使你使用的文件或数据格式是本书没有明确提到的，或者没有机会提及的，但其中的一般概念和原则仍然适用。只有一些库和接口细节会有所不同。特定的格式在导致数据错误的方式上可能有特定的缺陷，但是，很明显，数据可能以多种方式变坏，与表示和存储技术无关。

[*第 1 章*](Chapter_1.xhtml#_idTextAnchor003) 、 [*第 2 章*](Chapter_2.xhtml#_idTextAnchor004) 和 [*第 3 章*](Chapter_3.xhtml#_idTextAnchor005) 分别看了表格、层次和“特殊”数据源。我们看到了将数据从每个来源转换成对数据科学最有用的*整齐的*格式的特定工具和特定技术。所示的大多数例子使用 Python 库，或者简单地使用它的标准库；在 R 中使用相应工具的人数较少；我们不时地研究其他可能用来完成类似任务的编程语言。相对来说，我发现展示我自己经常使用的面向命令行的技术和工具是有意义的。这些通常是执行一些初始分析、总结或预处理的最简单的方法。它们几乎可以在任何类似 Unix 的系统上使用，比如 Linux、BSD、OS X 或 Linux 的 Windows 子系统。然而，我希望能够启发读者在处理数据时使用的想法和概念框架，而不仅仅是简单地介绍我在示例中选择的那些特定的库、API 和工具。

经过接收阶段，由于对数据格式中的一些问题非常敏感，我们进入了识别和修复数据问题的许多阶段——理想情况下，一旦它们进入实际生产阶段，就会流水线化。就识别而言，有两种常见类型的问题需要寻找，每一种都有许多细微差别。一方面，我们可能会寻找这样或那样的个别数据——例如，来自某一特定仪器的孤立读数——以某种方式(记录、转录、制表等)出错。

有时，正如第四章 所关注的那样，我们可以识别——至少有合理的可能性——这类问题的存在。另一方面，我们的数据可能有更多的系统性问题，这些数据描述了所有(或许多)观察值的集合，而不是单个数据点。大多数时候，这可以归结为这样或那样的*偏差*；然而，有时数据中也有真实的模式或趋势，反映了潜在的现象，但不是我们最感兴趣的“数据中的数据”。在第 5 章 的 [*中，我们研究了偏差和*标准化*和*去趋势化*的技术。*](Chapter_5.xhtml#_idTextAnchor007)

确定了偏差和可丢弃的趋势后，你管道的下一个阶段将是——广义地说——*编造数据*。我在整本书中都强调，版本化数据和编写可重复的脚本或自动化工作流对于良好的数据科学至关重要。当你估算值( [*第 6 章*](Chapter_6.xhtml#_idTextAnchor008) )或工程特征( [*第 7 章*](Chapter_7.xhtml#_idTextAnchor009) )时，你应该始终意识到这样一个事实，即数据不再是*原始的*而是经过处理的；您应该能够恢复管道中的每个重要阶段，并重复所有转换。你对发明什么样的价值观是合理的所做的假设总是会随着你了解的更多而被修正。但是绝对会有数据丢失的时候——要么是原始数据中不存在，要么是通过分析确定是非常不可靠的——对丢失的数据进行良好的猜测是一种好的做法。此外，有时在最终建模或分析之前，应该以确定的方式对字段进行规范化、组合和/或转换。

这本书的章节安排类似于你在数据科学实践中开发的管道的阶段顺序。显然，您需要确定哪些特定的格式、技术和工具与您的特定问题相关。尽管如此，按照粗略的顺序，这些阶段将类似于本书的顺序。我从许多不同的领域中提取了例子，并使用了不同“形状”的数据尽管如此，当然，你的领域和你的问题，在许多或大多数方面，与我所举的例子完全不同。我希望并相信你会从这些其他领域中找到概念上的联系和思考的食粮。你所面临的任务太广泛和多样了，以至于不能简化为一个小的食谱，但是它们仍然适合于相当小数量的概念领域和总体目的。

# 你(还)不知道的

你在这本书里读到的几乎都没有提到你应该使用哪些统计测试或者哪些机器学习模型。到底是支持向量机，还是梯度提升树，或者深度神经网络(DNN)更适用于你的问题，我始终不知道。

对于 Kolmogorov–Smirnov、Anderson–Darling 或 Shapiro–维尔克测试是否能更好地测试数据集的正态性，我不知道也没有意见(尽管从我的样本中，人们可能会得出结论，你的测试应该有两个数学家的名字)。你应该阅读其他书籍来帮助你做出判断。

与这种有意的限制并行的是，这些选择大多与数据清理无关。无论您使用什么模型，或者应用什么统计数据，您都希望进入模型的数据尽可能的干净。本书推荐并描述的整个管道的各个阶段，对于每一个分析或建模任务都是必要的，而且几乎完全相同，不管管道下一阶段的最终选择是什么。然而，这一段带有一个试探性的警告。

一个幽灵正在困扰着数据科学时代精神——自动化的幽灵。也许很大一部分数据清理工作由非常聪明的机器来完成会比由人类数据科学家来完成更好，特别是开始主宰每个领域的深度神经网络。事实上，我对这本书的最初计划是包括一章讨论使用机器学习进行数据清理。与我讨论的相对简单的技术相比，也许一个复杂的训练模型可以更好地判断“异常”与“可靠数据”。也许深层网络中的附加层可以隐式地将信号从噪声中分离出来，或者消除信号中不感兴趣的*部分。或许规范化和工程化要素只不过是 DNN 输入图层附近的几个全连接、卷积或递归图层自动执行的功能的更粗糙版本。*

这些数据清理自动化的想法代表了有趣的可能性。就目前而言，这种自动化的轮廓是不确定和不断变化的。许多商业云服务——截至 2021 年年中——提供前端和“系统”，其肤浅的描述使它们听起来类似于自动化的幽灵，至少在电梯推销的水平上是如此。然而，在我看来，截至今天，这些服务在现实中做得远不如其营销人员暗示的那样:它们只是足够多的集群化机器的聚合，以尝试相同的模型、超参数、数据清理管道等。你可以自己按顺序表演。你可以——也很可能应该——为大数据和复杂的建模管道租用大规模并行，但这在某种程度上仍然缺乏真正指导分析决策的机器。

我今天写的任何关于数据清理自动化的东西在一年内都会过时。尽管如此，当你寻找未来的写作、培训材料、讲座等等时，还是要寻找我的名字，以及其他思考这些问题的数据科学家的名字。我希望在其他地方有更多关于这些想法的内容。当你读到这里的时候，看看这些云提供商真正提供的细节；随着时间的推移，我的警告可能会变得不那么相关。然而，我希望我在本文中的建议仍然是恰当的。